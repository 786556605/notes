### **Chapter 11. Threads**

### Introduction

Processes are discussed in earlier chapters. A limited amount of sharing can occur between related processes.

This chapter looks inside a process further to see how to use multiple threads of control (or simply threads) to perform multiple tasks within the environment of a single process. All threads within a single process have access to the same process components, such as file descriptors and memory.

This chapter is concluded with synchronization mechanisms available to prevent multiple threads from viewing inconsistencies in their shared resources.

### Thread Concepts

With multiple threads of control, the programs can more than one thing at a time within a single process, with each thread handling a separate task. This approach can have several benefits:

* We can simplify code that deals with asynchronous events by assigning a separate thread to handle each event type, while each thread can then handle its event using a synchronous programming model. A synchronous programming model is much simpler than an asynchronous one.
* Multiple processes have to use complex mechanisms provided by the operating system to share memory and file descriptors. Threads, in contrast, automatically have access to the same memory address space and file descriptors
* The processing of independent tasks can be interleaved by assigning a separate thread per task (only if they don’t depend on the processing performed by each other), so that overall program throughput can be improved. (A single-threaded process has to implicitly serializes those tasks.)
* Interactive programs can be improved in response time by using multiple threads to separate the portions of the program that deal with user input and output from the other parts of the program.

The benefits of a multithreaded programming model can be realized on multiprocessor or multicore systems, and even on uniprocessor systems. A program can be simplified using threads regardless of the number of processors, since that doesn’t affect the program structure. As long as your program has to block when serializing tasks, there are improvements in response time and throughput when running on a uniprocessor, because some threads might be able to run while others are blocked.

A thread consists of the information necessary to represent an execution context within a process:

* **Thread ID**: identifies the thread within a process
* Set of register values
* Stack
* Scheduling priority and policy,
* Signal mask
* An errno variable ([Section 1.7](ch1.md#error-handling))
* Thread-specific data ([Section 12.6](ch12.md#thread-specific-data)).

Everything within a process is sharable among the threads in a process:

* Text of the executable program
* The program’s global and heap memory
* Stacks
* File descriptors.

The threads interfaces of this chapter are from POSIX.1-2001, known as **pthreads** for "POSIX threads". The feature test macro for POSIX threads is `_POSIX_THREADS`. Applications can either use this in an `#ifdef` test to determine at compile time whether threads are supported or call `sysconf` with the `_SC_THREADS` constant to determine this at runtime. [p384]

### Thread Identification

Unlike the process ID, which is unique in the system, the thread ID has significance only within the context of the process to which it belongs.

A thread ID is represented by the `pthread_t` data type. Implementations are allowed to use a structure to represent the `pthread_t` data type, so portable implementations can’t treat them as integers (process ID's `pid_t` data type is a non-negative integer). The `pthread_equal` function (below) must be used to compare two thread IDs. A consequence of allowing the `pthread_t` data type to be a structure is that there is no portable way to print its value. Linux 3.2.0 uses an unsigned long integer for the `pthread_t` data type. FreeBSD 8.0 and Mac OS X 10.6.8 use a pointer to the `pthread` structure for the `pthread_t` data type.

```c
#include <pthread.h>

int pthread_equal(pthread_t tid1, pthread_t tid2);

/* Returns: nonzero if equal, 0 otherwise */
```

A thread can obtain its own thread ID by calling the pthread_self function.

```c
#include <pthread.h>

pthread_t pthread_self(void);

Returns: the thread ID of the calling thread
```

This function can be used with `pthread_equal` when a thread needs to identify data structures that are tagged with its thread ID. For example, a single master thread places new jobs on a work queue. A pool of three worker threads removes jobs from the queue. Instead of allowing each thread to process whichever job is at the head of the queue, the master thread controls job assignment by placing the ID of the thread that should process the job in each job structure. Each worker thread then removes only jobs that are tagged with its own thread ID. This situation is illustrated below:

[![Figure 11.1 Work queue example](figure_11.1.png)](figure_11.1.png "Figure 11.1 Work queue example")

### Thread Creation

The traditional UNIX process model (one thread of control per process) is conceptually the same as a threads-based model whereby each process is made up of only one thread. As the program runs, its behavior should be indistinguishable from the traditional process, until it creates more threads of control. [p385] Additional threads can be created by calling the `pthread_create` function:

```c
#include <pthread.h>

int pthread_create(pthread_t *restrict tidp,
                   const pthread_attr_t *restrict attr,
                   void *(*start_rtn)(void *), void *restrict arg);

/* Returns: 0 if OK, error number on failure */
```

* The memory location pointed to by *tidp* is set to the thread ID of the newly created thread when `pthread_create` returns successfully.
* The *attr* argument is used to customize various thread attributes (detailed in [Section 12.3](ch12.md#thread-attributes)). This chapter sets this to `NULL` to create a thread with the default attributes.
* The newly created thread starts running at the address of the *start_rtn* function.
* The *arg* is a pointer to the single argument passed to the *start_rtn*. If you need to pass more than one argument to the `start_rtn` function, then you need to store them in a structure and pass the address of the structure in *arg*.

When a thread is created, there is no guarantee whether the newly created thread or the calling thread. <u>The newly created thread has access to the process address space and inherits the calling thread’s floating-point environment ([`fenv.h`](http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/fenv.h.html)) and signal mask; however, the set of pending signals for the thread is cleared.</u>

The following example creates one thread and prints the process and thread IDs of the new thread and the initial thread:

<small>[threads/threadid.c](https://github.com/shichao-an/apue.3e/blob/master/threads/threadid.c)</small>

```c
#include "apue.h"
#include <pthread.h>

pthread_t ntid;

void
printids(const char *s)
{
	pid_t		pid;
	pthread_t	tid;

	pid = getpid();
	tid = pthread_self();
	printf("%s pid %lu tid %lu (0x%lx)\n", s, (unsigned long)pid,
	  (unsigned long)tid, (unsigned long)tid);
}

void *
thr_fn(void *arg)
{
	printids("new thread: ");
	return((void *)0);
}

int
main(void)
{
	int		err;

	err = pthread_create(&ntid, NULL, thr_fn, NULL);
	if (err != 0)
		err_exit(err, "can't create thread");
	printids("main thread:");
	sleep(1);
	exit(0);
}
```

This example handles the races between the main thread and the new thread as follows:

* First is the need to sleep in the main thread. Without sleep, the main thread might exit, thereby terminating the entire process before the new thread
gets a chance to run. This behavior is dependent on the operating system’s threads implementation and scheduling algorithms
* Second, the new thread obtains its thread ID by calling `pthread_self` instead of reading it out of shared memory or receiving it as an argument to its thread-start routine. If the new thread runs before the main thread returns from calling `pthread_create`, then the new thread will see the uninitialized contents of *ntid* instead of the thread ID. [p387-388]

### Thread Termination

If any thread within a process calls `exit`, `_Exit`, or `_exit`, then the entire process terminates. Similarly, when the default action is to terminate the process, a signal sent to a thread will terminate the entire process.

A single thread can exit in three ways, without terminating the entire process:

1. The thread can simply return from the start routine. The return value is the thread’s exit code.
2. The thread can be canceled by another thread in the same process.
3. The thread can call `pthread_exit`.

####  The `pthread_exit` and `pthread_join` functions

```c
#include <pthread.h>

void pthread_exit(void *rval_ptr);
```

The *rval_ptr* argument is a typeless pointer is available to other threads in the process by calling the `pthread_join` function.

```c
#include <pthread.h>

int pthread_join(pthread_t thread, void **rval_ptr);

/* Returns: 0 if OK, error number on failure */
```

The thread that calls `pthread_join` will block until the specified thread calls `pthread_exit`, returns from its start routine, or is canceled. If the thread simply returned from its start routine, *rval_ptr* will contain the return code. If the thread was canceled, the memory location specified by *rval_ptr* is set to `PTHREAD_CANCELED`.

<u>By calling `pthread_join`, we automatically place the thread with which we’re joining in the detached state so that its resources can be recovered.  If the thread was already in the detached state, `pthread_join` can fail, returning `EINVAL`.</u>

If we’re not interested in a thread’s return value, we can set *rval_ptr* to `NULL`.

The following example shows how to fetch the exit code from a thread that has terminated:

<small>[threads/exitstatus.c](https://github.com/shichao-an/apue.3e/blob/master/threads/exitstatus.c)</small>

[p389-390]

The typeless pointer passed to `pthread_create` and `pthread_exit` can be used to pass the address of a structure containing more complex information.

If the structure was allocated on the caller’s stack, the memory contents might have changed by the time the structure is used. If a thread allocates a structure on its stack and passes a pointer to this structure to `pthread_exit`, then the stack might be destroyed and its memory reused for something else by the time the caller of `pthread_join` tries to use it.

The following example shows the problem with using an automatic variable (allocated on the stack) as the argument to `pthread_exit`:

<small>[threads/badexit2.c](https://github.com/shichao-an/apue.3e/blob/master/threads/badexit2.c)</small>

```c
#include "apue.h"
#include <pthread.h>

struct foo {
	int a, b, c, d;
};

void
printfoo(const char *s, const struct foo *fp)
{
	printf("%s", s);
	printf("  structure at 0x%lx\n", (unsigned long)fp);
	printf("  foo.a = %d\n", fp->a);
	printf("  foo.b = %d\n", fp->b);
	printf("  foo.c = %d\n", fp->c);
	printf("  foo.d = %d\n", fp->d);
}

void *
thr_fn1(void *arg)
{
	struct foo	foo = {1, 2, 3, 4};

	printfoo("thread 1:\n", &foo);
	pthread_exit((void *)&foo);
}

void *
thr_fn2(void *arg)
{
	printf("thread 2: ID is %lu\n", (unsigned long)pthread_self());
	pthread_exit((void *)0);
}

int
main(void)
{
	int			err;
	pthread_t	tid1, tid2;
	struct foo	*fp;

	err = pthread_create(&tid1, NULL, thr_fn1, NULL);
	if (err != 0)
		err_exit(err, "can't create thread 1");
	err = pthread_join(tid1, (void *)&fp);
	if (err != 0)
		err_exit(err, "can't join with thread 1");
	sleep(1);
	printf("parent starting second thread\n");
	err = pthread_create(&tid2, NULL, thr_fn2, NULL);
	if (err != 0)
		err_exit(err, "can't create thread 2");
	sleep(1);
	printfoo("parent:\n", fp);
	exit(0);
}
```

When we run this program on Linux, we get:

```shell-session
$ ./a.out
thread 1:
structure at 0x7f2c83682ed0
foo.a = 1
foo.b = 2
foo.c = 3
foo.d = 4
parent starting second thread
thread 2: ID is 139829159933696
parent:
structure at 0x7f2c83682ed0
foo.a = -2090321472
foo.b = 32556
foo.c = 1
foo.d = 0
```

The contents of the structure (allocated on the stack of thread *tid1*) have changed by the time the main thread can access the structure. Note how the stack of the second thread (*tid2*) has overwritten the first thread’s stack. To solve this problem, we can either use a global structure or allocate the structure using `malloc`.

#### The `pthread_cancel` function

```c
#include <pthread.h>

int pthread_cancel(pthread_t tid);

/* Returns: 0 if OK, error number on failure */
```

* By default, `pthread_cancel` will cause the thread specified by *tid* to behave as if it had called `pthread_exit` with an argument of `PTHREAD_CANCELED`, though a thread can ignore or otherwise control how it is canceled.
* `pthread_cancel` doesn’t wait for the thread to terminate; it merely makes the request.

#### The `pthread_cleanup_push` and `pthread_cleanup_pop` functions

A thread can arrange for functions to be called when it exits, similar to the way that the `atexit` function ([Section 7.3](ch7.md#atexit-function)). The functions are known as **thread cleanup handlers**. More than one cleanup handler can be established for a thread. The handlers are recorded in a stack, which means that they are executed in the reverse order from that with which they were registered.

```c
#include <pthread.h>

void pthread_cleanup_push(void (*rtn)(void *), void *arg);
void pthread_cleanup_pop(int execute);
```

The `pthread_cleanup_push` function schedules the cleanup function, *rtn*, to be called with the single argument, *arg*, when the thread performs one of the following actions:

* Makes a call to `pthread_exit`
* Responds to a cancellation request
* Makes a call to `pthread_cleanup_pop` with a nonzero execute argument

If the *execute* argument is set to zero, the cleanup function is not called.

`pthread_cleanup_pop` removes the cleanup handler established by the last call to `pthread_cleanup_push`.

Because they can be implemented as macros, they must be used in matched pairs within the same scope in a thread. The macro definition of `pthread_cleanup_push` can include a `{` character, in which case the matching `}` character is in the `pthread_cleanup_pop` definition.

The following example shows how to use thread cleanup handlers. We need to match calls to `pthread_cleanup_pop` with the calls to `pthread_cleanup_push`; otherwise, the program might not compile. [p394]

<small>[threads/cleanup.c](https://github.com/shichao-an/apue.3e/blob/master/threads/cleanup.c)</small>

```c
#include "apue.h"
#include <pthread.h>

void
cleanup(void *arg)
{
	printf("cleanup: %s\n", (char *)arg);
}

void *
thr_fn1(void *arg)
{
	printf("thread 1 start\n");
	pthread_cleanup_push(cleanup, "thread 1 first handler");
	pthread_cleanup_push(cleanup, "thread 1 second handler");
	printf("thread 1 push complete\n");
	if (arg)
		return((void *)1);
	pthread_cleanup_pop(0);
	pthread_cleanup_pop(0);
	return((void *)1);
}

void *
thr_fn2(void *arg)
{
	printf("thread 2 start\n");
	pthread_cleanup_push(cleanup, "thread 2 first handler");
	pthread_cleanup_push(cleanup, "thread 2 second handler");
	printf("thread 2 push complete\n");
	if (arg)
		pthread_exit((void *)2);
	pthread_cleanup_pop(0);
	pthread_cleanup_pop(0);
	pthread_exit((void *)2);
}

int
main(void)
{
	int			err;
	pthread_t	tid1, tid2;
	void		*tret;

	err = pthread_create(&tid1, NULL, thr_fn1, (void *)1);
	if (err != 0)
		err_exit(err, "can't create thread 1");
	err = pthread_create(&tid2, NULL, thr_fn2, (void *)1);
	if (err != 0)
		err_exit(err, "can't create thread 2");
	err = pthread_join(tid1, &tret);
	if (err != 0)
		err_exit(err, "can't join with thread 1");
	printf("thread 1 exit code %ld\n", (long)tret);
	err = pthread_join(tid2, &tret);
	if (err != 0)
		err_exit(err, "can't join with thread 2");
	printf("thread 2 exit code %ld\n", (long)tret);
	exit(0);
}
```

Running the program  on Linux gives us:

```shell-session
$ ./a.out
thread 1 start
thread 1 push complete
thread 2 start
thread 2 push complete
cleanup: thread 2 second handler
cleanup: thread 2 first handler
thread 1 exit code 1
thread 2 exit code 2
```

Note that if the thread terminates by returning from its start routine, its cleanup handlers are not called. [p396]

The table below summarize similarities between the thread functions and the process functions.

Process primitive | Thread primitive | Description
----------------- | ---------------- | -----------
`fork` | `pthread_create` | create a new flow of control
`exit` | `pthread_exit` | exit from an existing flow of control
`waitpid` | `pthread_join` | get exit status from flow of control
`atexit` | `pthread_cleanup_push` | register function to be called at exit from flow of control
`getpid` | `pthread_self` | get ID for flow of control
`abort` | `pthread_cancel` | request abnormal termination of flow of control

#### The `pthread_detach` function

By default, a thread’s termination status is retained until we call `pthread_join` for that thread. A thread’s underlying storage can be reclaimed immediately on termination if the thread has been detached. After a thread is detached, we can’t use the `pthread_join` function to wait for its termination status, because calling `pthread_join` for a detached thread results in undefined behavior. We can detach a thread by calling `pthread_detach`.

```c
#include <pthread.h>

int pthread_detach(pthread_t tid);

/* Returns: 0 if OK, error number on failure */
```

We can create a thread that is already in the detached state by modifying the thread attributes we pass to `pthread_create`. This is detailed in the next chapter.

### Thread Synchronization

When multiple threads of control share the same memory, one thread can modify a variable that other threads can read or modify, thus we need to synchronize the threads to ensure that they don’t use an invalid value when accessing the variable’s memory contents.

When one thread modifies a variable, other threads can potentially see inconsistencies when reading the value of that variable. On processor architectures in which the modification takes more than one memory cycle, this can happen when the memory read is interleaved between the memory write cycles.

In the following figure, thread A reads the variable and then writes a new value to it, but the write operation takes two memory cycles.  If thread B reads the same variable between the two write cycles, it will see an inconsistent value:

[![Figure 11.7 Interleaved memory cycles with two threads](figure_11.7.png)](figure_11.7.png "Figure 11.7 Interleaved memory cycles with two threads")

To solve this problem, the threads have to use a lock that will allow only one thread to access the variable at a time, as show in the following figure:

[![Figure 11.8 Two threads synchronizing memory access](figure_11.8.png)](figure_11.8.png "Figure 11.8 Two threads synchronizing memory access")

* If thread B wants to read the variable, it acquires a lock.
* When thread A updates the variable, it acquires the same lock. Thus thread B will be unable to read the variable until thread A releases the lock.

We also need to synchronize two or more threads that might try to modify the same variable at the same time.

For example (as in the following figure), the increment operation is usually broken down into three steps.

1. Read the memory location into a register.
2. Increment the value in the register.
3. Write the new value back to the memory location.

[![Figure 11.9 Two unsynchronized threads incrementing the same variable](figure_11.9.png)](figure_11.9.png "Figure 11.9 Two unsynchronized threads incrementing the same variable")

If two threads try to increment the same variable at almost the same time without synchronizing with each other, the results can be inconsistent. [p398]

There is no race if one of the following (assumed) condition occurs:

* The modification is atomic.
* (In the previous example) The increment takes only one memory cycle.
* Data always appears to be [**sequentially consistent**](https://en.wikipedia.org/wiki/Sequential_consistency).

Our operations are sequentially consistent when multiple threads can’t observe inconsistencies in our data. In modern computer systems, memory accesses take multiple bus cycles, and multiprocessors generally interleave bus cycles among multiple processors, so we aren’t guaranteed that our data is sequentially consistent.

[p399]

Besides the computer architecture, races can arise from the ways in which our programs use variables, creating places where it is possible to view inconsistencies. For example, we might increment a variable and then make a decision based on its value. The combination of the increment step and the decision-making step isn’t atomic, which opens a window where inconsistencies can arise.

#### Mutexes

We can protect our data and ensure access by only one thread at a time by using the pthreads mutual-exclusion interfaces. A [**mutex**](https://en.wikipedia.org/wiki/Mutual_exclusion) is basically a lock that we set (lock) before accessing a shared resource and release (unlock) when we’re done.

* While it is set, any other thread that tries to set it will block until we release it.
* If more than one thread is blocked when we unlock the mutex, then all threads blocked on the lock will be made runnable, and the first one to run will be able to set the lock. The others will see that the mutex is still locked and go back to waiting for it to become available again.

In this way, only one thread will proceed at a time.

[p400]

A mutex variable is represented by the `pthread_mutex_t` data type. Before we can use a mutex variable, we must first initialize it by either setting it to the constant `PTHREAD_MUTEX_INITIALIZER` (for statically allocated mutexes only) or calling `pthread_mutex_init`. If we allocate the mutex dynamically (by calling `malloc`, for example), then we need to call `pthread_mutex_destroy` before freeing the memory.

```c
#include <pthread.h>

int pthread_mutex_init(pthread_mutex_t *restrict mutex,
                       const pthread_mutexattr_t *restrict attr);

int pthread_mutex_destroy(pthread_mutex_t *mutex);

/* Both return: 0 if OK, error number on failure */
```

To initialize a mutex with the default attributes, we set *attr* to `NULL` (mutex attributes is discussed [Section 12.4](synchronization-attributes)).

To lock a mutex, we call `pthread_mutex_lock`. If the mutex is already locked, the calling thread will block until the mutex is unlocked. To unlock a mutex, we call `pthread_mutex_unlock`.

```c
#include <pthread.h>

int pthread_mutex_lock(pthread_mutex_t *mutex);
int pthread_mutex_trylock(pthread_mutex_t *mutex);
int pthread_mutex_unlock(pthread_mutex_t *mutex);

/* All return: 0 if OK, error number on failure */
```

If a thread can’t afford to block, it can use `pthread_mutex_trylock` to lock the mutex conditionally. If the mutex is unlocked at the time `pthread_mutex_trylock` is called, then `pthread_mutex_trylock` will lock the mutex without blocking and return 0. Otherwise, `pthread_mutex_trylock` will fail, returning `EBUSY` without locking the mutex.

The following example illustrates a mutex used to protect a data structure. When more than one thread needs to access a dynamically allocated object, we can embed a reference count in the object to ensure that we don’t free its memory before all threads are done using it.

<small>[threads/mutex1.c](https://github.com/shichao-an/apue.3e/blob/master/threads/mutex1.c)</small>

```c
#include <stdlib.h>
#include <pthread.h>

struct foo {
	int             f_count;
	pthread_mutex_t f_lock;
	int             f_id;
	/* ... more stuff here ... */
};

struct foo *
foo_alloc(int id) /* allocate the object */
{
	struct foo *fp;

	if ((fp = malloc(sizeof(struct foo))) != NULL) {
		fp->f_count = 1;
		fp->f_id = id;
		if (pthread_mutex_init(&fp->f_lock, NULL) != 0) {
			free(fp);
			return(NULL);
		}
		/* ... continue initialization ... */
	}
	return(fp);
}

void
foo_hold(struct foo *fp) /* add a reference to the object */
{
	pthread_mutex_lock(&fp->f_lock);
	fp->f_count++;
	pthread_mutex_unlock(&fp->f_lock);
}

void
foo_rele(struct foo *fp) /* release a reference to the object */
{
	pthread_mutex_lock(&fp->f_lock);
	if (--fp->f_count == 0) { /* last reference */
		pthread_mutex_unlock(&fp->f_lock);
		pthread_mutex_destroy(&fp->f_lock);
		free(fp);
	} else {
		pthread_mutex_unlock(&fp->f_lock);
	}
}
```

* We lock the mutex before incrementing the reference count, decrementing the reference count, and checking whether the reference count reaches zero.
* <u>No locking is necessary when we initialize the reference count to 1 in the `foo_alloc` function, because the allocating thread is the only reference to it so far.</u> If we were to place the structure on a list at this point, it could be found by other threads, so we would need to lock it first.

Before using the object, threads are expected to add a reference to it by calling `foo_hold`. When they are done, they must call `foo_rele` to release the reference. When the last reference is released, the object’s memory is freed.

In this example, we have ignored how threads find an object before calling `foo_hold`. Even though the reference count is zero, it would be a mistake for `foo_rele` to free the object’s memory if another thread is blocked on the mutex in a call to `foo_hold`. We can avoid this problem by ensuring that the object can’t be found before freeing its memory. We’ll see how to do this in the examples that follow.

### Deadlock Avoidance

A thread will deadlock itself if it tries to lock the same mutex twice. There are less obvious ways to create deadlocks with mutexes. For example, when we use more than one mutex in our programs, a deadlock can occur if we allow one thread to hold a mutex and block while trying to lock a second mutex at the same time that another thread holding the second mutex tries to lock the first mutex. Neither thread can proceed, because each needs a resource that is held by the other.

Deadlocks can be avoided by carefully controlling the order in which mutexes are locked. For example, assume that you have two mutexes, A and B, that you need to lock at the same time. If all threads always lock mutex A before mutex B (vice versa), no deadlock can occur from the use of the two mutexes (but you can still deadlock on other resources). You’ll have the potential for a deadlock only when one thread attempts to lock the mutexes in the opposite order from another thread.

Another approach when many locks and data structures are involved (it is difficult to apply the previous approach) is that you might be able to release your locks and try again at a later time. You can use the `pthread_mutex_trylock` interface to avoid deadlocking in this case. If you are already holding locks and `pthread_mutex_trylock` is successful, then you can proceed. If it can’t acquire the lock, however, you can release the locks you already hold, clean up, and try again later.

#### Example of two mutexes

In the following example which shows the use of two mutexes, we avoid deadlocks by ensuring that when we need to acquire two mutexes at the same time, we always lock them in the same order. The second mutex protects a hash list that we use to keep track of the foo data structures. Thus the hashlock mutex protects both the fh hash table and the `f_next` hash link field in the foo structure. The `f_lock` mutex in the foo structure protects access to the remainder of the foo structure’s fields.

<small>[threads/mutex2.c](https://github.com/shichao-an/apue.3e/blob/master/threads/mutex2.c)</small>

```c
#include <stdlib.h>
#include <pthread.h>

#define NHASH 29
#define HASH(id) (((unsigned long)id)%NHASH)

struct foo *fh[NHASH];

pthread_mutex_t hashlock = PTHREAD_MUTEX_INITIALIZER;

struct foo {
	int             f_count;
	pthread_mutex_t f_lock;
	int             f_id;
	struct foo     *f_next; /* protected by hashlock */
	/* ... more stuff here ... */
};

struct foo *
foo_alloc(int id) /* allocate the object */
{
	struct foo	*fp;
	int			idx;

	if ((fp = malloc(sizeof(struct foo))) != NULL) {
		fp->f_count = 1;
		fp->f_id = id;
		if (pthread_mutex_init(&fp->f_lock, NULL) != 0) {
			free(fp);
			return(NULL);
		}
		idx = HASH(id);
		pthread_mutex_lock(&hashlock);
		fp->f_next = fh[idx];
		fh[idx] = fp;
		pthread_mutex_lock(&fp->f_lock);
		pthread_mutex_unlock(&hashlock);
		/* ... continue initialization ... */
		pthread_mutex_unlock(&fp->f_lock);
	}
	return(fp);
}

void
foo_hold(struct foo *fp) /* add a reference to the object */
{
	pthread_mutex_lock(&fp->f_lock);
	fp->f_count++;
	pthread_mutex_unlock(&fp->f_lock);
}

struct foo *
foo_find(int id) /* find an existing object */
{
	struct foo	*fp;

	pthread_mutex_lock(&hashlock);
	for (fp = fh[HASH(id)]; fp != NULL; fp = fp->f_next) {
		if (fp->f_id == id) {
			foo_hold(fp);
			break;
		}
	}
	pthread_mutex_unlock(&hashlock);
	return(fp);
}

void
foo_rele(struct foo *fp) /* release a reference to the object */
{
	struct foo	*tfp;
	int			idx;

	pthread_mutex_lock(&fp->f_lock);
	if (fp->f_count == 1) { /* last reference */
		pthread_mutex_unlock(&fp->f_lock);
		pthread_mutex_lock(&hashlock);
		pthread_mutex_lock(&fp->f_lock);
		/* need to recheck the condition */
		if (fp->f_count != 1) {
			fp->f_count--;
			pthread_mutex_unlock(&fp->f_lock);
			pthread_mutex_unlock(&hashlock);
			return;
		}
		/* remove from list */
		idx = HASH(fp->f_id);
		tfp = fh[idx];
		if (tfp == fp) {
			fh[idx] = fp->f_next;
		} else {
			while (tfp->f_next != fp)
				tfp = tfp->f_next;
			tfp->f_next = fp->f_next;
		}
		pthread_mutex_unlock(&hashlock);
		pthread_mutex_unlock(&fp->f_lock);
		pthread_mutex_destroy(&fp->f_lock);
		free(fp);
	} else {
		fp->f_count--;
		pthread_mutex_unlock(&fp->f_lock);
	}
}
```

Comparing [threads/mutex2.c](https://github.com/shichao-an/apue.3e/blob/master/threads/mutex2.c) with [threads/mutex1.c](https://github.com/shichao-an/apue.3e/blob/master/threads/mutex1.c), we can see;

* The allocation function `foo_alloc` now locks the hash list lock, adds the new structure to a hash bucket, and <u>before unlocking the hash list lock, locks the mutex in the new structure.</u> Since the new structure is placed on a global list, other threads can find it, so we need to block them if they try to access the new structure, until we are done initializing it.
* The `foo_find` function locks the hash list lock and searches for the requested structure. If it is found, we increase the reference count and return a pointer to the structure. This follows the lock ordering by locking the hash list lock in `foo_find` before `foo_hold` locks the foo structure’s f_lock mutex.
* With two locks, the `foo_rele` function is more complicated. If this is the last reference, we need to unlock the structure mutex so that we can acquire the hash list lock, since we’ll need to remove the structure from the hash list. Then we reacquire the structure mutex. Because we could have blocked since the last time we held the structure mutex, we need to recheck the condition to see whether we still need to free the structure. If another thread found the structure and added a reference to it while we blocked to honor the lock ordering, we simply need to decrement the reference count, unlock everything, and return.

#### Example of two mutexes (simplified)

We can simplify the previous example considerably by using the hash list lock to protect the structure reference count. The structure mutex can be used to protect everything else in the `foo` structure.

<small>[threads/mutex3.c](https://github.com/shichao-an/apue.3e/blob/master/threads/mutex3.c)</small>

```c
#include <stdlib.h>
#include <pthread.h>

#define NHASH 29
#define HASH(id) (((unsigned long)id)%NHASH)

struct foo *fh[NHASH];
pthread_mutex_t hashlock = PTHREAD_MUTEX_INITIALIZER;

struct foo {
	int             f_count; /* protected by hashlock */
	pthread_mutex_t f_lock;
	int             f_id;
	struct foo     *f_next; /* protected by hashlock */
	/* ... more stuff here ... */
};

struct foo *
foo_alloc(int id) /* allocate the object */
{
	struct foo	*fp;
	int			idx;

	if ((fp = malloc(sizeof(struct foo))) != NULL) {
		fp->f_count = 1;
		fp->f_id = id;
		if (pthread_mutex_init(&fp->f_lock, NULL) != 0) {
			free(fp);
			return(NULL);
		}
		idx = HASH(id);
		pthread_mutex_lock(&hashlock);
		fp->f_next = fh[idx];
		fh[idx] = fp;
		pthread_mutex_lock(&fp->f_lock);
		pthread_mutex_unlock(&hashlock);
		/* ... continue initialization ... */
		pthread_mutex_unlock(&fp->f_lock);
	}
	return(fp);
}

void
foo_hold(struct foo *fp) /* add a reference to the object */
{
	pthread_mutex_lock(&hashlock);
	fp->f_count++;
	pthread_mutex_unlock(&hashlock);
}

struct foo *
foo_find(int id) /* find an existing object */
{
	struct foo	*fp;

	pthread_mutex_lock(&hashlock);
	for (fp = fh[HASH(id)]; fp != NULL; fp = fp->f_next) {
		if (fp->f_id == id) {
			fp->f_count++;
			break;
		}
	}
	pthread_mutex_unlock(&hashlock);
	return(fp);
}

void
foo_rele(struct foo *fp) /* release a reference to the object */
{
	struct foo	*tfp;
	int			idx;

	pthread_mutex_lock(&hashlock);
	if (--fp->f_count == 0) { /* last reference, remove from list */
		idx = HASH(fp->f_id);
		tfp = fh[idx];
		if (tfp == fp) {
			fh[idx] = fp->f_next;
		} else {
			while (tfp->f_next != fp)
				tfp = tfp->f_next;
			tfp->f_next = fp->f_next;
		}
		pthread_mutex_unlock(&hashlock);
		pthread_mutex_destroy(&fp->f_lock);
		free(fp);
	} else {
		pthread_mutex_unlock(&hashlock);
	}
}
```

In this example, we solved the lock-ordering issues surrounding the hash list and the reference count when we use the same lock for both purposes. Multithreaded software design involves these types of trade-offs:

* If the locking granularity is too coarse, you end up with too many threads blocking behind the same locks, with little improvement possible from concurrency.
* If the locking granularity is too fine, then you suffer bad performance from excess locking overhead, and you end up with complex code.

As a programmer, you need to find the correct balance between code complexity and performance, while still satisfying your locking requirements.

#### `pthread_mutex_timedlock` Function

The `pthread_mutex_timedlock` function allows us to bound the time that a thread blocks when a mutex it is trying to acquire is already locked is equivalent to `pthread_mutex_lock`, but if the timeout value is reached, `pthread_mutex_timedlock` will return the error code `ETIMEDOUT` without locking the mutex:

```c
#include <pthread.h>
#include <time.h>

int pthread_mutex_timedlock(pthread_mutex_t *restrict mutex,
                            const struct timespec *restrict tsptr);

/* Returns: 0 if OK, error number on failure */
```

The timeout is represented by the `timespec` structure (seconds and nanoseconds) and is [absolute time](http://pubs.opengroup.org/onlinepubs/9699919799/functions/pthread_mutex_timedlock.html).

The following is the output:

```shell-session
$ ./a.out
mutex is locked
current time is 11:41:58 AM
the time is now 11:42:08 AM
can’t lock mutex again: Connection timed out
```

This strategy is not recommended in practice, because it can lead to deadlock.

Mac OS X 10.6.8 doesn’t support `pthread_mutex_timedlock` yet, but FreeBSD 8.0, Linux 3.2.0, and Solaris 10 do support it.

#### Reader–Writer Locks

The state of a mutex is either locked or unlocked, and only one thread can lock it at a time. A reader–writer lock (also called shared–exclusive lock) has three possible states:

* Locked in read mode (also called locked in shared mode)
* Locked in write mode (also called locked in exclusive mode)
* Unlocked

Only one thread at a time can hold a reader–writer lock in write mode, but multiple threads can hold a reader–writer lock in read mode at the same time.

```c
#include <pthread.h>

int pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,
                        const pthread_rwlockattr_t *restrict attr);

int pthread_rwlock_destroy(pthread_rwlock_t *rwlock);

/* Both return: 0 if OK, error number on failure */
```

A reader–writer lock is initialized by `pthread_rwlock_init`. A `NULL` value of *attr* indicates default attributes.

Before freeing the memory backing a reader–writer lock, we need to call `pthread_rwlock_destroy` to clean it up. If `pthread_rwlock_init` allocated any resources for the reader–writer lock, `pthread_rwlock_destroy` frees those resources. If we free the memory backing a reader–writer lock without first calling `pthread_rwlock_destroy`, any resources assigned to the lock will be lost (see [Doubts and Solutions](#doubts-and-solutions)).

A reader–writer lock can be read locked, write locked and unlocked with the following functions:

```c
#include <pthread.h>

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);
int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);
int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);

/* All return: 0 if OK, error number on failure */
```
* Implementations might limit the number of times a reader–writer lock can be locked in shared mode, so we need to check the return value of `pthread_rwlock_rdlock`.










### Doubts and Solutions

#### Verbatim

p409-410 on Reader–Writer Locks

> If we free the memory backing a reader–writer lock without first calling `pthread_rwlock_destroy`, any resources assigned to the lock will be lost.

"any resources assigned to the lock will be lost" probably means a form of [resource leak](https://en.wikipedia.org/wiki/Resource_leak).

