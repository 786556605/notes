### **Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation**

### IP Fragmentation

IP employs **fragmentation** and **reassembly**. Fragmentation in IPv4 can take place at the original sending host and at any intermediate routers along the end-to-end path. Note that datagram fragments can themselves be fragmented. Fragmentation in IPv6 is somewhat different because <u>only the source is permitted to perform fragmentation</u>.

When an IP datagram is fragmented, it is not reassembled until it reaches its final destination, because:

1. Not performing reassembly within the network alleviates the forwarding software (or hardware) in routers from implementing this feature
2. Different fragments of the same datagram may follow different paths to their common destination

#### Example: UDP/IPv4 Fragmentation

An UDP application may wish to avoid IP fragmentation, because when the size of the resulting datagram exceeds the linkâ€™s MTU, the IP datagram is split across multiple IP packets, which can lead to performance issues because <u>if any fragment is lost, the entire datagram is lost.</u>

[![A single UDP datagram with 2992 UDP payload bytes is fragmented into three UDP/ IPv4 packets (no options).](figure_10-9.png)](figure_10-9.png "A single UDP datagram with 2992 UDP payload bytes is fragmented into three UDP/ IPv4 packets (no options).")

A single UDP datagram with 2992 UDP payload bytes is fragmented into three UDP/ IPv4 packets (no options). The UDP header that contains the source and destination port numbers appears only in the first fragment (a complicating factor for firewalls and NATs). Fragmentation is controlled by the **Identification**, **Fragment Offset**, and **More Fragments** (MF) fields in the IPv4 header.

The original UDP datagram included 2992 bytes of application (UDP payload) data and 8 bytes of UDP header, resulting in an IPv4 Total Length field value of 3020 bytes (IP header is 20-byte). When this datagram was fragmented into three packets, 40 extra bytes were created (20 bytes for each of the newly created IPv4 fragment headers). Thus, the total number of bytes sent is 3060. [p489]

Fields:

* **Identification**: its value (set by the original sender) is copied to each fragment and is used to group them together when they arrive
* **Fragment Offset**: the offset of the first byte of the fragment payload byte in the original IPv4 datagram (in 8-byte units)
* **MF**: indicates whether more fragments in the datagram should be expected and is 0 only in the final fragment

If one fragment is lost, the entire datagram is lost, since IP itself has no error correction mechanism of its own. Mechanisms such as timeout and retransmission are left as the responsibility of the higher layers. <u>For this reason, fragmentation is often avoided.</u>

We can use our `sock` program and increase the size of the datagram until fragmentation occurs. On an Ethernet, the maximum amount of data in a frame is ordinarily 1500 bytes, which leaves at most 1472 bytes for application data to avoid fragmentation, assuming 20 bytes for the IPv4 header and 8 bytes for the UDP header.

We will run our sock program with data sizes of 1471, 1472, 1473, and 1474 bytes. We expect the last two to cause fragmentation:

[p490-492]

```bash
Linux% sock -u -i -n1 -w1471 10.0.0.3 discard
Linux% sock -u -i -n1 -w1472 10.0.0.3 discard 
Linux% sock -u -i -n1 -w1473 10.0.0.3 discard
Linux% sock -u -i -n1 -w1474 10.0.0.3 discard
```

```text
1 23:42:43.562452 10.0.0.5.46530 > 10.0.0.3.9:
		udp 1471 (DF) (ttl 64, id 61350, len 1499)
2 23:42:50.267424 10.0.0.5.46531 > 10.0.0.3.9:
		udp 1472 (DF) (ttl 64, id 62020, len 1500)
3 23:42:57.814555 10.0.0.5 > 10.0.0.3:
		udp (frag 37671:1@1480) (ttl 64, len 21)
4 23:42:57.814715 10.0.0.5.46532 > 10.0.0.3.9:
		udp 1473 (frag 37671:1480@0+) (ttl 64, len 1500)
5 23:43:04.368677 10.0.0.5 > 10.0.0.3:
		udp (frag 37672:2@1480) (ttl 64, len 22)
6 23:43:04.368838 10.0.0.5.46535 > 10.0.0.3.9:
		udp 1474 (frag 37672:1480@0+) (ttl 64, len 1500)
```

One observation that may be surprising is that the fragments with larger offsets are delivered *prior* to the first fragments. In effect, <u>the sender has intentionally reordered the fragments.</u> This behavior can be beneficial. If the last fragment is delivered first, the receiving host is able to ascertain the maximum amount of buffer space it will require in order to reassemble the entire datagram.



