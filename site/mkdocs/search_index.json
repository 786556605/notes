{
    "docs": [
        {
            "location": "/", 
            "text": "Shichao's Notes\n\n\nThis site documents reading and learning notes of the following books and materials.\n\n\n\n  \n\n    \n\n      (function() {\n        var cx = '000491777875727507539:_gc3mx7cstg';\n        var gcse = document.createElement('script');\n        gcse.type = 'text/javascript';\n        gcse.async = true;\n        gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +\n            '//cse.google.com/cse.js?cx=' + cx;\n        var s = document.getElementsByTagName('script')[0];\n        s.parentNode.insertBefore(gcse, s);\n      })();\n    \n\n    \n\n  \n\n\n\n\n\nReading Notes\n\n\nEach chapter is organized as a single page; the included sections are noted with major concepts, along with personal doubts (with possible solutions figured out afterwards) and summary.\n\n\nAdvanced Programming in the UNIX Environment, 3rd Edition\n\n\nby W. Richard Stevens and Stephen A. Rago\n\n\n\n\nUNIX System Overview\n\n\nUNIX Standardization and Implementations\n\n\nFile I/O\n\n\nFiles and Directories\n\n\nStandard I/O Library\n\n\nSystem Data Files and Information\n\n\nProcess Environment\n\n\nProcess Control\n\n\nProcess Relationships\n\n\nSignals\n\n\nThreads\n\n\nThread Control\n\n\nDaemon Processes\n\n\nAdvanced I/O\n\n\nInterprocess Communication\n\n\n\n\nLinux Kernel Development (3rd Edition)\n\n\nby Robert Love\n\n\n\n\nIntroduction to the Linux Kernel\n\n\nGetting Started with the Kernel\n\n\nProcess Management\n\n\nProcess Scheduling\n\n\nSystem Calls\n\n\nKernel Data Structures\n\n\n\n\nUnix Network Programming, Volume 1: The Sockets Networking API (3rd Edition)\n\n\nby W. Richard Stevens and Bill Fenner\n\n\n\n\nIntroduction\n\n\nThe Transport Layer: TCP, UDP, and SCTP\n\n\nSockets Introduction\n\n\nElementary TCP Sockets\n\n\nTCP Client/Server Example\n\n\nI/O Multiplexing: The select and poll Functions\n\n\n\n\nTCP/IP Illustrated, Volume 1: The Protocols (2nd Edition)\n\n\nby Kevin R. Fall and W. Richard Stevens\n\n\n\n\nIntroduction\n\n\nThe Internet Address Architecture\n\n\n\n\nUnderstanding the Linux Kernel, Third Edition\n\n\nby Daniel P. Bovet and Marco Cesati\n\n\n\n\nIntroduction\n\n\nMemory Addressing\n\n\n\n\nCCENT/CCNA ICND1 640-822 Official Cert Guide, Third Edition\n\n\n\n\nNetworking Fundamentals\n\n\n\n\nCCNA ICND2 Official Exam Certification Guide, Second Edition\n\n\n\n\nLAN Switching\n\n\n\n\nHacking: The Art of Exploitation, 2nd Edition\n\n\nby Jon Erickson\n\n\n\n\nIntroduction (skipped)\n\n\nProgramming\n\n\n\n\nLearning Notes\n\n\nEach topic is included in a single page and references one or more books and materials.\n\n\nProgramming Languages\n\n\n\n\nGolang\n\n\nBash\n\n\nC\n\n\nx86 Assembly\n\n\n\n\nSoftware and Technologies\n\n\n\n\nNginx\n\n\nIptables\n\n\nVim", 
            "title": "Home"
        }, 
        {
            "location": "/apue/ch1/", 
            "text": "Chapter 1. UNIX System Overview\n\n\nIntroduction\n\n\nThis chapter gives basic Unix system concepts that are familiar to system administrators, from a programmer's perspective.\n\n\nUNIX Architecture\n\n\nAn operating system can be defined as the software that controls the hardware resources of the computer and provides an environment under which programs can run. This software is generally called the \nkernel\n, since it is relatively small and resides at the core of the environment. The figure below shows a diagram of the UNIX System architecture.\n\n\n\n\n\n\nThe interface to the kernel is a layer of software called the \nsystem calls\n.\n\n\nLibraries of common functions are built on top of the system call interface, but applications are free to use both.\n\n\nThe shell is a special application that provides an interface for running other applications.\n\n\n\n\nLinux is the kernel used by the GNU operating system. Some people refer to this combination as the GNU/Linux operating system, but it is more commonly referred to as simply Linux. Although this usage may not be correct in a strict sense, it is understandable, given the dual meaning of the phrase \noperating system\n.\n\n\nLogging In\n\n\nShells\n\n\nA \nshell\n is a command-line interpreter that reads user input and executes commands. The user input to a shell is normally from the terminal (an interactive shell) or sometimes from a file (called a \nshell script\n).\n\n\nFiles and Directories\n\n\nFile system\n\n\nThe UNIX file system is a hierarchical arrangement of directories and files. Everything starts in the directory called root, whose name is the single character \n/\n.\n\n\nFilename\n\n\nThe names in a directory are called filenames. The only two characters that cannot appear in a filename are the slash character (/) and the null character. The slash separates the filenames that form a pathname (described next) and the null character terminates a pathname. For portability, POSIX.1 recommends restricting filenames to consist of the following characters: letters (\na-z\n, \nA-Z\n), numbers (\n0-9\n), period (\n.\n), dash (\n-\n), and underscore (\n_\n).\n\n\nPathname\n\n\nA sequence of one or more filenames, separated by slashes and optionally starting with a slash, forms a \npathname\n. A pathname that begins with a slash is called an \nabsolute pathname\n; otherwise, it\u2019s called a \nrelative pathname\n.\n\n\nWorking Directory\n\n\nEvery process has a working directory, sometimes called the \ncurrent working directory\n. This is the directory from which all relative pathnames are interpreted. A process can change its working directory with the \nchdir\n function.\n\n\nHome Directory\n\n\nThe working directory is set to our home directory, which is obtained from our entry in the password file.\n\n\nInput and Output\n\n\nFile Descriptors\n\n\nFile descriptors are normally small non-negative integers that the kernel uses to identify the files accessed by a process. Whenever it opens an existing file or creates a new file, the kernel returns a file descriptor that we use when we want to read or write the file\n\n\nStandard Input, Standard Output, and Standard Error\n\n\nBy convention, all shells open three descriptors whenever a new program is run: standard input, standard output, and standard error.\n\n\nPrograms and Processes\n\n\nProgram\n\n\nA \nprogram\n is an executable file residing on disk in a directory.\n\n\nProcesses and Process ID\n\n\nAn executing instance of a program is called a \nprocess\n.\n\n\nThe UNIX System guarantees that every process has a unique numeric identifier called the \nprocess ID\n. The process ID is always a non-negative integer.\n\n\nProcess Control\n\n\nThreads and Thread IDs\n\n\nThreads are identified by IDs. Thread IDs are local to a process. A thread ID from one process has no meaning in another process. We use thread IDs to refer to specific threads as we manipulate the threads within a process.\n\n\nError Handling\n\n\nWhen an error occurs in one of the UNIX System functions, a negative value is often returned, and the integer \nerrno\n is usually set to a value that tells why.  Some functions use a convention other than returning a negative value. For example:\n\n\n\n\nThe \nopen\n function returns either a non-negative file descriptor if all is OK or \u22121 if an error occurs.\n\n\nMost functions that return a pointer to an object return a null pointer to indicate an error.\n\n\n\n\nThe file \nerrno.h\n defines the symbol errno and constants for each value that errno can assume. Each of these constants begins with the character \nE\n. On Linux, the error constants are listed in the \nerrno(3)\n manual page\n\n\nPOSIX and ISO C define \nerrno\n as a symbol expanding into a modifiable lvalue of type integer. This can be either an integer that contains the error number or a function that returns a pointer to the error number. The historical definition is:\n\n\nextern\n \nint\n \nerrno\n;\n\n\n\n\n\n\nBut in an environment that supports threads, the process address space is shared among multiple threads, and each thread needs its own local copy of errno to prevent one thread from interfering with another. Linux supports multithreaded access to \nerrno\n by defining it as:\n\n\nextern\n \nint\n \n*\n_\n \n_errno_location\n(\nvoid\n);\n\n\n#define errno (*_ _errno_location())\n\n\n\n\n\n\nThere are two rules to be aware of with respect to \nerrno\n:\n\n\n\n\nThe value of \nerrno\n is never cleared by a routine if an error does not occur. Therefore, we should examine its value only when the return value from a function indicates that an error occurred.\n\n\nThe value of \nerrno\n is never set to 0 by any of the functions, and none of the constants defined in \nerrno.h\n has a value of 0.\n\n\n\n\nThe following functions are defined by the C standard to help with printing error messages.\n\n\nThe \nstrerror\n function maps errnum, which is typically the \nerrno\n value, into an error message string and returns a pointer to the string.\n\n\n#include \nstring.h\n\n\n\nchar\n \n*\nstrerror\n(\nint\n \nerrnum\n);\n\n\n\n/* Returns: pointer to message string */\n\n\n\n\n\n\nThe \nperror\n function produces an error message on the standard error, based on the current value of \nerrno\n, and returns. It outputs the string pointed to by msg, followed by a colon and a space, followed by the error message corresponding to the value of \nerrno\n, followed by a newline.\n\n\n#include \nstdio.h\n\n\n\nvoid\n \nperror\n(\nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nThe following code shows the use of these two error functions.\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n      \nfprintf\n(\nstderr\n,\n \nEACCES: %s\n\\n\n,\n \nstrerror\n(\nEACCES\n));\n\n      \nerrno\n \n=\n \nENOENT\n;\n\n      \nperror\n(\nargv\n[\n0\n]);\n\n      \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nIf this program is compiled into the file \na.out\n, we have:\n\n\n$ ./a.out\n\n\nEACCES: Permission denied\n\n\n./a.out: No such file or directory\n\n\n\n\n\n\nUser Identification\n\n\nSignals\n\n\nTime Values\n\n\nSystem Calls and Library Functions\n\n\n\n\nLinux 3.2.0 has 380 system calls and FreeBSD 8.0 has over 450\n\n\nEach system call has a function of the same name in the standard C library\n\n\nAn application can either make a system call or call a library routine", 
            "title": "Chapter 1. UNIX System Overview"
        }, 
        {
            "location": "/apue/ch2/", 
            "text": "Chapter 2. UNIX Standardization and Implementations\n\n\nThis chapter discusses Unix standards, specifications and implementations.\n\n\nUNIX Standardization\n\n\n\n\nISO C\n\n\nIEEE POSIX\n\n\nSingle UNIX Specification (SUS): superset of the POSIX.1 standard\n\n\n\n\nLimits\n\n\n\n\nCompile-time limits\n\n\nRuntime limits", 
            "title": "Chapter 2. UNIX Standardization and Implementations"
        }, 
        {
            "location": "/apue/ch3/", 
            "text": "Chapter 3. File I/O\n\n\nThis chapter discusses unbuffered I/O, which are not part of ISO C but are part of POSIX.1 and the Single UNIX Specification.\n\n\nFile Descriptors\n\n\n\n\nAll open files are referred to by file descriptors\n\n\nNon-negative integer\n\n\nRange from 0 to \nOPEN_MAX - 1\n. With FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10, the limit is essentially infinite, bounded by the amount of memory on the system, the size of an integer, and any hard and soft limits configured by the system administrator.\n\n\n\n\nopen\n and \nopenat\n Functions\n\n\napue_open.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \nopen\n(\nconst\n \nchar\n \n*\npath\n,\n \nint\n \noflag\n,\n \n...\n \n/* mode_t mode */\n \n);\n\n\nint\n \nopenat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npath\n,\n \nint\n \noflag\n,\n \n...\n \n/* mode_t mode */\n \n);\n\n\n\n/* Both return: file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\noflag\n argument is formed by ORing one or more of the following constants from \nfcntl.h\n [p62]:\n\n\nRequired:\n\n\n\n\nO_RDONLY\n\n\nO_WRONLY\n\n\nO_RDWR\n\n\nO_EXEC\n\n\nO_SEARCH\n: Open for search only (applies to directories).\n\n\n\n\nOptional:\n\n\n\n\nO_APPEND\n\n\nO_CLOEXEC\n: Set the \nFD_CLOEXEC\n file descriptor flag\n\n\nO_CREAT\n: Create the file if it doesn\u2019t exist\n\n\nO_DIRECTORY\n: Generate an error if \nO_CREAT\n is also specified and the file already exists. This test for whether the file already exists and the creation of the file if it doesn\u2019t exist is an atomic operation\n\n\nO_EXCL\n\n\nO_NOCTTY\n\n\nO_NOFOLLOW\n\n\nO_NONBLOCK\n\n\nO_SYNC\n: Have each \nwrite\n wait for physical I/O to complete\n\n\nO_TRUNC\n\n\nO_TTY_INIT\n\n\nO_DSYNC\n\n\nO_RSYNC\n\n\n\n\nTOCTTOU\n\n\nopenat\n, for example, provides a way to avoid \ntime-of-check-to-time-of-use\n (TOCTTOU) errors. A program is vulnerable if it makes two file-based function calls where the second call depends on the results of the first call (two calls are not atomic).\n\n\nFilename and Pathname Truncation\n\n\nMost modern file systems support a maximum of 255 characters for filenames.\n\n\ncreat\n Function\n\n\napue_creat.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \ncreat\n(\nconst\n \nchar\n \n*\npath\n,\n \nmode_t\n \nmode\n);\n\n\n\n/* Returns: file descriptor opened for write-only if OK, \u22121 on error */\n\n\n\n\n\n\nThis function is equivalent to:\n\n\nopen\n(\npath\n,\n \nO_WRONLY\n \n|\n \nO_CREAT\n \n|\n \nO_TRUNC\n,\n \nmode\n);\n\n\n\n\n\n\nWith \ncreat\n, the file is opened only for writing. To read and write a file, use [p66]:\n\n\nopen\n(\npath\n,\n \nO_RDWR\n \n|\n \nO_CREAT\n \n|\n \nO_TRUNC\n,\n \nmode\n);\n\n\n\n\n\n\nclose\n Function\n\n\napue_close.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nclose\n(\nint\n \nfd\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWhen a process terminates, all of its open files are closed automatically by the kernel. Many programs take advantage of this fact and don\u2019t explicitly close open files.\n\n\nlseek\n Function\n\n\nEvery open file has a \"current file offset\", normally a non-negative integer that measures the number of bytes from the beginning of the file.\n\n\napue_lseek.h\n\n\n#include \nunistd.h\n\n\n\noff_t\n \nlseek\n(\nint\n \nfd\n,\n \noff_t\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: new file offset if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nwhence\n argument can be:\n\n\n\n\nSEEK_SET\n: the file\u2019s offset is set to \noffset\n bytes from the beginning of the file\n\n\nSEEK_CUR\n: the file\u2019s offset is set to its current value plus the \noffset\n. The \noffset\n can be positive or negative.\n\n\nSEEK_END\n: the file\u2019s offset is set to the size of the file plus the \noffset\n. The \noffset\n can be positive or negative.\n\n\n\n\nTo determine the current offset, \nseek zero bytes from the current position\n:\n\n\noff_t\n \ncurrpos\n;\n\n\ncurrpos\n \n=\n \nlseek\n(\nfd\n,\n \n0\n,\n \nSEEK_CUR\n);\n\n\n\n\n\n\nThis technique (above code) can also be used to determine if a file is capable of seeking. If the file descriptor refers to a pipe, FIFO, or socket, \nlseek\n sets \nerrno\n to \nESPIPE\n and returns \u22121.\n\n\n\n\nNegative offsets are possible for certain devices, but for regular files, the offset must be non-negative.\n\n\nlseek\n only records the current file offset within the kernel and does not cause any I/O to take place. This offset is then used by the next read or write operation.\n\n\nHole in a file: file\u2019s offset can be greater than the file\u2019s current size, in which case the next \nwrite\n to the file will extend the file. This creates a hole in the file.\n\n\nBytes in the hole (bytes that have not been writen) are read back as 0.\n\n\nA hole in a file isn\u2019t required to have storage backing it on disk.\n\n\n\n\n\n\n\n\nread\n Function\n\n\napue_read.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nread\n(\nint\n \nfd\n,\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: number of bytes read, 0 if end of file, \u22121 on error */\n\n\n\n\n\n\n\n\nbuf\n: type \nvoid *\n is used for generic pointers.\n\n\nReturn value is required to be a signed integer (\nssize_t\n) to return a positive byte count, 0 (for end of file), or \u22121 (for an error).\n\n\n\n\nSeveral cases in which the number of bytes actually read is less than the amount requested:\n\n\n\n\nRegular file: if the end of file is reached before the requested number of bytes has been read.\n\n\nTerminal device: up to one line is read at a time\n\n\nNetwork: buffering within the network may cause less than the requested amount to be returned\n\n\nPipe or FIFO: if the pipe contains fewer bytes than requested, \nread\n will return only what is available\n\n\nRecord-oriented device\n\n\nInterrupted by a signal and a partial amount of data has already been read\n\n\n\n\nwrite\n Function\n\n\napue_write.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: number of bytes written if OK, \u22121 on error */\n\n\n\n\n\n\nThe return value is usually equal to the \nnbytes\n argument; otherwise, an error has occurred.\n\n\nCommon causes for a \nwrite\n error:\n\n\n\n\nFilling up a disk\n\n\nExceeding the file size limit for a given process\n\n\n\n\nFor a regular file, the write operation starts at the file\u2019s current offset. If the \nO_APPEND\n option was specified when the file was opened, the file\u2019s offset is set to the current end of file before each write operation. After a successful write, the file\u2019s offset is incremented by the number of bytes actually written.\n\n\nI/O Efficiency\n\n\n\n\nmycat.c\n\n\n\n\n#include \napue.h\n\n\n\n#define BUFFSIZE 4096\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nn\n;\n\n    \nchar\n \nbuf\n[\nBUFFSIZE\n];\n\n\n    \nwhile\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n\n    \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nn\n)\n \n!=\n \nn\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nCaveats of the above program:\n\n\n\n\nIt reads from standard input and writes to standard output, assuming that these have been set up by the shell before this program is executed.\n\n\nIt doesn\u2019t close the input file or output file. Instead, the program uses the feature of the \nUNIX kernel that closes all open file descriptors in a process when that process terminates.\n\n\nThis example works for both text files and binary files, since there is no difference between the two to the UNIX kernel.\n\n\n\n\nTiming results for reading with different buffer sizes (\nBUFFSIZE\n) on Linux:\n\n\n\n\nThe file was read using the program shown above, with standard output redirected to \n/dev/null\n. The file system used for this test was the Linux ext4 file system with 4,096-byte blocks (the \nst_blksize\n value is 4,096). This accounts for the minimum in the system time occurring at the few timing measurements starting around a \nBUFFSIZE\n of 4,096. Increasing the buffer size beyond this limit has little positive effect.\n\n\nMost file systems support some kind of read-ahead to improve performance. When sequential reads are detected, the system tries to read in more data than an application requests, assuming that the application will read it shortly. The effect of read-ahead can be seen in Figure 3.6, where the elapsed time for buffer sizes as small as 32 bytes is as good as the elapsed time for larger buffer sizes. [p73]\n\n\nFile Sharing\n\n\nThe UNIX System supports the sharing of open files among different processes.\n\n\n\n\nThe kernel uses three data structures to represent an open file, and the relationships among them determine the effect one process has on another with regard to file sharing.\n\n\n\n\nProcess table entry\n: every process has an entry in the process table. Each process table entry has a table of open file descriptors. Associated with each file descriptor are:\n\n\nFile descriptor flags\n (close-on-exec)\n\n\nPointer to a file table entry:\n\n\n\n\n\n\nFile table entry\n: the kernel maintains a file table for all open files. Each file table entry contains:\n\n\nFile status flags\n\n\nCurrent file offset\n\n\nPointer to the v-node table entry for the file\n\n\n\n\n\n\nv-node\n structure: contains information about the type of file and pointers to functions that operate on the file\n\n\nThis information is read from disk when the file is opened, so that all the pertinent information about the file is readily available\n\n\nv-node also contains the \ni-node\n for the file\n\n\nLinux has no v-node. Instead, a generic i-node structure is used. [p75] Instead of splitting the data structures into a v-node and an i-node, Linux uses a file system\u2013independent i-node and a file system\u2013dependent i-node. [p76]\n\n\n\n\n\n\n\n\nFigure 3.7\n shows a pictorial arrangement of these three tables for a single process that has two different files open: one file is open on standard input (file descriptor 0), and the other is open on standard output (file descriptor 1).\n\n\nIf two independent processes have the same file open, we could have the arrangement shown in Figure 3.8 (below).\n\n\n\n\nEach process that opens the file gets its own file table entry, but only a single v-node table entry is required for a given file. One reason \neach process gets its own file table entry is so that each process has its own current offset for the file.\n\n\nSpecific operations\n\n\n\n\nFile offset: After each \nwrite\n is complete, the current file offset in the file table entry is incremented by the number of bytes written. If this causes the current file offset to exceed the current file size, the current file size in the i-node table entry is set to the current file offset (the file is extended).\n\n\nO_APPEND\n: If a file is opened with the \nO_APPEND\n flag, a corresponding flag is set in the file status flags of the file table entry. Each time a \nwrite\n is performed for a file with this append flag set, the current file offset in the file table entry is first set to the current file size from the i-node table entry. Th is forces every \nwrite\n to be appended to the current end of file.\n\n\nlseek\n\n\nIf a file is positioned to its current end of file using \nlseek\n, all that happens is the current file offset in the file table entry is set to the current file size from the i-node table entry. \nThis is not the same as if the file was opened with the \nO_APPEND\n flag.\n\n\nThe \nlseek\n function modifies only the current file offset in the file table entry. No I/O takes place.\n\n\n\n\n\n\n\n\nIt is possible for more than one file descriptor entry to point to the same file table entry:\n\n\n\n\ndup\n\n\nfork\n: the parent and the child share the same file table entry for each open descriptor\n\n\n\n\nFile descriptor flags vs. the file status flags\n\n\n\n\nFile descriptor flags: apply only to a single descriptor in a single process\n\n\nFile status flags: apply to all descriptors in any process that point to the given file table entry\n\n\nfcntl\n is used to fetch and modify both of them\n\n\n\n\nAtomic Operations\n\n\nOlder versions of the UNIX System didn\u2019t support the \nO_APPEND\n option if a single process wants to append to the end of a file. The program would be:\n\n\nif\n \n(\nlseek\n(\nfd\n,\n \n0L\n,\n \n2\n)\n \n \n0\n)\n \n/* position to EOF, 2 means SEEK_END */\n\n    \nerr_sys\n(\nlseek error\n);\n\n\nif\n \n(\nwrite\n(\nfd\n,\n \nbuf\n,\n \n100\n)\n \n!=\n \n100\n)\n \n/* and write */\n\n    \nerr_sys\n(\nwrite error\n);\n\n\n\n\n\n\nThis works fine for a single process, but problems arise if multiple processes (or multiple instances of the same program) use this technique to append to the same file. The problem here is that our logical operation of \"position to the end of file and write\" requires two separate function calls. The solution is to have the positioning to the current end of file and the write be an atomic operation with regard to other processes. Any operation that requires more than one function call cannot be atomic, as there is always the possibility that the kernel might temporarily suspend the process between the two function calls. The UNIX System provides an atomic way to do this operation if we set the \nO_APPEND\n flag when a file is opened. This causes the kernel to position the file to its current end of file before each \nwrite\n. We no longer have to call lseek before each \nwrite\n.\n\n\npread\n and \npwrite\n Functions\n\n\nThe Single UNIX Specification includes two functions that allow applications to seek and perform I/O atomically:\n\n\napue_pread.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \npread\n(\nint\n \nfd\n,\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n,\n \noff_t\n \noffset\n);\n\n\n/* Returns: number of bytes read, 0 if end of file, \u22121 on error */\n\n\n\nssize_t\n \npwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \nnbytes\n,\n \noff_t\n \noffset\n);\n\n\n/* Returns: number of bytes written if OK, \u22121 on error */\n\n\n\n\n\n\n\n\npread\n: equivalent to calling \nlseek\n followed by a call to \nread\n, with the following exceptions:\n\n\nThere is no way to interrupt the two operations that occur calling \npread\n.\n\n\nThe current file offset is not updated.\n\n\n\n\n\n\npwrite\n:  equivalent to calling lseek followed by a call to write, with similar exceptions to \npread\n.\n\n\n\n\nCreating a File\n\n\nAtomic operation\n\n\nWhen both of \nO_CREAT\n and \nO_EXCL\n options are specified, the \nopen\n will fail if the file already exists. The check for the existence of the file and the creation of the file was performed as an atomic operation.\n\n\nNon-atomic operation\n\n\nIf we didn\u2019t have this atomic operation, we might try:\n\n\nif\n \n((\nfd\n \n=\n \nopen\n(\npath\n,\n \nO_WRONLY\n))\n \n \n0\n)\n \n{\n\n    \nif\n \n(\nerrno\n \n==\n \nENOENT\n)\n \n{\n\n        \nif\n \n((\nfd\n \n=\n \ncreat\n(\npath\n,\n \nmode\n))\n \n \n0\n)\n\n            \nerr_sys\n(\ncreat error\n);\n\n    \n}\n \nelse\n \n{\n\n        \nerr_sys\n(\nopen error\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe problem occurs if the file is created by another process between the \nopen\n and the \ncreat\n. If the file is created by another process between these two function calls, and if that other process writes something to the file, that data is erased when this \ncreat\n is executed. Combining the test for existence and the creation into a single atomic operation avoids this problem.\n\n\nAtomic operation\n refers to an operation that might be composed of multiple steps. \nIf the operation is performed atomically, either all the steps are performed (on success) or none are performed (on failure). It must not be possible for only a subset of the steps to be performed.\n\n\ndup\n and \ndup2\n Functions\n\n\nAn existing file descriptor is duplicated by either of the following functions:\n\n\napue_dup.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ndup\n(\nint\n \nfd\n);\n\n\nint\n \ndup2\n(\nint\n \nfd\n,\n \nint\n \nfd2\n);\n\n\n\n/* Both return: new file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ndup\n: return the new file descriptor, which is guaranteed to be the lowest-numbered available file descriptor\n\n\ndup2\n: \nfd2\n argument is the new file descriptor we specifiy.\n\n\nIf \nfd2\n is already open, it is first closed\n\n\nIf \nfd\n equals \nfd2\n, then \ndup2\n returns \nfd2\n without closing it. Otherwise, the \nFD_CLOEXEC\n file descriptor flag is cleared for \nfd2\n, so that \nfd2\n is left open if the process calls \nexec\n.\n\n\n\n\n\n\n\n\nKernel data structures after \ndup(1)\n:\n\n\n\n\nIn the above figure, we assume the process executes:\n\n\nnewfd\n \n=\n \ndup\n(\n1\n);\n\n\n\n\n\n\n\n\nBecause both descriptors point to the same file table entry, they share the same file status flags (e.g. read, write, append) and the same current file offset.\n\n\nEach descriptor has its own set of file descriptor flags\n\n\n\n\nAnother way to duplicate a descriptor is with the \nfcntl\n function:\n\n\ndup\n(\nfd\n);\n\n\n\n\n\n\nis equivalent to\n\n\nfcntl\n(\nfd\n,\n \nF_DUPFD\n,\n \n0\n);\n\n\n\n\n\n\nSimilarly, the call\n\n\ndup2\n(\nfd\n,\n \nfd2\n);\n\n\n\n\n\n\nis equivalent to\n\n\nclose\n(\nfd2\n);\n\n\nfcntl\n(\nfd\n,\n \nF_DUPFD\n,\n \nfd2\n);\n\n\n\n\n\n\nIn this last case (above), the \ndup2\n is not exactly the same as a \nclose\n followed by an \nfcntl\n:\n\n\n\n\ndup2\n is an atomic operation, whereas the alternate form involves two function calls. It is possible in the latter case to have a signal catcher called between the \nclose\n and the \nfcntl\n that could modify the file descriptors. The same problem could occur if a different thread changes the file descriptors.\n\n\nThere are some \nerrno\n differences between \ndup2\n and \nfcntl\n.\n\n\n\n\nsync\n, \nfsync\n, and \nfdatasync\n Functions\n\n\nTraditional implementations of the UNIX System have a buffer cache or page cache in the kernel through which most disk I/O passes.\n\n\n\n\nDelayed write\n: when we write data to a file, the data is normally copied by the kernel into one of its buffers and queued for writing to disk at some later time\n\n\n\n\nThe kernel eventually writes all the delayed-write blocks to disk, normally when it needs to reuse the buffer for some other disk block. To ensure consistency of the file system on disk with the contents of the buffer cache, the \nsync\n, \nfsync\n, and \nfdatasync\n functions are provided.\n\n\napue_fsync.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nfsync\n(\nint\n \nfd\n);\n\n\nint\n \nfdatasync\n(\nint\n \nfd\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nvoid\n \nsync\n(\nvoid\n);\n\n\n\n\n\n\n\n\nsync\n: queues all the modified block buffers for writing and returns. It does not wait for the disk writes to take place\n\n\nsync\n is normally called periodically (usually every 30 seconds) from a system daemon, often called \nupdate\n, which guarantees regular flushing of the kernel\u2019s block buffers. The command \nsync(1)\n also calls the \nsync\n function.\n\n\n\n\n\n\nfsync\n: applies to a single file specified by the file descriptor \nfd\n, and waits for the disk writes to complete before returning.\n\n\nfsync\n also updates the file's attributes synchronously\n\n\n\n\n\n\nfdatasync\n: similar to \nfsync\n, but it affects only the data portions of a file.\n\n\n\n\nfcntl\n Function\n\n\nThe \nfcntl\n function can change the properties of a file that is already open.\n\n\napue_fcntl.h\n\n\n#include \nfcntl.h\n\n\n\nint\n \nfcntl\n(\nint\n \nfd\n,\n \nint\n \ncmd\n,\n \n...\n \n/* int arg */\n \n);\n\n\n\n/* Returns: depends on cmd if OK (see following), \u22121 on error */\n\n\n\n\n\n\nIn this section, the third argument of \nfcntl\n is always an integer, corresponding to the comment in the function prototype just shown.\n\n\nThe \nfcntl\n function is used for five different purposes:\n\n\n\n\nDuplicate an existing descriptor (\ncmd\n = \nF_DUPFD\n or \nF_DUPFD_CLOEXEC\n)\n\n\nGet/set file descriptor flags (\ncmd\n = \nF_GETFD\n or \nF_SETFD\n)\n\n\nGet/set file status flags (\ncmd\n = \nF_GETFL\n or \nF_SETFL\n)\n\n\nGet/set asynchronous I/O ownership (\ncmd\n = \nF_GETOWN\n or \nF_SETOWN\n)\n\n\nGet/set record locks (\ncmd\n = \nF_GETLK\n, \nF_SETLK\n, or \nF_SETLKW\n)\n\n\n\n\nThe following text discusses both the file descriptor flags associated with each file descriptor in the process table entry and the file status flags associated with each file table entry.\n\n\n\n\nF_DUPFD\n: Duplicate the file descriptor \nfd\n. The new file descriptor, which is the lowest-numbered descriptor that is not already open and is greater than or equal to the third argument (integer), is returned as the value of the function. The new descriptor has its own set of file descriptor flags with \nFD_CLOEXEC\n cleared.\ncleared.\n\n\nF_DUPFD_CLOEXEC\n: Duplicate the file descriptor and set the \nFD_CLOEXEC\n file descriptor flag associated with the new descriptor.\n\n\nF_GETFD\n: Return the file descriptor flags for \nfd\n. Currently, only one file descriptor flag (\nFD_CLOEXEC\n) is defined.\n\n\nF_SETFD\n: Set the file descriptor flags for \nfd\n. The new flag value is set from the third argument.\n\n\nSome existing programs don\u2019t use constant \nFD_CLOEXEC\n. Instead, these programs set the flag to either 0 (don\u2019t close-on-exec, the default) or 1 (do close-on-exec).\n\n\n\n\n\n\n\n\nF_GETFL\n: Return the file status flags for \nfd\n. The file status flags were described with the \nopen\n function.\n\n\n\n\nThe five access-mode flags (\nO_RDONLY\n, \nO_WRONLY\n, \nO_RDWR\n, \nO_EXEC\n, and \nO_SEARCH\n) are not separate bits that can be tested.\n\n\nO_RDONLY\n, \nO_WRONLY\n, \nO_RDWR\n often have the values 0, 1, and 2, respectively\n\n\nThe five access-mode flags are mutually exclusive: this means a file can have only one of them enabled.\n\n\nWe must first use the \nO_ACCMODE\n mask to obtain the access-mode bits and then compare the result against any of the five values.\n\n\n\n\n\n\n\n\n\n\nFile status flag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nO_RDONLY\n\n\nopen for reading only\n\n\n\n\n\n\nO_WRONLY\n\n\nopen for writing only\n\n\n\n\n\n\nO_RDWR\n\n\nopen for reading and writing\n\n\n\n\n\n\nO_EXEC\n\n\nopen for execute only\n\n\n\n\n\n\nO_SEARCH\n\n\nopen directory for searching only\n\n\n\n\n\n\nO_APPEND\n\n\nappend on each write\n\n\n\n\n\n\nO_NONBLOCK\n\n\nnonblocking mode\n\n\n\n\n\n\nO_SYNC\n\n\nwait for writes to complete (data and attributes)\n\n\n\n\n\n\nO_DSYNC\n\n\nwait for writes to complete (data only)\n\n\n\n\n\n\nO_RSYNC\n\n\nsynchronize reads and writes\n\n\n\n\n\n\nO_FSYNC\n\n\nwait for writes to complete (FreeBSD and Mac OS X only)\n\n\n\n\n\n\nO_ASYNC\n\n\nasynchronous I/O (FreeBSD and Mac OS X only)\n\n\n\n\n\n\n\n\n\n\n\n\nF_SETFL\n: Set the file status flags to the value of the third argument (integer). The only flags that can be changed are:\n\n\n\n\nO_APPEND\n\n\nO_NONBLOCK\n\n\nO_SYNC\n\n\nO_DSYNC\n\n\nO_RSYNC\n\n\nO_FSYNC\n\n\nO_ASYNC\n\n\n\n\n\n\nF_GETOWN\n: Get the process ID or process group ID currently receiving the \nSIGIO\n and \nSIGURG\n signals.\n\n\nF_SETOWN\n: Set the process ID or process group ID to receive the \nSIGIO\n and \nSIGURG\n signals.\n\n\n\n\nThe return value from \nfcntl\n depends on the command. All commands return \u22121 on an error or some other value if OK. The following four commands have special return values:\n\n\n\n\nF_DUPFD\n: returns the new file descriptor\n\n\nF_GETFD\n: returns the file descriptor flags\n\n\nF_GETFL\n: returns the file status flags\n\n\nF_GETOWN\n: returns a positive process ID or a negative process group ID\n\n\n\n\nGetting file flags\n\n\nExample:\n\n\n\n\nfileflags.c\n\n\n\n\n#include \napue.h\n\n\n#include \nfcntl.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n \nval\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: a.out \ndescriptor#\n);\n\n    \nif\n \n((\nval\n \n=\n \nfcntl\n(\natoi\n(\nargv\n[\n1\n]),\n \nF_GETFL\n,\n \n0\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl error for fd %d\n,\n \natoi\n(\nargv\n[\n1\n]));\n\n\n    \nswitch\n \n(\nval\n \n \nO_ACCMODE\n)\n \n{\n\n    \ncase\n \nO_RDONLY\n:\n\n        \nprintf\n(\nread only\n);\n\n        \nbreak\n;\n\n    \ncase\n \nO_WRONLY\n:\n\n        \nprintf\n(\nwrite only\n);\n\n        \nbreak\n;\n\n    \ncase\n \nO_RDWR\n:\n\n        \nprintf\n(\nread write\n);\n\n        \nbreak\n;\n\n    \ndefault\n:\n\n        \nerr_dump\n(\nunknown access mode\n);\n\n    \n}\n\n\n    \nif\n \n(\nval\n \n \nO_APPEND\n)\n\n        \nprintf\n(\n, append\n);\n\n    \nif\n \n(\nval\n \n \nO_NONBLOCK\n)\n\n        \nprintf\n(\n, nonblocking\n);\n\n    \nif\n \n(\nval\n \n \nO_SYNC\n)\n\n        \nprintf\n(\n, synchronous writes\n);\n\n\n\n#if !defined(_POSIX_C_SOURCE) \n defined(O_FSYNC) \n (O_FSYNC != O_SYNC)\n\n    \nif\n \n(\nval\n \n \nO_FSYNC\n)\n\n        \nprintf\n(\n, synchronous writes\n);\n\n\n#endif\n\n\n    \nputchar\n(\n\\n\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ \n./a.out \n0\n \n /dev/tty\n\nread \nonly\n\n$ \n./a.out \n1\n \n temp.foo\n\n$ \ncat temp.foo\nwrite only\n\n$ \n./a.out \n2\n 2\ntemp.foo\nwrite only, append\n\n$ \n./a.out \n5\n 5\ntemp.foo\n\nread \nwrite\n\n\n\n\n\nModifying file flags\n\n\nTo modify either the file descriptor flags or the file status flags, we must be careful to fetch the existing flag value, modify it as desired, and then set the new flag value. We can\u2019t simply issue an \nF_SETFD\n or an \nF_SETFL\n command, as this could turn off flag bits that were previously set.\n\n\nExample:\n\n\n#include \napue.h\n\n\n#include \nfcntl.h\n\n\n\nvoid\n\n\nset_fl\n(\nint\n \nfd\n,\n \nint\n \nflags\n)\n \n/* flags are file status flags to turn on */\n\n\n{\n\n    \nint\n \nval\n;\n\n    \nif\n \n((\nval\n \n=\n \nfcntl\n(\nfd\n,\n \nF_GETFL\n,\n \n0\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl F_GETFL error\n);\n\n    \nval\n \n|=\n \nflags\n;\n \n/* turn on flags */\n\n    \nif\n \n(\nfcntl\n(\nfd\n,\n \nF_SETFL\n,\n \nval\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nfcntl F_SETFL error\n);\n\n\n}\n\n\n\n\n\n\nIf we change the middle statement to\n\n\nval\n \n=\n \n\u02dc\nflags\n;\n \n/* turn flags off */\n\n\n\n\n\n\nwe have a function named \nclr_fl\n,  logically ANDs the one\u2019s complement of \nflags\n with the current \nval\n.\n\n\nSynchronous-write flag\n\n\nIf we add the line\n\n\nset_fl\n(\nSTDOUT_FILENO\n,\n \nO_SYNC\n);\n\n\n\n\n\n\nto the beginning of the program shown in \nI/O Efficiency section\n, we\u2019ll turn on the synchronous-write flag. This causes each write to wait for the data to be written to disk before returning. Normally in the UNIX System, \na \nwrite\n only queues the data for writing; the actual disk write operation can take place sometime later.\n A database system is a likely candidate for using \nO_SYNC\n, so that it knows on return from a write that the data is actually on the disk, in case of an abnormal system failure.\n\n\nLinux ext4 timing results using various synchronization mechanisms [p86]\n\n\nMac OS X HFS timing results using various synchronization mechanisms [p87]\n\n\nThe \nabove program\n operates on a descriptor (standard output), never knowing the name of the file that was opened on that descriptor. We can\u2019t set the \nO_SYNC\n flag when the file is opened, since the shell opened the file. With \nfcntl\n, we can modify the properties of a descriptor, knowing only the descriptor for the open file.\n\n\nioctl\n Function\n\n\napue_ioctl.h\n\n\n#include \nunistd.h\n \n/* System V */\n\n\n#include \nsys/ioctl.h\n \n/* BSD and Linux */\n\n\n\nint\n \nioctl\n(\nint\n \nfd\n,\n \nint\n \nrequest\n,\n \n...);\n\n\n\n/* Returns: \u22121 on error, something else if OK */\n\n\n\n\n\n\nThe \nioctl\n function has always been the catchall for I/O operations. Anything that couldn\u2019t be expressed using one of the other functions in this chapter usually ended up being specified with an \nioctl\n. Terminal I/O was the biggest user of this function.\n\n\nFor the ISO C prototype, an ellipsis is used for the remaining arguments. Normally, however, there is only one more argument, and it\u2019s usually a pointer to a variable or a structure.\n\n\nEach device driver can define its own set of \nioctl\n commands. The system, however, provides generic ioctl commands for different classes of devices.\n\n\nWe use the \nioctl\n function in Section 18.12 to fetch and set the size of a terminal\u2019s window, and in Section 19.7 when we access the advanced features of pseudo terminals.\n\n\n/dev/fd\n\n\nNewer systems provide a directory named \n/dev/fd\n whose entries are files named 0, 1, 2, and so on. Opening the file \n/dev/fd/n\n is equivalent to duplicating descriptor \nn\n, assuming that descriptor \nn\n is open. \n/dev/fd\n is not part of POSIX.1.\n\n\nThe following are equivalent:\n\n\nfd\n \n=\n \nopen\n(\n/dev/fd/0\n,\n \nmode\n);\n\n\nfd\n \n=\n \ndup\n(\n0\n);\n\n\n\n\n\n\nMost systems ignore the specified \nmode\n, whereas others require that it be a subset of the mode used when the referenced file (standard input, in this case) was originally opened. The descriptors 0 and \nfd\n \nshare the same file table entry\n.\n\n\nThe Linux implementation of \n/dev/fd\n is an exception. It maps file descriptors into symbolic links pointing to the underlying physical files. When you open \n/dev/fd/0\n, for example, you are really opening the file associated with your standard input. Thus the mode of the new file descriptor returned is unrelated to the mode of the \n/dev/fd\n file descriptor.\n\n\nWe can also call \ncreat\n with a \n/dev/fd\n pathname argument as well as specify \nO_CREAT\n in a call to open. This allows a program that calls \ncreat\n to still work if the pathname argument is \n/dev/fd/1\n, for example.\n\n\nSome systems provide the pathnames \n/dev/stdin\n, \n/dev/stdout\n, and \n/dev/stderr\n. These pathnames are equivalent to \n/dev/fd/0\n, \n/dev/fd/1\n, and \n/dev/fd/2\n, respectively.\n\n\nThe main use of the \n/dev/fd\n files is from the shell. It allows programs that use pathname arguments to handle standard input and standard output in the same manner as other pathnames.\n\n\nThe following are equivalent:\n\n\nfilter file2 \n|\n cat file1 - file3 \n|\n lpr\nfilter file2 \n|\n cat file1 /dev/fd/0 file3 \n|\n lpr", 
            "title": "Chapter 3. File I/O"
        }, 
        {
            "location": "/apue/ch4/", 
            "text": "Chapter 4. Files and Directories\n\n\nThis chapter centers on I/O for regular files.\n\n\nrestrict\n keyword\n\n\nAdded in C99, \nrestrict\n keyword is used to tell the compiler which pointer references can be optimized, by indicating that the object to which the pointer refers is accessed in the function only via that pointer. [p26]\n\n\nstat\n, \nfstat\n, \nfstatat\n, and \nlstat\n Functions\n\n\napue_stat.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nstat\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n);\n\n\nint\n \nfstat\n(\nint\n \nfd\n,\n \nstruct\n \nstat\n \n*\nbuf\n);\n\n\nint\n \nlstat\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n);\n\n\nint\n \nfstatat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nstruct\n \nstat\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nflag\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nstat\n: returns a structure of information about the named file\n\n\nfstat\n: returns a structure of information about the given file descriptor\n\n\nlstat\n: similar to \nstat\n, returns information about the symbolic link, not the file referenced by the symbolic link\n\n\nfstatat\n:  return the file statistics for a pathname relative to an open directory represented by the fd argument; the flag argument controls whether symbolic links are followed\n\n\n\n\nThe \nbuf\n argument is a pointer to a \nstructure\n that we must supply. The functions fill in the structure.\n\n\nstruct\n \nstat\n \n{\n\n    \nmode_t\n    \nst_mode\n;\n\n    \nino_t\n    \nst_ino\n;\n\n    \ndev_t\n    \nst_dev\n;\n\n    \ndev_t\n    \nst_rdev\n;\n\n    \nnlink_t\n    \nst_nlink\n;\n\n    \nuid_t\n    \nst_uid\n;\n\n    \ngid_t\n    \nst_gid\n;\n\n    \noff_t\n    \nst_size\n;\n\n    \nstruct\n \ntimespec\n    \nst_atim\n;\n\n    \nstruct\n \ntimespec\n    \nst_mtim\n;\n\n    \nstruct\n \ntimespec\n    \nst_ctim\n;\n\n    \nblksize_t\n    \nst_blksize\n;\n\n    \nblkcnt_t\n    \nst_blocks\n;\n\n\n};\n\n\n\n\n\n\ntimespec\n structure\n\n\nThe \ntimespec\n structure type defines time in terms of seconds and nanoseconds. It includes at least the following fields:\n\n\ntime_t\n \ntv_sec\n;\n\n\nlong\n \ntv_nsec\n;\n\n\n\n\n\n\nFile Types\n\n\n\n\nRegular file. All binary executable files conform to a format that allows the kernel to identify where to load a program\u2019s text and data.\n\n\nDirectory file. A file that contains the names of other files and pointers to information on these files. Any process that has read permission for a directory file can read the contents of the directory, but only the kernel can write directly to a directory file.\n\n\nBlock special file\n\n\nCharacter special file\n\n\nFIFO\n\n\nSocket\n\n\nSymbolic link\n\n\n\n\nThis program prints the type of file for each command-line argument.\n\n\n\n\nfiletype.c\n\n\n\n\nSet-User-ID and Set-Group-ID\n\n\nFile Access Permissions\n\n\n\n\nWhenever we want to open any type of file by name, we must have execute permission in each directory mentioned in the name, including the current directory, if it is implied. Read permission for a directory and execute permission for a directory mean different things. Read permission lets us read the directory, obtaining a list of all the filenames in the directory. Execute permission lets us pass through the directory when it is a component of a pathname that we are trying to access. [p100]\n\n\nWe cannot create a new file in a directory unless we have write permission and execute permission in the directory.\n\n\n\n\nOwnership of New Files and Directories\n\n\n\n\nThe user ID of a new file is set to the effective user ID of the process\n\n\nThe group ID of a new file can be the effective group ID of the process; or group ID of the directory in which the file is being created.\n\n\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 always copy the new file\u2019s group ID from the directory.\n\n\naccess\n and \nfaccessat\n Functions\n\n\napue_access.h\n\n\n#include \nunistd.h\n\n\n\nint\n \naccess\n(\nconst\n \nchar\n \n*\npathname\n,\n \nint\n \nmode\n);\n\n\nint\n \nfaccessat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nint\n \nmode\n,\n \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese functions test accessibility based on the real user and group IDs.\n\n\nThe \nflag\n argument can be used to change the behavior of \nfaccessat\n. If the \nAT_EACCESS\n flag is set, the access checks are made using the effective user and group IDs.\n\n\n\n\naccess.c\n\n\n\n\numask\n Function\n\n\nThe Single UNIX Specification requires that the \numask\n command support a symbolic mode of operation. Unlike the octal format, the symbolic format specifies which permissions are to be allowed instead of which ones are to be denied.\n\n\n$ \numask\n  \n# first print the current file mode creation mask\n\n002\n\n$ \numask\n -S  \n# print the symbolic form\n\n\nu\n=\nrwx,g\n=\nrwx,o\n=\nrx\n\n$ \numask \n027\n  \n# print the symbolic form\n\n\n$ \numask\n -S  \n# print the symbolic form\n\n\nu\n=\nrwx,g\n=\nrx,o\n=\n\n\n\n\n\n\nchmod\n, \nfchmod\n, and \nfchmodat\n Functions\n\n\napue_chmod.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nchmod\n(\nconst\n \nchar\n \n*\npathname\n,\n \nmode_t\n \nmode\n);\n\n\nint\n \nfchmod\n(\nint\n \nfd\n,\n \nmode_t\n \nmode\n);\n\n\nint\n \nfchmodat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nmode_t\n \nmode\n,\n \nint\n \nflag\n);\n\n\n\n/* All three return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nchmod\n automatically clears the following permission bits under the following conditions:\n\n\n\n\nSetting sticky bit on a regular file without superuser privileges (Solaris)\n\n\nIf the group ID of the new file does not equal either the effective group ID of the process or one of the process\u2019s supplementary group IDs and if the process does not have superuser privileges, then the set-group-ID bit is automatically turned off. On FreeBSD 8.0, Linux 3.2.0 and Mac OS X 10.6.8, if a process that does not have superuser privileges writes to a file, the set-user-ID and set-group-ID bits are automatically turned off.\n\n\n\n\nSticky Bit\n\n\nSticky Bit (\nS_ISVTX\n), or saved-text bit in the later versions of the UNIX System.\n\n\n\n\nOn file: only on a minority of systems\n\n\nOn directory: \n/tmp\n and \n/var/tmp\n\n\n\n\nchown\n, \nfchown\n, \nfchownat\n, and \nlchown\n Functions\n\n\napue_chown.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nchown\n(\nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\nint\n \nfchown\n(\nint\n \nfd\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\nint\n \nfchownat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n,\n \nint\n \nflag\n);\n\n\nint\n \nlchown\n(\nconst\n \nchar\n \n*\npathname\n,\n \nuid_t\n \nowner\n,\n \ngid_t\n \ngroup\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nlchown\n and \nfchownat\n (with the \nAT_SYMLINK_NOFOLLOW\n flag set) change the owners of the symbolic link itself.\n\n\nfchown\n operates on a open file, it can\u2019t be used to change the ownership of a symbolic link.\n\n\n\n\nOnly the superuser can change the ownership of a file (FreeBSD 8.0, Linux 3.2.0, and Mac OS X 10.6.8)\n\n\nWhen \n_POSIX_CHOWN_RESTRICTED\n is in effect, a non-superuser can\u2019t change the user ID of your files; A nonsuperuser can change the group ID of files that he owns, but only to groups that he belongs to.\n\n\nFile Size\n\n\nThe \nst_size\n member of the stat structure contains the size of the file in bytes. This field is meaningful only for regular files, directories, and symbolic links.\n\n\nFreeBSD 8.0, Mac OS X 10.6.8, and Solaris 10 also define the file size for a pipe as the number of bytes that are available for reading from the pipe.\n\n\n\n\nFor a regular file, a file size of 0 is allowed. We\u2019ll get an end-of-file indication on the first read of the file.\n\n\nFor a directory, the file size is usually a multiple of a number, such as 16 or 512.\n\n\nFor a symbolic link, the file size is the number of bytes in the filename.\n\n\n\n\nMost contemporary UNIX systems provide two fields:\n\n\n\n\nst_blksize\n: preferred block size for I/O for the file\n\n\nst_blocks\n: actual number of 512-byte blocks that are allocated\n\n\n\n\nBe aware that different versions of the UNIX System use units other than 512-byte blocks for \nst_blocks\n. Use of this value is \nnonportable\n.\n\n\nHoles in a File\n\n\n$ \nls -l core\n-rw-r--r-- \n1\n sar \n8483248\n Nov \n18\n 12:18 core\n\n$ \ndu -s core\n\n272\n core\n\n\n\n\n\nFile Truncation\n\n\napue_truncate.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ntruncate\n(\nconst\n \nchar\n \n*\npathname\n,\n \noff_t\n \nlength\n);\n\n\nint\n \nftruncate\n(\nint\n \nfd\n,\n \noff_t\n \nlength\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese two functions truncate an existing file to \nlength\n bytes. If the previous size of the file was greater than \nlength\n, the data beyond \nlength\n is no longer accessible. Otherwise, if the previous size was less than \nlength\n, the file size will increase and the data between the old end of file and the new end of file will read as 0 (a hole is probably created in the file).\n\n\nFile Systems\n\n\nMost UNIX file systems support \ncase-sensitive\n filenames. On Mac OS X, however, the HFS file system is \ncase-preserving\n with \ncase-insensitive\n comparisons.\n\n\n\n\n\n\nEvery i-node has a link count that contains the number of directory entries that point to it. Only when the link count (\nst_nlink\n) goes to 0 can the file be deleted.\n\n\nWith a symbolic link (file type \nS_IFLNK\n), the actual contents of the file (the data blocks) store the name of the file that the symbolic link points to.\n\n\nThe i-node contains all the information about the file: the file type, the file\u2019s access permission bits, the size of the file, pointers to the file\u2019s data blocks, and so on.\n\n\nOnly two items are stored in the directory entry: the filename and the i-node number. The data type for the i-node number is \nino_t\n.\n\n\n\n\nlink\n, \nlinkat\n, \nunlink\n, \nunlinkat\n, and \nremove\n Functions\n\n\napue_link.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nlink\n(\nconst\n \nchar\n \n*\nexistingpath\n,\n \nconst\n \nchar\n \n*\nnewpath\n);\n\n\nint\n \nlinkat\n(\nint\n \nefd\n,\n \nconst\n \nchar\n \n*\nexistingpath\n,\n \nint\n \nnfd\n,\n \nconst\n \nchar\n \n*\nnewpath\n,\n\n           \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWhen a file is closed, the kernel first checks the count of the number of processes that have the file open. If this count has reached 0, the kernel then checks the link count; if it is 0, the file\u2019s contents are deleted.\n\n\nWhen the \nAT_REMOVEDIR\n flag is set, then the \nunlinkat\n function can be used to remove a directory, similar to using \nrmdir\n.\n\n\napue_remove.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nremove\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nrename\n and \nrenameat\n Functions\n\n\napue_rename.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nrename\n(\nconst\n \nchar\n \n*\noldname\n,\n \nconst\n \nchar\n \n*\nnewname\n);\n\n\nint\n \nrenameat\n(\nint\n \noldfd\n,\n \nconst\n \nchar\n \n*\noldname\n,\n \nint\n \nnewfd\n,\n \nconst\n \nchar\n \n*\nnewname\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nSymbolic Links\n\n\nIt is possible to introduce loops into the file system by using symbolic links. Most functions that look up a pathname return an \nerrno\n of \nELOOP\n when this occurs.\n\n\nOn Linux, the \nftw\n and \nnftw\n functions record all directories seen and avoid processing a directory more than once, so they don\u2019t display this behavior.\n\n\n\n\nls -l\n\n\nls -F\n\n\n\n\napue_symlink.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsymlink\n(\nconst\n \nchar\n \n*\nactualpath\n,\n \nconst\n \nchar\n \n*\nsympath\n);\n\n\nint\n \nsymlinkat\n(\nconst\n \nchar\n \n*\nactualpath\n,\n \nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nsympath\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nBecause the open function follows a symbolic link, we need a way to open the link itself and read the name in the link.\n\n\napue_readlink.h\n\n\n#include \nunistd.h\n\n\n\nssize_t\n \nreadlink\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nchar\n \n*\nrestrict\n \nbuf\n,\n\n                 \nsize_t\n \nbufsize\n);\n\n\n\nssize_t\n \nreadlinkat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n\n                   \nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nbufsize\n);\n\n\n\n/* Both return: number of bytes read if OK, \u22121 on error */\n\n\n\n\n\n\nThese functions combine the actions of \nopen\n, \nread\n, and \nclose\n.\n\n\nFile Times\n\n\n\n\n\n\n\n\nField\n\n\nDescription\n\n\nExample\n\n\nls(1) option\n\n\n\n\n\n\n\n\n\n\nst_atim\n\n\nlast-access time of file data\n\n\nread\n\n\n-u\n\n\n\n\n\n\nst_mtim\n\n\nlast-modification time of file data\n\n\nwrite\n\n\ndefault\n\n\n\n\n\n\nst_ctim\n\n\nlast-change time of i-node status\n\n\nchmod\n, \nchown\n\n\n-c\n\n\n\n\n\n\n\n\nThe system does not maintain the last-access time for an i-node. The functions \naccess\n and \nstat\n don\u2019t change any of the three times.\n\n\nfutimens\n, \nutimensat\n, and \nutimes\n Functions\n\n\napue_futimens.h\n\n\n#include \nsys/stat.h\n\n\n\nint\n \nfutimens\n(\nint\n \nfd\n,\n \nconst\n \nstruct\n \ntimespec\n \ntimes\n[\n2\n]);\n\n\nint\n \nutimensat\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\npath\n,\n \nconst\n \nstruct\n \ntimespec\n \ntimes\n[\n2\n],\n \nint\n \nflag\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nIn both functions, the first element of the times array argument contains the \naccess time\n, and the second element contains the \nmodification time\n.\n\n\n\n\napue_utimes\n\n\n\n\n#include \nsys/time.h\n\n\n\nint\n \nutimes\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nstruct\n \ntimeval\n \ntimes\n[\n2\n]);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nWe are unable to specify a value for the \nchanged-status time\n, \nst_ctim\n (the time the i-node was last changed), as this field is automatically updated when the \nutime\n function is called.\n\n\nmkdir\n, \nmkdirat\n, and \nrmdir\n Functions\n\n\napue_rmdir.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nrmdir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nFor a directory, we normally want at least one of the execute bits enabled, to allow access to filenames within the directory.\n\n\nSolaris 10 and Linux 3.2.0 also have the new directory inherit the set-group-ID bit from the parent directory. Files created in the new directory will then inherit the group ID of that directory. With Linux, the file system implementation determines whether this behavior is supported. For example, the ext2, ext3, and ext4 file systems allow this behavior to be controlled by an option to the mount(1) command.\n\n\nReading Directories\n\n\napue_opendir.h\n\n\n#include \ndirent.h\n\n\n\nDIR\n \n*\nopendir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\nDIR\n \n*\nfdopendir\n(\nint\n \nfd\n);\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\nstruct\n \ndirent\n \n*\nreaddir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: pointer if OK, NULL at end of directory or error */\n\n\n\nvoid\n \nrewinddir\n(\nDIR\n \n*\ndp\n);\n\n\nint\n \nclosedir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nlong\n \ntelldir\n(\nDIR\n \n*\ndp\n);\n\n\n/* Returns: current location in directory associated with dp */\n\n\n\nvoid\n \nseekdir\n(\nDIR\n \n*\ndp\n,\n \nlong\n \nloc\n);\n\n\n\n\n\n\nThe \ndirent\n structure defined in \n is implementation dependent, with at least the following two members:\n\n\n    \nino_t\n  \nd_ino\n;\n                 \n/* i-node number */\n\n    \nchar\n   \nd_name\n[];\n              \n/* null-terminated filename */\n\n\n\n\n\n\nThe \nDIR\n structure is an internal structure used by these seven functions to maintain information about the directory being read. The purpose of the DIR structure is similar to that of the \nFILE\n structure maintained by the standard I/O library,\n\n\n\n\nftw8.c\n\n\n\n\nchdir\n, \nfchdir\n, and \ngetcwd\n Functions\n\n\napue_chdir.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nchdir\n(\nconst\n \nchar\n \n*\npathname\n);\n\n\nint\n \nfchdir\n(\nint\n \nfd\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\napue_getcwd.h\n\n\n#include \nunistd.h\n\n\n\nchar\n \n*\ngetcwd\n(\nchar\n \n*\nbuf\n,\n \nsize_t\n \nsize\n);\n\n\n\n/* Returns: buf if OK, NULL on error */\n\n\n\n\n\n\nDevice Special Files\n\n\n\n\nEvery file system is known by its \nmajor\n and \nminor\n device numbers, which are encoded in the primitive system data type \ndev_t\n.\n\n\nWe can usually access the major and minor device numbers through two macros defined by most implementations: \nmajor\n and \nminor\n.\n\n\n\n\nOn Linux 3.2.0, \ndev_t\n is a 64-bit integer, only 12 bits are used for the major number and 20 bits are used for the minor number. Linux defines these macros in \nsys/sysmacros.h\n, which is included by \nsys/types.h\n.\n\n\nThe \nst_dev\n value for every filename on a system is the device number of the file system containing that filename and its corresponding i-node.\n\n\nOnly character special files and block special files have an \nst_rdev\n value. This value contains the device number for the actual device.\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nSection 4.21 on \nrmdir\n [p130]:\n\n\n\n\nIf the link count of the directory becomes 0 with this call, and if no other process has the directory open, then the space occupied by the directory is freed. If one or more processes have the directory open when the link count reaches 0, the last link is removed and the dot and dot-dot entries are removed before this function returns. Additionally, no new files can be created in the directory.\n\n\n\n\nDoes \"link count\" here mean number of entries (except dot and dot-dot)? Otherwise, this contradicts  \"any leaf directory (a directory that does not contain any other directories) always has a link count of 2\" in section 4.14 on page 115.", 
            "title": "Chapter 4. Files and Directories"
        }, 
        {
            "location": "/apue/ch5/", 
            "text": "Chapter 5. Standard I/O Library\n\n\nThe standard I/O library handles such details as buffer allocation and performing I/O in optimal-sized chunks.\n\n\nStreams and \nFILE\n Objects\n\n\nStandard I/O file streams can be used with both \nsingle-byte\n and \nmultibyte\n (\"wide\") character sets. A stream\u2019s orientation determines whether the characters that are read and written are single byte or multibyte.\n\n\n\n\nThis book deals only with \nbyte-oriented\n (single byte) streams.\n\n\nThis book refers to a pointer to a \nFILE\n object, the type \nFILE *\n, as a \nfile pointer\n.\n\n\n\n\nStandard Input, Standard Output, and Standard Error\n\n\nThree streams are predefined and automatically available to a process. They refer to file descriptors \nSTDIN_FILENO\n, \nSTDOUT_FILENO\n, and \nSTDERR_FILENO\n (defined in \nunistd.h\n) [p9]. These three standard I/O streams are referenced through the predefined file pointers \nstdin\n, \nstdout\n,and \nstderr\n(defined in \nstdio.h\n).\n\n\nBuffering\n\n\n\n\nFully buffered\n\n\nLine buffered\n\n\nUnbuffered\n\n\n\n\nMost implementations default to the following types of buffering:\n\n\n\n\nStandard error is always unbuffered.\n\n\nAll other streams are line buffered if they refer to a terminal device; otherwise, they are fully buffered.\n\n\n\n\napue_setbuf.h\n\n\n#include \nstdio.h\n\n\n\nvoid\n \nsetbuf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nchar\n \n*\nrestrict\n \nbuf\n \n);\n\n\nint\n \nsetvbuf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nchar\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nmode\n,\n \nsize_t\n \nsize\n);\n\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\n\n\n\n\n\nsetbuf\n: \nbuf\n must point to a buffer of length \nBUFSIZ\n, a constant defined in \nstdio.h\n\n\nsetvbuf\n: type of buffering is specified with \n_IOFBF\n, \n_IOLBF\n, \n_IONBF\n.\n\n\n\n\nThe GNU C librarys use the value from the \nst_blksize\n member of the \nstat\n structure to determine the optimal standard I/O buffer size.\n\n\nThe \nfflush\n function causes any unwritten data for the stream to be passed to the kernel. If \nfp\n is \nNULL\n, \nfflush\n causes all output streams to be flushed.\n\n\nOpening a Stream\n\n\napue_fopen.h\n\n\n#include \nstdio.h\n\n\n\nFILE\n \n*\nfopen\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n \nconst\n \nchar\n \n*\nrestrict\n \ntype\n);\n\n\nFILE\n \n*\nfreopen\n(\nconst\n \nchar\n \n*\nrestrict\n \npathname\n,\n\n              \nconst\n \nchar\n \n*\nrestrict\n \ntype\n,\n\n              \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nFILE\n \n*\nfdopen\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\ntype\n);\n\n\n\n/* All three return: file pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\nfdopen\n function is often used with descriptors returned by the functions that create pipes and network communication channels, because these special types of files cannot be opened with the \nfopen\n function.\n\n\n\n\ntype\n argument has 15 values as specifed by ISO C:\n\n\n\n\n\n\n\n\ntype\n\n\nDescription\n\n\nopen\n(2) Flags\n\n\n\n\n\n\n\n\n\n\nr\n, \nrb\n\n\nopen for reading\n\n\nO_RDONLY\n\n\n\n\n\n\nw\n, \nwb\n\n\ntruncate to 0 length or create for writing\n\n\nO_WRONLY\nO_CREAT\nO_TRUNC\n\n\n\n\n\n\na\n, \nab\n\n\nappend; open for writing at end of file, or create for writing\n\n\nO_WRONLY\nO_CREAT\nO_APPEND\n\n\n\n\n\n\nr+\n, \nr+b\n, \nrb+\n\n\nopen for reading and writing\n\n\nO_RDWR\n\n\n\n\n\n\nw+\n, \nw+b\n, \nwb+\n\n\ntruncate to 0 length or create for reading and writing\n\n\nO_RDWR\nO_CREAT\nO_TRUNC\n\n\n\n\n\n\na+\n, \na+b\n, \nab+\n\n\nopen or create for reading and writing at end of file\n\n\nO_RDWR\nO_CREAT\nO_APPEND\n\n\n\n\n\n\n\n\nCharacter \nb\n allows the standard I/O system to differentiate between a text file and a binary file. The UNIX kernel doesn\u2019t differentiate between these types of files, thus character \nb\n has no effect.\n\n\n\n\nWrite\n: The \nfdopen\n function cannot truncate any file it opens for writing\n\n\nAppend\n: each write will take place at the then current end of file. If multiple processes open the same file with the standard I/O append mode, the data from each process will be correctly written to the file\n\n\nRead and write\n (\n+\n sign in type): Output cannot be directly followed by input without an intervening \nfflush\n, \nfseek\n, \nfsetpos\n, or \nrewind\n. Input cannot be directly followed by output without an intervening \nfseek\n, \nfsetpos\n, or \nrewind\n, or an input operation that encounters an end of file.\n\n\n\n\napue_fclose.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfclose\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: 0 if OK, EOF on error */\n\n\n\n\n\n\nAn open stream is closed by calling \nfclose\n:\n\n\n\n\nAny buffered output data is flushed before the file is closed\n\n\nAny input data that may be buffered is discarded\n\n\n\n\nWhen a process terminates normally, either by calling the exit function directly or by returning from the main function, all standard I/O streams with unwritten buffered data are flushed and all open standard I/O streams are closed.\n\n\nReading and Writing a Stream\n\n\nUnformatted I/O:\n\n\n\n\nCharacter-at-a-time I/O\n\n\nLine-at-a-time I/O: \nfgets\n and \nfputs\n. Each line is terminated with a newline character.\n\n\nDirect I/O (binary I/O, object-at-a-time I/O, record-oriented I/O, or structure-oriented I/O): \nfread\n and \nfwrite\n. For each I/O operation, we read or write some number of objects, where each object is of a specified size\n\n\n\n\nInput Functions\n\n\napue_getc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \ngetc\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \nfgetc\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \ngetchar\n(\nvoid\n);\n\n\n\n/* All three return: next character if OK, EOF on end of file or error */\n\n\n\n\n\n\n\n\nThe function \ngetchar\n is defined to be equivalent to \ngetc(stdin)\n.\n\n\ngetc\n can be implemented as a macro, whereas \nfgetc\n cannot be implemented as a macro.\n\n\nThese three functions return the next character as an \nunsigned char\n converted to an \nint\n. Thus, all possible character values can be returned, along with an indication that either an error occurred or the end of file has been encountered. The constant EOF in \nstdio.h\n is required to be a negative value. Its value is often \u22121.\n\n\n\n\nThese functions return the same value whether an error occurs or the end of file is reached. To distinguish between the two, we must call either \nferror\n or \nfeof\n:\n\n\napue_ferror.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nferror\n(\nFILE\n \n*\nfp\n);\n\n\nint\n \nfeof\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Both return: nonzero (true) if condition is true, 0 (false) otherwise */\n\n\n\nvoid\n \nclearerr\n(\nFILE\n \n*\nfp\n);\n\n\n\n\n\n\nIn most implementations, two flags are maintained for each stream in the \nFILE\n object:\n\n\n\n\nAn error flag\n\n\nAn end-of-file flag\n\n\n\n\nBoth flags are cleared by calling \nclearerr\n.\n\n\nPushback\n\n\nAfter reading from a stream, we can push back characters by calling \nungetc\n.\n\n\napue_ungetc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nungetc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: c if OK, EOF on error */\n\n\n\n\n\n\n\n\nThe characters that are pushed back are returned by subsequent reads on the stream in reverse order of their pushing.\n\n\nThe character that is pushed back does not have to be the same character that was read.\n\n\nWhen characters are pushed back with \nungetc\n, they are not written back to the underlying file or device. Instead, they are kept incore in the standard I/O library\u2019s buffer for the stream. EOF cannot be pushed back.\n\n\nUsed for peeking characters.\n\n\n\n\nOutput Functions\n\n\napue_putc.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nputc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\nint\n \nfputc\n(\nint\n \nc\n,\n \nFILE\n \n*\nfp\n);\n\n\nint\n \nputchar\n(\nint\n \nc\n);\n\n\n\n/* All three return: c if OK, EOF on error */\n\n\n\n\n\n\n\n\nputchar(c)\n is equivalent to \nputc(c, stdout)\n\n\nputc\n can be implemented as a macro, whereas \nfputc\n cannot be implemented as a macro.\n\n\n\n\nLine-at-a-Time I/O\n\n\napue_fgets.h\n\n\n#include \nstdio.h\n\n\n\nchar\n \n*\nfgets\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nint\n \nn\n,\n \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nchar\n \n*\ngets\n(\nchar\n \n*\nbuf\n);\n\n\n\n/* Both return: buf if OK, NULL on end of file or error */\n\n\n\n\n\n\n\n\ngets\n function reads from standard input, whereas \nfgets\n reads from the specified stream.\n\n\nfgets\n: reads \nn - 1\n characters (including the newline) or partial line if longer than \nn - 1\n into the buffer, then the buffer is (always) null terminated.\n\n\ngets\n: should never be used. Without specifying buffer size, this may cause buffer to overflow if the line is longer than the buffer, writing over whatever happens to follow the buffer in memory. \ngets\n is marked as an obsolescent interface in SUSv4 and has been omitted from the latest version of the ISO C standard\n\n\n\n\napue_fputs.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfputs\n(\nconst\n \nchar\n \n*\nrestrict\n \nstr\n,\n \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nint\n \nputs\n(\nconst\n \nchar\n \n*\nstr\n);\n\n\n\n/* Both return: non-negative value if OK, EOF on error */\n\n\n\n\n\n\n\n\nfputs\n: writes the null-terminated string to the specified stream without writing the null byte\n\n\nputs\n: writes the null-terminated string to the standard output without writing the null byte, and then writes a newline character to the standard output. \nputs\n should be avoided being used to prevent having to remember whether it appends a newline.\n\n\n\n\nStandard I/O Efficiency\n\n\n\n\n\n\n\n\nFunction\n\n\nUser CPU (seconds)\n\n\nSystem CPU (seconds)\n\n\nClock time (seconds)\n\n\nBytes of program text\n\n\n\n\n\n\n\n\n\n\nbest time from Figure 3.6\n\n\n0.05\n\n\n0.29\n\n\n3.18\n\n\n\n\n\n\n\n\nfgets\n, \nfputs\n\n\n2.27\n\n\n0.30\n\n\n3.49\n\n\n143\n\n\n\n\n\n\ngetc\n, \nputc\n\n\n8.45\n\n\n0.29\n\n\n10.33\n\n\n114\n\n\n\n\n\n\nfgetc\n, \nfputc\n\n\n8.16\n\n\n0.40\n\n\n10.18\n\n\n114\n\n\n\n\n\n\nsingle byte time from Figure 3.6\n\n\n134.61\n\n\n249.94\n\n\n394.95\n\n\n\n\n\n\n\n\n\n\n\n\nOne advantage of using the standard I/O routines is that we don\u2019t have to worry about buffering or choosing the optimal I/O size.\n\n\nUsually, \ngetc\n and \nputc\n are implemented as macros, but in the GNU C library implementation the macro simply expands to a function call.\n\n\nThe line-at-a-time functions are implemented using \nmemccpy(3)\n. Often, the memccpy function is implemented in assembly language instead of C, for efficiency.\n\n\n\n\nBinary I/O\n\n\nIf doing binary I/O, we often want to read or write an entire structure at a time. There are problems with the previous functions:\n\n\n\n\ngetc\n, \nputc\n: we have to loop through the entire structure one byte a time\n\n\nfputs\n: stops writing when it hits a null byte\n\n\nfgets\n: won't work correctly on input if any data bytes are null or newlines\n\n\n\n\napue_fread.h\n\n\n#include \nstdio.h\n\n\n\nsize_t\n \nfread\n(\nvoid\n \n*\nrestrict\n \nptr\n,\n \nsize_t\n \nsize\n,\n \nsize_t\n \nnobj\n,\n\n             \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\nsize_t\n \nfwrite\n(\nconst\n \nvoid\n \n*\nrestrict\n \nptr\n,\n \nsize_t\n \nsize\n,\n \nsize_t\n \nnobj\n,\n\n              \nFILE\n \n*\nrestrict\n \nfp\n);\n\n\n\n/* Both return: number of objects read or written */\n\n\n\n\n\n\nThese functions have two common uses:\n\n\nRead or write a binary array (e.g write elements 2 through 5 of a floating-point array):\n\n\nfloat\n   \ndata\n[\n10\n];\n\n\n\nif\n \n(\nfwrite\n(\ndata\n[\n2\n],\n \nsizeof\n(\nfloat\n),\n \n4\n,\n \nfp\n)\n \n!=\n \n4\n)\n\n    \nerr_sys\n(\nfwrite error\n);\n\n\n\n\n\n\nRead or write a structure:\n\n\nstruct\n \n{\n\n    \nshort\n  \ncount\n;\n\n    \nlong\n   \ntotal\n;\n\n    \nchar\n   \nname\n[\nNAMESIZE\n];\n\n\n}\n \nitem\n;\n\n\n\nif\n \n(\nfwrite\n(\nitem\n,\n \nsizeof\n(\nitem\n),\n \n1\n,\n \nfp\n)\n \n!=\n \n1\n)\n\n    \nerr_sys\n(\nfwrite error\n);\n\n\n\n\n\n\n\n\nfread\n: return value can be less than \nnobj\n if an error occurs or if the end of file is encountered\n\n\nfwrite\n: if the return value is less than the requested \nnobj\n, an error has occurred\n\n\n\n\nThese two functions won't work on different systems (sometimes even on the same system):\n\n\n\n\nThe offset of a member within a structure can differ between compilers and systems because of different \nalignment requirements\n. Even on a single system, the binary layout of a structure can differ, depending on compiler options. [p157]\n\n\nThe binary formats used to store multibyte integers and floating-point values differ among machine architectures\n\n\n\n\nPositioning a Stream\n\n\napue_ftell.h\n\n\n#include \nstdio.h\n\n\n\nlong\n \nftell\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: current file position indicator if OK, \u22121L on error */\n\n\n\nint\n \nfseek\n(\nFILE\n \n*\nfp\n,\n \nlong\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nvoid\n \nrewind\n(\nFILE\n \n*\nfp\n);\n\n\n\n\n\n\n\n\nftell\n: return file's position indicator (bytes from the beginning of the file)\n\n\nfseek\n:\n\n\nBinary file: \nwhence\n can be \nSEEK_SET\n, \nSEEK_CUR\n, and \nSEEK_END\n\n\nText file: \nwhence\n has to be \nSEEK_SET\n; \noffset\n can only be 0 (rewind the file to its beginning) or a value that was returned by \nftell\n for that file.\n\n\n\n\n\n\nrewind\n: set the stream to the beginning of the file\n\n\n\n\napue_ftello.h\n\n\n#include \nstdio.h\n\n\n\noff_t\n \nftello\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: current file position indicator if OK, (off_t)\u22121 on error */\n\n\n\nint\n \nfseeko\n(\nFILE\n \n*\nfp\n,\n \noff_t\n \noffset\n,\n \nint\n \nwhence\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\napue_fgetpos.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfgetpos\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nfpos_t\n \n*\nrestrict\n \npos\n);\n\n\nint\n \nfsetpos\n(\nFILE\n \n*\nfp\n,\n \nconst\n \nfpos_t\n \n*\npos\n);\n\n\n\n/* Both return: 0 if OK, nonzero on error */\n\n\n\n\n\n\nFormatted I/O\n\n\nFormatted Output\n\n\napue_printf.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nprintf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nfprintf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \ndprintf\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n\n/* All three return: number of characters output if OK, negative value if output error */\n\n\n\nint\n \nsprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n/* Returns: number of characters stored in array if OK, negative value if encoding error */\n\n\n\nint\n \nsnprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nn\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n/* Returns: number of characters that would have been stored in array if buffer was\n\n\n   large enough, negative value if encoding error */\n\n\n\n\n\n\n\n\nsprintf\n: automatically appends a null byte at the end of the array, but this null byte is not included in the return value. \nsprintf\n is possible to overflow the buffer.\n\n\nsnprintf\n: returns the number of characters that would have been written to the buffer had it been big enough. If \nsnprintf\n returns a positive value less than the buffer size n, then the output was not truncated.\n\n\n\n\nConversion specification\n\n\n%[flags][fldwidth][precision][lenmodifier]convtype\n\n\n\n\n\n\n\n\n\n\nFlag\n\n\n\n\n\n\n\n\nFlag\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n\u2019\n\n\n(apostrophe) format integer with thousands grouping characters\n\n\n\n\n\n\n-\n\n\nleft-justify the output in the field\n\n\n\n\n\n\n+\n\n\nalways display sign of a signed conversion\n\n\n\n\n\n\n(space)\n\n\nprefix by a space if no sign is generated\n\n\n\n\n\n\n#\n\n\nconvert using alternative form (include 0x prefix for hexadecimal format, for example)\n\n\n\n\n\n\n0\n\n\nprefix with leading zeros instead of padding with spaces\n\n\n\n\n\n\n\n\n\n\n\n\nfldwidth\n specifies a minimum field width for the conversion\n\n\n\n\nprecision\n specifies the minimum number of digits to appear for integer conversions, the minimum number of digits to appear to the right of the decimal point for floating-point conversions, or the maximum number of bytes for string conversions\n\n\n\n\nlenmodifier\n pecifies the size of the argument\n\n\n\n\n\n\n\n\nLength modifier\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nhh\n\n\nsigned or unsigned \nchar\n\n\n\n\n\n\nh\n\n\nsigned or unsigned \nshort\n\n\n\n\n\n\nl\n\n\nsigned or unsigned \nlong\n or wide character\n\n\n\n\n\n\nll\n\n\nsigned or unsigned \nlong\n \nlong\n\n\n\n\n\n\nj\n\n\nintmax_t\n or \nuintmax_t\n\n\n\n\n\n\nz\n\n\nsize_t\n\n\n\n\n\n\nt\n\n\nptrdiff_t\n\n\n\n\n\n\nL\n\n\nlong double\n\n\n\n\n\n\n\n\n\n\n\n\nconvtype\n is required.\n\n\n\n\n\n\n\n\n\n\n\n\nConversion type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nd\n,\ni\n\n\nsigned decimal\n\n\n\n\n\n\no\n\n\nunsigned octal\n\n\n\n\n\n\nu\n\n\nunsigned decimal\n\n\n\n\n\n\nx\n,\nX\n\n\nunsigned hexadecimal\n\n\n\n\n\n\nf\n,\nF\n\n\ndouble floating-point number\n\n\n\n\n\n\ne\n,\nE\n\n\ndouble floating-point number in exponential format\n\n\n\n\n\n\ng\n,\nG\n\n\ninterpreted as \nf\n, \nF\n, \ne\n, or \nE\n, depending on value converted\n\n\n\n\n\n\na\n,\nA\n\n\ndouble floating-point number in hexadecimal exponential format\n\n\n\n\n\n\nc\n\n\ncharacter (with \nl\n length modifier, wide character)\n\n\n\n\n\n\ns\n\n\nstring (with \nl\n length modifier, wide character string)\n\n\n\n\n\n\np\n\n\npointer to a void\n\n\n\n\n\n\nn\n\n\npointer to a signed integer into which is written the number of characters written so far\n\n\n\n\n\n\n%\n\n\na \n%\n character\n\n\n\n\n\n\nC\n\n\nwide character (XSI option, equivalent to \nlc\n)\n\n\n\n\n\n\nS\n\n\nwide character string (XSI option, equivalent to \nls\n)\n\n\n\n\n\n\n\n\nWith the normal conversion specification, conversions are applied to the arguments in the order they appear after the format argument. An alternative conversion specification syntax allows the arguments to be named explicitly with the sequence \n%n$\n representing the \nn\nth argument.\n\n\nThe following five variants of the printf family are similar to the previous five, but the variable argument list (\n...\n) is replaced with \narg\n.\n\n\napue_vprintf.h\n\n\n#include \nstdarg.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nvprintf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\nint\n \nvfprintf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n\n             \nva_list\n \narg\n);\n\n\nint\n \nvdprintf\n(\nint\n \nfd\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* All three return: number of characters output if OK, negative value if output error */\n\n\n\nint\n \nvsprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* Returns: number of characters stored in array if OK, negative value if encoding error */\n\n\n\nint\n \nvsnprintf\n(\nchar\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nn\n,\n\n              \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \nva_list\n \narg\n);\n\n\n\n/* Returns: number of characters that would have been stored in array if buffer was\n\n\n   large enough, negative value if encoding error */\n\n\n\n\n\n\nFormatted Output\n\n\napue_scanf.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nscanf\n(\nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nfscanf\n(\nFILE\n \n*\nrestrict\n \nfp\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\nint\n \nsscanf\n(\nconst\n \nchar\n \n*\nrestrict\n \nbuf\n,\n \nconst\n \nchar\n \n*\nrestrict\n \nformat\n,\n \n...);\n\n\n\n/* All three return: number of input items assigned, EOF if input error\n\n\n   or end of file before any conversion */\n\n\n\n\n\n\nExcept for the conversion specifications and white space, other characters in the format have to match the input. If a character doesn\u2019t match, processing stops, leaving the remainder of the input unread.\n\n\nConversion specification\n\n\n%[*][fldwidth][m][lenmodifier]convtype\n\n\n\n\n\n\n\n\n*\n (leading asterisk) causes the result not stored in an argument\n\n\n\n\nm\n: \nassignment-allocation character\n, used with the \n%c\n, \n%s\n, and \n%[\n to force a memory  buffer to be allocated to hold the converted string. The caller is responsible for freeing the buffer.\n\n\n\n\n\n\nconvtype\n\n\n\n\n\n\n\n\n\n\n\n\nConversion type\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nd\n\n\nsigned decimal, base 10\n\n\n\n\n\n\ni\n\n\nsigned decimal, base determined by format of input\n\n\n\n\n\n\no\n\n\nunsigned octal (input optionally signed)\n\n\n\n\n\n\nu\n\n\nunsigned decimal, base 10 (input optionally signed)\n\n\n\n\n\n\nx\n,\nX\n\n\nunsigned hexadecimal (input optionally signed)\n\n\n\n\n\n\na\n,\nA\n,\ne\n,\nE\n,\nf\n,\nF\n,\ng\n,\nG\n\n\nfloating-point number\n\n\n\n\n\n\nc\n\n\ncharacter (with \nl\n length modifier, wide character)\n\n\n\n\n\n\ns\n\n\nstring (with \nl\n length modifier, wide character string)\n\n\n\n\n\n\n[\n\n\nmatches a sequence of listed characters, ending with \n]\n\n\n\n\n\n\n[\u02c6\n\n\nmatches all characters except the ones listed, ending with \n]\n\n\n\n\n\n\np\n\n\npointer to a void\n\n\n\n\n\n\nn\n\n\npointer to a signed integer into which is written the number of characters read so far\n\n\n\n\n\n\n%\n\n\na \n%\n character\n\n\n\n\n\n\nC\n\n\nwide character (XSI option, equivalent to \nlc\n)\n\n\n\n\n\n\nS\n\n\nwide character string (XSI option, equivalent to \nls\n)\n\n\n\n\n\n\n\n\nImplementation Details\n\n\napue_fileno.h\n\n\n#include \nstdio.h\n\n\n\nint\n \nfileno\n(\nFILE\n \n*\nfp\n);\n\n\n\n/* Returns: the file descriptor associated with the stream */\n\n\n\n\n\n\nEach standard I/O stream has an associated file descriptor, and we can obtain the descriptor for a stream by calling \nfileno\n.\n\n\n\n\nFILE\n implementaion in GNU C.\n\n\nbuf.c\n (Figure 5.11): print buffering for various standard I/O streams\n\n\n\n\nResult on OS X 10.10:\n\n\n$ ./buf\nenter any character\n\none line to standard error\nstream = stdin, line buffered, buffer size = 4096\nstream = stdout, line buffered, buffer size = 4096\nstream = stderr, unbuffered, buffer size = 1\nstream = /etc/passwd, fully buffered, buffer size = 4096\n\n$ ./buf \n /etc/group \n std.out 2\n std.err\n$ cat std.out\nenter any character\nstream = stdin, fully buffered, buffer size = 4096\nstream = stdout, fully buffered, buffer size = 4096\nstream = stderr, unbuffered, buffer size = 1\nstream = /etc/passwd, fully buffered, buffer size = 4096\n$ cat std.err\none line to standard error\n\n\n\n\n\nTemporary Files\n\n\napue_tmpnam.h\n\n\n#include \nstdio.h\n\n\n\nchar\n \n*\ntmpnam\n(\nchar\n \n*\nptr\n);\n\n\nFILE\n \n*\ntmpfile\n(\nvoid\n);\n\n\n\n/* Returns: pointer to unique pathname Returns: file pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\ntmpnam\n: generates a string that is a valid pathname that does not match any existing file. This function generates a different pathname each time it is called, up to \nTMP_MAX\n times.\n\n\nWhen \nptr\n is \nNULL\n: pathname is stored in a static area\n\n\nWhen \nptr\n is not \nNULL\n: it is assumed that it points to an array of at least \nL_tmpnam\n characters. The generated pathname is stored in this array, and \nptr\n is returned as the value of the function.\n\n\n\n\n\n\ntmpfile\n: creates a temporary binary file (type \nwb+\n) that is automatically removed when it is closed or on program termination.\n\n\n\n\napue_mkdtemp.h\n\n\n#include \nstdlib.h\n\n\n\nchar\n \n*\nmkdtemp\n(\nchar\n \n*\ntemplate\n);\n\n\n\n/* Returns: pointer to directory name if OK, NULL on error */\n\n\n\nint\n \nmkstemp\n(\nchar\n \n*\ntemplate\n);\n\n\n\n/* Returns: file descriptor if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nmkdtemp\n: creates a uniquely named directory\n\n\nmkstemp\n: creates a uniquely named regular file\n\n\ntemplate\n: a pathname whose last six characters are set to \nXXXXXX\n (\n/tmp/dirXXXXXX\n)\n\n\n\n\nUnlike \ntmpfile\n, the temporary file created by \nmkstemp\n is not removed automatically for us.\n\n\nThe \ntmpfile\n and \nmkstemp\n functions should be used instead of \ntmpnam\n. [p169]\n\n\nExample:\n\n\n\n\napue_stdio_mkstemp.c\n: the array variable is allocated on the stacl. For a pointer to a string literal, only the pointer itself resides on the stack; the (constant) string is stored in the read-only segment of the program.\n\n\n\n\nMemory Streams\n\n\nMemory streams\n are standard I/O streams for which there are no underlying files, although they are still accessed with \nFILE\n pointers. All I/O is done by transferring bytes to and from buffers in main memory.\n\n\napue_fmemopen.h\n\n\n#include \nstdio.h\n\n\n\nFILE\n \n*\nfmemopen\n(\nvoid\n \n*\nrestrict\n \nbuf\n,\n \nsize_t\n \nsize\n,\n\n               \nconst\n \nchar\n \n*\nrestrict\n \ntype\n);\n\n\n\n/* Returns: stream pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\nbuf\n: points to the beginning of the user-allocated buffer and the size argument specifies the size of the buffer in bytes. If the buf argument is null, then the fmemopen function allocates a buffer of \nsize\n bytes.\n\n\ntype\n: controls how the stream can be used [p171]\n\n\n\n\nNote:\n\n\n\n\nUnder append mode, the current file position is set to the first null byte in the buffer. If the buffer contains no null bytes, then the current position is set to one byte past the end of the buffer. Under non-append mode, the current position is set to the beginning of the buffer. Thus, memory streams aren\u2019t well suited for storing binary data (which might contain null bytes before the end of the data).\n\n\nIf the \nbuf\n argument is a null pointer, it makes no sense to open the stream for only reading or only writing. Because the buffer is allocated by \nfmemopen\n in this case, there is no way to find the buffer's address\n\n\nA null byte is written at the current position in the stream whenever we increase the amount of data in the stream\u2019s buffer and call \nfclose\n, \nfflush\n, \nfseek\n, \nfseeko\n, or \nfsetpos\n.\n\n\n\n\nAlternatives to Standard I/O\n\n\nWhen we use the line-at-a-time functions, \nfgets\n and \nfputs\n, the data is usually copied twice: once between the kernel and the standard I/O buffer (when the corresponding read or write is issued) and again between the standard I/O buffer and our line buffer.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nSection 5.4 on line buffering [p145]\n\n\n\n\nSecond, whenever input is requested through the standard I/O library from either (a) an unbuffered stream or (b) a line-buffered stream (that requires data to be requested from the kernel), all line-buffered output streams are flushed. The reason for the qualifier on (b) is that the requested data may already be in the buffer, which doesn\u2019t require data to be read from the kernel. Obviously, any input from an unbuffered stream, item (a), requires data to be obtained from the kernel.\n\n\n\n\nSection 5.8 Standard I/O Efficiency [p155]\n\n\n\n\nThe version using line-at-a-time I/O is almost twice as fast as the version using character-at-a-time I/O. If the fgets and fputs functions are implemented using getc and putc, then we would expect the timing to be similar to the getc version. Actually, we might expect the line-at-a-time version to take longer, since we would be adding the overhead of 200 million extra function calls to the existing 6 million ones.\n\n\n\n\nSection 5.14 on Memory Stream [p172]\n\n\n\n\nThird, a null byte is written at the current position in the stream whenever we increase the amount of data in the stream\u2019s buffer and call fclose, fflush, fseek, fseeko, or fsetpos.", 
            "title": "Chapter 5. Standard I/O Library"
        }, 
        {
            "location": "/apue/ch6/", 
            "text": "Chapter 6. System Data Files and Information\n\n\nThis chapter covers portable interfaces to data files, system identification functions and the time and date functions.\n\n\nPassword File\n\n\nThe UNIX System's password file, called the user database by POSIX.1, contains the following fields:\n\n\n\n\nHistorically, the password file has been stored in \n/etc/passwd\n and has been an ASCII file.\n\n\n\n\nroot\n has a user ID of 0 (superuser)\n\n\nThe encrypted password field contains a single character as a placeholder (\nx\n)\n\n\nSome fields can be empty\n\n\nThe shell field contains the user's login shell. The default value for an empty shell field is usually \n/bin/sh\n. Other executable that prevents a user from loggin in to a system:\n\n\n/dev/null\n\n\n/bin/false\n: exits with an unsuccessful (nonzero) status\n\n\n/bin/true\n: exits with a successful (zero) status\n\n\nnologin\n: prints a customizable error message and exits with a nonzero exit status\n\n\n\n\n\n\nnobody\n user name can be used to allow people to log in to a system, but with a user ID (65534) and group ID (65534) that provide no privileges.\n\n\nSome systems that provide the \nfinger(1)\n command support additional information in the comment field\n\n\n\n\nSome systems provide the \nvipw\n command to allow administrators to edit the password file.\n\n\napue_getpwuid.h\n\n\n#include \npwd.h\n\n\n\nstruct\n \npasswd\n \n*\ngetpwuid\n(\nuid_t\n \nuid\n);\n\n\nstruct\n \npasswd\n \n*\ngetpwnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\n\n\n\n\n\ngetpwuid\n: used by the \nls(1)\n program to map the numerical user ID contained in an i-node into a user's login name.\n\n\ngetpwnam\n: used by the \nlogin(1)\n program when we enter our login name\n\n\n\n\nBoth functions return a pointer to a passwd structure that the functions fill in. \nThis structure is usually a static variable within the function, so its contents are overwritten each time we call either of these functions.\n\n\napue_getpwent.h\n\n\n#include \npwd.h\n\n\n\nstruct\n \npasswd\n \n*\ngetpwent\n(\nvoid\n);\n\n\n\n/* Returns: pointer if OK, NULL on error or end of file */\n\n\n\nvoid\n \nsetpwent\n(\nvoid\n);\n\n\nvoid\n \nendpwent\n(\nvoid\n);\n\n\n\n\n\n\n\n\ngetpwent\n: returns the next entry (a pointer to a structure that it has filled in, this structure is overwritten each time we call this function) in the password file.\n\n\nsetpwent\n: rewinds files\n\n\nendpwent\n: closes files\n\n\n\n\nExample:\n\n\n\n\ngetpwnam.c\n\n\n\n\nsetpwent\n at the beginning of this function is self-defense: we ensure that the files are rewound, in case the caller has already opened them by calling getpwent.\n\n\nShadow Passwords\n\n\nSystems store the encrypted password in another file, often called the \nshadow password file\n. Minimally, this file has to contain the user name and the encrypted password.\n\n\n\n\nThe shadow password file should not be readable by the world. Only a few programs need to access encrypted passwords, e.g. \nlogin(1)\n and \npasswd(1)\n, and these programs are often set-user-ID root. With shadow passwords, the regular password file, \n/etc/passwd\n, can be left readable by the world.\n\n\napue_getspnam.h\n\n\n#include \nshadow.h\n\n\n\nstruct\n \nspwd\n \n*\ngetspnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\nstruct\n \nspwd\n \n*\ngetspent\n(\nvoid\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\nvoid\n \nsetspent\n(\nvoid\n);\n\n\nvoid\n \nendspent\n(\nvoid\n);\n\n\n\n\n\n\nGroup File\n\n\nThe UNIX System\u2019s group file, called the group database by POSIX.1, contains the following fields:\n\n\n\n\nThe field \ngr_mem\n is an array of pointers to the user names that belong to this group. This array is terminated by a null pointer.\n\n\napue_getgrgid.h\n\n\n#include \ngrp.h\n\n\n\nstruct\n \ngroup\n \n*\ngetgrgid\n(\ngid_t\n \ngid\n);\n\n\nstruct\n \ngroup\n \n*\ngetgrnam\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: pointer if OK, NULL on error */\n\n\n\n\n\n\nLike the password file functions, both of these functions normally return pointers to a static variable, which is overwritten on each call.\n\n\napue_getgrent.h\n\n\n#include \ngrp.h\n\n\n\nstruct\n \ngroup\n \n*\ngetgrent\n(\nvoid\n);\n\n\n\n/* Returns: pointer if OK, NULL on error or end of file */\n\n\n\nvoid\n \nsetgrent\n(\nvoid\n);\n\n\nvoid\n \nendgrent\n(\nvoid\n);\n\n\n\n\n\n\n\n\ngetgrent\n: reads the next entry from the group file, opening the file first, if it\u2019s not already open\n\n\n\n\nSupplementary Group IDs\n\n\nnewgrp(1)\n can be used to change the real group ID to the new group\u2019s ID. We could always go back to our original group (as listed in \n/etc/passwd\n) by executing \nnewgrp\n without any arguments.\n\n\nWith 4.2BSD, the concept of \nsupplementary group IDs\n was introduced. The file access permission checks were modified so that in addition to comparing the the file\u2019s group ID to the process effective group ID, it was also compared to all the supplementary group IDs.\n\n\nThe constant \nNGROUPS_MAX\n specifies the number of supplementary group IDs.\n\n\napue_getgroups.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ngetgroups\n(\nint\n \ngidsetsize\n,\n \ngid_t\n \ngrouplist\n[]);\n\n\n\n/* Returns: number of supplementary group IDs if OK, \u22121 on error */\n\n\n\n#include \ngrp.h\n \n/* on Linux */\n\n\n#include \nunistd.h\n \n/* on FreeBSD, Mac OS X, and Solaris */\n\n\n\nint\n \nsetgroups\n(\nint\n \nngroups\n,\n \nconst\n \ngid_t\n \ngrouplist\n[]);\n\n\n\n#include \ngrp.h\n \n/* on Linux and Solaris */\n\n\n#include \nunistd.h\n \n/* on FreeBSD and Mac OS X */\n\n\n\nint\n \ninitgroups\n(\nconst\n \nchar\n \n*\nusername\n,\n \ngid_t\n \nbasegid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ngetgroups\n\n\ngidsetsize\n \n 0: the function fills in the array up to \ngidsetsize\n supplementary group IDs\n\n\ngidsetsize\n = 0: the function returns only the number of supplementary group IDs; \ngrouplist\n is not modified\n\n\n\n\n\n\nsetgroups\n: called by the superuser to set the supplementary group ID list for the calling process\n\n\ninitgroups\n: reads the entire group file with the functions \ngetgrent\n, \nsetgrent\n, and \nendgrent\n and determines the group membership for username.  It then calls setgroups to initialize the supplementary group ID list for the user. It includes \nbasegid\n in the supplementary group ID list; basegid is the group ID from the password file for username. See \nSetting the Group IDs\n\n\n\n\nImplementation Differences\n\n\n[p184-185]\n\n\nOther Data Files\n\n\nNumerous other files are used by UNIX systems in normal day-to-day operation.\n\n\nServices and networks:\n\n\n\n\n/etc/services\n\n\n/etc/protocols\n\n\n/etc/networks\n\n\n\n\nThe general principle is that every data file has at least three functions:\n\n\n\n\nget\n: reads the next record, opening the file\n\n\nset\n: opens the file, if not already open, and rewinds the file\n\n\nend\n: closes the data file\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\nData file\n\n\nHeader\n\n\nStructure\n\n\nAdditional keyed lookup functions\n\n\n\n\n\n\n\n\n\n\npasswords\n\n\n/etc/passwd\n\n\npwd.h\n\n\npasswd\n\n\ngetpwnam\n, \ngetpwuid\n\n\n\n\n\n\ngroups\n\n\n/etc/group\n\n\ngrp.h\n\n\ngroup\n\n\ngetgrnam\n, \ngetgrgid\n\n\n\n\n\n\nshadow\n\n\n/etc/shadow\n\n\nshadow.h\n\n\nspwd\n\n\ngetspnam\n\n\n\n\n\n\nhosts\n\n\n/etc/hosts\n\n\nnetdb.h\n\n\nhostent\n\n\ngetnameinfo\n, \ngetaddrinfo\n\n\n\n\n\n\nnetworks\n\n\n/etc/networks\n\n\nnetdb.h\n\n\nnetent\n\n\ngetnetbyname\n, \ngetnetbyaddr\n\n\n\n\n\n\nprotocols\n\n\n/etc/protocols\n\n\nnetdb.h\n\n\nprotoent\n\n\ngetprotobyname\n, \ngetprotobynumber\n\n\n\n\n\n\nservices\n\n\n/etc/services\n\n\nnetdb.h\n\n\nservent\n\n\ngetservbyname\n, \ngetservbyport\n\n\n\n\n\n\n\n\nLogin Accounting\n\n\nTwo data files provided with most UNIX systems:\n\n\n\n\nutmp\n: keeps track of all the users currently logged in\n\n\nwtmp\n: keeps track of all logins and logouts\n\n\n\n\nstruct\n \nutmp\n \n{\n\n    \nchar\n \nut_line\n[\n8\n];\n \n/* tty line: \nttyh0\n, \nttyd0\n, \nttyp0\n, ... */\n\n    \nchar\n \nut_name\n[\n8\n];\n \n/* login name */\n\n    \nlong\n \nut_time\n;\n \n/* seconds since Epoch */\n\n\n};\n\n\n\n\n\n\nOn login, the \nlogin\n program fills one of these structures, and writes it to the \nutmp\n and \nwtmp\n file. On logout, the \ninit\n process erases this entry (fills with null bytes) in \nutmp\n file and appends a new logout entry. This logout entry in the \nwtmp\n file had the \nut_name\n field zeroed out. Special entries were appended to the \nwtmp\n file to indicate when the system was rebooted and right before and after the system\u2019s time and date was changed.\n\n\nThe \nwho(1)\n program read the \nutmp\n file and printed its contents in a readable form\n\n\nSystem Identification\n\n\napue_uname.h\n\n\n#include \nsys/utsname.h\n\n\n\nint\n \nuname\n(\nstruct\n \nutsname\n \n*\nname\n);\n\n\n\n/* Returns: non-negative value if OK, \u22121 on error */\n\n\n\n\n\n\nstruct\n \nutsname\n \n{\n\n    \nchar\n \nsysname\n[];\n \n/* name of the operating system */\n\n    \nchar\n \nnodename\n[];\n \n/* name of this node */\n\n    \nchar\n \nrelease\n[];\n \n/* current release of operating system */\n\n    \nchar\n \nversion\n[];\n \n/* current version of this release */\n\n    \nchar\n \nmachine\n[];\n \n/* name of hardware type */\n\n\n};\n\n\n\n\n\n\napue_gethostname.h\n\n\n#include \nunistd.h\n\n\n\nint\n \ngethostname\n(\nchar\n \n*\nname\n,\n \nint\n \nnamelen\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\ngethostname\n (now defined as part of POSIX.1) specifies that the maximum host name length is \nHOST_NAME_MAX\n.\n\n\n\n\n\n\n\n\nInterface\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nuname\n\n\n256\n\n\n65\n\n\n256\n\n\n257\n\n\n\n\n\n\ngethostname\n\n\n256\n\n\n64\n\n\n256\n\n\n256\n\n\n\n\n\n\n\n\nIf the host is connected to a TCP/IP network, the \nhost name is normally the fully qualified domain name of the host.\n\n\nThere is also a \nhostname(1)\n command that can fetch or set the host name. (The host name is set by the superuser using a similar function, \nsethostname\n.) The host name is normally set at bootstrap time from one of the start-up files invoked by \n/etc/rc\n or \ninit\n.\n\n\nTime and Date Routines\n\n\nCalendar times\n: number of seconds (represented in a \ntime_t\n data type) that have passed since the \nEpoch\n: 00:00:00 January 1, 1970, Coordinated Universal Time (UTC). These calendar times represent both the time and the date. The UNIX System has always differed from other operating systems in:\n\n\n\n\nkeeping time in UTC instead of the local time\n\n\nautomatically handling conversions, such as daylight saving time\n\n\nkeeping the time and date as a single quantity\n\n\n\n\nThe \ntime\n function returns the current time and date.\n\n\napue_time.h\n\n\n#include \ntime.h\n\n\n\ntime_t\n \ntime\n(\ntime_t\n \n*\ncalptr\n);\n\n\n\n/* Returns: value of time if OK, \u22121 on error */\n\n\n\n\n\n\nThe time value is always returned as the value of the function. If the argument is non-null, the time value is also stored at the location pointed to by \ncalptr\n.\n\n\nClock type identifiers\n\n\nThe real-time extensions to POSIX.1 added support for multiple system clocks. A clock is identified by the \nclockid_t\n type.\n\n\n\n\n\n\n\n\nIdentifier\n\n\nOption\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCLOCK_REALTIME\n\n\n\n\nreal system time\n\n\n\n\n\n\nCLOCK_MONOTONIC\n\n\n_POSIX_MONOTONIC_CLOCK\n\n\nreal system time with no negative jumps\n\n\n\n\n\n\nCLOCK_PROCESS_CPUTIME_ID\n\n\n_POSIX_CPUTIME\n\n\nCPU time for calling process\n\n\n\n\n\n\nCLOCK_THREAD_CPUTIME_ID\n\n\n_POSIX_THREAD_CPUTIME\n\n\nCPU time for calling thread\n\n\n\n\n\n\n\n\napue_clock_gettime.h\n\n\n#include \nsys/time.h\n\n\n\nint\n \nclock_gettime\n(\nclockid_t\n \nclock_id\n,\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \nclock_getres\n(\nclockid_t\n \nclock_id\n,\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \nclock_settime\n(\nclockid_t\n \nclock_id\n,\n \nconst\n \nstruct\n \ntimespec\n \n*\ntsp\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\nint\n \ngettimeofday\n(\nstruct\n \ntimeval\n \n*\nrestrict\n \ntp\n,\n \nvoid\n \n*\nrestrict\n \ntzp\n);\n\n\n/* Returns: 0 always */\n\n\n\n\n\n\n\n\nclock_gettime\n: gets the time of the specified clock. The time is returned in a \ntimespec\n structure\n\n\nclock_getres\n: determines the resolution of a given system clock. It initializes the \ntimespec\n structure pointed to by the \ntsp\n\n\nclock_settime\n: sets the time for a particular clock.\n\n\ngettimeofday\n: now obsolescent. The only legal value for \ntzp\n is \nNULL\n.\n\n\n\n\nOnce we have the integer value that counts the number of seconds since the Epoch, we normally call a function to convert it to a broken-down time structure, and then call another function to generate a human-readable time and date.\n\n\n\n\nThe two functions \nlocaltime\n and \ngmtime\n convert a calendar time into a broken-down time, a \ntm\n structure.\n\n\nstruct\n \ntm\n \n{\n \n/* a broken-down time */\n\n    \nint\n \ntm_sec\n;\n \n/* seconds after the minute: [0 - 60] */\n\n    \nint\n \ntm_min\n;\n \n/* minutes after the hour: [0 - 59] */\n\n    \nint\n \ntm_hour\n;\n \n/* hours after midnight: [0 - 23] */\n\n    \nint\n \ntm_mday\n;\n \n/* day of the month: [1 - 31] */\n\n    \nint\n \ntm_mon\n;\n \n/* months since January: [0 - 11] */\n\n    \nint\n \ntm_year\n;\n \n/* years since 1900 */\n\n    \nint\n \ntm_wday\n;\n \n/* days since Sunday: [0 - 6] */\n\n    \nint\n \ntm_yday\n;\n \n/* days since January 1: [0 - 365] */\n\n    \nint\n \ntm_isdst\n;\n \n/* daylight saving time flag: \n0, 0, \n0 */\n\n\n};\n\n\n\n\n\n\nThe reason that the seconds can be greater than 59 is to allow for a \nleap second\n.\n\n\napue_gmtime.h\n\n\n#include \ntime.h\n\n\n\nstruct\n \ntm\n \n*\ngmtime\n(\nconst\n \ntime_t\n \n*\ncalptr\n);\n\n\nstruct\n \ntm\n \n*\nlocaltime\n(\nconst\n \ntime_t\n \n*\ncalptr\n);\n\n\n\n/* Both return: pointer to broken-down time, NULL on error */\n\n\n\n\n\n\n\n\ngmtime\n: converts the calendar time to UTC time (broken time)\n\n\nlocaltime\n: converts the calendar time to local time (broken time)\n\n\nmktime\n: takes a broken-down time, expressed as a local time, and converts it into a \ntime_t\n value\n\n\nThe \nstrftime\n and \nstrftime_l\n functions are the same, except that the \nstrftime_l\n function allows the caller to specify the locale as an argument. The strftime function uses the locale specified by the \nTZ\n environment variable\n\n\ntmptr\n argument is the time value to format, specified by a pointer to a broken-down time value. [p192]\n\n\nformat\n argument controls the formatting of the time value\n\n\n\n\n\n\n\n\nConversion specifiers for \nstrftime\n\n\n\n\n\n\n\n\nFormat\n\n\nDescription\n\n\nExample\n\n\n\n\n\n\n\n\n\n\n%a\n\n\nabbreviated weekday name\n\n\nThu\n\n\n\n\n\n\n%A\n\n\nfull weekday name\n\n\nThursday\n\n\n\n\n\n\n%b\n\n\nabbreviated month name\n\n\nJan\n\n\n\n\n\n\n%B\n\n\nfull month name\n\n\nJanuary\n\n\n\n\n\n\n%c\n\n\ndate and time\n\n\nThu Jan 19 21:24:52 2012\n\n\n\n\n\n\n%C\n\n\nyear/100: [00\u201399]\n\n\n20\n\n\n\n\n\n\n%d\n\n\nday of the month: [01\u201331]\n\n\n19\n\n\n\n\n\n\n%D\n\n\ndate [MM/DD/YY]\n\n\n01/19/12\n\n\n\n\n\n\n%e\n\n\nday of month (single digit preceded by space) [1\u201331]\n\n\n19\n\n\n\n\n\n\n%F\n\n\nISO 8601 date format [YYYY\u2013MM\u2013DD]\n\n\n2012-01-19\n\n\n\n\n\n\n%g\n\n\nlast two digits of ISO 8601 week-based year [00\u201399]\n\n\n12\n\n\n\n\n\n\n%G\n\n\nISO 8601 week-based year\n\n\n2012\n\n\n\n\n\n\n%h\n\n\nsame as \n%b\n\n\nJan\n\n\n\n\n\n\n%H\n\n\nhour of the day (24-hour format): [00\u201323]\n\n\n21\n\n\n\n\n\n\n%I\n\n\nhour of the day (12-hour format): [01\u201312]\n\n\n09\n\n\n\n\n\n\n%j\n\n\nday of the year: [001\u2013366]\n\n\n019\n\n\n\n\n\n\n%m\n\n\nmonth: [01\u201312]\n\n\n01\n\n\n\n\n\n\n%M\n\n\nminute: [00\u201359]\n\n\n24\n\n\n\n\n\n\n%n\n\n\nnewline character\n\n\n\n\n\n\n\n\n%p\n\n\nAM/PM\n\n\nPM\n\n\n\n\n\n\n%r\n\n\nlocale\u2019s time (12-hour format)\n\n\n09:24:52 PM\n\n\n\n\n\n\n%R\n\n\nsame as \n%H:%M\n\n\n21:24\n\n\n\n\n\n\n%S\n\n\nsecond: [00\u201360]\n\n\n52\n\n\n\n\n\n\n%t\n\n\nhorizontal tab character\n\n\n\n\n\n\n\n\n%T\n\n\nsame as \n%H:%M:%S\n\n\n21:24:52\n\n\n\n\n\n\n%u\n\n\nISO 8601 weekday [Monday = 1, 1\u20137]\n\n\n4\n\n\n\n\n\n\n%U\n\n\nSunday week number: [00\u201353]\n\n\n03\n\n\n\n\n\n\n%V\n\n\nISO 8601 week number: [01\u201353]\n\n\n03\n\n\n\n\n\n\n%w\n\n\nweekday: [0 = Sunday, 0\u20136]\n\n\n4\n\n\n\n\n\n\n%W\n\n\nMonday week number: [00\u201353]\n\n\n03\n\n\n\n\n\n\n%x\n\n\nlocale\u2019s date 01/19/\n\n\n12\n\n\n\n\n\n\n%X\n\n\nlocale\u2019s time 21:24:\n\n\n52\n\n\n\n\n\n\n%y\n\n\nlast two digits of year: [00\u201399]\n\n\n12\n\n\n\n\n\n\n%Y\n\n\nyear\n\n\n2012\n\n\n\n\n\n\n%z\n\n\noffset from UTC in ISO 8601 format\n\n\n-0500\n\n\n\n\n\n\n%Z\n\n\ntime zone name\n\n\nEST\n\n\n\n\n\n\n%%\n\n\ntranslates to a percent sign\n\n\n%\n\n\n\n\n\n\n\n\n\n\nstrftime\n example: \nstrftime.c\n\n\n\n\nConversion specifiers for \nstrptime\n\n\n\n\n\n\n\n\nFormat\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n%a\n\n\nabbreviated or full weekday name\n\n\n\n\n\n\n%A\n\n\nsame as \n%a\n\n\n\n\n\n\n%b\n\n\nabbreviated or full month name\n\n\n\n\n\n\n%B\n\n\nsame as \n%b\n\n\n\n\n\n\n%c\n\n\ndate and time\n\n\n\n\n\n\n%C\n\n\nall but the last two digits of the year\n\n\n\n\n\n\n%d\n\n\nday of the month: [01\u201331]\n\n\n\n\n\n\n%D\n\n\ndate [MM/DD/YY]\n\n\n\n\n\n\n%e\n\n\nsame as \n%d\n\n\n\n\n\n\n%h\n\n\nsame as \n%b\n\n\n\n\n\n\n%H\n\n\nhour of the day (24-hour format): [00\u201323]\n\n\n\n\n\n\n%I\n\n\nhour of the day (12-hour format): [01\u201312]\n\n\n\n\n\n\n%j\n\n\nday of the year: [001\u2013366]\n\n\n\n\n\n\n%m\n\n\nmonth: [01\u201312]\n\n\n\n\n\n\n%M\n\n\nminute: [00\u201359]\n\n\n\n\n\n\n%n\n\n\nany white space\n\n\n\n\n\n\n%p\n\n\nAM/PM\n\n\n\n\n\n\n%r\n\n\nlocale\u2019s time (12-hour format, AM/PM notation)\n\n\n\n\n\n\n%R\n\n\ntime as \n%H:%M\n\n\n\n\n\n\n%S\n\n\nsecond: [00\u201360]\n\n\n\n\n\n\n%t\n\n\nany white space\n\n\n\n\n\n\n%T\n\n\ntime as \n%H:%M:%S\n\n\n\n\n\n\n%U\n\n\nSunday week number: [00\u201353]\n\n\n\n\n\n\n%w\n\n\nweekday: [0 = Sunday, 0\u20136]\n\n\n\n\n\n\n%W\n\n\nMonday week number: [00\u201353]\n\n\n\n\n\n\n%x\n\n\nlocale\u2019s date\n\n\n\n\n\n\n%X\n\n\nlocale\u2019s time\n\n\n\n\n\n\n%y\n\n\nlast two digits of year: [00\u201399]\n\n\n\n\n\n\n%Y\n\n\nyear\n\n\n\n\n\n\n%%\n\n\ntranslates to a percent sign\n\n\n\n\n\n\n\n\nFunctions that are affected by \nTZ\n environment variable. If defined, the value of this environment variable is used by these functions instead of the default time zone:\n\n\n\n\nlocaltime\n\n\nmktime\n\n\nstrftime", 
            "title": "Chapter 6. System Data Files and Information"
        }, 
        {
            "location": "/apue/ch7/", 
            "text": "Chapter 7. Process Environment\n\n\nIntroduction\n\n\nmain\n Function\n\n\nA C program starts execution with a function called \nmain\n:\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[]);\n\n\n\n\n\n\n\n\nargc\n: number of command-line arguments\n\n\nargv\n: an array of pointers to the arguments\n\n\n\n\nWhen a C program is executed by the kernel (by one of the \nexec\n functions), a special start-up routine is called before the \nmain\n function is called. The executable program file specifies this routine as the starting address for the program; this is set up by the link editor (linker) when it is invoked by the C compiler. This start-up routine takes values from the kernel (the command-line arguments and the environment) and sets things up so that the \nmain\n function is called as shown earlier.\n\n\nProcess Termination\n\n\nThere are eight ways for a process to terminate.\n\n\n\n\n\n\nNormal termination occurs in five ways:\n\n\n\n\nReturn from \nmain\n\n\nCalling \nexit\n\n\nCalling \n_exit\n or \n_Exit\n\n\nReturn of the last thread from its start routine (Section 11.5)\n\n\nCalling \npthread_exit\n (Section 11.5) from the last thread\n\n\n\n\n\n\n\n\nAbnormal termination occurs in three ways:\n\n\n\n\nCalling \nabort\n (Section 10.17)\n\n\nReceipt of a signal (Section 10.2)\n\n\nResponse of the last thread to a cancellation request (Sections 11.5 and 12.7)\n\n\n\n\n\n\n\n\nExit Functions\n\n\nThree functions terminate a program normally:\n\n\napue_exit.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \nexit\n(\nint\n \nstatus\n);\n\n\nvoid\n \n_Exit\n(\nint\n \nstatus\n);\n\n\n\n#include \nunistd.h\n\n\n\nvoid\n \n_exit\n(\nint\n \nstatus\n);\n\n\n\n\n\n\n\n\n_exit\n: returns to the kernel immediately\n\n\n_Exit\n: same as \n_exit\n\n\nexit\n: performs certain cleanup processing and then returns to the kernel. Historically, it has always performed a clean shutdown of the standard I/O library: the \nfclose\n function is called for all open streams\n\n\n\n\nAll three exit functions expect a single integer argument (\nexit status\n).\n\n\nThe \nexit status of the process is undefined\n, if any of the following occurs:\n\n\n\n\nAny of these functions is called without an exit status\n\n\nmain\n does a return without a return value\n\n\nmain\n function is not declared to return an integer\n\n\n\n\nIf the return type of main is an integer and main \"falls off the end\" (an implicit return), the exit status of the process is 0.\n\n\nReturning an integer value from the main function is equivalent to calling exit with the same value:\n\n\nexit(0);\n is same as \nreturn(0);\n from the \nmain\n function.\n\n\natexit\n Function\n\n\nWith ISO C, a process can register at least 32 functions that are automatically called by \nexit\n. These are called \nexit handlers\n and are registered by calling the \natexit\n function.\n\n\napue_atexit.h\n\n\n#include \nstdlib.h\n\n\n\nint\n \natexit\n(\nvoid\n \n(\n*\nfunc\n)(\nvoid\n));\n\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\n\n\n\n\n\nfunc\n argument is the address of the function to be called by \nexit\n. When this function is called, it is not passed any arguments and is not expected to return a value. The \nexit\n function calls these functions in reverse order of their registration. Each function is called as many times as it was registered.\n\n\n\n\nWith ISO C and POSIX.1, \nexit\n first calls the exit handlers and then closes (via \nfclose\n) all open streams. POSIX.1 extends the ISO C standard by specifying that any exit handlers installed will be cleared if the program calls any of the \nexec\n family of functions.\n\n\nThe only way a program can be executed by the kernel is if one of the \nexec\n functions is called. \nThe only way a process can voluntarily terminate is if \n_exit\n or \n_Exit\n is called\n, either explicitly or implicitly (by calling \nexit\n). A process can also be involuntarily terminated by a signal.\n\n\nCommand-Line Arguments\n\n\nWhen a program is executed, the process that does the \nexec\n can pass command-line arguments to the new program. This is part of the normal operation of the UNIX system shells.\n\n\nExample:\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n \ni\n;\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nargc\n;\n \ni\n++\n)\n \n/* echo all command-line args */\n\n        \nprintf\n(\nargv[%d]: %s\n\\n\n,\n \ni\n,\n \nargv\n[\ni\n]);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWe are guaranteed by both ISO C and POSIX.1 that argv[argc] is a null pointer. This lets us alternatively code the argument-processing loop as:\n\n\nfor\n \n(\ni\n \n=\n \n0\n;\n \nargv\n[\ni\n]\n \n!=\n \nNULL\n;\n \ni\n++\n)\n\n\n\n\n\n\nEnvironment List\n\n\nEach program is also passed an environment list, which is an array of character pointers, with each pointer containing the address of a null-terminated C string. It is contained in the global variable environ:\n\n\nextern\n \nchar\n \n**\nenviron\n;\n\n\n\n\n\n\n\n\n\n\nenviron\n is called the \nenvironment pointer\n, the array of pointers the environment list, and the strings they point to the \nenvironment strings\n, which by convention is \nname=value\n strings. By convetion, predefined names are entirely uppercase.\n\n\n\n\nMemory Layout of a C Program\n\n\nHistorically, a C program has been composed of the following pieces:\n\n\n\n\nText segment: consists of the machine instructions that the CPU executes\n\n\nInitialized data segment (or simply data segment): contains variables that are specifically initialized in the program\n\n\nUninitialized data segment (often called the \"bss\" segment, which is named after \"block started by symbol\"): data in this segment is initialized by the kernel to arithmetic 0 or null pointers before the program starts executing\n\n\nStack: stores automatic variables, along with information that is saved each time a function is called\n\n\nHeap is where dynamic memory allocation usually takes place\n\n\n\n\n\n\nWith Linux on a 32-bit Intel x86 processor, the text segment starts at location \n0x08048000\n, and the bottom of the stack starts just below \n0xC0000000\n. \nThe stack grows from higher-numbered addresses to lower-numbered addresses on this particular architecture.\n The unused virtual address space between the top of the heap and the top of the stack is large\n\n\nThe \nsize(1)\n command reports the sizes (in bytes) of the text, data, and bss segments:\n\n\n$ \nsize /usr/bin/cc /bin/sh\ntext data bss dec hex filename\n\n346919\n \n3576\n \n6680\n \n357175\n \n57337\n /usr/bin/cc\n\n102134\n \n1776\n \n11272\n \n115182\n 1c1ee /bin/sh\n\n\n\n\n\nShared Libraries\n\n\nShared libraries remove the common library routines from the executable file and maintains a single copy of the library routine somewhere in memory that all processes reference:\n\n\n\n\nPros: reduces the size of each executable file; library functions can be replaced with new versions without having to relink edit every program that uses the library\n\n\nCons: adds some runtime overhead, either when the program is first executed or the first time each shared library function is called\n\n\n\n\nMemory Allocation\n\n\napue_malloc.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \n*\nmalloc\n(\nsize_t\n \nsize\n);\n\n\nvoid\n \n*\ncalloc\n(\nsize_t\n \nnobj\n,\n \nsize_t\n \nsize\n);\n\n\nvoid\n \n*\nrealloc\n(\nvoid\n \n*\nptr\n,\n \nsize_t\n \nnewsize\n);\n\n\n\n/* All three return: non-null pointer if OK, NULL on error */\n\n\n\nvoid\n \nfree\n(\nvoid\n \n*\nptr\n);\n\n\n\n\n\n\n\n\nmalloc\n: allocates a specified number of bytes of memory\n\n\ncalloc\n: allocates space for a specified number of objects of a specified size\n\n\nrealloc\n: increases or decreases the size of a previously allocated area. The final argument to realloc is the new size of the region, not the\ndifference between the old and new sizes\n\n\n\n\nThe pointer returned by the three allocation functions is guaranteed to be suitably aligned so that it can be used for any data object.\n\n\nBecause the three \nalloc\n functions return a generic \nvoid *\n pointer, if we \n#include \nstdlib.h\n (to obtain the function prototypes), we do not explicitly have to cast the pointer returned by these functions when we assign it to a pointer of a different type. \nThe default return value for undeclared functions is int, so using a cast without the proper function declaration could hide an error on systems where the size of type int differs from the size of a function\u2019s return value (a pointer in this case).\n\n\n\n\nfree\n: causes the space pointed to by \nptr\n to be deallocated. This freed space is usually put into a pool of available memory and can be allocated in a later call to one of the three \nalloc\n functions.\n\n\n\n\nThe allocation routines are usually implemented with the \nsbrk(2)\n system call. This system call expands (or contracts) the heap of the process. Although \nsbrk\n can expand or contract the memory of a process, most versions of \nmalloc\n and free never decrease their memory size. \nThe space that we free is available for a later allocation, but the freed space is not usually returned to the kernel; instead, that space is kept in the \nmalloc\n pool.\n\n\nAlternate Memory Allocators\n\n\n[p209]\n\n\n\n\nlibmalloc\n\n\nvmalloc\n\n\nquick-fit\n\n\njemalloc\n\n\nTCMalloc\n\n\nalloca\n Function: has the same calling sequence as \nmalloc\n; however, instead of allocating memory from the heap, the memory is allocated from the stack frame of the current function\n\n\n\n\nEnvironment Variables\n\n\nThe environment strings are usually of the form:\n\n\nname=value\n\n\n\n\n\nThe UNIX kernel never looks at these strings; their interpretation is up to the various applications.\n\n\napue_getenv.h\n\n\n#include \nstdlib.h\n\n\n\nchar\n \n*\ngetenv\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n/* Returns: pointer to value associated with name, NULL if not found */\n\n\n\nint\n \nputenv\n(\nchar\n \n*\nstr\n);\n\n\n/* Returns: 0 if OK, nonzero on error */\n\n\n\nint\n \nsetenv\n(\nconst\n \nchar\n \n*\nname\n,\n \nconst\n \nchar\n \n*\nvalue\n,\n \nint\n \nrewrite\n);\n\n\nint\n \nunsetenv\n(\nconst\n \nchar\n \n*\nname\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\ngetenv\n: returns a pointer to the value of a \nname=value\n string. We should always use \ngetenv\n to fetch a specific value from the environment, instead of accessing \nenviron\n directly\n\n\n\n\n\n\n\n\nputenv\n: takes a string of the form \nname=value\n and places it in the environment list. If name already exists, its old definition is first removed.\n\n\nsetenv\n: sets \nname\n to \nvalue\n. If name already exists in the environment, then:\n\n\nIf \nrewrite\n is nonzero, the existing definition for \nname\n is first removed\n\n\nIf \nrewrite\n is 0, the existing definition for \nname\n is not removed, \nname\n is not set to the new value, and no error occurs\n\n\n\n\n\n\nunsetenv\n: removes any definition of name. It is not an error if such a definition does not exist.\n\n\n\n\nNote the difference between \nputenv\n and \nsetenv\n. Whereas \nsetenv\n must allocate memory to create the \nname=value\n string from its arguments, \nputenv\n is free to place the string passed to it directly into the environment. Indeed, many implementations do exactly this, so \nit would be an error to pass putenv a string allocated on the stack, since the memory would be reused after we return from the current function.\n\n\n\n\nDeleting a string: we just find the pointer in the environment list and move all subsequent pointers down one.\n\n\nModifying a existing \nname\n:\n\n\nIf new \nvalue\n is smaller than or equal to old: we just copy the string\n\n\nIf new \nvalue\n is larger than old: we must \nmalloc\n and replace the old pointer in the environment list for \nname\n with the pointer to this allocated area\n\n\n\n\n\n\nAdding a new \nname\n:\n\n\nFirst time: we call \nmalloc\n, copy the old environment list to this new area and store a pointer to the \nname=value\n string at the end of\nthis list of pointers. We also store a null pointer at the end of this list, of course. Finally, we set \nenviron\n to point to this new list of pointers. \nIf the original environment list was contained above the top of the stack, as is common, then we have moved this list of pointers to the heap. But most of the pointers in this list still point to \nname=value\n strings above the top of the stack.\n\n\nNot first time: we call \nrealloc\n to allocate room for one more pointer. The pointer to the new \nname=value\n string is stored at the end of the list (on top of the previous null pointer), followed by a null pointer.\n\n\n\n\n\n\n\n\nsetjmp\n and \nlongjmp\n Functions\n\n\nIn C, we can't \ngoto\n a label that\u2019s in another function. Instead, we must use the \nsetjmp\n and \nlongjmp\n functions to perform this type of branching. These two functions are useful for handling error conditions that occur in a deeply nested function call.\n\n\napue_setjmp.h\n\n\n#include \nsetjmp.h\n\n\n\nint\n \nsetjmp\n(\njmp_buf\n \nenv\n);\n\n\n/* Returns: 0 if called directly, nonzero if returning from a call to longjmp */\n\n\n\nvoid\n \nlongjmp\n(\njmp_buf\n \nenv\n,\n \nint\n \nval\n);\n\n\n\n\n\n\nExamples:\n\n\n\n\ncmd1.c\n\n\ncmd2.c\n\n\n\n\nAutomatic, Register, and Volatile Variables\n\n\nWhen we return to \nmain\n as a result of the \nlongjmp\n, implementations do not try to roll back these automatic variables and register variables (in \nmain\n), though standards say only that their values are indeterminate.\n\n\nExample:\n\n\n\n\ntestjmp.c\n\n\n\n\nCompile the above program, with and without compiler optimizations, the results are different:\n\n\n$ gcc testjmp.c compile without any optimization\n$ ./a.out\nin f1():\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\nafter longjmp:\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\n$ gcc -O testjmp.c compile with full optimization\n$ ./a.out\nin f1():\nglobval = 95, autoval = 96, regival = 97, volaval = 98, statval = 99\nafter longjmp:\nglobval = 95, autoval = 2, regival = 3, volaval = 98, statval = 99\n\n\n\n\n\nThe optimizations don\u2019t affect the global, static, and volatile variables. The \nsetjmp(3)\n manual page on one system states that variables stored in memory will have values as of the time of the \nlongjmp\n, whereas variables in the CPU and floating-point registers are restored to their values when \nsetjmp\n was called. Without optimization, all five variables are stored in memory. When we enable optimization, both \nautoval\n and \nregival\n go into registers, even though the former wasn't declared \nregister\n, and the \nvolatile\n variable stays in memory.\n\n\nPotential Problem with Automatic Variables\n\n\nAn automatic variable can never be referenced after the function that declared it returns.\n\n\nIncorrect usage of an automatic variable:\n\n\n#include \nstdio.h\n\n\nFILE\n \n*\n\n\nopen_data\n(\nvoid\n)\n\n\n{\n\n    \nFILE\n \n*\nfp\n;\n\n    \nchar\n \ndatabuf\n[\nBUFSIZ\n];\n \n/* setvbuf makes this the stdio buffer */\n\n    \nif\n \n((\nfp\n \n=\n \nfopen\n(\ndatafile\n,\n \nr\n))\n \n==\n \nNULL\n)\n\n        \nreturn\n(\nNULL\n);\n\n    \nif\n \n(\nsetvbuf\n(\nfp\n,\n \ndatabuf\n,\n \n_IOLBF\n,\n \nBUFSIZ\n)\n \n!=\n \n0\n)\n\n        \nreturn\n(\nNULL\n);\n\n    \nreturn\n(\nfp\n);\n \n/* error */\n\n\n}\n\n\n\n\n\n\nThe problem is that when \nopen_data\n returns, the space it used on the stack will be used by the stack frame for the next function that is called. But the standard I/O library will still be using that portion of memory for its stream buffer. Chaos is sure to result. To correct this problem, the array \ndatabuf\n needs to be allocated from global memory, either statically (\nstatic\n or \nextern\n) or dynamically (one of the \nalloc\n functions).\n\n\ngetrlimit\n and \nsetrlimit\n Functions\n\n\nEvery process has a set of resource limits, some of which can be queried and changed by the \ngetrlimit\n and \nsetrlimit\n functions.\n\n\napue_getrlimit.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \ngetrlimit\n(\nint\n \nresource\n,\n \nstruct\n \nrlimit\n \n*\nrlptr\n);\n\n\nint\n \nsetrlimit\n(\nint\n \nresource\n,\n \nconst\n \nstruct\n \nrlimit\n \n*\nrlptr\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThese two functions are defined in the XSI option in the Single UNIX Specification. The resource limits for a process are normally established by process 0 when the system is initialized and then inherited by each successive process. Each implementation has its own way of tuning the various limits.\n\n\n\n\nrlptr\n: a pointer to the following structure:\n\n\n\n\nstruct\n \nrlimit\n \n{\n\n    \nrlim_t\n \nrlim_cur\n;\n \n/* soft limit: current limit */\n\n    \nrlim_t\n \nrlim_max\n;\n \n/* hard limit: maximum value for rlim_cur */\n\n\n};\n\n\n\n\n\n\n\n\n\n\nresource\n argument takes on one of the following values:\n\n\n\n\nRLIMIT_AS\n: The maximum size in bytes of a process\u2019s total available memory. This affects the \nsbrk\n function and the \nmmap\n function.\n\n\nRLIMIT_CORE\n: The maximum size in bytes of a core file. A limit of 0 prevents the creation of a core file.\n\n\nRLIMIT_CPU\n: The maximum amount of CPU time in seconds. When the soft limit is exceeded, the SIGXCPU signal is sent to the process.\n\n\nRLIMIT_DATA\n: The maximum size in bytes of the data segment: the sum of the initialized data, uninitialized data, and heap from \nFigure 7.6\n.\n\n\nRLIMIT_FSIZE\n: The maximum size in bytes of a file that may be created.  When the soft limit is exceeded, the process is sent the \nSIGXFSZ\n signal.\n\n\nRLIMIT_MEMLOCK\n: The maximum amount of memory in bytes that a process can lock into memory using \nmlock(2)\n.\n\n\nRLIMIT_MSGQUEUE\n: The maximum amount of memory in bytes that a process can allocate for POSIX message queues.\n\n\nRLIMIT_NICE\n: The limit to which a process\u2019s nice value can be raised to affect its scheduling priority.\n\n\nRLIMIT_NOFILE\n: The maximum number of open files per process. Changing this limit affects the value returned by the \nsysconf\n function for its \n_SC_OPEN_MAX\n argument.\n\n\nRLIMIT_NPROC\n: The maximum number of child processes per real user ID. Changing this limit affects the value returned for \n_SC_CHILD_MAX\n by the \nsysconf\n function.\n\n\nRLIMIT_NPTS\n: The maximum number of pseudo terminals that a user can have open at one time.\n\n\nRLIMIT_RSS\n: Maximum resident set size (RSS) in bytes. If available physical memory is low, the kernel takes memory from processes that exceed their RSS.\n\n\nRLIMIT_SBSIZE\n: The maximum size in bytes of socket buffers that a user can consume at any given time.\n\n\nRLIMIT_SIGPENDING\n: The maximum number of signals that can be queued for a process. This limit is enforced by the sigqueue function\n\n\nRLIMIT_STACK\n: The maximum size in bytes of the stack. See \nFigure 7.6\n.\n\n\nRLIMIT_SWAP\n: The maximum amount of swap space in bytes that a user can consume.\n\n\nRLIMIT_VMEM\n This is a synonym for \nRLIMIT_AS\n.\n\n\n\n\n\n\n\n\nRules of changing resource limits:\n\n\n\n\nA process can change its soft limit to a value less than or equal to its hard limit.\n\n\nA process can lower its hard limit to a value greater than or equal to its soft limit. \nThis lowering of the hard limit is irreversible for normal users.\n\n\nOnly a superuser process can raise a hard limit.\n\n\n\n\nThe resource limits affect the calling process and are inherited by any of its children. This means that the setting of resource limits needs to be built into the shells to affect all our future processes. Indeed, the Bourne shell, the GNU Bourne-again shell, and the Korn shell have the built-in \nulimit\n command, and the C shell has the built-in limit command. (The \numask\n and \nchdir\n functions also have to be handled as shell built-ins.)\n\n\nExample:\n\n\n\n\ngetrlimit.c\n\n\n\n\nSummary\n\n\nUnderstanding the environment of a C program within a UNIX system\u2019s environment is a prerequisite to understanding the process control features of the UNIX System. This chapter discusses process start and termination, and how a process is passed  an argument list and an environment. Although both the argument list and the environment are uninterpreted by the kernel, it is the kernel that passes both from the caller of \nexec\n to the new process.  This chapter also examines the typical memory layout of a C program and how a process can dynamically allocate and free memory.", 
            "title": "Chapter 7. Process Environment"
        }, 
        {
            "location": "/apue/ch8/", 
            "text": "Chapter 8. Process Control\n\n\nProcess Identifiers\n\n\nEvery process has a unique process ID, a non-negative integer. As processes terminate, their IDs can be reused. \nMost UNIX systems implement algorithms to delay reuse so that newly created processes are assigned IDs different from those used by processes that terminated recently. This prevents a new process from being mistaken for the previous process to have used the same ID.\n\n\nThere are some special processes, but the details differ from implementation to implementation:\n\n\n\n\nProcess ID 0: scheduler process (often known as the \nswapper\n), which is part of the kernel and is known as a system process\n\n\nProcess ID 1: \ninit\n process, invoked by the kernel at the end of the bootstrap procedure.\n\n\nIt is responsible for bringing up a UNIX system after the kernel has been bootstrapped. \ninit\n usually reads the system-dependent initialization files (\n/etc/rc*\n files or \n/etc/inittab\n and the files in \n/etc/init.d\n) and brings the system to a certain state.\n\n\nIt never dies.\n\n\nIt is a normal user process, not a system process within the kernel.\n\n\nIt runs with superuser privileges.\n\n\n\n\n\n\n\n\nEach UNIX System implementation has its own set of kernel processes that provide operating system services.\n For example, on some virtual memory implementations of the UNIX System, process ID 2 is the \npagedaemon\n. This process is responsible for supporting the paging of the virtual memory system.\n\n\napue_getpid.h\n\n\ninclude\n \nunistd\n.\nh\n\n\n\npid_t\n \ngetpid\n(\nvoid\n);\n\n\n/* Returns: process ID of calling process */\n\n\n\npid_t\n \ngetppid\n(\nvoid\n);\n\n\n/* Returns: parent process ID of calling process */\n\n\n\nuid_t\n \ngetuid\n(\nvoid\n);\n\n\n/* Returns: real user ID of calling process */\n\n\n\nuid_t\n \ngeteuid\n(\nvoid\n);\n\n\n/* Returns: effective user ID of calling process */\n\n\n\ngid_t\n \ngetgid\n(\nvoid\n);\n\n\n/* Returns: real group ID of calling process */\n\n\n\ngid_t\n \ngetegid\n(\nvoid\n);\n\n\n/* Returns: effective group ID of calling process */\n\n\n\n\n\n\nNone of these functions has an error return.\n\n\nfork\n Function\n\n\nAn existing process can create a new one by calling the \nfork\n function.\n\n\napue_fork.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \nfork\n(\nvoid\n);\n\n\n\n/* Returns: 0 in child, process ID of child in parent, \u22121 on error */\n\n\n\n\n\n\n\n\nThe new process created by \nfork\n is called the \nchild process\n. This function is called once but returns twice. The only difference in the returns is that the return value in the child is 0, whereas the return value in the parent is the process ID of the new child. [p299]\n\n\nfork\n returns child's process ID in parent: a process can have more than one child, and \nthere is no function that allows a process to obtain the process IDs of its children\n\n\nfork\n returns 0 in child: \na process can have only a single parent, and the child can always call \ngetppid\n to obtain the process ID of its parent\n\n\n\n\n\n\nBoth the child and the parent continue executing with the instruction that follows the call to \nfork\n. The child is a copy of the parent; the parent and the child do not share these portions of memory. The parent and the child do share the text segment.\n\n\nCopy-on-write (COW) is used on modern implementations: a complete copy of the parent\u2019s data, stack and heap is not performed. The shared regions are changed to read-only by the kernel. The kernel makes a copy of that piece of memory only if either process tries to modify these regions.\n\n\n\n\nVariations of the \nfork\n function are provided by some platforms. All four platforms discussed in this book support the \nvfork(2)\n variant discussed in the next section. Linux 3.2.0 also provides new process creation through the \nclone(2)\n system call. This is a generalized form of \nfork\n that allows the caller to control what is shared between parent and child.\n\n\nExample (\nfork1.c\n):\n\n\n#include \napue.h\n\n\n\nint\n \nglobvar\n \n=\n \n6\n;\n \n/* external variable in initialized data */\n\n\nchar\n \nbuf\n[]\n \n=\n \na write to stdout\n\\n\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nvar\n;\n \n/* automatic variable on the stack */\n\n    \npid_t\n \npid\n;\n\n\n    \nvar\n \n=\n \n88\n;\n\n    \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nsizeof\n(\nbuf\n)\n-\n1\n)\n \n!=\n \nsizeof\n(\nbuf\n)\n-\n1\n)\n\n        \nerr_sys\n(\nwrite error\n);\n\n    \nprintf\n(\nbefore fork\n\\n\n);\n \n/* we don\u2019t flush stdout */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nglobvar\n++\n;\n \n/* modify variables */\n\n        \nvar\n++\n;\n\n    \n}\n \nelse\n \n{\n\n        \nsleep\n(\n2\n);\n \n/* parent */\n\n    \n}\n\n\n    \nprintf\n(\npid = %ld, glob = %d, var = %d\n\\n\n,\n \n(\nlong\n)\ngetpid\n(),\n \nglobvar\n,\n\n           \nvar\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\n$ ./a.out\na write to stdout\nbefore fork\npid = 430, glob = 7, var = 89 # child\u2019s variables were changed\npid = 429, glob = 6, var = 88 # parent\u2019s copy was not changed\n$ ./a.out \n temp.out\n$ cat temp.out\na write to stdout\nbefore fork\npid = 432, glob = 7, var = 89\nbefore fork\npid = 431, glob = 6, var = 88\n\n\n\n\n\nAnalysis:\n\n\n\n\nWhether the child starts executing before the parent or vice versa is not known. The order depends on the scheduling algorithm used by the kernel. If it\u2019s required that the child and parent synchronize their actions, some form of interprocess communication is required.\n\n\nsizeof(buf)-1\n (subtracting 1 from the size of \nbuf\n) avoids writing the terminating null byte. \nstrlen\n calculates the length of a string not including the terminating null byte, while \nsizeof\n calculates the size of the buffer, including the terminating null byte. However, using \nstrlen\n requires a function call, whereas \nsizeof\n calculates the buffer length at compile time.\n\n\n\"a write to stdout\" (once): \nwrite\n function is not buffered and is called before the \nfork\n, its data is written once to standard output\n\n\n\"before fork\" (once in the first case, twice in the second case): \nprintf\n from the standard I/O library is buffered\n\n\nFirst case (running the program interactively): standard I/O is \nline buffered\n and standard output buffer is flushed by the newline\n\n\nSecond case (redirect stdout to a file): standard I/O is \nfully buffered\n. The \nprintf\n (\nprintf(\"before fork\\n\");\n) before the \nfork\n is called once, but the line remains in the buffer when \nfork\n is called. \nThis buffer is then copied into the child when the parent\u2019s data space is copied to the child. Both the parent and the child now have a standard I/O buffer with this line in it.\n The second \nprintf\n (\nprintf(\"pid = %ld, glob = %d, var = %d\\n\", ...);\n), right before the exit, just appends its data to the existing buffer. When each process terminates, its copy of the buffer is finally flushed.\n\n\n\n\n\n\n\n\nFile Sharing\n\n\nOne characteristic of \nfork\n is that all file descriptors that are open in the parent are duplicated in the child, because it\u2019s as if the \ndup\n function had been called for each descriptor. The parent and the child shareafile table entry for every open descriptor.\n\n\nFor a process that has three different files opened for standard input, standard output, and standard error, on return from \nfork\n, we have the arrangement shown below:\n\n\n\n\nIt is important that the parent and the child share the same file offset. Otherwise, this type of interaction would be more difficult to accomplish and would require explicit actions by the parent.\n\n\nThere are two normal cases for handling the descriptors after a \nfork\n:\n\n\n\n\nThe parent waits for the child to complete.\n\n\nBoth the parent and the child go their own ways. After the fork, both the parent and child close the descriptors that they don't need, so neither interferes with the other\u2019s open descriptors. This scenario is often found with network servers.\n\n\n\n\nBesides the open files, other properties of the parent are inherited by the child:\n\n\n\n\nReal user ID, real group ID, effective user ID, and effective group ID\n\n\nSupplementary group IDs\n\n\nProcess group ID\n\n\nSession ID\n\n\nControlling terminal\n\n\nThe set-user-ID and set-group-ID flags\n\n\nCurrent working directory\n\n\nRoot directory\n\n\nFile mode creation mask\n\n\nSignal mask and dispositions\n\n\nThe close-on-exec flag for any open file descriptors\n\n\nEnvironment\n\n\nAttached shared memory segments\n\n\nMemory mappings\n\n\nResource limits\n\n\n\n\nThe differences between the parent and child are:\n\n\n\n\nThe return values from fork are different.\n\n\nThe process IDs are different.\n\n\nThe two processes have different parent process IDs: the parent process ID of the child is the parent; the parent process ID of the parent doesn\u2019t change.\n\n\nThe child\u2019s \ntms_utime\n, \ntms_stime\n, \ntms_cutime\n, and \ntms_cstime\n values are set to 0 (these times are discussed in Section 8.17).\n\n\nFile locks set by the parent are not inherited by the child.\n\n\nPending alarms are cleared for the child.\n\n\nThe set of pending signals for the child is set to the empty set\n\n\n\n\nThe two main reasons for \nfork\n to fail\n\n\n\n\nIf too many processes are already in the system, which usually means that something else is wrong\n\n\nIf the total number of processes for this real user ID exceeds the system\u2019s limit. (\nCHILD_MAX\n specifies the maximum number of simultaneous processes per real user ID.)\n\n\n\n\nThe two uses for \nfork\n\n\n\n\nWhen a process wants to duplicate itself so that the parent and the child can each execute different sections of code at the same time.\n\n\nThis is common for network servers\u2014the parent waits for a service request from a client. When the request arrives, the parent calls \nfork\n and lets the child handle the request. The parent goes back to waiting for the next service request to arrive.\n\n\n\n\n\n\nWhen a process wants to execute a different program.\n\n\nThis is common for shells. In this case, the child does an \nexec\n right after it returns from the \nfork\n.\n\n\n\n\n\n\n\n\nSome operating systems combine the operations from step 2, a \nfork\n followed by an \nexec\n, into a single operation called a \nspawn\n. The UNIX System separates the two, as there are numerous cases where it is useful to \nfork\n without doing an \nexec\n. Also, separating the two operations allows the child to change the per-process attributes between the \nfork\n and the \nexec\n, such as I/O redirection, user ID, signal disposition, and so on\n\n\nvfork\n Function\n\n\nThe function \nvfork\n has the same calling sequence and same return values as \nfork\n, but the semantics of the two functions differ.\n\n\nThe \nvfork\n function was intended to create a new process for the purpose of executing a new program (step 2 at the end of the previous section). \nThe \nvfork\n function creates the new process, just like \nfork\n, without copying the address space of the parent into the child\n, as the child won\u2019t reference that address space; the child simply calls \nexec\n (or \nexit\n) right after the \nvfork\n. Instead, \nthe child runs in the address space of the parent until it calls either \nexec\n or \nexit\n.\n\n\nThis optimization is more efficient on some implementations of the UNIX System, but leads to undefined results if the child:\n\n\n\n\nmodifies any data (except the variable used to hold the return value from \nvfork\n)\n\n\nmakes function calls\n\n\nreturns without calling \nexec\n or \nexit\n\n\n\n\nAnother difference between the two functions is that \nvfork\n guarantees that the child runs first, until the child calls \nexec\n or \nexit\n. When the child calls either of these functions, the parent resumes. (This can lead to deadlock if the child depends on further actions of the parent before calling either of these two functions.)\n\n\nExample (\nvfork1.c\n)\n\n\nThe program is a modified version of the program from \nfork1.c\n. We\u2019ve replaced the call to \nfork\n with \nvfork\n and removed the write to standard output. Also, we don\u2019t need to have the parent call \nsleep\n, as we\u2019re guaranteed that it is put to sleep by the kernel until the child calls either \nexec\n or \nexit\n.\n\n\n#include \napue.h\n\n\n\nint\n \nglobvar\n \n=\n \n6\n;\n \n/* external variable in initialized data */\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nvar\n;\n \n/* automatic variable on the stack */\n\n    \npid_t\n \npid\n;\n\n\n    \nvar\n \n=\n \n88\n;\n\n    \nprintf\n(\nbefore vfork\n\\n\n);\n \n/* we don\u2019t flush stdio */\n\n    \nif\n \n((\npid\n \n=\n \nvfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nvfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nglobvar\n++\n;\n \n/* modify parent\u2019s variables */\n\n        \nvar\n++\n;\n\n        \n_exit\n(\n0\n);\n \n/* child terminates */\n\n    \n}\n\n\n    \n/* parent continues here */\n\n    \nprintf\n(\npid = %ld, glob = %d, var = %d\n\\n\n,\n \n(\nlong\n)\ngetpid\n(),\n \nglobvar\n,\n\n           \nvar\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nRunning this program gives us\n\n\n$ ./a.out\nbefore vfork\npid = 29039, glob = 7, var = 89\n\n\n\n\n\nAnalysis:\n\n\n\n\nThe incrementing of the variables done by the child changes the values in the parent. Because the child runs in the address space of the parent.\n\n\n_exit\n is called instead of \nexit\n, because \n_exit\n does not perform any flushing of standard I/O buffers. If we call \nexit\n instead, the results are indeterminate. Depending on the implementation of the standard I/O library, we might see no difference in the output, or we might find that the output from the \nfirst \nprintf\n (see \nDoubts and Solutions\n) in the parent has disappeared.\n\n\nIf the implementation only flushes the standard I/O streams, then we will see no difference from the output generated if the child called \n_exit\n.\n\n\nIf the implementation also closes the standard I/O streams, however, the memory representing the \nFILE\n object for the standard output will be cleared out. Because the child is borrowing the parent\u2019s address space, when the parent resumes and calls \nprintf\n, no output will appear and \nprintf\n will return \u22121.\n\n\nThe parent\u2019s \nSTDOUT_FILENO\n is still valid, as the child gets a copy of the parent\u2019s file descriptor array\n\n\n\n\n\n\n\n\nMost modern implementations of \nexit\n do not close the streams. Because the process is about to exit, the kernel will close all the file descriptors open in the process. Closing them in the library simply adds overhead without any benefit.\n\n\nexit\n Functions\n\n\nA process can terminate normally in five ways (as described in \nSection 7.3\n):\n\n\n\n\nExecuting a return from the \nmain\n function. This is equivalent to calling \nexit\n.\n\n\nCalling the exit function, which includes the calling of all exit handlers that have been registered by calling \natexit\n and closing all standard I/O streams.\n\n\nISO C does not deal with file descriptors, multiple processes (parents and children), and job control. The definition of this function is incomplete for a UNIX system.\n\n\n\n\n\n\nCalling the \n_exit\n or \n_Exit\n function.\n\n\n_Exit\n: defined by ISO C to provide a way for a process to terminate without running exit handlers or signal handlers\n\n\n_exit\n: called by \nexit\n and handles the UNIX system-specific details; \n_exit\n is specified by POSIX.1.\n\n\nWhether standard I/O streams are flushed depends on the implementation.\n\n\nOn UNIX systems, \n_Exit\n and \n_exit\n are synonymous and do not flush standard I/O streams.\n\n\n\n\n\n\nExecuting a \nreturn\n from the start routine of the last thread in the process.\n\n\nThe return value of the thread is not used as the return value of the process. When the last thread returns from its start routine, the process exits with a termination status of 0.\n\n\n\n\n\n\nCalling the \npthread_exit\n function from the last thread in the process.\n\n\n\n\nThe three forms of abnormal termination:\n\n\n\n\nCalling \nabort\n. This is a special case of the next item, as it generates the \nSIGABRT\n signal.\n\n\nWhen the process receives certain signals. The signal can be generated by:\n\n\nthe process itself, e.g. calling the \nabort\n function\n\n\nsome other processes\n\n\nthe kernel, e.g. the process references a memory location not within its address space or tries to divide by 0\n\n\n\n\n\n\nThe last thread responds to a cancellation request. By default, cancellation occurs in a deferred manner: one thread requests that another be canceled, and sometime later the target thread terminates.\n\n\n\n\nRegardless of how a process terminates, the same code in the kernel is eventually executed. This kernel code closes all the open descriptors for the process, releases the memory that it was using, and so on.\n\n\nThe terminating process is to be able to notify its parent how it terminated by by passing an exit status as the argument to one of the three exit functions. In the case of an abnormal termination, the kernel (not the process) generates a termination status to indicate the reason for the abnormal termination. In any case, the parent of the process can obtain the termination status from either the \nwait\n or the \nwaitpid\n function.\n\n\nExit status vs. termination status\n\n\n\n\nExit status\n: is the argument to one of the three exit functions or the return value from main.\n\n\nTermination status\n: the exit status is converted into a termination status by the kernel when \n_exit\n is finally called. If the child terminated normally, the parent can obtain the exit status of the child.\n\n\n\n\nOrphan process\n\n\nOrphan process\n (or \norphaned child process\n) is any process whose parent terminates.\n\n\nThe child has a parent process after the call to \nfork\n. What happens if the parent terminates before the child? The answer is the \ninit\n process becomes the parent process of any process whose parent terminates. This is called \"the process has been inherited by \ninit\n\". Whenever a process terminates, the kernel goes through all active processes to see whether the terminating process is the parent of any process that still exists. If so, the parent process ID of the surviving process is changed to be 1 (the process ID of \ninit\n). This way, it's guaranteed that every process has a parent.\n\n\nZombie process\n\n\nZombie process\n is a process that has terminated, but whose parent has not yet waited for it. The \nps(1)\n command prints the state of a zombie process\nas \nZ\n.\n\n\nWhat happens when a child terminates before its parent?\n\n\nIf the child completely disappeared, the parent wouldn\u2019t be able to fetch its termination status when and if the parent was finally ready to check if the child had terminated. The kernel keeps a small amount of information for every terminating process, so that the information is available when the parent of the terminating process calls \nwait\n or \nwaitpid\n. This information consists of the process ID, the termination status of the process, and the amount of CPU time taken by the process. The kernel can discard all the memory used by the process and close its open files.\n\n\ninit\n's children\n\n\nWhat happens when a process that has been inherited by \ninit\n terminates? It does not become a zombie. \ninit\n is written so that whenever one of its children terminates, \ninit\n calls one of the \nwait\n functions to fetch the termination status. By doing this, init prevents the system from being clogged by zombies.\n\n\nOne of init\u2019s children refers to either of the following:\n\n\n\n\nA process that \ninit\n generates directly (e.g. \ngetty\n)\n\n\nA process whose parent has terminated and has been subsequently inherited by \ninit\n.\n\n\n\n\nwait\n and \nwaitpid\n Functions\n\n\nWhen a process terminates, either normally or abnormally, the kernel notifies the parent by sending the \nSIGCHLD\n signal to the parent.\n Because the termination of a child is an asynchronous event (it can happen at any time while the parent is running). This signal is the asynchronous notification from the kernel to the parent. The parent can choose to ignore this signal, or it can provide a function that is called when the signal occurs: a signal handler. \nThe default action for this signal is to be ignored.\n\n\nA process that calls \nwait\n or \nwaitpid\n can:\n\n\n\n\nBlock, if all of its children are still running\n\n\nReturn immediately with the termination status of a child, if a child has terminated and is waiting for its termination status to be fetched\n\n\nReturn immediately with an error, if it doesn\u2019t have any child processes\n\n\n\n\nIf the process is calling \nwait\n because it received the \nSIGCHLD\n signal, we expect wait to return immediately. But if we call it at any random point in time, it can block.\n\n\napue_wait.h\n\n\n#include \nsys/wait.h\n\n\n\npid_t\n \nwait\n(\nint\n \n*\nstatloc\n);\n\n\npid_t\n \nwaitpid\n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n);\n\n\n\n/* Both return: process ID if OK, 0 (see later), or \u22121 on error */\n\n\n\n\n\n\nThe differences between these two functions are:\n\n\n\n\nThe \nwait\n function can block the caller until a child process terminates, whereas \nwaitpid\n has an option that prevents it from blocking.\n\n\nThe \nwaitpid\n function doesn\u2019t wait for the child that terminates first; it has a number of options that control which process it waits for.\n\n\n\n\nIf a child has already terminated and is a zombie, \nwait\n returns immediately with that child\u2019s status. Otherwise, it blocks the caller until a child terminates. If the caller blocks and has multiple children, \nwait\n returns when one terminates. We can always tell which child terminated, because the process ID is returned by the function.\n\n\nThe argument \nstatloc\n is is a pointer to an integer. If this argument is not a null pointer, the termination status of the terminated process is stored in the location pointed to by the argument.\n\n\nThe integer status that these two functions return has been defined by the implementation, with certain bits indicating the exit status (for a normal return), other bits indicating the signal number (for an abnormal return), one bit indicating whether a core file was generated, and so on.\n\n\nFour mutually exclusive macros are defined in \nsys/wait.h\n to tell us how the process terminated, and they all begin with \nWIF\n. Based on which of these four macros is true, other macros are used to obtain the exit status, signal number, and the like.\n\n\nMacros to examine the termination status returned by \nwait\n and \nwaitpid\n:\n\n\n\n\n\n\n\n\nMacro\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWIFEXITED(status)\n\n\nTrue if status was returned for a child that terminated normally. In this case, we can execute \nWEXITSTATUS(status)\n to fetch the low-order 8 bits of the argument that the child passed to \nexit\n, \n_exit\n, or \n_Exit\n.\n\n\n\n\n\n\nWIFSIGNALED(status)\n\n\nTrue if status was returned for a child that terminated abnormally, by receipt of a signal that it didn\u2019t catch. In this case, we can execute \nWTERMSIG(status)\n to fetch the signal number that caused the termination. Additionally, some implementations (but not the Single UNIX Specification) define the macro \nWCOREDUMP(status)\n that returns true if a core file of the terminated process was generated.\n\n\n\n\n\n\nWIFSTOPPED(status)\n\n\nTrue if status was returned for a child that is currently stopped. In this case, we can execute \nWSTOPSIG(status)\n to fetch the signal number that caused the child to stop.\n\n\n\n\n\n\nWIFCONTINUED(status)\n\n\nTrue if status was returned for a child that has been continued after a job control stop (XSI option; \nwaitpid\n only).\n\n\n\n\n\n\n\n\nThe function \npr_exit\n uses these macros (above) to print a description of the termination status.\n\n\n\n\nlib/prexit.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nvoid\n\n\npr_exit\n(\nint\n \nstatus\n)\n\n\n{\n\n    \nif\n \n(\nWIFEXITED\n(\nstatus\n))\n\n        \nprintf\n(\nnormal termination, exit status = %d\n\\n\n,\n\n                \nWEXITSTATUS\n(\nstatus\n));\n\n    \nelse\n \nif\n \n(\nWIFSIGNALED\n(\nstatus\n))\n\n        \nprintf\n(\nabnormal termination, signal number = %d%s\n\\n\n,\n\n                \nWTERMSIG\n(\nstatus\n),\n\n\n#ifdef  WCOREDUMP\n\n                \nWCOREDUMP\n(\nstatus\n)\n \n?\n \n (core file generated)\n \n:\n \n);\n\n\n#else\n\n                \n);\n\n\n#endif\n\n    \nelse\n \nif\n \n(\nWIFSTOPPED\n(\nstatus\n))\n\n        \nprintf\n(\nchild stopped, signal number = %d\n\\n\n,\n\n                \nWSTOPSIG\n(\nstatus\n));\n\n\n}\n\n\n\n\n\n\n\n\nwait1.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstatus\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nexit\n(\n7\n);\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nabort\n();\n                    \n/* generates SIGABRT */\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_sys\n(\nfork error\n);\n\n    \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n              \n/* child */\n\n        \nstatus\n \n/=\n \n0\n;\n                \n/* divide by 0 generates SIGFPE */\n\n\n    \nif\n \n(\nwait\n(\nstatus\n)\n \n!=\n \npid\n)\n       \n/* wait for child */\n\n        \nerr_sys\n(\nwait error\n);\n\n    \npr_exit\n(\nstatus\n);\n                \n/* and print its status */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nnormal termination, exit status = 7\nabnormal termination, signal number = 6 (core file generated)\nabnormal termination, signal number = 8 (core file generated)\n\n\n\n\n\nWe print the signal number from \nWTERMSIG\n. We can look at the \nsignal.h\n header to verify that \nSIGABRT\n has a value of 6 and that \nSIGFPE\n has a value of 8.\n\n\nwait\n for a specific process: \nwaitpid\n\n\nIf we have more than one child, \nwait\n returns on termination of any of the children. If we want to wait for a specific process to terminate (assuming we know which process ID we want to wait for), in older versions of the UNIX System, we would have to call \nwait\n and compare the returned process ID with the one we\u2019re interested in. The POSIX.1 \nwaitpid\n function can be used to wait for a specific process.\n\n\nThe interpretation of the pid argument for waitpid depends on its value:\n\n\n\n\npid\n == \u22121 - Waits for any child process. In this respect, \nwaitpid\n is equivalent to \nwait\n.\n\n\npid\n \n 0 - Waits for the child whose process ID equals \npid\n.\n\n\npid\n == 0 - Waits for any child whose \nprocess group ID\n equals that of the calling process.\n\n\npid\n \n \u22121 - Waits for any child whose process group ID equals the absolute value of \npid\n.\n\n\n\n\nThe \nwaitpid\n function returns the process ID of the child that terminated and stores the child\u2019s termination status in the memory location pointed to by \nstatloc\n.\n\n\nErrors of \nwait\n and \nwaitpid\n\n\n\n\nWith \nwait\n, the only real error is if the calling process has no children. (Another error return is possible, in case the function call is interrupted by a signal) [p242]\n\n\nWith \nwaitpid\n, it\u2019s possible to get an error if the specified process or process group does not exist or is not a child of the calling process\n\n\n\n\noptions\n argument of \nwaitpid\n\n\nThe \noptions\n argument either is 0 or is constructed from the bitwise OR of the constants in the table below.\n\n\nThe \noptions\n constants for \nwaitpid\n:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWCONTINUED\n\n\nIf the implementation supports job control, the status of any child specified by \npid\n that has been continued after being stopped, but whose status has not yet been reported, is returned (XSI option).\n\n\n\n\n\n\nWNOHANG\n\n\nThe \nwaitpid\n function will not block if a child specified by \npid\n is not immediately available. In this case, the return value is 0.\n\n\n\n\n\n\nWUNTRACED\n\n\nIf the implementation supports job control, the status of any child specified by \npid\n that has stopped, and whose status has not been reported since it has stopped, is returned. The \nWIFSTOPPED\n macro determines whether the return value corresponds to a stopped child process.\n\n\n\n\n\n\n\n\nThe \nwaitpid\n function provides three features that aren\u2019t provided by the \nwait\n function:\n\n\n\n\nThe \nwaitpid\n function lets us wait for one particular process, whereas the \nwait\n function returns the status of any terminated child (\npopen\n function)\n\n\nThe \nwaitpid\n function provides a nonblocking version of \nwait\n. There are times when we want to fetch a child\u2019s status, but we don\u2019t want to block.\n\n\nThe \nwaitpid\n function provides support for job control with the \nWUNTRACED\n and \nWCONTINUED\n options.\n\n\n\n\nfork\n twice\n\n\nExample (\nfork2.c\n)\n\n\nIf we want to write a process so that it \nfork\ns a child but we don\u2019t want to wait for the child to complete and we don\u2019t want the child to become a zombie until we terminate, \nthe trick is to call \nfork\n twice.\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n      \n/* first child */\n\n        \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n            \nerr_sys\n(\nfork error\n);\n\n        \nelse\n \nif\n \n(\npid\n \n \n0\n)\n\n            \nexit\n(\n0\n);\n    \n/* parent from second fork == first child */\n\n\n        \n/*\n\n\n         * We\nre the second child; our parent becomes init as soon\n\n\n         * as our real parent calls exit() in the statement above.\n\n\n         * Here\ns where we\nd continue executing, knowing that when\n\n\n         * we\nre done, init will reap our status.\n\n\n         */\n\n        \nsleep\n(\n2\n);\n\n        \nprintf\n(\nsecond child, parent pid = %ld\n\\n\n,\n \n(\nlong\n)\ngetppid\n());\n\n        \nexit\n(\n0\n);\n\n    \n}\n\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n!=\n \npid\n)\n   \n/* wait for first child */\n\n        \nerr_sys\n(\nwaitpid error\n);\n\n\n    \n/*\n\n\n     * We\nre the parent (the original process); we continue executing,\n\n\n     * knowing that we\nre not the parent of the second child.\n\n\n     */\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\n$ second child, parent pid = 1\n\n\n\n\n\nAnalysis:\n\n\nWe call \nsleep\n in the second child to ensure that the first child terminates before printing the parent process ID. After a \nfork\n, either the parent or the child can continue executing; we never know which will resume execution first. If we didn\u2019t put the second child to sleep, and if it resumed execution after the \nfork\n before its parent, the parent process ID that it printed would be that of its parent, not process ID 1.\n\n\nNote that the shell prints its prompt when the original process terminates, which is before the second child prints its parent process ID.\n\n\nwaitid\n Function\n\n\nThe Single UNIX Specification includes an additional \nwaitid\n function to retrieve the exit status of a process.\n\n\napue_waitid.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n \nwaitid\n(\nidtype_t\n \nidtype\n,\n \nid_t\n \nid\n,\n \nsiginfo_t\n \n*\ninfop\n,\n \nint\n \noptions\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nLike \nwaitpid\n, \nwaitid\n allows a process to specify which children to wait for. Instead of encoding this information in a single argument combined with the process ID or process group ID, two separate arguments are used. The \nid\n parameter is interpreted based on the value of \nidtype\n.\n\n\n\n\n\n\nThe \nidtype\n constants for \nwaitid\n:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nP_PID\n\n\nWait for a particular process: \nid\n contains the process ID of the child to wait for.\n\n\n\n\n\n\nP_PGID\n\n\nWait for any child process in a particular process group: \nid\n contains the process group ID of the children to wait for.\n\n\n\n\n\n\nP_ALL\n\n\nWait for any child process: \nid\n is ignored.\n\n\n\n\n\n\n\n\n\n\n\n\nThe \noptions\n argument is a bitwise OR of the flags shown below:\n\n\n\n\n\n\n\n\nConstant\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nWCONTINUED\n\n\nWait for a process that has previously stopped and has been continued, and whose status has not yet been reported.\n\n\n\n\n\n\nWEXITED\n\n\nWait for processes that have exited.\n\n\n\n\n\n\nWNOHANG\n\n\nReturn immediately instead of blocking if there is no child exit status available.\n\n\n\n\n\n\nWNOWAIT\n\n\nDon\u2019t destroy the child exit status. The child\u2019s exit status can be retrieved by a subsequent call to \nwait\n, \nwaitid\n, or \nwaitpid\n.\n\n\n\n\n\n\nWSTOPPED\n\n\nWait for a process that has stopped and whose status has not yet been reported.\n\n\n\n\n\n\n\n\nAt least one of \nWCONTINUED\n, \nWEXITED\n, or \nWSTOPPED\n must be specified in the options argument.\n\n\n\n\n\n\nThe \ninfop\n argument is a pointer to a \nsiginfo\n structure. This structure contains detailed information about the signal generated that caused the state change in the child process (Section 10.14)\n\n\n\n\n\n\nwait3\n and \nwait4\n Functions\n\n\nMost UNIX system implementations provide two additional functions: \nwait3\n and \nwait4\n, with an additional argument \nrusage\n that allows the kernel to return a summary of the resources used by the terminated process and all its child processes.\n\n\napue_wait3.h\n\n\n#include \nsys/types.h\n\n\n#include \nsys/wait.h\n\n\n#include \nsys/time.h\n\n\n#include \nsys/resource.h\n\n\n\npid_t\n \nwait3\n(\nint\n \n*\nstatloc\n,\n \nint\n \noptions\n,\n \nstruct\n \nrusage\n \n*\nrusage\n);\n\n\npid_t\n \nwait4\n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n,\n \nstruct\n \nrusage\n \n*\nrusage\n);\n\n\n\n/* Both return: process ID if OK, 0, or \u22121 on error */\n\n\n\n\n\n\nThe resource information includes such statistics as the amount of user CPU time, amount of system CPU time, number of page faults, number of signals received, and the like. Refer to the \ngetrusage(2)\n manual page for additional details.\n\n\nRace Conditions\n\n\nA \nrace condition\n occurs when multiple processes are trying to do something with shared data and the final outcome depends on the order in which the processes run. The \nfork\n function is a lively breeding ground for race conditions, \nif any of the logic after the \nfork\n depends on whether the parent or child runs first. In general, we cannot predict which process runs first. Even if we knew which process would run first, what happens after that process starts running depends on the system load and the kernel\u2019s scheduling algorithm.\n\n\nWe saw a potential race condition in the program in \nFigure 8.8\n when the second child printed its parent process ID.\n\n\n\n\nIf the second child runs before the first child, then its parent process will be the first child.\n\n\nIf the first child runs first and has enough time to \nexit\n, then the parent process of the second child is init.\n\n\nIf the system was heavily loaded, the second child could resume after sleep returns, before the first child has a chance to run, calling \nsleep\n  guarantees nothing.\n\n\n\n\nProblems of this form can be difficult to debug because they tend to work \"most of the time\".\n\n\n\n\nA process that wants to wait for a child to terminate must call one of the \nwait\n functions.\n\n\nA process that wants to wait for its parent to terminate can use a loop in the following form:\n\n\n\n\nwhile\n \n(\ngetppid\n()\n \n!=\n \n1\n)\n\n    \nsleep\n(\n1\n);\n\n\n\n\n\n\nThe problem with this type of loop, called \npolling\n, is that it wastes CPU time, as the caller is awakened every second to test the condition.\n\n\nTo avoid race conditions and to avoid polling, some form of signaling is required between multiple processes:\n\n\n\n\nSignals can be used for this purpose\n\n\nInterprocess communication (IPC) can also be used\n\n\n\n\nFor a parent and child relationship, we often have the following scenario. After the \nfork\n, both the parent and the child have something to do. For example, the parent could update a record in a log file with the child\u2019s process ID, and the child might have to create a file for the parent. In this example, we require that each process tell the other when it has finished its initial set of operations, and that each wait for the other to complete, before heading off on its own. The following code illustrates this scenario:\n\n\n#include \napue.h\n\n\n\nTELL_WAIT\n();\n \n/* set things up for TELL_xxx \n WAIT_xxx */\n\n\n\nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n    \nerr_sys\n(\nfork error\n);\n\n\n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n\n    \n/* child does whatever is necessary ... */\n\n\n    \nTELL_PARENT\n(\ngetppid\n());\n \n/* tell parent we\u2019re done */\n\n    \nWAIT_PARENT\n();\n \n/* and wait for parent */\n\n\n    \n/* and the child continues on its way ... */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n/* parent does whatever is necessary ... */\n\n\n\nTELL_CHILD\n(\npid\n);\n \n/* tell child we\u2019re done */\n\n\nWAIT_CHILD\n();\n \n/* and wait for child */\n\n\n\n/* and the parent continues on its way ... */\n\n\nexit\n(\n0\n);\n\n\n\n\n\n\nWe assume that the header \napue.h\n defines whatever variables are required. The five routines \nTELL_WAIT\n, \nTELL_PARENT\n, \nTELL_CHILD\n, \nWAIT_PARENT\n, and \nWAIT_CHILD\n can be either macros or functions (\nlib/tellwait.c\n). We\u2019ll show various ways to implement these \nTELL\n and \nWAIT\n routines in later chapters: Section 10.16 shows an implementation using signals; Figure 15.7 shows an implementation using pipes.\n\n\nThe program below contains a race condition because the output depends on the order in which the processes are run by the kernel and the length of time for which each process runs.\n\n\n\n\ntellwait1.c\n\n\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \ncharatatime\n(\nchar\n \n*\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n    \n}\n \nelse\n \n{\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\ncharatatime\n(\nchar\n \n*\nstr\n)\n\n\n{\n\n    \nchar\n    \n*\nptr\n;\n\n    \nint\n     \nc\n;\n\n\n    \nsetbuf\n(\nstdout\n,\n \nNULL\n);\n           \n/* set unbuffered */\n\n    \nfor\n \n(\nptr\n \n=\n \nstr\n;\n \n(\nc\n \n=\n \n*\nptr\n++\n)\n \n!=\n \n0\n;\n \n)\n\n        \nputc\n(\nc\n,\n \nstdout\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nooutput from child\nutput from parent\n$ ./a.out\nooutput from child\nutput from parent\n$ ./a.out\noutput from child\noutput from parent\n\n\n\n\n\nAnalysis:\nWe set the standard output unbuffered, so every character output generates a write.  The goal in this example is to allow the kernel to switch between the two processes as often as possible to demonstrate the race condition.\n\n\nWe need to change (part of) the above program in to use the \nTELL\n and \nWAIT\n functions.\n\n\n\n\nThe parent goes first:\n\n\n\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \nWAIT_PARENT\n();\n      \n/* parent goes first */\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n    \n}\n \nelse\n \n{\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n        \nTELL_CHILD\n(\npid\n);\n\n    \n}\n\n\n\n\n\n\n\n\nThe child goes first:\n\n\n\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n        \ncharatatime\n(\noutput from child\n\\n\n);\n\n        \nTELL_PARENT\n(\ngetppid\n());\n\n    \n}\n \nelse\n \n{\n\n        \nWAIT_CHILD\n();\n \n/* child goes first */\n\n        \ncharatatime\n(\noutput from parent\n\\n\n);\n\n    \n}\n\n\n\n\n\n\nexec\n Functions\n\n\nOne use of the \nfork\n function is to create a new process (the child) that then causes another program to be executed by calling one of the \nexec\n functions.\n\n\n\n\nWhen a process calls one of the \nexec\n functions, that process is completely replaced by the new program which starts executing at its \nmain\n function.\n\n\nThe process ID does not change across an \nexec\n, because a new process is not created.\n\n\nexec\n merely replaces the current process (its text, data, heap, and stack segments) with a brand-new program from disk.\n\n\n\n\nUNIX System process control primitives:\n\n\n\n\nfork\n creates new processes\n\n\nexec\n functions initiates new programs\n\n\nexit\n handles termination\n\n\nwait\n functions handle waiting for termination\n\n\n\n\nWe\u2019ll use these primitives in later sections to build additional functions, such as \npopen\n and \nsystem\n.\n\n\nThere are seven different \nexec\n functions:\n\n\napue_execl.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nexecl\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n \n/* (char *)0 */\n \n);\n\n\nint\n \nexecv\n(\nconst\n \nchar\n \n*\npathname\n,\n \nchar\n \n*\nconst\n \nargv\n[]);\n\n\nint\n \nexecle\n(\nconst\n \nchar\n \n*\npathname\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n\n           \n/* (char *)0, char *const envp[] */\n \n);\n\n\nint\n \nexecve\n(\nconst\n \nchar\n \n*\npathname\n,\n \nchar\n \n*\nconst\n \nargv\n[],\n \nchar\n \n*\nconst\n \nenvp\n[]);\n\n\nint\n \nexeclp\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nconst\n \nchar\n \n*\narg0\n,\n \n...\n \n/* (char *)0 */\n \n);\n\n\nint\n \nexecvp\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nchar\n \n*\nconst\n \nargv\n[]);\n\n\nint\n \nfexecve\n(\nint\n \nfd\n,\n \nchar\n \n*\nconst\n \nargv\n[],\n \nchar\n \n*\nconst\n \nenvp\n[]);\n\n\n\n/* All seven return: \u22121 on error, no return on success */\n\n\n\n\n\n\nThe first four take a pathname argument, the next two take a filename argument, and the last one takes a file descriptor argument.\n\n\nWhen \nfilename\n argument is specified:\n\n\n\n\nIf filename contains a slash, it is taken as a pathname.\n\n\nOtherwise, the executable file is searched for in the directories specified by the PATH environment variable.\n\n\nThe \nPATH\n variable contains a list of directories, called path prefixes, that are separated by colons, like the \nname=value\n environment string \nPATH=/bin:/usr/bin:/usr/local/bin/:.\n. The dot (\n.\n) specifies the current directory (There are security reasons for never including the current directory in the search path). A zero-length prefix also means the current directory. It can be specified as:\n\n\na colon at the beginning of the \nvalue\n: \nPATH=:/bin:/usr/bin\n\n\ntwo colons in a row: \nPATH=/bin::/usr/bin\n\n\na colon at the end of the \nvalue\n: \nPATH=/bin:/usr/bin:\n\nIf either \nexeclp\n or \nexecvp\n finds an executable file using one of the path prefixes, but the file isn\u2019t a machine executable that was generated by the link editor, the function assumes that the file is a shell script and tries to invoke \n/bin/sh\n with the filename as input to the shell.\n\n\n\n\n\n\n\n\nWith \nfexecve\n (using a file descriptor), the caller can verify the file is in fact the intended file and execute it without a race. Otherwise, a malicious user with appropriate privileges could replace the executable file (or a portion of the path to the executable file) after it has been located and verified, but before the caller can execute it. See \nTOCTTOU\n errors in Section 3.3.\n\n\nThe passing of the argument list (\nl\n stands for list and \nv\n stands for vector):\n\n\n\n\nexecl\n, \nexeclp\n, and \nexecle\n require each of the command-line arguments to be specified as separate arguments.\n\n\nexecv\n, \nexecvp\n, \nexecve\n, and \nfexecve\n require (the address) of an array of pointers to the arguments\n\n\n\n\nThe arguments for \nexecl\n, \nexecle\n, and \nexeclp\n are shown as:\n\n\n    \nchar\n \n*\narg0\n,\n \nchar\n \n*\narg1\n,\n \n...,\n \nchar\n \n*\nargn\n,\n \n(\nchar\n \n*\n)\n0\n\n\n\n\n\n\nThe final command-line argument is followed by a null pointer. If this null pointer is specified by the constant 0, we must cast it to a pointer; if we don\u2019t, it\u2019s interpreted as an integer argument.\n\n\nThe passing of the environment list to the new program.\n\n\n\n\nexecle\n, \nexecve\n, and \nfexecve\n functions (ending in \ne\n) allow us to pass a pointer to an array of pointers to the environment strings.\n\n\nexecl\n, \nexecv\n, \nexeclp\n and \nexecvp\n use the \nenviron\n variable in the calling process to copy the existing environment for the new program. [p251]\n\n\n\n\nThe arguments to \nexecle\n were shown as:\n\n\nchar\n \n*\npathname\n,\n \nchar\n \n*\narg0\n,\n \n...,\n \nchar\n \n*\nargn\n,\n \n(\nchar\n \n*\n)\n0\n,\n \nchar\n \n*\nenvp\n[]\n\n\n\n\n\n\nDifferences among the seven \nexec\n functions\n\n\n\n\n\n\n\n\nFunction\n\n\npathname\n\n\nfilename\n\n\nfd\n\n\nArg list\n\n\nargv[]\n\n\nenviron\n\n\nenvp[]\n\n\n\n\n\n\n\n\n\n\n\n\nexecl\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexeclp\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecle\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n\n\n*\n\n\n\n\n\n\n\n\nexecv\n\n\n*\n\n\n\n\n\n\n\n\n*\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecvp\n\n\n\n\n*\n\n\n\n\n\n\n*\n\n\n*\n\n\n\n\n\n\n\n\n\n\nexecve\n\n\n*\n\n\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\nfexecve\n\n\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n*\n\n\n\n\n\n\n\n\n(letter in name)\n\n\n\n\np\n\n\nf\n\n\nl\n\n\nv\n\n\n\n\ne\n\n\n\n\n\n\n\n\n\n\nEvery system has a limit on the total size of the argument list and the environment list. This limit is given by \nARG_MAX\n and its value must be at least 4,096 bytes on a POSIX.1 system. For example, the following command can generate a shell error:\n\n\n$\n grep getrlimit /usr/share/man/*/*\n\nArgument list too long\n\n\n\n\n\n\nTo get around the limitation in argument list size, we can use the \nxargs(1)\n:\n\n\n$\n find /usr/share/man -type f -print \n|\n xargs grep getrlimit\n\n$\n find /usr/share/man -type f -print \n|\n xargs bzgrep getrlimit\n\n\n\n\n\nThe process ID does not change after an \nexec\n, but the new program inherits additional properties from the calling process:\n\n\n\n\nProcess ID and parent process ID\n\n\nReal user ID and real group ID\n\n\nSupplementary group IDs\n\n\nProcess group ID\n\n\nSession ID\n\n\nControlling terminal\n\n\nTime left until alarm clock\n\n\nCurrent working directory\n\n\nRoot directory\n\n\nFile mode creation mask\n\n\nFile locks\n\n\nProcess signal mask\n\n\nPending signals\n\n\nResource limits\n\n\nNice value\n\n\nValues for \ntms_utime\n, \ntms_stime\n, \ntms_cutime\n, and \ntms_cstime\n\n\n\n\nThe handling of open files depends on the value of the close-on-exec (\nFD_CLOEXEC\n) flag for each descriptor:\n\n\n\n\nIf this flag is set, the descriptor is closed across an exec. The default (the flag is not set) is to leave the descriptor open across the \nexec\n.\n\n\nPOSIX.1 specifically requires that open directory streams (see \nopendir\n in \nChapter 4\n). This is normally done by the\n\nopendir\n function calling \nfcntl\n to set the close-on-exec flag.\n\n\n\n\nThe real user ID and the real group ID remain the same across the \nexec\n, but the effective IDs can change, depending on the status of the set-user-ID and the setgroup-ID bits for the program file that is executed. If the set-user-ID bit is set for the new program, the effective user ID becomes the owner ID of the program file.  Otherwise, the effective user ID is not changed (it\u2019s not set to the real user ID). The group ID is handled in the same way.\n\n\nexec\n library functions and system call\n\n\nIn many UNIX system implementations, only one of these seven functions, \nexecve\n, is a system call within the kernel. The other six are just library functions that eventually invoke this system call.\n\n\nRelationship of the seven \nexec\n functions:\n\n\n\n\nExample:\n\n\n\n\nexec1.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nchar\n    \n*\nenv_init\n[]\n \n=\n \n{\n \nUSER=unknown\n,\n \nPATH=/tmp\n,\n \nNULL\n \n};\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n  \n/* specify pathname, specify environment */\n\n        \nif\n \n(\nexecle\n(\n/home/sar/bin/echoall\n,\n \nechoall\n,\n \nmyarg1\n,\n\n                \nMY ARG2\n,\n \n(\nchar\n \n*\n)\n0\n,\n \nenv_init\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecle error\n);\n\n    \n}\n\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nwait error\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n  \n/* specify filename, inherit environment */\n\n        \nif\n \n(\nexeclp\n(\nechoall\n,\n \nechoall\n,\n \nonly 1 arg\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexeclp error\n);\n\n    \n}\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\n\n\nechoall.c\n\n\n\n\n#include \napue.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nint\n         \ni\n;\n\n    \nchar\n        \n**\nptr\n;\n\n    \nextern\n \nchar\n \n**\nenviron\n;\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nargc\n;\n \ni\n++\n)\n      \n/* echo all command-line args */\n\n        \nprintf\n(\nargv[%d]: %s\n\\n\n,\n \ni\n,\n \nargv\n[\ni\n]);\n\n\n    \nfor\n \n(\nptr\n \n=\n \nenviron\n;\n \n*\nptr\n \n!=\n \n0\n;\n \nptr\n++\n)\n   \n/* and all env strings */\n\n        \nprintf\n(\n%s\n\\n\n,\n \n*\nptr\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ ./a.out\nargv[0]: echoall\nargv[1]: myarg1\nargv[2]: MY ARG2\nUSER=unknown\nPATH=/tmp\n$ argv[0]: echoall\nargv[1]: only 1 arg\nUSER=sar\nLOGNAME=sar\nSHELL=/bin/bash\n...\nHOME=/home/sar\n\n\n\n\n\nAnalysis:\n\n\n\n\nThe program \nechoall\n is executed twice in the program.\n\n\nWe set the first argument, \nargv[0]\n in the new program, to be the filename component of the pathname. Some shells set this argument to be the complete pathname. This is a convention only; we can set \nargv[0]\n to any string we like.\n\n\nThe \nlogin\n command does this when it executes the shell. Before executing the shell, login adds a dash as a prefix to \nargv[0]\n to indicate to the shell that it is being invoked as a login shell. A login shell will execute the start-up profile commands, whereas a nonlogin shell will not.\n\n\n\n\n\n\nThe shell prompt (\n$\n) appeared before the printing of \nargv[0]\n from the second exec. This occurred because the parent did not wait for this child process to finish.\n\n\n\n\nChanging User IDs and Group IDs\n\n\nIn the UNIX System, privileges and access control are on user and group IDs. When programs need additional privileges or access to unallowed resources, they need to change their user or group ID to an ID that has the appropriate privilege or access. It is similar when the programs need to lower their privileges or prevent access to certain resources. [p255]\n\n\nWhen designing applications, we try to use the \nleast-privilege\n model, which means our programs should use the least privilege necessary to accomplish any given task. This reduces the risk that security might be compromised by a malicious user trying to trick our programs into using their privileges in unintended ways.\n\n\nWe can set the real user ID and effective user ID with the \nsetuid\n function and set the real group ID and the effective group ID with the \nsetgid\n function.\n\n\napue_setuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetuid\n(\nuid_t\n \nuid\n);\n\n\nint\n \nsetgid\n(\ngid_t\n \ngid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe rules for who can change the IDs, considering only the user ID now (Everything we describe for the user ID also applies to the group ID.)\n\n\n\n\nIf the process has superuser privileges, the \nsetuid\n function sets the real user ID, effective user ID, and saved set-user-ID to \nuid\n.\n\n\nIf the process does not have superuser privileges, but \nuid\n equals either the real user ID or the saved set-user-ID, setuid sets only the effective user ID to \nuid\n. The real user ID and the saved set-user-ID are not changed.\n\n\nIf neither of these two conditions is true, \nerrno\n is set to \nEPERM\n and \u22121 is returned.\n\n\n\n\nWe are assuming that \n_POSIX_SAVED_IDS\n is true. The saved IDs areamandatory feature in the 2001 version of POSIX.1.\n\n\nThe statements about the three user IDs that the kernel maintains:\n\n\n\n\nOnly a superuser process can change the real user ID.\n\n\nNormally, the real user ID is set by the \nlogin(1)\n program when we log in and never changes. Because \nlogin\n is a superuser process, it sets all three user IDs when it calls \nsetuid\n.\n\n\n\n\n\n\nThe effective user ID is set by the \nexec\n functions only if the set-user-ID bit is set for the program file.\n\n\nIf the set-user-ID bit is not set, the \nexec\n functions leave the effective user ID as its current value.\n\n\nWe can call \nsetuid\n at any time to set the effective user ID to either the real user ID or the saved set-user-ID.\n\n\nNaturally, we can\u2019t set the effective user ID to any random value.\n\n\n\n\n\n\nThe saved set-user-ID is copied from the effective user ID by \nexec\n. If the file\u2019s set-user-ID bit is set, this copy is saved after \nexec\n stores the effective user ID from the file\u2019s user ID.\n\n\n\n\nThe following figure summarizes the various ways these three user IDs can be changed:\n\n\n\n\nWe can obtain only the current value of the real user ID and the effective user ID with the functions \ngetuid\n and \ngeteuid\n (\napue_getpid.h\n). There is no portable way to obtain the current value of the saved set-user-ID. FreeBSD 8.0 and LINUX 3.2.0 provide the \ngetresuid\n and \ngetresgid\n functions, which can be used to get the saved set-user-ID and saved set-group-ID, respectively.\n\n\nsetreuid\n and \nsetregid\n Functions\n\n\nHistorically, BSD supported the swapping of the real user ID and the effective user ID with the setreuid function.\n\n\napue_setreuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetreuid\n(\nuid_t\n \nruid\n,\n \nuid_t\n \neuid\n);\n\n\nint\n \nsetregid\n(\ngid_t\n \nrgid\n,\n \ngid_t\n \negid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nA value of \u22121 for any of the arguments indicates that the corresponding ID should remain unchanged.\n\n\nAn unprivileged user can always swap between the real user ID and the effective user ID. This allows a set-user-ID program to swap to the user\u2019s normal permissions and swap back again later for set-user-ID operations.\n\n\nWhen the saved set-user-ID feature was introduced with POSIX.1, the rule was enhanced to also allow an unprivileged user to set its effective user ID to its saved set-user-ID.\n\n\n\n\n[p257]\n\n\nseteuid\n and \nsetegid\n Functions\n\n\nPOSIX.1 includes \nseteuid\n and \nsetegid\n that only change the effective user ID or effective group ID.\n\n\napue_seteuid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nseteuid\n(\nuid_t\n \nuid\n);\n\n\nint\n \nsetegid\n(\ngid_t\n \ngid\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nAn unprivileged user can set its effective user ID to either its real user ID or its saved set-user-ID.\n\n\nFor a privileged user, only the effective user ID is set to \nuid\n. This differs from \nsetuid\n function, which changes all three user IDs.\n\n\n\n\nThe figure below summarizes all the functions that we\u2019ve described here that modify the three user IDs:\n\n\n\n\nGroup IDs\n\n\nEverything covered so far for user IDs in this section also applies in a similar fashion to group IDs. The \nsupplementary group IDs\n are not affected by \nsetgid\n, \nsetregid\n, or \nsetegid\n.\n\n\nExample of set-user-ID programs: \nat\n\n\nOn Linux 3.2.0, the \nat\n program is installed set-user-ID to user \ndaemon\n and the programs are run by the \natd(8)\n daemon. This allows the at command to write privileged files owned by the daemon that will run the commands on behalf of the user running the \nat\n command.\n\n\nTo prevent privilege breach, the daemon that run the commands on users's behalf have to switch between sets of privileges: users and those of the daemon. The following steps take place [p259-260]:\n\n\n\n\nAssuming that the \nat\n program file is owned by \nroot\n with set-user-ID bit set. When we run it, we have:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = root\n\n\nsaved set-user-ID = root\n\n\n\n\n\n\nat\n command reduces its privileges by calling \nseteuid\n function to set the effective user ID to our read user ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nWhen \nat\n needs to access the configuration files (these files are owned by the daemon that will run the commands for us) that control which commands are to be run and the time at which they need to run, it calls \nseteuid\n to set the effective user ID to root, which is allowed because the argument to seteuid equals the saved set-user-ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = root\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nAfter the files are modified to record the commands to be run and the time at which they are to be run, the \nat\n command lowers its privileges by calling \nseteuid\n to set its effective user ID to our user ID:\n\n\nreal user ID = our user ID (unchanged)\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = root (unchanged)\n\n\n\n\n\n\nThe daemon starts out running with root privileges. To run commands on our behalf, the daemon calls \nfork\n and the child calls \nsetuid\n to change its user ID to our user ID. Because the child is running with root privileges, this changes all of the IDs. We have:\n\n\nreal user ID = our user ID\n\n\neffective user ID = our user ID\n\n\nsaved set-user-ID = our user ID\n\n\n\n\n\n\n\n\nThen the daemon safely executes commands on our behalf, because it can access only the files to which we normally have access.\n\n\nBy using the saved set-user-ID in this fashion, we can use the extra privileges granted to us by the set-user-ID of the program file only when we need elevated privileges. Any other time, however, the process runs with our normal permissions. [p260]\n\n\nInterpreter Files\n\n\nOn contemporary UNIX systems, \ninterpreter files\n are text files that begin with a line of the form (\nshebang\n):\n\n\n#! pathname [ optional-argument ]\n\n\n\n\n\n\nThe space between the exclamation point and the pathname is optional. The most common of these interpreter files begin with the line:\n\n\n#!/bin/sh\n\n\n\n\n\n\n\n\npathname\n is normally an absolute pathname, since no special operations are performed on it (\nPATH\n is not used)\n\n\nThe recognition of interpreter files is done within the kernel as part of processing the \nexec\n system call\n\n\nThe actual file that gets executed by the kernel is not the interpreter file, but rather the file specified by the \npathname\n on the first line of the interpreter file.\n\n\n\n\nInterpreter file vs. Interpreter\n\n\n\n\nInterpreter file: is a text file that begins with \n#!\n.\n\n\nInterpreter: is specified by the \npathname\n on the first line of the interpreter file.\n\n\n\n\nBe aware that systems place a size limit on the first line of an interpreter file. This limit includes the \n#!\n, the \npathname\n, the optional argument, the terminating newline, and any spaces. On Linux 3.2.0, the limit is 128 bytes.\n\n\nExample: A program that \nexec\ns an interpreter file\n\n\n\n\nexec2.c\n\n\n\n\n#include \napue.h\n\n\n#include \nsys/wait.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \npid_t\n \npid\n;\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n \n/* child */\n\n        \nif\n \n(\nexecl\n(\n/home/sar/bin/testinterp\n,\n\n                  \ntestinterp\n,\n \nmyarg1\n,\n \nMY ARG2\n,\n \n(\nchar\n \n*\n)\n0\n)\n \n \n0\n)\n\n            \nerr_sys\n(\nexecl error\n);\n\n    \n}\n\n    \nif\n \n(\nwaitpid\n(\npid\n,\n \nNULL\n,\n \n0\n)\n \n \n0\n)\n \n/* parent */\n\n        \nerr_sys\n(\nwaitpid error\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResults:\n\n\n$ cat /home/sar/bin/testinterp\n#!/home/sar/bin/echoarg foo\n$ ./a.out\nargv[0]: /home/sar/bin/echoarg\nargv[1]: foo\nargv[2]: /home/sar/bin/testinterp\nargv[3]: myarg1\nargv[4]: MY ARG2\n\n\n\n\n\nAnalysis:\n\n\nThe program (from \nSection 7.4\n) \nechoarg\n is the interpreter that echoes each of its command-line arguments.\n\n\nWhen the kernel \nexec\ns the interpreter (\n/home/sar/bin/echoarg\n):\n\n\n\n\nargv[0]\n is \npathname\n of the interpreter\n\n\nargv[1]\n is the optional argument from the interpreter file (\nfoo\n)\n\n\nThe remaining arguments are the \npathname\n (\n/home/sar/bin/testinterp\n) and the second and third arguments from the call to \nexecl\n in the program (\nmyarg1\n and \nMY ARG2\n)\n\n\nBoth \nargv[1]\n and \nargv[2]\n from the call to \nexecl\n have been shifted right two positions.\n\n\nThe kernel takes the \npathname\n from the \nexecl\n call instead of the first argument (\ntestinterp\n), on the assumption that the \npathname\n might contain more information than the first argument.\n\n\n\n\nExample: \nawk\n\n\nA common use for the optional argument following the interpreter pathname is to specify the \n-f\n option for programs that support this option. For example, an \nawk(1)\n program can be executed as:\n\n\nawk -f myfile\n\n\n\n\n\nIt tells \nawk\n to read the \nawk\n program from the file \nmyfile\n.\n\n\nUsing the \n-f\n option with an interpreter file lets us write\n\n\n#!/bin/awk -f\n\n\n# (awk program follows in the interpreter file)\n\n\n\n\n\n\n\n\nawkexample\n\n\n\n\n#!/usr/bin/awk -f\n\nBEGIN \n{\n\n    \nfor\n \n(\ni\n \n=\n 0\n;\n i \n ARGC\n;\n i++\n)\n\n        \nprintf\n \nARGV[%d] = %s\\n\n, i, ARGV\n[\ni\n]\n\n    \nexit\n\n\n}\n\n\n\n\n\n\nAssume the above interpreter file is  \n/usr/local/bin/awkexample\n and one of the path prefixes is \n/usr/local/bin\n, we can execute the program:\n\n\n$ awkexample file1 FILENAME2 f3\nARGV[0] = awk\nARGV[1] = file1\nARGV[2] = FILENAME2\nARGV[3] = f3\n\n\n\n\n\nWhen \n/bin/awk\n is executed, its command-line arguments are:\n\n\n/bin/awk -f /usr/local/bin/awkexample file1 FILENAME2 f3\n\n\n\n\n\n[p263]\n\n\nInterpreter files provide an efficiency gain for the user at some expense in the kernel, since it\u2019s the kernel that recognizes these files. They are useful for the following reasons:\n\n\nFirst, they hide that certain programs are scripts in some other language. For example, use \nawkexample optional-arguments\n instead of \nawk -f awkexample optional-argument\n, we do not need to know that the program is really an \nawk\n script.\n\n\nSecond, interpreter scripts provide an efficiency gain. For example, if we place the previous \nawk\n program into a shell script like this:\n\n\nawk \nBEGIN {\n\n\n    for (i = 0; i \n ARGC; i++)\n\n\n        printf \nARGV[%d] = %s\\n\n, i, ARGV[i]\n\n\n    exit\n\n\n}\n \n$*\n\n\n\n\n\n\nMore work is required when executing this script:\n\n\n\n\nThe shell reads the command and tries to \nexeclp\n the filename (shell script). Since the shell script is an executable file but isn't a machine executable, an error is returned and \nexeclp\n assumes that the file is a shell script.\n\n\n/bin/sh\n is executed with the pathname of the shell script as its argument.\n\n\nThe shell correctly runs the script, but to run the \nawk\n programs, the shell does \nfork\n, \nexec\n and \nwait\n.\n\n\n\n\nThird, interpreter scripts let us write shell scripts using shells other than \n/bin/sh\n. When it finds an executable file that isn\u2019t a machine executable, \nexeclp\n has to choose a shell to invoke, and it always uses \n/bin/sh\n.\n\n\nsystem\n Function\n\n\nIt is convenient to execute a command string from within a program.\n\n\napue_system.h\n\n\n#include \nstdlib.h\n\n\n\nint\n \nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n);\n\n\n\n\n\n\nArguments:\n\n\nIf \ncmdstring\n is a null pointer, system returns nonzero only if a command processor is available, which determines whether the \nsystem\n function is supported on a given platform. Under UNIX systems, it is always available.\n\n\nReturn values:\n\n\nSince \nsystem\n is implemented by calling \nfork\n, \nexec\n, and \nwaitpid\n, there are three types of return values:\n\n\n\n\nIf either the \nfork\n fails or \nwaitpid\n returns an error other than \nEINTR\n, \nsystem\n returns \u22121 with \nerrno\n set to indicate the error.\n\n\nIf the \nexec\n fails, implying that the shell can\u2019t be executed, the return value is as if the shell had executed \nexit(127)\n.\n\n\nIf all three functions succeed, the return value is the termination status of the shell, in the format specified for \nwaitpid\n.\n\n\n\n\nThe code below is an implementation of the \nsystem\n function, which doesn't handle signals.\n\n\n#include    \nsys/wait.h\n\n\n#include    \nerrno.h\n\n\n#include    \nunistd.h\n\n\n\nint\n\n\nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n)\n   \n/* version without signal handling */\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstatus\n;\n\n\n    \nif\n \n(\ncmdstring\n \n==\n \nNULL\n)\n\n        \nreturn\n(\n1\n);\n      \n/* always a command processor with UNIX */\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nstatus\n \n=\n \n-\n1\n;\n    \n/* probably out of processes */\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n              \n/* child */\n\n        \nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncmdstring\n,\n \n(\nchar\n \n*\n)\n0\n);\n\n        \n_exit\n(\n127\n);\n     \n/* execl error */\n\n    \n}\n \nelse\n \n{\n                            \n/* parent */\n\n        \nwhile\n \n(\nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n!=\n \nEINTR\n)\n \n{\n\n                \nstatus\n \n=\n \n-\n1\n;\n \n/* error other than EINTR from waitpid() */\n\n                \nbreak\n;\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n    \nreturn\n(\nstatus\n);\n\n\n}\n\n\n\n\n\n\n\n\nThe shell\u2019s \n-c\n option tells it to take the next command-line argument, \ncmdstring\n, as its command input instead of reading from standard input or from a given file. The shell parses this null-terminated C string and breaks it up into separate command-line arguments for the command. The actual command string that is passed to the shell can contain any valid shell commands.\n\n\n_exit\n is called instead of \nexit\n. This prevents any standard I/O buffers, which would have been copied from the parent to the child across the \nfork\n, from being flushed in the child.\n\n\n\n\n[p266-267]\n\n\nSet-User-ID Programs\n\n\nCalling \nsystem\n from a set-user-ID program creates a security hole and should never be attempted.\n\n\n[p267-269]\n\n\nThe superuser permissions that we gave the set-user-ID program are retained across the \nfork\n and \nexec\n that are done by \nsystem\n.\n\n\nIf it is running with special permissions (set-user-ID or set-group-ID), and wants to spawn another process, a process should use \nfork\n and \nexec\n directly, being certain to change back to normal permissions after the \nfork\n, before calling \nexec\n. The \nsystem\n function should never be used from a set-user-ID or a set-group-ID program.\n\n\nProcess Accounting\n\n\nOn UNIX systems, process accounting can be enabled so that kernel writes an accounting record each time a process terminates, which typically contain a small amount of binary data with the name of the command, the amount of CPU time used, the user ID and group ID, the starting time.\n\n\nThe function \nacct\n enables and disables process accounting. The only use of this function is from the \naccton(8)\n command.\n\n\nA superuser executes accton with a pathname argument to enable accounting. The accounting records are written to the specified file, which is usually \n/var/account/acct\n on FreeBSD and Mac OS X, \n/var/log/account/pacct\n on Linux, and \n/var/adm/pacct\n on Solaris. Accounting is turned off by executing accton without any arguments.\n\n\nThe structure of the accounting records is defined in the header \nsys/acct.h\n, which look something like:\n\n\ntypedef\n \nu_short\n \ncomp_t\n;\n \n/* 3-bit base 8 exponent; 13-bit fraction */\n\n\n\nstruct\n \nacct\n\n\n{\n\n    \nchar\n \nac_flag\n;\n \n/* flag (see Figure 8.26) */\n\n    \nchar\n \nac_stat\n;\n \n/* termination status (signal \n core flag only) */\n\n    \n/* (Solaris only) */\n\n    \nuid_t\n \nac_uid\n;\n \n/* real user ID */\n\n    \ngid_t\n \nac_gid\n;\n \n/* real group ID */\n\n    \ndev_t\n \nac_tty\n;\n \n/* controlling terminal */\n\n    \ntime_t\n \nac_btime\n;\n \n/* starting calendar time */\n\n    \ncomp_t\n \nac_utime\n;\n \n/* user CPU time */\n\n    \ncomp_t\n \nac_stime\n;\n \n/* system CPU time */\n\n    \ncomp_t\n \nac_etime\n;\n \n/* elapsed time */\n\n    \ncomp_t\n \nac_mem\n;\n \n/* average memory usage */\n\n    \ncomp_t\n \nac_io\n;\n \n/* bytes transferred (by read and write) */\n\n    \n/* \nblocks\n on BSD systems */\n\n    \ncomp_t\n \nac_rw\n;\n \n/* blocks read or written */\n\n    \n/* (not present on BSD systems) */\n\n    \nchar\n \nac_comm\n[\n8\n];\n \n/* command name: [8] for Solaris, */\n\n    \n/* [10] for Mac OS X, [16] for FreeBSD, and */\n\n    \n/* [17] for Linux */\n\n\n};\n\n\n\n\n\n\n\n\nTimes are recorded in units of clock ticks on most platforms, but FreeBSD stores microseconds instead.\n\n\nThe \nac_flag\n member records certain events during the execution of the process. See table below.\n\n\n\n\n\n\n\n\n\n\nac_flag\n\n\nDescription\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nAFORK\n\n\nprocess is the result of \nfork\n, but never called \nexec\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nASU\n\n\nprocess used superuser privileges\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nACORE\n\n\nprocess dumped core\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nAXSIG\n\n\nprocess was killed by a signal\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nAEXPND\n\n\nexpanded accounting entry\n\n\n\n\n\n\n\n\nx\n\n\n\n\n\n\nANVER\n\n\nnew record format\n\n\nx\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe data required for the accounting record (e.g. CPU times and number of characters transferred) is kept by the kernel in the process table and initialized whenever a new process is created, as in the child after a \nfork\n. Each accounting record is written when the process terminates. This has two consequences:\n\n\n\n\nWe cannot get accounting records for processes that never terminate, such as \ninit\n and kernel daemons.\n\n\nThe order of the records in the accounting file corresponds to the termination order of the processes, not the order in which they were started. [p270]. We can\u2019t reconstruct the exact starting order of various processes, given the data in the accounting file.\n\n\n\n\nThe accounting records correspond to processes, not programs. A new record is initialized by the kernel for the child after a \nfork\n, not when a new program is executed. Although exec doesn\u2019t create a new accounting record, the command name changes, and the \nAFORK\n flag is cleared. For example, if A \nexec\ns B, then B \nexec\ns C, and C \nexit\n, only a single accounting record is written.  The command name in the record corresponds to program C, but the CPU times are the sum for programs A, B, and C.\n\n\nUser Identification\n\n\nAny process can find out its real and effective user ID and group ID. \ngetpwuid(getuid())\n can be used to find out the login name of the user who\u2019s running the program. However, a single user can have multiple login names, that is, a person might have multiple entries in the password file with the same user ID to have a different login shell for each entry. The system normally keeps track of the name we log in under the \nutmp\n file (see \nSection 6.8\n), and the \ngetlogin\n function provides a way to fetch that login name.\n\n\napue_getlogin.h\n\n\n#include \nunistd.h\n\n\n\nchar\n \n*\ngetlogin\n(\nvoid\n);\n\n\n\n/* Returns: pointer to string giving login name if OK, NULL on error */\n\n\n\n\n\n\nThis function can fail if the process is not attached to a terminal that a user logged in to. We normally call these processes \ndaemons\n.\n\n\nGiven the login name, we can then use it to look up the user in the password file (e.g. to determine the login shell) using \ngetpwnam\n.\n\n\nThe environment variable \nLOGNAME\n is usually initialized with the user\u2019s login name by \nlogin(1)\n and inherited by the login shell. However, a user can modify an environment variable, so we shouldn\u2019t use \nLOGNAME\n to validate the user in any way. Instead, we should use \ngetlogin\n.\n\n\nProcess Scheduling\n\n\nHistorically, the UNIX System provided processes with only coarse control over their scheduling priority. The scheduling policy and priority were determined by the kernel.\n\n\n\n\nA process could choose to run with lower priority by adjusting its \nnice value\n\n\nA process could be \"nice\" and reduce its share of the CPU by adjusting its nice value\n\n\n\n\n\n\nOnly a privileged process was allowed to increase its scheduling priority.\n\n\n\n\nIn the Single UNIX Specification, nice values range from 0 to \n(2*NZERO)\u22121\n, although some implementations support a range from 0 to \n2*NZERO\n. Lower nice values have higher scheduling priority. Lower nice values have higher scheduling priority. \n\"The more nice you are, the lower your scheduling priority is.\"\n \nNZERO\n is the default nice value of the system. [p276]\n\n\nA process can retrieve and change its nice value with the \nnice\n function. With this function, a process can affect only its own nice value; it can\u2019t affect the nice value of any other process.\n\n\napue_nice.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nnice\n(\nint\n \nincr\n);\n\n\n\n/* Returns: new nice value \u2212 NZERO if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe \nincr\n argument is added to the nice value of the calling process.\n\n\nIf \nincr\n is too large or too small, the system silently reduces it to the maximum or minimum legal value.\n\n\n-1 is a legal successful return value. We need to clear \nerrno\n before calling nice and check its value if nice returns \u22121. If the call to nice succeeds and the return value is \u22121, then errno will still be zero. If \nerrno\n is nonzero, it means that the call to nice failed.\n\n\n\n\n\n\n\n\nThe \ngetpriority\n function can be used to get the nice value for a process and for a group of related processes.\n\n\napue_getpriority.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \ngetpriority\n(\nint\n \nwhich\n,\n \nid_t\n \nwho\n);\n\n\n\n/* Returns: nice value between \u2212NZERO and NZERO\u22121 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe \nwhich\n argument can take on one of three following values; it controls how the \nwho\n argument is interpreted:\n\n\nPRIO_PROCESS\n: a process\n\n\nPRIO_PGRP\n: a process group\n\n\nPRIO_USER\n: a user ID\n\n\n\n\n\n\nThe \nwho\n argument:\n\n\n0 (a value of zero): the calling process, process group, or user (depending on the value of the \nwhich\n argument).\n\n\n\n\n\n\n\n\nWhen the which argument applies to more than one process, the highest priority (lowest value) of all the applicable processes is returned.\n\n\nThe \nsetpriority\n function can be used to set the priority of a process, a process group, or all the processes belonging to a particular user ID.\n\n\napue_setpriority.h\n\n\n#include \nsys/resource.h\n\n\n\nint\n \nsetpriority\n(\nint\n \nwhich\n,\n \nid_t\n \nwho\n,\n \nint\n \nvalue\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nwhich\n and \nwho\n arguments are the same as in the \ngetpriority\n function. The \nvalue\n is added to \nNZERO\n and this becomes the new nice value.\n\n\nA child process inherits the nice value from its parent process in FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10.\n\n\nProcess Times\n\n\nThree times can be measured:\n\n\n\n\nWall clock time\n\n\nUser CPU time\n\n\nSystem CPU time\n\n\n\n\nAny process can call the \ntimes\n function to obtain these values for itself and any terminated children.\n\n\napue_times.h\n\n\n#include \nsys/times.h\n\n\n\nclock_t\n \ntimes\n(\nstruct\n \ntms\n \n*\nbuf\n);\n\n\n\n/* Returns: elapsed wall clock time in clock ticks if OK, \u22121 on error */\n\n\n\n\n\n\nThis function fills in the \ntms\n structure pointed to by \nbuf\n:\n\n\nstruct\n \ntms\n \n{\n\n    \nclock_t\n \ntms_utime\n;\n \n/* user CPU time */\n\n    \nclock_t\n \ntms_stime\n;\n \n/* system CPU time */\n\n    \nclock_t\n \ntms_cutime\n;\n \n/* user CPU time, terminated children */\n\n    \nclock_t\n \ntms_cstime\n;\n \n/* system CPU time, terminated children */\n\n\n};\n\n\n\n\n\n\nThe \ntms\n structure does not contain any measurement for the wall clock time. Instead, the function returns the wall clock time as the value of the function. This value is measured from some arbitrary point in the past, so we can\u2019t use its absolute value; instead, we use its relative value. We call \ntimes\n and save the return value. At some later time, we call \ntimes\n again and subtract the earlier return value from the new return value. The difference is the wall clock time.\n\n\nThe two structure fields for child processes contain values only for children that we have waited for with one of the \nwait\n functions.\n\n\nAll the \nclock_t\n values returned by this function are converted to seconds using the number of clock ticks per second, the \n_SC_CLK_TCK\n value returned by \nsysconf\n, that is, divide the \nclock_t\n value by the \n_SC_CLK_TCK\n value. For example,\n\n\n[p280-282]\n\n\n#include \napue.h\n\n\n#include \nsys/times.h\n\n\n\nclock_t\n \nstart\n,\n \nend\n;\n\n\nlong\n \nclktck\n \n=\n \n0\n;\n\n\nstruct\n \ntms\n \ntmsstart\n,\n \ntmsend\n\n\n\nif\n \n((\nclktck\n \n=\n \nsysconf\n(\n_SC_CLK_TCK\n))\n \n \n0\n)\n\n    \nerr_sys\n(\nsysconf error\n);\n\n\n\nif\n \n((\nstart\n \n=\n \ntimes\n(\ntmsstart\n))\n \n==\n \n-\n1\n)\n \n/* starting values */\n\n    \nerr_sys\n(\ntimes error\n);\n\n\n\n/* do some work */\n\n\n\nif\n \n((\nend\n \n=\n \ntimes\n(\ntmsend\n))\n \n==\n \n-\n1\n)\n \n/* ending values */\n\n    \nerr_sys\n(\ntimes error\n);\n\n\n\nprintf\n(\n real: %7.2f\n\\n\n,\n \nreal\n \n/\n \n(\ndouble\n)\n \nclktck\n);\n\n\n\n\n\n\nSummary\n\n\nA thorough understanding of process control is essential for advanced UNIX programming. There are only a few functions to master: \nfork\n, the \nexec\n family, \n_exit\n, \nwait\n, and \nwaitpid\n. These primitives are used in many applications.\n\n\nExamination of the \nsystem\n function and process accounting gave us another look at all these process control functions.\n\n\nAn understanding of the various user IDs and group IDs that are provided (real, effective, and saved) is critical to writing safe set-user-ID programs.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np235 on \nvfork\n\n\n\n\nIf we call \nexit\n instead, the results are indeterminate. Depending on the implementation of the standard I/O library, we might see no difference in the output, or we might find that the output from the first \nprintf\n in the parent has disappeared.\n\n\n\n\nI think \"first \nprintf\n\" should be \"second \nprintf\n\", because the output of the first \nprintf\n is flushed. For the second \nprintf\n, it says \"no output will appear and \nprintf\n will return \u22121\".", 
            "title": "Chapter 8. Process Control"
        }, 
        {
            "location": "/apue/ch9/", 
            "text": "Chapter 9. Process Relationships\n\n\nIntroduction\n\n\nEvery process has a parent process (the initial kernel-level process is usually its own parent). The parent is notified when the child terminates, and the parent can obtain the child\u2019s exit status.\n\n\nThis chapter details process groups and the concept of session introduced by POSIX.1, as well as relationship between the login shell that is invoked when a user logs in and all the processes that are started from the login shell.\n\n\nThe concept of UNIX system signal mechanism in \nChapter 10\n is needed.\n\n\nTerminal Logins\n\n\nIn early UNIX systems, the terminals (dumb terminals that are hard-wired connected to the host) were either local (directly connected) or remote (connected through a modem). These logins came through a terminal device driver in the kernel. [p285]\n\n\nAs bitmapped graphical terminals became available, windowing systems were developed to provide users with new ways to interact with host computers.  Applications were developed to create \"terminal windows\" to emulate character-based terminals, allowing users to interact with hosts in familiar ways (i.e., via the shell command line).\n\n\nToday, some platforms allow you to start a windowing system after logging in, whereas other platforms automatically start the windowing system for you. In the latter case, you might still have to log in, depending on how the windowing system is configured (some windowing systems can be configured to log you in automatically).\n\n\nThe procedure that we now describe is used to log in to a UNIX system using a terminal. The procedure is similar regardless of the type of terminal we use. It could be a:\n\n\n\n\ncharacter-based terminal,\n\n\na graphical terminal emulating a simple character-based terminal,\n\n\nor a graphical terminal running a windowing system.\n\n\n\n\nBSD Terminal Logins\n\n\nThe file \n/etc/ttys\n (created by the system administrator) has one line per terminal device. Each line specifies the name of the device and other parameters (e.g. baud rate) that are passed to the \ngetty\n program.\n\n\nAfter the system is bootstrapped, the kernel creates the \ninit\n process (PID 1) which brings the system up in multiuser mode. The \ninit\n process reads the file \n/etc/ttys\n and, for every terminal device that allows a login, does a \nfork\n followed by an \nexec\n of the program \ngetty\n.\n\n\n\n\nAll the processes shown in the figure above have a real user ID of 0 and an effective user ID of 0 (they all have superuser privileges). All the processes other than the original \ninit\n process have a parent process ID of 1.\n\n\n\n\nThe \ninit\n process \nexec\ns the \ngetty\n program with an empty environment.\n\n\ngetty\n calls \nopen\n to open terminal device for reading and writing. File descriptors 0, 1, and 2 are set to the device.\n\n\nThen, \ngetty\n outputs something like \nlogin:\n and waits for us to enter our user name. \ngetty\n can detect special characters to change the terminal's speed (baud rate). [p287]\n\n\n\n\nWhen we enter our user name, \ngetty\n\u2019s job is complete, and it then invokes the \nlogin\n program, similar to:\n\n\nexecle(\n/bin/login\n, \nlogin\n, \n-p\n, username, (char *)0, envp);\n\n\n\n\n\n\n\n\n\nThough \ninit\n invokes \ngetty\n with an empty environment, \ngetty\n creates an environment for \nlogin\n (the \nenvp\n argument) with the name of the terminal (something like \nTERM=foo\n, where the type of terminal \nfoo\n is taken from the \ngettytab\n file) and any environment strings that are specified in the \ngettytab\n. The \n-p\n flag to \nlogin\n tells it to preserve the environment that it is passed and to add to that environment, not replace it.\n\n\n\n\nlogin\n does the following things:\n\n\nIt calls \ngetpwnam\n to fetch our password file entry.\n\n\nIt calls \ngetpass(3)\n to display the prompt \nPassword:\n and read our password (with echoing disabled).\n\n\nIt calls \ncrypt(3)\n to encrypt the password that we entered and compares the encrypted result to the \npw_passwd\n field from our shadow password file entry.\n\n\nIf the login attempt fails because of an invalid password (after a few tries), \nlogin\n calls \nexit\n with an argument of 1. This termination will be noticed by the parent (\ninit\n), and it will do another \nfork\n followed by an \nexec\n of \ngetty\n, starting the procedure over again for this terminal.\n\n\n\n\n\n\n\n\nThis is the traditional authentication procedure used on UNIX systems. Modern UNIX systems have evolved to support multiple authentication procedures. FreeBSD, Linux, Mac OS X, and Solaris all support a more flexible scheme known as PAM (\nPluggable Authentication Modules\n). PAM allows an administrator to configure the authentication methods to be used to access services that are written to use the PAM library. [p288]\n\n\nIf we log in correctly, \nlogin\n will:\n\n\n\n\nChange to our home directory (\nchdir\n)\n\n\nChange the ownership of our terminal device (\nchown\n) so we own it\n\n\nChange the access permissions for our terminal device so we have permission to read from and write to it\n\n\nSet our group IDs by calling \nsetgid\n and \ninitgroups\n\n\nInitialize the environment with all the information that login has:\n\n\nour home directory (\nHOME\n),\n\n\nshell (\nSHELL\n),\n\n\nuser name (\nUSER\n and \nLOGNAME\n),\n\n\nand a default path (\nPATH\n).\n\n\n\n\n\n\n\n\nChange to our user ID (\nsetuid\n) and invoke our login shell, as in\n\n\nexecl(\n/bin/sh\n, \n-sh\n, (char *)0);\n\n\n\n\n\nThe minus sign as the first character of \nargv[0]\n is a flag to all the shells that indicates they are being invoked as a \nlogin shell\n. The shells can look at this character and modify their start-up accordingly.\n\n\n\n\n\n\nThe \nlogin\n can optionally print the \nmessage-of-the-day\n file, check for new mail, and performs other tasks.\n\n\nSince it is called by a superuser process, \nsetuid\n changes all three user IDs: the real user ID, effective user ID, and saved set-user-ID. The call to \nsetgid\n that was done earlier by \nlogin\n has the same effect on all three group IDs.\n\n\nAt this point, our login shell is running. Its parent process ID is the original \ninit\n process (process ID 1), so when our login shell terminates, \ninit\n is sent a \nSIGCHLD\n signal and it starts the whole procedure over again for this terminal. File descriptors 0, 1, and 2 for our login shell are set to the terminal device. See the figure below:\n\n\n\n\nOur login shell now reads its start-up files (\n.profile\n for the Bourne shell and Korn shell; \n.bash_profile\n, \n.bash_login\n, or \n.profile\n for the GNU Bourne-again shell; and \n.cshrc\n and \n.login\n for the C shell). These start-up files usually change some of the environment variables and add many other variables to the environment. For example, most users set their own \nPATH\n and often prompt for the actual terminal type (\nTERM\n). When the start-up files are done, we finally get the shell\u2019s prompt and can enter commands.\n\n\nMac OS X Terminal Logins\n\n\nOn Mac OS X, the terminal login process follows essentially the same steps as in the BSD login process (since Mac OS X is based in part on FreeBSD) with the following differences:\n\n\n\n\nThe work of \ninit\n is performed by \nlaunchd\n.\n\n\nWe are presented with a graphical-based login screen from the start.\n\n\n\n\nLinux Terminal Logins\n\n\nThe Linux login procedure is very similar to the BSD procedure. The login command is derived from 4.3BSD. The main difference is in terminal configuration.\n\n\nSome Linux distributions ship with a version of the \ninit\n program that uses administrative files patterned after System V\u2019s \ninit\n file formats. where \n/etc/inittab\n specifies the terminal devices for which \ninit\n should start a \ngetty\n process. Other Linux distributions, such as Ubuntu, ship with a version of init that is known as \"\nUpstart\n\". It uses configuration files named \n*.conf\n that are\nstored in the \n/etc/init\n directory. For example, the specifications for running \ngetty\n on \n/dev/tty1\n might be found in the file \n/etc/init/tty1.conf\n.\n\n\nDepending on the version of \ngetty\n in use, the terminal characteristics are specified either on the command line (as with \nagetty\n) or in the file \n/etc/gettydefs\n (as with \nmgetty\n).\n\n\nSolaris Terminal Logins\n\n\n[p290]\n\n\nNetwork Logins\n\n\nThe main difference between a serial terminal login and a network login is that the connection between the terminal and the computer isn\u2019t point-to-point. In this case, \nlogin\n is simply a service available, just like any other network service, such as FTP or SMTP.\n\n\nWith the terminal logins, \ninit\n knows which terminal devices are enabled for logins and spawns a \ngetty\n process for each device. In the case of network logins, however, all the logins come through the kernel\u2019s network interface drivers (e.g., the Ethernet driver), and we don\u2019t know ahead of time how many of these will occur. Instead of having a process waiting for each possible login, we now have to wait for a network connection request to arrive.\n\n\nTo allow the same software to process logins over both terminal logins and network logins, a software driver called a \npseudo terminal\n (detailed in \nChapter 19\n) is used to emulate the behavior of a serial terminal and map terminal operations to network operations, and vice versa.\n\n\nBSD Network Logins\n\n\nIn BSD, the \ninetd\n process, sometimes called the \nInternet superserver\n, waits for most network connections.\n\n\nAs part of the system start-up, \ninit\n invokes a shell that executes the shell script \n/etc/rc\n, which starts \ninetd\n along with other daemons. Once the shell script terminates, the parent process of \ninetd\n becomes \ninit\n; \ninetd\n waits for TCP/IP connection requests to arrive at the host. When a connection request arrives for it to handle, \ninetd\n does a \nfork\n and \nexec\n of the appropriate program.\n\n\nAssume a TCP connection request arrives for the TELNET server (a remote login application). The remote user initiates the login by starting the TELNET client:\n\n\ntelnet hostname\n\n\n\n\n\nThe client opens a TCP connection to \nhostname\n and the user who started the client program is now logged in to the server\u2019s host. The figure below shows the sequence of processes involved in executing the TELNET server, called \ntelnetd\n:\n\n\n\n\nThen, \nthe \ntelnetd\n process then opens a pseudo terminal device and splits into two processes using \nfork\n,\n which do the following:\n\n\n\n\nThe parent (\ntelnetd\n) handles the communication across the network connection.\n\n\nThe child \nexec\ns the \nlogin\n program.\n\n\nThe parent and the child are connected through the pseudo terminal. Before doing the \nexec\n, the child sets up file descriptors 0, 1, and 2 to the pseudo terminal.\n\n\nIf we log in correctly, login performs the same steps described in \nSection 9.2\n: it changes to our home directory and sets our group IDs, user ID, and our initial environment. Then \nlogin\n replaces itself with our login shell by calling \nexec\n.\n\n\n\n\n\n\nWhether we log in through a terminal (\nFigure 9.3\n) or a network (\nFigure 9.5\n), we have a login shell with its standard input, standard output, and standard error connected to either a terminal device or a pseudo terminal device.\n\n\nIn the coming sections, we'll see that the login shell is the start of a POSIX.1 session, and that the terminal or pseudo terminal is the controlling terminal for the session.\n\n\nMac OS X Network Logins\n\n\nThe network login on Mac OS X is identical to that on BSD, except that the \ntelnet\n daemon is run from \nlaunchd\n. By default, the \ntelnet\n daemon is disabled on Mac OS X (although it can be enabled with the \nlaunchctl(1)\n command). The preferred way to perform a network login on Mac OS X is with \nssh\n, the secure shell command.\n\n\nLinux Network Logins\n\n\nNetwork logins under Linux are the same as under BSD, except that some distributions use an alternative \ninetd\n process called the extended Internet services daemon, \nxinetd\n. The \nxinetd\n process provides a finer level of control over services it starts compared to \ninetd\n.\n\n\nSolaris Network Logins\n\n\n[p293]\n\n\nProcess Groups\n\n\nIn addition to having a process ID, each process belongs to a \nprocess group\n.\n\n\n\n\nA process group is a collection of one or more processes (usually associated with the same job) that can receive signals from the same terminal.\n\n\nEach process group has a unique process group ID. Process group IDs are similar to process IDs: they are positive integers and can be stored in a \npid_t\n data type.\n\n\n\n\nThe function \ngetpgrp\n returns the process group ID of the calling process. The \ngetpgid\n function took a \npid\n argument and returned the process group for that process.\n\n\napue_getpgrp.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ngetpgrp\n(\nvoid\n);\n\n\n/* Returns: process group ID of calling process */\n\n\n\npid_t\n \ngetpgid\n(\npid_t\n \npid\n);\n\n\n/* Returns: process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nFor \ngetpgid\n, if \npid\n is 0, the process group ID of the calling process is returned. Thus,\n\n\ngetpgid\n(\n0\n);\n\n\n\n\n\n\nis equivalent to:\n\n\ngetpgrp\n();\n\n\n\n\n\n\nEach process group can have a \nprocess group leader\n, whose process group ID equals to its process ID.\n\n\nProcess group lifetime\n\n\nThe process group life time is the period of time that begins when the group is created and ends when the last remaining process leaves the group. It is possible for a process group leader to create a process group, create processes in the group, and then terminate. The process group still exists, as long as at least one process is in the group, regardless of whether the group leader terminates. The last remaining process in the process group can either terminate or enter some other process group.\n\n\nsetpgid\n function\n\n\nA process can join an existing process group or creates a new process group by calling \nsetpgid\n.\n\n\napue_setpgid.h\n\n\n#include \nunistd.h\n\n\n\nint\n \nsetpgid\n(\npid_t\n \npid\n,\n \npid_t\n \npgid\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nsetpgid\n function sets the process group ID of the process whose process ID equals \npid\n to \npgid\n.\n\n\nArguments:\n\n\n\n\nIf \npid\n == \npgid\n, the process specified by \npid\n becomes a process group leader.\n\n\nIf \npid\n == 0, the process ID of the caller is used.\n\n\nIf \npgid\n == 0, then the specified \npid\n is used as the process group ID.\n\n\n\n\nRules:\n\n\n\n\nA process can set the process group ID of only itself or any of its children.\n\n\nA process cannot change the process group ID of one of its children after that child has called one of the \nexec\n functions.\n\n\n\n\nJob-control shells\n\n\nIn most job-control shells, this function is called after a \nfork\n to have the parent set the process group ID of the child, and to have the child set its own process group ID. \nOne of these calls is redundant, but by doing both, we are guaranteed that the child is placed into its own process group before either process assumes that this has happened.  If we didn\u2019t do this, we would have a race condition, since the child\u2019s process group membership would depend on which process executes first.\n (See \nDoubts and Solutions\n for details) [p294]\n\n\nProcess groups and signals\n\n\nWe can send a signal to either a single process (identified by its process ID) or a process group (identified by its process group ID). Similarly, the \nwaitpid\n function lets us wait for either a single process or one process from a specified process group.\n\n\nSessions\n\n\nA \nsession\n is a collection of one or more process groups.\n\n\n\n\nThe processes in a process group are usually placed there by a shell pipeline. The arrangement in the figure above is generated by the shell commands of the form:\n\n\nproc1 \n|\n proc2 \n\nproc3 \n|\n proc4 \n|\n proc5\n\n\n\n\n\nThe \nsetsid\n function\n\n\nA process establishes a new session by calling the \nsetsid\n function.\n\n\napue_setsid.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \nsetsid\n(\nvoid\n);\n\n\n\n/* Returns: process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nIf the calling process is not a process group leader, this function creates a new session. Three things happen:\n\n\n\n\nThe process becomes the \nsession leader\n of this new session. (A session leader is the process that creates a session.) The process is the only process in this new session\n\n\nThe process becomes the process group leader of a new process group. The new process group ID is the process ID of the calling process.\n\n\nThe process has no controlling terminal. If the process had a controlling terminal before calling \nsetsid\n, that association is broken.\n\n\n\n\nThis function returns an error if the caller is already a process group leader.\n\n\nEnsuring the successful call of \nsetsid\n\n\nSince the \nsetsid\n function returns an error if the caller is a process group leader, to ensure this is not the case, the usual practice is to call \nfork\n and have the parent terminate and the child continue. It is guaranteed that the child is not a process group leader, because the process group ID of the parent is inherited by the child, but the child gets a new process ID. Hence, it is impossible for the child\u2019s process ID to equal its inherited process group ID.\n\n\nSession Leader and Session ID\n\n\nThe Single UNIX Specification talks only about a \"session leader\"; there is no \"session ID\" similar to a process ID or a process group ID. A session leader is a single process that has a unique process ID, so we could talk about a session ID that is the process ID of the session leader. This concept of a session ID was introduced in SVR4.\n\n\nThe \ngetsid\n function\n\n\nThe \ngetsid\n function returns the process group ID of a process\u2019s session leader.\n\n\napue_getsid.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ngetsid\n(\npid_t\n \npid\n);\n\n\n\n/* Returns: session leader\u2019s process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nIf \npid\n is 0, \ngetsid\n returns the process group ID of the calling process\u2019s session leader. For security reasons, some implementations may restrict the calling process from obtaining the process group ID of the session leader if \npid\n doesn\u2019t belong to the same session as the caller.\n\n\nControlling Terminal\n\n\nSessions and process groups have a few other characteristics.\n\n\n\n\nA session can have a single \ncontrolling terminal\n. This is usually the terminal device (in the case of a \nterminal login\n) or pseudo terminal device (in the case of a \nnetwork login\n) on which we log in.\n\n\nThe session leader that establishes the connection to the controlling terminal is called the \ncontrolling process\n.\n\n\nThe process groups within a session can be divided into a single \nforeground process group\n and one or more \nbackground process groups\n.\n\n\nIf a session has a controlling terminal, it has a single foreground process group and all other process groups in the session are background process groups.\n\n\nWhenever we press the terminal\u2019s interrupt key (often DELETE or Control-C), the interrupt signal is sent to all processes in the foreground process group.\n\n\nWhenever we press the terminal\u2019s quit key (often Control-backslash), the quit signal is sent to all processes in the foreground process group.\n\n\nIf a modem (or network) disconnect is detected by the terminal interface, the hang-up signal is sent to the controlling process (the session leader).\n\n\n\n\nThese characteristics are shown in the figure below:\n\n\n\n\nUsually, the controlling terminal is established automatically when we log in.\n\n\nMechanisms of allocating a controlling terminal\n\n\nSystem V\n\n\nSystems derived from UNIX System V allocate the controlling terminal for a session when the session leader opens the first terminal device that is not already associated with a session, as long as the call to \nopen\n does not specify the \nO_NOCTTY\n flag.\n\n\nBSD\n\n\nBSD-based systems allocate the controlling terminal for a session when the session leader calls \nioctl\n with a request argument of \nTIOCSCTTY\n (the third argument is a null pointer). The session cannot already have a controlling terminal for this call to succeed. Normally, this call to \nioctl\n follows a call to \nsetsid\n, which guarantees that the process is a session leader without a controlling terminal.\n\n\nNote that although Mac OS X 10.6.8 is derived from BSD, it behaves like System V when allocating a controlling terminal.\n\n\n\n\n\n\n\n\nMethod\n\n\nFreeBSD 8.0\n\n\nLinux 3.2.0\n\n\nMac OS X 10.6.8\n\n\nSolaris 10\n\n\n\n\n\n\n\n\n\n\nopen\n without \nO_NOCTTY\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nTIOCSCTTY\n \nioctl\n command\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nWhen a program wants to talk to the controlling terminal, regardless of whether the standard input or standard output is redirected, it can \nopen\n the file \n/dev/tty\n. This special file is a synonym within the kernel for the controlling terminal. If the program doesn\u2019t have a controlling terminal, the \nopen\n of this device will fail.\n\n\nThe \ncrypt\n command and \ngetpass\n function\n\n\nThe classic example is the \ngetpass(3)\n function, which reads a password (with terminal echoing turned off, of course). [p298]\n\n\nThe \ngetpass\n function is called by the \ncrypt(1)\n program and can be used in a pipeline. For example:\n\n\ncrypt \n salaries \n|\n lpr\n\n\n\n\n\nIt decrypts the file salaries and pipes the output to the print spooler. Because \ncrypt\n reads its input file on its standard input, the standard input can\u2019t be used to enter the password. Also, \ncrypt\n is designed so that we have to enter the encryption password each time we run the program, to prevent us from saving the password in a file (which could be a security hole).\n\n\ntcgetpgrp\n, \ntcsetpgrp\n, and \ntcgetsid\n Functions\n\n\nWe need a way to tell the kernel which process group is the foreground process group, so that the terminal device driver knows where to send the terminal input and the terminal-generated signals. (\nFigure 9.7\n)\n\n\napue_tcgetpgrp.h\n\n\n#include \nunistd.h\n\n\n\npid_t\n \ntcgetpgrp\n(\nint\n \nfd\n);\n\n\n/* Returns: process group ID of foreground process group if OK, \u22121 on error */\n\n\n\nint\n \ntcsetpgrp\n(\nint\n \nfd\n,\n \npid_t\n \npgrpid\n);\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe function \ntcgetpgrp\n returns the process group ID of the foreground process group associated with the terminal open on \nfd\n.\n\n\nIf the process has a controlling terminal, the process can call \ntcsetpgrp\n to set the foreground process group ID to \npgrpid\n. The value of \npgrpid\n must be the process group ID of a process group in the same session, and \nfd\n must refer to the controlling terminal of the session.\n\n\n\n\nThese two functions are normally called by job-control shells.\n\n\nThe \ntcgetsid\n function allows an application to obtain the process group ID for the session leader given a file descriptor for the controlling TTY.\n\n\napue_tcgetsid.h\n\n\n#include \ntermios.h\n\n\n\npid_t\n \ntcgetsid\n(\nint\n \nfd\n);\n\n\n\n/* Returns: session leader\u2019s process group ID if OK, \u22121 on error */\n\n\n\n\n\n\nApplications that need to manage controlling terminals can use \ntcgetsid\n to identify the session ID of the controlling terminal\u2019s session leader, which is equivalent to the session leader\u2019s process group ID.\n\n\nJob Control\n\n\nJob control\n allows us to start multiple jobs (groups of processes) from a single terminal and to control which jobs can access the terminal and which jobs are run in the background. Job control requires three forms of support:\n\n\n\n\nA shell that supports job control\n\n\nThe terminal driver in the kernel must support job control\n\n\nThe kernel must support certain job-control signals\n\n\n\n\nFrom our perspective, when using job control from a shell, we can start a job in either the foreground or the background. A job is simply a collection of processes, often a pipeline of processes.\n\n\nFor example, start a job consisting of one process in the foreground:\n\n\nvi main.c\n\n\n\n\n\nStart two jobs in the background (all the processes invoked by these background jobs are in the background.):\n\n\npr *.c \n|\n lpr \n\nmake all \n\n\n\n\n\n\nKorn shell example\n\n\nWhen we start a background job, the shell assigns it a job identifier and prints one or more of the process IDs.\n\n\n$ make all \n Make.out \n\n\n[1] 1475\n\n\n$ pr *.c | lpr \n\n\n[2] 1490\n\n\n$   # just press RETURN\n\n\n[2] + Done pr *.c | lpr \n\n\n[1] + Done make all \n Make.out \n\n\n\n\n\n\n\n\nThe \nmake\n is job number 1 and the starting process ID is 1475. The next pipeline is job number 2 and the process ID of the first process is 1490.\n\n\nWhen the jobs are done and we press RETURN, the shell tells us that the jobs are complete. The reason we have to press RETURN is to have the shell print its prompt. The shell doesn\u2019t print the changed status of background jobs at any random time (only after we press RETURN and right before it prints its prompt, to let us enter a new command line). If the shell didn\u2019t do this, it could produce output while we were entering an input line.\n\n\nThe interaction with the terminal driver arises because a special terminal character affects the foreground job. The terminal driver looks for three special characters, which generate signals to (all processes in ) the foreground process group:\n\n\nSIGINT\n: generated by the interrupt character (typically DELETE or Control-C).\n\n\nSIGQUIT\n: generated by the quit character (typically Control-backslash).\n\n\nSIGTSTP\n: generated by the suspend character (typically Control-Z).\n\n\n\n\n\n\n\n\nWhile we can have a foreground job and one or more background jobs, only the foreground job receives terminal input (the characters that we enter at the terminal). It is not an error for a background job to try to read from the terminal, but the terminal driver detects this and sends a special signal to the background job: \nSIGTTIN\n. This signal normally stops the background job; by using the shell, we are notified of this event and can bring the job into the foreground so that it can read from the terminal.\n\n\ncat \n temp.foo \n   # start in background, but it\u2019ll read from standard input\n\n\n[1] 1681\n\n\n$                  # we press RETURN\n\n\n[1] + Stopped (SIGTTIN) cat \n temp.foo \n\n\n$ fg %1            # bring job number 1 into the foreground\n\n\ncat \n temp.foo     # the shell tells us which job is now in the foreground\n\n\nhello, world       # enter one line\n\n\n\u02c6D                 # type the end-of-file character\n\n\n$ cat temp.foo     # check that the one line was put into the file\n\n\nhello, world\n\n\n\n\n\n\n\n\nSIGTTIN\n: When the background \ncat\n tries to read its standard input (the controlling terminal), the terminal driver, knowing that it is a background job, sends the \nSIGTTIN\n signal to the background job.\n\n\nThe shell detects the change in status of its child (see \nwait\n and \nwaitpid\n function in \nSection 8.6\n) and tells us that the job has been stopped.\n\n\nThe shell\u2019s \nfg\n command move the stopped job into the foreground, which causes the shell to place the job into the foreground process group (tcsetpgrp) and send the continue signal (\nSIGCONT\n) to the process group.\n\n\nSince it is now in the foreground process group, the job can read from the controlling terminal.\n\n\n\n\nNote that this example doesn\u2019t work on Mac OS X 10.6.8. When we try to bring the cat command into the foreground, the read fails with errno set to EINTR. Since Mac OS X is based on FreeBSD, and FreeBSD works as expected, this must be a bug in Mac OS X.\n\n\nThere is an option that we can allow or disallow a background job to send its output to the controlling terminal. Normally, we use the \nstty(1)\n command to change this option.\n\n\n$ cat temp.foo \n   # execute in background\n\n\n[1] 1719\n\n\n$ hello, world     # the output from the background job appears after the prompt\n\n\nwe press RETURN\n\n\n[1] + Done cat temp.foo \n\n\n$ stty tostop      # disable ability of background jobs to output to controlling terminal\n\n\n$ cat temp.foo \n   # try it again in the background\n\n\n[1] 1721\n\n\n$                  # we press RETURN and find the job is stopped\n\n\n[1] + Stopped(SIGTTOU) cat temp.foo \n\n\n$ fg %1            # resume stopped job in the foreground\n\n\ncat temp.foo       # the shell tells us which job is now in the foreground\n\n\nhello, world       # and here is its output\n\n\n\n\n\n\nWhen we disallow background jobs from writing to the controlling terminal, cat will block when it tries to write to its standard output, because the terminal driver identifies the write as coming from a background process and sends the job the \nSIGTTOU\n signal. When we use the shell\u2019s \nfg\n command to bring the job into the foreground, the job completes.\n\n\nThe figure below summarizes some of the features of job control that have been described so far:\n\n\n\n\n\n\nThe solid lines through the terminal driver box mean that the terminal I/O and the terminal-generated signals are always connected from the foreground process group to the actual terminal.\n\n\nThe dashed line corresponding to the \nSIGTTOU\n signal means that whether the output from a process in the background process group appears on the terminal is an option.\n\n\n\n\nJob control was originally designed and implemented before windowing terminals were widespread. It is a required feature of POSIX.1. [p302-303]\n\n\nShell Execution of Programs\n\n\nThis section examines how the shells execute programs and how this relates to the concepts of process groups, controlling terminals, and sessions\n\n\nThe shell without job control: the Bourne shell on Solaris\n\n\nFor example, with the classic Bourne shell running on Solaris, we execute:\n\n\nps -o pid,ppid,pgid,sid,comm\n\n\n\n\n\nThe output is\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1774   949   949  949 ps\n\n\n\n\n\n\n\nThe parent of the \nps\n command is the shell.\n\n\nBoth the shell and the \nps\n command are in the same session and foreground process group (949), \nbecause that is what you get when you execute a command with a shell that doesn\u2019t support job control.\n\n\n\n\nTerminal process group ID: \ntpgid\n option of the \nps(1)\n command\n\n\n[p303]\n\n\nSome platforms support an \ntpgid\n option to have the \nps(1)\n command print the process group ID associated with the session\u2019s controlling terminal. This value would be shown under the TPGID column:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm\n\n\n\n\n\nNote that it is misleading to associate a process with a terminal process group ID (the TPGID column):\n\n\n\n\nA process does not have a terminal process control group. A process belongs to a process group, and the process group belongs to a session.\n\n\nThe session may or may not have a controlling terminal.\n\n\nIf the session does have a controlling terminal, then the terminal device knows the process group ID of the foreground process. This value can be set in the terminal driver with the \ntcsetpgrp\n function (\nFigure 9.9\n).\n\n\n\n\n\n\nThe foreground process group ID is an attribute of the terminal, not the process. This value from the terminal device driver is what \nps\n prints as the TPGID. If it finds that the session doesn\u2019t have a controlling terminal, \nps\n prints either 0 or \u22121, depending on the platform.\n\n\n\n\nIf we execute the command in the background:\n\n\nps -o pid,ppid,pgid,sid,comm \n\n\n\n\n\n\nThe only value that changes is the process ID of the command:\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1812   949   949  949 ps\n\n\n\n\n\nThis shell doesn\u2019t know about job control, so the background job is not put into its own process group and the controlling terminal isn\u2019t taken away from the background job.\n\n\nTo see how this shell handles a pipeline, we execute:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1\n\n\n\n\n\nThe output is:\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1823   949   949  949 cat1\n 1824  1823   949  949 ps\n\n\n\n\n\nThe program \ncat1\n is just a copy of the standard \ncat\n program, with a different name. The last process in the pipeline (\ncat\n) is the child of the shell and that the first process in the pipeline (\nps\n) is a child of the last process. It appears that \nthe shell \nfork\ns a copy of itself and that this copy then forks to make each of the previous processes in the pipeline.\n\n\nIf we execute the pipeline in the background:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1 \n\n\n\n\n\n\nOnly the process IDs change. Since the shell doesn\u2019t handle job control, the process group ID of the background processes remains 949, as does the process group ID of the session\n\n\nIf a background process tries to read from its controlling terminal, like:\n\n\ncat \n temp.foo \n\n\n\n\n\n\nWithout job control, the shell automatically redirects the standard input of a background process to \n/dev/null\n, if the process doesn\u2019t redirect standard input itself. A read from \n/dev/null\n generates an end of file. This means that our background \ncat\n process immediately reads an end of file and terminates normally.\n\n\nThe previous paragraph adequately handles the case of a background process accessing the controlling terminal through its standard input, but what happens if a background process specifically opens \n/dev/tty\n and reads from the controlling terminal? The answer is \"It depends\", but the result is probably not what we want. For example:\n\n\ncrypt \n salaries \n|\n lpr \n\n\n\n\n\n\nThis pipeline is run in the background, but the \ncrypt\n program opens \n/dev/tty\n, changes the terminal characteristics (to disable echoing), reads from the device, and resets the terminal characteristics. The prompt \nPassword:\n from \ncrypt\n is printed on the terminal, but what we enter (the encryption password) is read by the shell, which tries to execute a command of that name. The next line we enter to the shell is taken as the password, and the file is not encrypted correctly, sending junk to the printer. Here we have two processes trying to read from the same device at the same time, and the result depends on the system. Job control, as described earlier, handles this multiplexing of a single terminal between multiple processes in a better fashion. [p304]\n\n\nIf we execute three processes in the pipeline, we can examine the process control used by this shell:\n\n\nps -o pid,ppid,pgid,sid,comm \n|\n cat1 \n|\n cat2\n\n\n\n\n\nThe output is: [p305]\n\n\n  PID  PPID  PGID  SID COMMAND\n  949   947   949  949 sh\n 1988   949   949  949 cat2\n 1989  1988   949  949 ps\n 1990  1988   949  949 cat1\n\n\n\n\n\nAgain, the last process in the pipeline is the child of the shell, and all previous processes in the pipeline are children of the last process. See the figure below:\n\n\n\n\nSince the last process in the pipeline is the child of the login shell, the shell is notified when that process (\ncat2\n) terminates.\n\n\nThe shell with job control: Bourne-again shell on Linux\n\n\nStarting with this example, foreground process group are shown in \nbolder font\n.\n\n\nThe command:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  2837   2818   2837  2837   5796  bash\n  \n5796\n   2837   \n5796\n  2837   5796  ps\n\n\n\n\nWe can see the result, which is different from the Bourne shell example:\n\n\n\n\nThe Bourne-again shell places the foreground job (\nps\n) into its own process group (5796).\n\n\nThe \nps\n command is the process group leader and the only process in this process group. This process group is the foreground process group, since it has the controlling terminal.\n\n\nThe login shell is a background process group while the \nps\n command executes.\n\n\nBoth process groups, 2837 and 5796, are members of the same session.\n\n\n\n\nExecuting this process in the background:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  \n2837\n   2818   \n2837\n  2837   2837  bash\n  5797   2837   5797  2837   2837  ps\n\n\n\n\n\n\nps\n command is again placed into its own process group.\n\n\nThe process group (5797) is no longer the foreground process group but a background process group.\n\n\nThe foreground process group is our login shell, as indicated by TPGID of 2837.\n\n\n\n\nExecuting two processes in a pipeline, as in:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n|\n cat1\n\n\n\n\n\ngives us:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  2837   2818   2837  2837   5799  bash\n  \n5799\n   2837   \n5799\n  2837   5799  ps\n  \n5800\n   2837   \n5799\n  2837   5799  cat1\n\n\n\n\n\n\nBoth processes, \nps\n and \ncat1\n, are placed into a new process group (5799), which is the foreground process group.\n\n\nThe login shell is the parent of both processes. This is different from the Bourne shell, which created the last process (\ncat1\n) in the pipeline first, and this process is the parent of first process (\nps\n).\n\n\n\n\nIf we execute this pipeline in the background:\n\n\nps -o pid,ppid,pgid,sid,tpgid,comm \n|\n cat1 \n\n\n\n\n\n\nThe output:\n\n\n\n   PID   PPID   PGID   SID  TPGID  COMMAND\n  \n2837\n   2818   \n2837\n  2837   2837  bash\n  5801   2837   5801  2837   2837  ps\n  5802   2837   5801  2837   2837  cat1\n\n\n\n\nThe results are similar, but now \nps\n and \ncat1\n are placed in the same background process group (5801).\n\n\n[p307]\n\n\nOrphaned Process Groups\n\n\nA process whose parent terminates is called an orphan and is inherited by the \ninit\n process. The entire process groups that can be orphaned and this section discusses how POSIX.1 handles this situation.\n\n\nExample of a process whose child is stopped\n\n\nThe following figure shows a situation: the parent process has \nfork\ned a child that stops, and the parent is about to exit.\n\n\n\n\nThe program that creates an orphaned process group is shown below:\n\n\n\n\nrelation/orphan3.c\n\n\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nstatic\n \nvoid\n\n\nsig_hup\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\nSIGHUP received, pid = %ld\n\\n\n,\n \n(\nlong\n)\ngetpid\n());\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\npr_ids\n(\nchar\n \n*\nname\n)\n\n\n{\n\n    \nprintf\n(\n%s: pid = %ld, ppid = %ld, pgrp = %ld, tpgrp = %ld\n\\n\n,\n\n        \nname\n,\n \n(\nlong\n)\ngetpid\n(),\n \n(\nlong\n)\ngetppid\n(),\n \n(\nlong\n)\ngetpgrp\n(),\n\n        \n(\nlong\n)\ntcgetpgrp\n(\nSTDIN_FILENO\n));\n\n    \nfflush\n(\nstdout\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nchar\n    \nc\n;\n\n    \npid_t\n   \npid\n;\n\n\n    \npr_ids\n(\nparent\n);\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nerr_sys\n(\nfork error\n);\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n \n0\n)\n \n{\n   \n/* parent */\n\n        \nsleep\n(\n5\n);\n       \n/* sleep to let child stop itself */\n\n    \n}\n \nelse\n \n{\n            \n/* child */\n\n        \npr_ids\n(\nchild\n);\n\n        \nsignal\n(\nSIGHUP\n,\n \nsig_hup\n);\n    \n/* establish signal handler */\n\n        \nkill\n(\ngetpid\n(),\n \nSIGTSTP\n);\n    \n/* stop ourself */\n\n        \npr_ids\n(\nchild\n);\n    \n/* prints only if we\nre continued */\n\n        \nif\n \n(\nread\n(\nSTDIN_FILENO\n,\n \nc\n,\n \n1\n)\n \n!=\n \n1\n)\n\n            \nprintf\n(\nread error %d on controlling TTY\n\\n\n,\n \nerrno\n);\n\n    \n}\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nResult in a job-control shell:\n\n\n$ ./a.out\n\n\nparent: pid = 6099, ppid = 2837, pgrp = 6099, tpgrp = 6099\n\n\nchild: pid = 6100, ppid = 6099, pgrp = 6099, tpgrp = 6099\n\n\n$ SIGHUP received, pid = 6100\n\n\nchild: pid = 6100, ppid = 1, pgrp = 6099, tpgrp = 2837\n\n\nread error 5 on controlling TTY\n\n\n\n\n\n\nAnalysis: [p307-309]\n\n\n\n\nThe shell places the foreground process into its own process group (6099) and the shell itself stays in its own process group (2837). The child inherits the process group of its parent (6099).\n\n\nAfter \nfork\n, the parent sleeps for 5 seconds. This is our (imperfect) way of letting the child execute before the parent terminates.\n\n\nThe child establishes a signal handler for the hang-up signal (\nSIGHUP\n) so we can see whether it is sent to the child. (signal handlers are discussed in \nChapter 10\n)\n\n\nThe child sends itself the stop signal (\nSIGTSTP\n) with the \nkill\n function. This stops the child, similar to our stopping a foreground job with our terminal\u2019s suspend character (Control-Z).\n\n\nWhen the parent terminates, the child is orphaned, so the child\u2019s parent process ID becomes 1, which is the \ninit\n process ID.\n\n\nAt this point, the child is a member of an \norphaned process group\n:\n\n\nThe POSIX.1 definition of an orphaned process group: one in which the parent of every member is either itself a member of the group or is not a member of the group\u2019s session. Another way of saying this is: \nthe process group is not orphaned as long as a process in the group has a parent in a different process group but in the same session.\n\n\nIf the process group is not orphaned, there is a chance that one of those parents in a different process group but in the same session will restart a stopped process in the process group that is not orphaned. Here, the parent of every process in the group (e.g., process 1 is the parent of process 6100) belongs to another session.\n\n\n\n\n\n\nSince the process group is orphaned when the parent terminates, and the process group contains a stopped process, POSIX.1 requires that every process in the newly orphaned process group be sent the hang-up signal (\nSIGHUP\n) followed by the continue signal (\nSIGCONT\n).\n\n\nThis causes the child to be continued, after processing the hang-up signal. The default action for the hang-up signal is to terminate the process, so we have to provide a signal handler to catch the signal. We therefore expect the \nprintf\n in the \nsig_hup\n function to appear before the \nprintf\n in the \npr_ids\n function.\n\n\n\n\n\n\nNote that the shell prompt appears with the output from the child, because two processes (login shell and the child) are writing to the terminal. The parent process ID of the child has become 1.\n\n\nAfter calling \npr_ids\n in the child, the program tries to read from standard input. POSIX.1 specifies that the \nread\n is to return an error with \nerrno\n set to \nEIO\n (whose value is 5 on this system) in this situation. [p309]\n\n\nAs discussed earlier in this chapter, when a process in a background process group tries to read from its controlling terminal, \nSIGTTIN\n is generated for the background process group. But for an orphaned process group, if the kernel were to stop it with this signal, the processes in the process group would probably never be continued.\n\n\n\n\n\n\nFinally, our child was placed in a background process group when the parent terminated, since the parent was executed as a foreground job by the shell.\n\n\n\n\nFreeBSD Implementation\n\n\nThe figure below shows the FreeBSD implementation of sessions and process groups:\n\n\n\n\n\n\nsession\n structure is allocated for each session (each time \nsetsid\n is called).\n\n\ns_count\n: number of process groups in the session. When this counter is decremented to 0, the structure can be freed.\n\n\ns_leader\n: pointer to the proc structure of the session leader.\n\n\ns_ttyvp\n: pointer to the vnode structure of the controlling terminal.\n\n\ns_ttyp\n: pointer to the tty structure of the controlling terminal.\n\n\ns_sid\n: session ID. (Not part of the Single UNIX Specification)\n\n\n\n\n\n\n\n\nWhen \nsetsid\n is called, a new session structure is allocated within the kernel. \ns_count\n is set to 1, \ns_leader\n is set to point to the \nproc\n structure of the calling process, \ns_sid\n is set to the process ID, and \ns_ttyvp\n and \ns_ttyp\n are set to null pointers, since the new session doesn\u2019t have a controlling terminal.\n\n\n\n\ntty\n structure is contained in the kernel for each terminal device and each pseudo terminal device.\n\n\nt_session\n points to the \nsession\n structure that has this terminal as its controlling terminal. This pointer is used by the terminal to send a hangup signal to the session leader if the terminal loses carrier (\nFigure 9.7\n). Note that the \ntty\n and \nsession\n structure point to each other.\n\n\nt_pgrp\n points to the \npgrp\n structure of the foreground process group. This field is used by the terminal driver to send signals to the foreground process group. The three signals generated by entering special characters that are sent to the foreground process group are:\n\n\ninterrupt\n\n\nquit\n\n\nsuspend\n\n\n\n\n\n\nt_termios\n is a structure containing all the special characters and related information for this terminal, such as baud rate, whether echo is enabled, and so on.\n\n\nt_winsize\n is a \nwinsize\n structure that contains the current size of the terminal window. When the size of the terminal window changes, the \nSIGWINCH\n signal is sent to the foreground process group.\n\n\n\n\n\n\n\n\nThe kernel finds the foreground process group of a particular session by following fields of pointers, starting with the \nsession\n structure:\n\n\n\n\nFollow \ns_ttyp\n of the \nsession\n structure to get to the \ntty\n structure (controlling terminal).\n\n\n\n\nFollow \nt_pgrp\n of the \ntty\n structure to get to the \npgrp\n structure (foreground process group).\n\n\n\n\n\n\npgrp\n structure contains the information for a particular process group.\n\n\n\n\npg_id\n is the process group ID.\n\n\npg_session\n points to the \nsession\n structure for the session to which this process group belongs.\n\n\npg_members\n is a pointer to the list of \nproc\n structures that are members of this process group. The \np_pglist\n structure in that \nproc\n structure is a doubly linked list entry that points to both the next process and the previous process in the group. [p311]\n\n\n\n\n\n\nvnode\n structureis allocated when the controlling terminal device is opened. All references to \n/dev/tty\n in a process go through this \nvnode\n structure.\n\n\n\n\nSummary\n\n\nThis chapter describes relation between groups of processes, sessions, which are made up of process groups. Job control is a feature supported by most UNIX systems. The controlling terminal for a process, \n/dev/tty\n, is also involved in these process relationships.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np294 on \nfork\n's race condition concerning \nsetpgid\n\n\n\n\nIn most job-control shells, this function is called after a \nfork\n to have the parent set the process group ID of the child, and to have the child set its own process group ID. One of these calls is redundant, but by doing both, we are guaranteed that the child is placed into its own process group before either process assumes that this has happened.  If we didn\u2019t do this, we would have a race condition, since the child\u2019s process group membership would depend on which process executes first.\n\n\n\n\nSolution:\n\n\nThe shell (parent) wants and ensures the process to be in the right process group at any time before either of the child and parent continues execution.\n\n\n\n\nStack Overflow\n\n\nLaunching Jobs\n in the GNU C Library", 
            "title": "Chapter 9. Process Relationships"
        }, 
        {
            "location": "/apue/ch10/", 
            "text": "Chapter 10. Signals\n\n\nIntroduction\n\n\nSignals are software interrupts. They provide a way of handling asynchronous events. Most nontrivial application programs need to deal with signals.\n\n\nPOSIX reliable signals\n\n\nSignals have been provided since the early versions of the UNIX System, but the signal model provided with systems such as Version 7 was not reliable. Signals could get lost, and it was difficult for a process to turn off selected signals when executing critical regions of code. Both 4.3BSD and SVR3 made changes to the signal model, adding what are called \nreliable signals\n. But the changes made by Berkeley and AT\nT were incompatible. Fortunately, POSIX.1 standardized the reliable-signal routines, and that is what we describe here.\n\n\nThis chapter starts with an overview of signals and a description of what each signal is normally used for, then discusses problems with earlier implementations, since it is often important to understand what is wrong with an implementation before seeing how to do things correctly. This chapter contains numerous examples that are not entirely correct and a discussion of the defects.\n\n\nSignal Concepts\n\n\n\n\n\n\nEvery signal has a name. They all begin with the three characters \nSIG\n. For example:\n\n\n\n\nSIGABRT\n is the abort signal that is generated when a process calls the \nabort\n function.\n\n\nSIGALRM\n is the alarm signal that is generated when the timer set by the \nalarm\n function goes off.\n\n\n\n\nFreeBSD 8.0 supports 32 different signals. Mac OS X 10.6.8 and Linux 3.2.0 each support 31 different signals, whereas Solaris 10 supports 40 different signals. FreeBSD, Linux, and Solaris, support additional application-defined signals introduced to support \nreal-time applications\n.\n\n\n\n\n\n\nSignal names are all defined by positive integer constants (the signal number) in the header \nsignal.h\n.\n\n\n\n\nImplementations actually define the individual signals in a different header file, but this header file is included by \nsignal.h\n.\n\n\nIt bad for the kernel to include header files meant for user-level applications, so if the applications and the kernel both need the same definitions, the information is placed in a kernel header file that is then included by the user-level header file.\n\n\nsys/signal.h\n: FreeBSD 8.0 and Mac OS X 10.6.8\n\n\nbits/signum.h\n: Linux 3.2.0\n\n\nsys/iso/signal_iso.h\n: Solaris 10\n\n\n\n\n\n\n\n\n\n\nNo signal has a signal number of 0. The \nkill\n function uses the signal number of 0 for a special case. POSIX.1 calls this value the null signal.\n\n\nNumerous conditions can generate a signal:\n\n\nThe terminal-generated signals occur when users press certain terminal keys. Pressing the DELETE key or Control-C on the terminal normally causes the interrupt signal (\nSIGINT\n) to be generated.\n\n\nHardware exceptions generate signals. For example, divide by 0 and invalid memory reference. These conditions are usually detected by the hardware, and the kernel is notified. The kernel then generates the appropriate signal for the process that was running at the time the condition occurred. For example, \nSIGSEGV\n is generated for a process that executes an invalid memory reference.\n\n\nThe \nkill(2)\n function allows a process to send any signal to another process or process group, with limitations: we have to be the owner of the process that we\u2019re sending the signal to, or we have to be the superuser.\n\n\nThe \nkill(1)\n command allows us to send signals to other processes. This program is just an interface to the \nkill\n function. This command is often used to terminate a runaway background process.\n\n\nSoftware conditions can generate signals when a process should be notified of various events. For example:\n\n\nSIGURG\n: generated when out-of-band data arrives over a network connection),\n\n\nSIGPIPE\n: generated when a process writes to a pipe that has no reader)\n\n\nSIGALRM\n: generated when an alarm clock set by the process expires).\n\n\n\n\n\n\n\n\n\n\n\n\nSignals are classic examples of asynchronous events. They occur at random times to the process. The process can\u2019t simply test a variable (such as \nerrno\n) to see whether a signal has occurred; instead, the process has to tell the kernel \"if and when this signal occurs, do the following\".\n\n\nSignal dispositions\n\n\nWe can tell the kernel to do one of three things when a signal occurs. This is called the \ndisposition of the signal\n, or the \naction associated with a signal\n. (\nsignal(7)\n)\n\n\n\n\nIgnore the signal\n. Most signals can be ignored, but two signals can never be ignored: \nSIGKILL\n and \nSIGSTOP\n.\n\n\nThe reason these two signals can\u2019t be ignored is to provide the kernel and the superuser with a surefire way of either killing or stopping any process.\n\n\nIf we ignore some of the signals that are generated by a hardware exception (such as illegal memory reference or divide by 0), the behavior of the process is undefined.\n\n\n\n\n\n\nCatch the signal\n. To do this, we tell the kernel to call a function of ours whenever the signal occurs. In our function, we can do whatever we want to handle the condition. For example:\n\n\nIf we\u2019re writing a command interpreter, when the user generates the interrupt signal at the keyboard, we probably want to return to the main loop of the program, terminating whatever command we were executing for the user.\n\n\nIf the \nSIGCHLD\n signal is caught, it means that a child process has terminated, so the signal-catching function can call \nwaitpid\n to fetch the child\u2019s process ID and termination status.\n\n\nIf the process has created temporary files, we may want to write a signal-catching function for the SIGTERM signal (the termination signal that is the default signal sent by the kill command) to clean up the temporary files.\n\n\nNote that the two signals \nSIGKILL\n and \nSIGSTOP\n can\u2019t be caught.\n\n\n\n\n\n\nLet the default action apply\n. Every signal has a default action. The default action for most signals is to terminate the process.\n\n\n\n\nThe signals \nSIGKILL\n and \nSIGSTOP\n cannot be caught, blocked, or ignored. (\nsignal(7)\n)\n\n\nUNIX System signals\n\n\nThe following table lists the names of all the signals, an indication of which systems support the signal, and the default action for the signal. The SUS column contains \"x\" if the signal is defined as part of the base POSIX.1 specification and XSI if it is defined as part of the XSI option. The supported systems are FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8 and Solaris 10.\n\n\n\n\n\n\n\n\nName\n\n\nDescription\n\n\nISO C\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\nDefault action\n\n\n\n\n\n\n\n\n\n\nSIGABRT\n\n\nabnormal termination (\nabort\n)\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGALRM\n\n\ntimer expired (\nalarm\n)\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGBUS\n\n\nhardware fault\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGCANCEL\n\n\nthreads library internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGCHLD\n\n\nchange in status of child\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGCONT\n\n\ncontinue stopped process\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\ncontinue/ignore\n\n\n\n\n\n\nSIGEMT\n\n\nhardware fault\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGFPE\n\n\narithmetic exception\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGFREEZE\n\n\ncheckpoint freeze\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGHUP\n\n\nhangup\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGILL\n\n\nillegal instruction\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGINFO\n\n\nstatus request from keyboard\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\n\n\nignore\n\n\n\n\n\n\nSIGINT\n\n\nterminal interrupt character\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGIO\n\n\nasynchronous I/O\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate/ignore\n\n\n\n\n\n\nSIGIOT\n\n\nhardware fault\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGJVM1\n\n\nJava virtual machine internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGJVM2\n\n\nJava virtual machine internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGKILL\n\n\ntermination\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGLOST\n\n\nresource lost\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGLWP\n\n\nthreads library internal use\n\n\n\n\n\n\nx\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGPIPE\n\n\nwrite to pipe with no readers\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPOLL\n\n\npollable event (\npoll\n)\n\n\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPROF\n\n\nprofiling time alarm (\nsetitimer\n)\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGPWR\n\n\npower fail/restart\n\n\n\n\n\n\n\n\nx\n\n\n\n\nx\n\n\nterminate/ignore\n\n\n\n\n\n\nSIGQUIT\n\n\nterminal quit character\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGSEGV\n\n\ninvalid memory reference\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGSTKFLT\n\n\ncoprocessor stack fault\n\n\n\n\n\n\n\n\nx\n\n\n\n\n\n\nterminate\n\n\n\n\n\n\nSIGSTOP\n\n\nstop\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGSYS\n\n\ninvalid system call\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGTERM\n\n\ntermination\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGTHAW\n\n\ncheckpoint thaw\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGTHR\n\n\nthreads library internal use\n\n\n\n\n\n\nx\n\n\n\n\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGTRAP\n\n\nhardware fault\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core\n\n\n\n\n\n\nSIGTSTP\n\n\nterminal stop character\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGTTIN\n\n\nbackground read from control tty\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGTTOU\n\n\nbackground write to control tty\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nstop process\n\n\n\n\n\n\nSIGURG\n\n\nurgent condition (sockets)\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGUSR1\n\n\nuser-defined signal\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGUSR2\n\n\nuser-defined signal\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGVTALRM\n\n\nvirtual time alarm (\nsetitimer\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate\n\n\n\n\n\n\nSIGWAITING\n\n\nthreads library internal use\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGWINCH\n\n\nterminal window size change\n\n\n\n\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nignore\n\n\n\n\n\n\nSIGXCPU\n\n\nCPU limit exceeded (\nsetrlimit\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core/ignore\n\n\n\n\n\n\nSIGXFSZ\n\n\nfile size limit exceeded (\nsetrlimit\n)\n\n\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nterminate+core/ignore\n\n\n\n\n\n\nSIGXRES\n\n\nresource control exceeded\n\n\n\n\n\n\n\n\n\n\n\n\nx\n\n\nignore\n\n\n\n\n\n\n\n\nThe core file\n\n\nWhen the default action (in the table above) is labeled \"terminate+core\", it means that a memory image of the process is left in the file named \ncore\n of the current working directory of the process. This file can be used with most UNIX System debuggers to examine the state of the process at the time it terminated.\n\n\nThe name of the \ncore\n file varies among implementations.  On Mac OS X 10.6.8, the core file is named core.\npid\n, where \npid\n is the ID of the process that received the signal. On Linux 3.2.0, the name is configured through \n/proc/sys/kernel/core_pattern\n. (\ncore(5)\n) [p315]\n\n\nMost implementations leave the core file in the current working directory of the corresponding process; Mac OS X places all core files in \n/cores\n instead.\n\n\nThe core file will not be generated if:\n\n\n\n\nthe process was set-user-ID and the current user is not the owner of the program file,\n\n\nthe process was set-group-ID and the current user is not the group owner of the file,\n\n\nthe user does not have permission to write in the current working directory,\n\n\nthe file already exists and the user does not have permission to write to it,\n\n\nthe file is too big (see \nRLIMIT_CORE\n limit in \nSection 7.11\n)\n\n\n\n\nThe permissions of the core file (assuming that the file doesn\u2019t already exist) are usually user-read and user-write, although Mac OS X sets only user-read.\n\n\nIn the table, the signals with a description of \"hardware fault\" correspond to implementation-defined hardware faults.\n\n\nDetailed description of signals\n\n\n\n\nSIGABRT\n: generated by calling the \nabort\n function.  The process terminates abnormally.\n\n\nSIGALRM\n:\n\n\nThis signal is generated when a timer set with the \nalarm\n function expires.\n\n\nThis signal is also generated when an interval timer set by the \nsetitimer(2)\n function expires.\n\n\n\n\n\n\nSIGBUS\n: indicates an implementation-defined hardware fault.  Implementations usually generate this signal on certain types of memory faults.\n\n\nSIGCANCEL\n: used internally by the Solaris threads library. It is not meant for general use.\n\n\nSIGCHLD\n: Whenever a process terminates or stops, the \nSIGCHLD\n signal is sent to the parent. By default, this signal is ignored, so the parent must catch this signal if it wants to be notified whenever a child\u2019s status changes. The normal action in the signal-catching function is to call one of the \nwait\n functions to fetch the child\u2019s process ID and termination status. [p317]\n\n\nSIGCONT\n: this job-control signal is sent to a stopped process when it is continued. The default action is to continue a stopped process, but to ignore the signal if the process wasn\u2019t stopped.\n\n\nSIGEMT\n: indicates an implementation-defined hardware fault. Not all platforms support this signal. [p318]\n\n\nSIGFPE\n: signals an arithmetic exception, such as divide by 0, floating-point overflow, and so on. The name is derived from \"floating-point exception\" (\nProgram Error Signals\n).\n\n\nSIGFREEZE\n: defined only by Solaris. \n [p318]\n\n\nSIGHUP\n: this signal is sent to the controlling process (session leader) associated with a controlling terminal if a disconnect is detected by the terminal interface.\n\n\nThis signal is generated for this condition only if the terminal\u2019s \nCLOCAL\n flag is not set. The \nCLOCAL\n flag for a terminal is set if the attached terminal is local. The flag tells the terminal driver to ignore all modem status lines.\n\n\nThe session leader that receives this signal may be in the background (\nFigure 9.7\n). This differs from the normal terminal-generated signals (interrupt, quit, and suspend), which are always delivered to the foreground process group.\n\n\nThis signal is also generated if the session leader terminates. In this case, the signal is sent to each process in the foreground process group.\n\n\nThis signal is commonly used to notify daemon processes (\nChapter 13\n) to reread their configuration files. The reason \nSIGHUP\n is chosen for this task is that a daemon should not have a controlling terminal and would normally never receive this signal.\n\n\n\n\n\n\nSIGILL\n: indicates that the process has executed an illegal hardware instruction.\n\n\n4.3BSD generated this signal from the abort function. \nSIGABRT\n is now used for this purpose.\n\n\n\n\n\n\nSIGINFO\n: This BSD signal is generated by the terminal driver when we type the status key (often Control-T). This signal is sent to all processes in the foreground process group (Figure 9.9). This signal normally causes status information on processes in the foreground process group to be displayed on the terminal. Linux doesn\u2019t provide support for \nSIGINFO\n.\n\n\nSIGINT\n: generated by the terminal driver when we press the interrupt key (often DELETE or Control-C). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). This signal is often used to terminate a runaway program, especially when it\u2019s generating a lot of unwanted output on the screen.\n\n\nSIGIO\n: indicates an asynchronous I/O event.\n\n\nSIGIOT\n: indicates an implementation-defined hardware fault. \nSIGABRT\n is now used for this purpose. On FreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10, \nSIGIOT\n is defined to be the same value as \nSIGABRT\n.\n\n\nSIGJVM1\n and \nSIGJVM2\n: reserved for use by the Java virtual machine on Solaris.\n\n\nSIGKILL\n: one of the two that can\u2019t be caught or ignored. It provides the system administrator with a sure way to kill any process.\n\n\nSIGLOST\n: used to notify a process running on a Solaris NFSv4 client system that a lock could not be reacquired during recovery.\n\n\nSIGPIPE\n: If we write to a pipeline but the reader has terminated, \nSIGPIPE\n is generated. This signal is also generated when a process writes to a socket of type \nSOCK_STREAM\n that is no longer connected.\n\n\nSIGPOLL\n: This signal is marked obsolescent in SUSv4, so it might be removed in a future version of the standard. It can be generated when a specific event occurs on a pollable device.\n\n\nSIGPROF\n: This signal is marked obsolescent in SUSv4, so it might be removed in a future version of the standard. This signal is generated when a profiling interval timer set by the \nsetitimer(2)\n function expires.\n\n\nSIGPWR\n: system dependent, mainly used on a system that has an uninterruptible power supply (UPS).\n\n\nIf power fails, the UPS takes over and the software can usually be notified. Nothing needs to be done at this point, as the system continues running on battery power. But if the battery gets low, the software is usually notified again; at this point, it behooves the system to shut everything down. The process that is notified of the low-battery condition sends the \nSIGPWR\n signal to the \ninit\n process, and \ninit\n handles the system shutdown.\n\n\nSolaris 10 and some Linux distributions have entries in the \ninittab\n file for this purpose: \npowerfail\n and \npowerwait\n (or \npowerokwait\n).\n\n\nThe default action for \nSIGPWR\n as either \"terminate\" or \"ignore\", which depends on the system. The default on Linux is to terminate the process. On Solaris, the signal is ignored by default.\n\n\n\n\n\n\nSIGQUIT\n: generated by the terminal driver when we press the terminal quit key (often Control-backslash). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). This signal not only terminates the foreground process group (as does \nSIGINT\n), but also generates a \ncore\n file.\n\n\nSIGSEGV\n: indicates that the process has made an invalid memory reference (which is usually a sign that the program has a bug, such as dereferencing an uninitialized pointer). The name SEGV stands for \"segmentation violation\".\n\n\nSIGSTKFLT\n: This signal is defined only by Linux. It showed up in the earliest versions of Linux, where it was intended to be used for stack faults taken by the math coprocessor. This signal is not generated by the kernel, but remains for backward compatibility.\n\n\nSIGSTOP\n: This job-control signal stops a process. It is similar to the interactive stop signal (\nSIGTSTP\n), but \nSIGSTOP\n cannot be caught or ignored.\n\n\nSIGSYS\n: indicates an invalid system call. The process executed a machine instruction that the kernel thought was a system call, but the parameter with the instruction that indicates the type of system call was invalid. For example, if you build a program that uses a new system call and you then try to run the same binary on an older version of the operating system where the system call doesn\u2019t exist. [p320]\n\n\nSIGTERM\n: the termination signal sent by the \nkill(1)\n command by default. Because it can be caught by applications, using \nSIGTERM\n gives programs a chance to terminate gracefully by cleaning up before exiting (in contrast to \nSIGKILL\n, which can\u2019t be caught or ignored).\n\n\nSIGTHAW\n: defined only by Solaris and used to notify processes that need to take special action when the system resumes operation after being suspended.\n\n\nSIGTHR\n: reserved for use by the thread library on FreeBSD. It is defined to have the same value as \nSIGLWP\n.\n\n\nSIGTRAP\n: indicates an implementation-defined hardware fault. The signal name comes from the PDP-11 TRAP instruction. Implementations often use this signal to transfer control to a debugger when a breakpoint instruction is executed.\n\n\nSIGTSTP\n: This interactive stop signal is generated by the terminal driver when we press the terminal suspend key (often Control-Z). This signal is sent to all processes in the foreground process group (\nFigure 9.9\n). [p321]\n\n\nSIGTTIN\n: generated by the terminal driver when a process in a background process group tries to read from its controlling terminal. If either of the following case occurs, the signal is not generated; instead, the read operation fails with errno set to \nEIO\n:\n\n\nThe reading process is ignoring or blocking this signal.\n\n\nThe process group of the reading process is orphaned.\n\n\n\n\n\n\n\n\nSIGTTOU\n: generated by the terminal driver when a process in a background process group tries to write to its controlling terminal. Unlike the case with background reads, a process can choose to allow background writes to the controlling terminal. If background writes are not allowed, then like the \nSIGTTIN\n signal, the signal is not generated if either of the following cases occurs; instead, the read operation fails with errno set to \nEIO\n:\n\n\n\n\nThe writing process is ignoring or blocking this signal\n\n\nThe process group of the writing process is orphaned\n\n\n\n\nRegardless of whether background writes are allowed, certain terminal operations (other than writing), including \ntcsetattr\n, \ntcsendbreak\n, \ntcdrain\n, \ntcflush\n, \ntcflow\n, and \ntcsetpgrp\n can also generate the \nSIGTTOU\n signal.\n\n\n\n\n\n\nSIGURG\n: notifies the process that an urgent condition has occurred. It is optionally generated when \nout-of-band data\n is received on a network connection.\n\n\n\n\nSIGUSR1\n and \nSIGUSR2\n: user-defined signals, for use in application programs.\n\n\nSIGVTALRM\n: generated when a virtual interval timer set by the \nsetitimer(2)\n function expires.\n\n\nSIGWAITING\n: used internally by the Solaris threads library, and is not available for general use.\n\n\nSIGWINCH\n: The kernel maintains the size of the window associated with each terminal and pseudo terminal. A process can get and set the window size with the \nioctl\n function. If a process changes the window size from its previous value using the \nioctl\n set-window-size command, the kernel generates the \nSIGWINCH\n signal for the foreground process group.\n\n\nSIGXCPU\n: generated if the process exceeds its soft CPU time limit. The default action depends on the operating system. The Single UNIX Specification requires that the default action be to terminate the process abnormally.\n\n\nLinux 3.2.0 and Solaris 10 support a default action of terminate with a core file\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 support a default action of terminate without generating a core file.\n\n\n\n\n\n\nSIGXFSZ\n:  generated if the process exceeds its soft file size limit. The default action depends on the operating system, similar to \nSIGXCPU\n.\n\n\nSIGXRES\n: defined only by Solaris.\n\n\n\n\nsignal\n Function\n\n\nThe simplest interface to the signal features of the UNIX System is the signal function\n\n\napue_signal.h\n\n\n#include \nsignal.h\n\n\n\nvoid\n \n(\n*\nsignal\n(\nint\n \nsigno\n,\n \nvoid\n \n(\n*\nfunc\n)(\nint\n)))(\nint\n);\n\n\n\n/* Returns: previous disposition of signal (see following) if OK, SIG_ERR on error */\n\n\n\n\n\n\nImplementations derived from UNIX System V support the \nsignal\n function, which provides the old unreliable-signal semantics. New applications should not use these unreliable signals. 4.4BSD also provides the \nsignal\n function, but it is defined in terms of the \nsigaction\n function, so using it under 4.4BSD provides the newer reliable-signal semantics. Most current systems follow this strategy except Solaris. [p323]\n\n\nBecause the semantics of signal differ among implementations, we must use the \nsigaction\n function instead. We provide an implementation of \nsignal\n that uses \nsigaction\n (later this chapter).\n\n\nArguments:\n\n\n\n\nThe \nsigno\n argument is the name of the signal from \nprevious table\n.\n\n\nThe value of \nfunc\n one of the following:\n\n\nthe constant \nSIG_IGN\n, which tells the system ignore the signal;\n\n\nthe constant \nSIG_DFL\n, which sets the action associated with the signal to its default value;\n\n\nthe address of a function to be called when the signal occurs, which arranges to \"catch\" the signal. This function is called either the \nsignal handler\n or the \nsignal-catching function\n.\n\n\n\n\n\n\n\n\nThe prototype for the \nsignal\n function states that the function requires two arguments and returns a pointer to a function that returns nothing (\nvoid\n):\n\n\n\n\nThe first argument, \nsigno\n, is an integer.\n\n\nThe second argument, \nfunc\n, is a pointer to a function that takes a single integer argument and returns nothing.\n\n\nThe returned function (function whose address is returned as the value of \nsignal\n) takes a single integer argument (the final (\nint\n)).\n\n\n\n\nIn plain English, this declaration says that the signal handler is passed a single integer argument (the signal number) and that it returns nothing. When we call signal to establish the signal handler, the second argument is a pointer to the function.  The return value from \nsignal\n is the pointer to the previous signal handler.\n\n\nThe \nsignal\n function prototype can be made much simpler through the use of the following \ntypedef\n:\n\n\ntypedef\n \nvoid\n \nSigfunc\n(\nint\n);\n\n\n\n\n\n\nThen the prototype becomes:\n\n\nSigfunc\n \n*\nsignal\n(\nint\n,\n \nSigfunc\n \n*\n);\n\n\n\n\n\n\nThis \ntypedef\n is included in \napue.h\n and is used with the functions in this chapter.\n\n\nIf we examine the system\u2019s header \nsignal.h\n, we will probably find declarations of the form:\n\n\n#define SIG_ERR (void (*)())-1\n\n\n#define SIG_DFL (void (*)())0\n\n\n#define SIG_IGN (void (*)())1\n\n\n\n\n\n\nThese constants can be used in place of the \"pointer to a function that takes an integer argument and returns nothing\", the second argument to \nsignal\n, and the return value from \nsignal\n. The three values used for these constants need not be \u22121, 0, and 1. They must be three values that can never be the address of any declarable function. Most UNIX systems use the values shown. (See \nDoubts and Solutions\n for details)\n\n\nExample:\n\n\nThe following code shows a simple signal handler that catches either of the two user-defined signals and prints the signal number.\n\n\n\n\nsigusr.c\n\n\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_usr\n(\nint\n);\n   \n/* one handler for both signals */\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGUSR1\n);\n\n    \nif\n \n(\nsignal\n(\nSIGUSR2\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGUSR2\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n\n        \npause\n();\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_usr\n(\nint\n \nsigno\n)\n      \n/* argument is signal number */\n\n\n{\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGUSR1\n)\n\n        \nprintf\n(\nreceived SIGUSR1\n\\n\n);\n\n    \nelse\n \nif\n \n(\nsigno\n \n==\n \nSIGUSR2\n)\n\n        \nprintf\n(\nreceived SIGUSR2\n\\n\n);\n\n    \nelse\n\n        \nerr_dump\n(\nreceived signal %d\n\\n\n,\n \nsigno\n);\n\n\n}\n\n\n\n\n\n\nWe invoke the program in the background and use the \nkill(1)\n command to send it signals. The term \nkill\n in the UNIX System is a misnomer. The \nkill(1)\n command and the \nkill(2)\n function just send a signal to a process or process group. Whether that signal terminates the process depends on which signal is sent and whether the process has arranged to catch the signal.\n\n\nResult:\n\n\n$ ./a.out \n                # start process in background\n\n\n[1] 7216                   # job-control shell prints job number and process ID\n\n\n$ kill -USR1 7216          # send it SIGUSR1\n\n\nreceived SIGUSR1\n\n\n$ kill -USR2 7216          # send it SIGUSR2\n\n\nreceived SIGUSR2\n\n\n$ kill 7216                # now send it SIGTERM\n\n\n[1]+ Terminated ./a.out\n\n\n\n\n\n\nWhen we send the \nSIGTERM\n signal, the process is terminated, since it doesn\u2019t catch the signal, and the default action for the signal is termination.\n\n\nProgram Start-Up\n\n\nWhen a program is executed, the status of all signals is either default or ignore. All signals are set to their default action, unless the process that calls \nexec\n is ignoring the signal. The \nexec\n functions change the disposition of any signals being caught to their default action and leave the status of all other signals alone. The reason is that a signal that is being caught by a process that calls \nexec\n cannot be caught by the same function in the new program, since the address of the signal-catching function in the caller probably has no meaning in the new program file that is executed. [p325]\n\n\nWith a shell that doesn\u2019t support job control, when we execute a process in the background:\n\n\ncc main.c \n\n\n\n\n\n\nThe shell automatically sets the disposition of the interrupt and quit signals in the background process to be ignored. This is done so that if we type the interrupt character, it doesn\u2019t affect the background process. If this weren\u2019t done and we typed the interrupt character, it would terminate not only the foreground process, but also all the background processes.\n\n\nMany interactive programs that catch these two signals have code that looks like:\n\n\nvoid\n \nsig_int\n(\nint\n),\n \nsig_quit\n(\nint\n);\n\n\n\nif\n \n(\nsignal\n(\nSIGINT\n,\n \nSIG_IGN\n)\n \n!=\n \nSIG_IGN\n)\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n\n\nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nSIG_IGN\n)\n \n!=\n \nSIG_IGN\n)\n\n    \nsignal\n(\nSIGQUIT\n,\n \nsig_quit\n);\n\n\n\n\n\n\nFollowing this approach, the process catches the signal only if the signal is not currently being ignored.\n\n\nThe \nsignal\n function has a limitation: we are not able to determine the current disposition of a signal without changing the disposition. The \nsigaction\n function (discussed later in this chapter) allows us to determine a signal\u2019s disposition without changing it.\n\n\nProcess Creation\n\n\nWhen a process calls \nfork\n, the child inherits the parent\u2019s signal dispositions. Here, since the child starts off with a copy of the parent\u2019s memory image, the address of a signal-catching function has meaning in the child.\n\n\nUnreliable Signals\n\n\nIn earlier versions of the UNIX System, signals were unreliable, which means that signals could get lost: a signal could occur and the process would never know about it. [p326]\n\n\nOne problem with these early versions was that the action for a signal was reset to its default each time the signal occurred. The code that was described usually looked like:\n\n\n    \nint\n \nsig_int\n();\n \n/* my signal handling function */\n\n    \n...\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* establish handler */\n\n    \n...\n\n\n\nsig_int\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* reestablish handler for next time */\n\n    \n...\n \n/* process the signal ... */\n \n.\n\n\n}\n\n\n\n\n\n\nThe problem with this code fragment is that there is a window of time (after the signal has occurred, but before the call to \nsignal\n in the signal handler) when the interrupt signal could occur another time. This second signal would cause the default action to occur, which terminates the process. This is one of those conditions that works correctly most of the time, causing us to think that it is correct, when it isn\u2019t.\n\n\nAnother problem with these earlier systems was that the process was unable to turn a signal off when it didn\u2019t want the signal to occur. All the process could do was ignore the signal. There are times when we would like to tell the system \"prevent the following signals from interrupting me, but remember if they do occur\". The following code catches a signal and sets a flag for the process that indicates that the signal occurred:\n\n\nint\n \nsig_int\n();\n \n/* my signal handling function */\n\n\nint\n \nsig_int_flag\n;\n \n/* set nonzero when signal occurs */\n\n\n\nmain\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* establish handler */\n\n    \n...\n\n    \nwhile\n \n(\nsig_int_flag\n \n==\n \n0\n)\n\n        \npause\n();\n \n/* go to sleep, waiting for signal */\n\n    \n...\n\n\n}\n\n\n\nsig_int\n()\n\n\n{\n\n    \nsignal\n(\nSIGINT\n,\n \nsig_int\n);\n \n/* reestablish handler for next time */\n\n    \nsig_int_flag\n \n=\n \n1\n;\n \n/* set flag for main loop to examine */\n\n\n}\n\n\n\n\n\n\nThe process is calling the \npause\n function to put it to sleep until a signal is caught. When the signal is caught, the signal handler just sets the flag \nsig_int_flag\n to a nonzero value. The process is automatically awakened by the kernel after the signal handler returns, notices that the flag is nonzero, and does whatever it needs to do. But there is a window of time when things can go wrong. If the signal occurs after the test of \nsig_int_flag\n but before the call to pause, the process could go to sleep forever (assuming that the signal is never generated again). This occurrence of the signal is lost.\n\n\nInterrupted System Calls\n\n\nIn earlier UNIX systems, if a process caught a signal while the process was blocked in a \"slow\" system call, the system call was interrupted. The system call returned an error and \nerrno\n was set to \nEINTR\n. This was done under the assumption that since a signal occurred and the process caught it, there is a good chance that something has happened that should wake up the blocked system call.\n\n\nSlow system calls\n\n\nThe system calls are divided into two categories: the \"slow\" system calls and all the others. The slow system calls are those that can block forever:\n\n\n\n\nReads that can block the caller forever if data isn\u2019t present with certain file types (pipes, terminal devices, and network devices)\n\n\nWrites that can block the caller forever if the data can\u2019t be accepted immediately by these same file types\n\n\nOpens on certain file types that block the caller until some condition occurs (such as a terminal device open waiting until an attached modem answers the phone)\n\n\nThe \npause\n function (which by definition puts the calling process to sleep until a signal is caught) and the \nwait\n function\n\n\nCertain \nioctl\n operations\n\n\nSome of the interprocess communication functions\n\n\n\n\nThe notable exception to these slow system calls is anything related to disk I/O. Although a read or a write of a disk file can block the caller temporarily (while the disk driver queues the request and then the request is executed), unless a hardware error occurs, the I/O operation always returns and unblocks the caller quickly.\n\n\nHistorically, POSIX.1 semantics gave implementations a choice of how to deal with \nread\ns and \nwrite\ns that have processed partial amounts of data, implementations derived from System V fail the system call, whereas BSD-derived implementations return partial success. With the 2001 version of the POSIX.1 standard, the BSD-style semantics are required. [p328]\n\n\nThe problem with interrupted system calls is that we now have to handle the error return explicitly. Assuming a read operation and assuming that we want to restart the read even if it\u2019s interrupted, the typical code sequence would be:\n\n\nagain\n:\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nfd\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n            \ngoto\n \nagain\n;\n \n/* just an interrupted system call */\n\n        \n/* handle other errors */\n\n    \n}\n\n\n\n\n\n\nAutomatic restarts of interrupted system calls\n\n\nAutomatic restarting of certain interrupted system calls were introducted since 4.2BSD to prevent applications from having to handle interrupted system calls. The system calls that were automatically restarted are:\n\n\n\n\nFunctions that are interrupted by a signal only if they are operating on a slow device:\n\n\nioctl\n\n\nread\n\n\nreadv\n\n\nwrite\n\n\nwritev\n\n\n\n\n\n\nFunctions that are always interrupted when a signal is caught.\n\n\nwait\n\n\nwaitpid\n\n\n\n\n\n\n\n\nSome applications didn\u2019t want the operation restarted if it was interrupted; 4.3BSD allowed the process to disable this feature on a per-signal basis.\n\n\nDifference between the \nsignal\n and \nsigaction\n functions on restarts\n\n\nPOSIX.1 requires an implementation to restart system calls only when the \nSA_RESTART\n flag is in effect for the interrupting signal. This flag is used with the \nsigaction\n function to allow applications to request that interrupted system calls be restarted.\n\n\nHistorically, when using the \nsignal\n function to establish a signal handler, implementations varied with respect to how interrupted system calls were handled. System V never restarted system calls by default. BSD, in contrast, restarted them if the calls were interrupted by signals. On FreeBSD 8.0, Linux 3.2.0, and Mac OS X 10.6.8, when signal handlers are installed with the \nsignal\n function, interrupted system calls will be restarted. By using our own implementation of the \nsignal\n function, we avoid having to deal with these differences. [p329]\n\n\nOne reason 4.2BSD introduced the automatic restart feature is that sometimes we don\u2019t know that the input or output device is a slow device. [p329]\n\n\nThe figure below summarizes the signal functions and their semantics provided by the various implementations.\n\n\n\n\nLater this chapter, we provide our own version of the \nsignal\n function that automatically tries to restart interrupted system calls (other than for the \nSIGALRM\n signal), and \nsignal_intr\n, that tries to never do the restart.\n\n\nReentrant Functions\n\n\nWhen a signal that is being caught is handled by a process, the normal sequence of instructions being executed by the process is temporarily interrupted by the signal handler. The process then continues executing, but the instructions in the signal handler are now executed. If the signal handler returns (instead of calling \nexit\n or \nlongjmp\n), then the normal sequence of instructions that the process was executing when the signal was caught continues executing. This is similar to what happens when a hardware interrupt occurs.\n\n\nHowever, in the signal handler, we can\u2019t tell where the process was executing when the signal was caught:\n\n\n\n\nWhat if the process was in the middle of allocating additional memory on its heap using \nmalloc\n, and we call \nmalloc\n from the signal handler?\n\n\nHavoc can result for the process, since \nmalloc\n usually maintains a linked list of all its allocated areas, and it may have been in the middle of changing this list.\n\n\n\n\n\n\nWhat if the process was in the middle of a call to a function, such as \ngetpwnam\n (\nSection 6.2\n), that stores its result in a static location, and we call the same function from the signal handler?\n\n\nThe information returned to the normal caller can get overwritten with the information returned to the signal handler.\n\n\n\n\n\n\n\n\nThe Single UNIX Specification specifies the functions that are guaranteed to be safe to call from within a signal handler. These functions are reentrant and are called \nasync-signal safe\n by the SUS. Besides being reentrant, they block any signals during operation if delivery of a signal might cause inconsistencies.\n\n\nThe following table lists these async-signal safe functions, which are reentrant functions that may be called from a signal handler.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nabort\n\n\nfaccessat\n\n\nlinkat\n\n\nselect\n\n\nsocketpair\n\n\n\n\n\n\naccept\n\n\nfchmod\n\n\nlisten\n\n\nsem_post\n\n\nstat\n\n\n\n\n\n\naccess\n\n\nfchmodat\n\n\nlseek\n\n\nsend\n\n\nsymlink\n\n\n\n\n\n\naio_error\n\n\nfchown\n\n\nlstat\n\n\nsendmsg\n\n\nsymlinkat\n\n\n\n\n\n\naio_return\n\n\nfchownat\n\n\nmkdir\n\n\nsendto\n\n\ntcdrain\n\n\n\n\n\n\naio_suspend\n\n\nfcntl\n\n\nmkdirat\n\n\nsetgid\n\n\ntcflow\n\n\n\n\n\n\nalarm\n\n\nfdatasync\n\n\nmkfifo\n\n\nsetpgid\n\n\ntcflush\n\n\n\n\n\n\nbind\n\n\nfexecve\n\n\nmkfifoat\n\n\nsetsid\n\n\ntcgetattr\n\n\n\n\n\n\ncfgetispeed\n\n\nfork\n\n\nmknod\n\n\nsetsockopt\n\n\ntcgetpgrp\n\n\n\n\n\n\ncfgetospeed\n\n\nfstat\n\n\nmknodat\n\n\nsetuid\n\n\ntcsendbreak\n\n\n\n\n\n\ncfsetispeed\n\n\nfstatat\n\n\nopen\n\n\nshutdown\n\n\ntcsetattr\n\n\n\n\n\n\ncfsetospeed\n\n\nfsync\n\n\nopenat\n\n\nsigaction\n\n\ntcsetpgrp\n\n\n\n\n\n\nchdir\n\n\nftruncate\n\n\npause\n\n\nsigaddset\n\n\ntime\n\n\n\n\n\n\nchmod\n\n\nfutimens\n\n\npipe\n\n\nsigdelset\n\n\ntimer_getoverrun\n\n\n\n\n\n\nchown\n\n\ngetegid\n\n\npoll\n\n\nsigemptyset\n\n\ntimer_gettime\n\n\n\n\n\n\nclock_gettime\n\n\ngeteuid\n\n\nposix_trace_event\n\n\nsigfillset\n\n\ntimer_settime\n\n\n\n\n\n\nclose\n\n\ngetgid\n\n\npselect\n\n\nsigismember\n\n\ntimes\n\n\n\n\n\n\nconnect\n\n\ngetgroups\n\n\nraise\n\n\nsignal\n\n\numask\n\n\n\n\n\n\ncreat\n\n\ngetpeername\n\n\nread\n\n\nsigpause\n\n\nuname\n\n\n\n\n\n\ndup\n\n\ngetpgrp\n\n\nreadlink\n\n\nsigpending\n\n\nunlink\n\n\n\n\n\n\ndup2\n\n\ngetpid\n\n\nreadlinkat\n\n\nsigprocmask\n\n\nunlinkat\n\n\n\n\n\n\nexecl\n\n\ngetppid\n\n\nrecv\n\n\nsigqueue\n\n\nutime\n\n\n\n\n\n\nexecle\n\n\ngetsockname\n\n\nrecvfrom\n\n\nsigset\n\n\nutimensat\n\n\n\n\n\n\nexecv\n\n\ngetsockopt\n\n\nrecvmsg\n\n\nsigsuspend\n\n\nutimes\n\n\n\n\n\n\nexecve\n\n\ngetuid\n\n\nrename\n\n\nsleep\n\n\nwait\n\n\n\n\n\n\n_Exit\n\n\nkill\n\n\nrenameat\n\n\nsockatmark\n\n\nwaitpid\n\n\n\n\n\n\n_exit\n\n\nlink\n\n\nrmdir\n\n\nsocket\n\n\nwrite\n\n\n\n\n\n\n\n\nMost of the functions that are not included in table above are missing because:\n\n\n\n\nThey are known to use static data structures;\n\n\nThey call \nmalloc\n or \nfree\n;\n\n\nThey are part of the standard I/O library.\n\n\n\n\nNote when using the functions in the table above:\n\n\n\n\nMost implementations of the standard I/O library use global data structures in a nonreentrant way.\n\n\n\n\nBe aware that even if we call a function listed in the table above from a signal handler, there is only one \nerrno\n variable per thread (recall the discussion of errno and threads in \nSection 1.7\n), and we might potentially modify its value.\n\n\n\n\nConsider a signal handler that is invoked right after main has set \nerrno\n. If the signal handler calls \nread\n, for example, this call can change the value of \nerrno\n, wiping out the value that was just stored in \nmain\n.\n\n\n\n\nTherefore, as a general rule, when calling the functions listed in the table above from a signal handler, we should save and restore \nerrno\n. Be aware that a commonly caught signal is \nSIGCHLD\n, and its signal handler usually calls one of the wait functions. All the \nwait\n functions can change \nerrno\n.\n\n\n\n\n\n\nlongjmp\n (\nSection 7.10\n) and \nsiglongjmp\n (\nSection 10.15\n) are missing\nfrom the table because the signal may have occurred while the \nmain\n routine was updating a data structure in a nonreentrant way. This data structure could be left half updated if we call \nsiglongjmp\n instead of returning from the signal handler. If it is going to do such things as update global data structures, while catching signals that cause \nsigsetjmp\n to be executed, an application needs to block the signals while updating the data structures.\n\n\n\n\n\n\nExample of calling \ngetpwnam\n from a signal handler *\n\n\nThe code below shows a program that calls the nonreentrant function \ngetpwnam\n from a signal handler that is called every second. We use the \nalarm\n function (\nSection 10.10\n) here to generate a \nSIGALRM\n signal every second.\n\n\nsignals/reenter.c\n\n\n#include \napue.h\n\n\n#include \npwd.h\n\n\n\nstatic\n \nvoid\n\n\nmy_alarm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nstruct\n \npasswd\n   \n*\nrootptr\n;\n\n\n    \nprintf\n(\nin signal handler\n\\n\n);\n\n    \nif\n \n((\nrootptr\n \n=\n \ngetpwnam\n(\nroot\n))\n \n==\n \nNULL\n)\n\n            \nerr_sys\n(\ngetpwnam(root) error\n);\n\n    \nalarm\n(\n1\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nstruct\n \npasswd\n   \n*\nptr\n;\n\n\n    \nsignal\n(\nSIGALRM\n,\n \nmy_alarm\n);\n\n    \nalarm\n(\n1\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n((\nptr\n \n=\n \ngetpwnam\n(\nsar\n))\n \n==\n \nNULL\n)\n\n            \nerr_sys\n(\ngetpwnam error\n);\n\n        \nif\n \n(\nstrcmp\n(\nptr\n-\npw_name\n,\n \nsar\n)\n \n!=\n \n0\n)\n\n            \nprintf\n(\nreturn value corrupted!, pw_name = %s\n\\n\n,\n\n                    \nptr\n-\npw_name\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWhen this program was run, the results were random. Usually, the program would be terminated by a \nSIGSEGV\n signal when the signal handler returned after several iterations. An examination of the \ncore\n file showed that the main function had called \ngetpwnam\n, but that when \ngetpwnam\n called \nfree\n, the signal handler interrupted it and called \ngetpwnam\n, which in turn called \nfree\n. The data structures maintained by \nmalloc\n and \nfree\n had been corrupted when the signal handler (indirectly) called \nfree\n while the main function was also calling \nfree\n. Occasionally, the program would run for several seconds before crashing with a \nSIGSEGV\n error. When the main function did run correctly after the signal had been caught, the return value was sometimes corrupted and sometimes fine.\n\n\nSIGCLD\n Semantics\n\n\nTwo signals that continually generate confusion are \nSIGCLD\n and \nSIGCHLD\n. The name \nSIGCLD\n (without the \nH\n) is from System V, and this signal has different semantics from the BSD signal, named \nSIGCHLD\n. The POSIX.1 signal is also named \nSIGCHLD\n.\n\n\nThe semantics of the BSD \nSIGCHLD\n signal are normal and its semantics are similar to all other signals. When the signal occurs, the status of a child has changed, and we need to call one of the \nwait\n functions to determine what has happened.\n\n\nSystem V, however, has traditionally handled the \nSIGCLD\n signal differently from other signals:\n\n\n\n\nIf the process specifically sets its disposition to \nSIG_IGN\n, children of the calling process will not generate zombie processes. [p333]\n\n\n4.4BSD always generates zombies if \nSIGCHLD\n is ignored. If we want to avoid zombies, we have to \nwait\n for our children.\n\n\n\n\n\n\nIf we set the disposition of \nSIGCLD\n to be caught, the kernel immediately checks whether any child processes are ready to be \nwait\ned for and, if so, calls the \nSIGCLD\n handler. [p333-335]\n\n\nFreeBSD 8.0 and Mac OS X 10.6.8 don\u2019t exhibit this problem, because BSD-based systems generally don\u2019t support historical System V semantics for SIGCLD.\n\n\nLinux 3.2.0 also doesn\u2019t exhibit this problem, because it doesn\u2019t call the \nSIGCHLD\n signal handler when a process arranges to catch \nSIGCHLD\n and child processes are ready to be waited for, even though \nSIGCLD\n and \nSIGCHLD\n are defined to be the same value.\n\n\nSolaris avoids this problem by including extra code in the kernel.\n\n\n\n\n\n\n\n\nOf the four platforms described in this text, only Linux 3.2.0 and Solaris 10 define \nSIGCLD\n. On these platforms, \nSIGCLD\n is equivalent to \nSIGCHLD\n.\n\n\nReliable-Signal Terminology and Semantics\n\n\nThis section defines some terms used through the discussion of signals.\n\n\n\n\nA signal is \ngenerated\n for a process (or sent to a process) when the event that causes the signal occurs. When the signal is generated, the kernel usually sets a flag of some form in the process table. The event could be:\n\n\nHardware exception (e.g., divide by 0),\n\n\nSoftware condition (e.g., an alarm timer expiring),\n\n\nTerminal-generated signal,\n\n\nA call to the \nkill\n function.\n\n\n\n\n\n\nA signal is \ndelivered\n to a process when the action for a signal is taken.\n\n\nA signal is \npending\n during the time between its generation and delivery.\n\n\n\n\nA process has the option of \nblocking\n the delivery of a signal. If a signal that is blocked is generated for a process, and if the action for that signal is either the default action or to catch the signal, then the signal remains pending for the process until the process either:\n\n\n\n\nunblocks the signal, or\n\n\nchanges the action to ignore the signal.\n\n\n\n\nThe system determines what to do with a blocked signal when the signal is delivered, not when it\u2019s generated. This allows the process to change the action for the signal before it\u2019s delivered. The \nsigpending\n function (\nSection 10.13\n) can be called by a process to determine which signals are blocked and pending.\n\n\n\n\n\n\nPOSIX.1 allows the system to deliver the signal either once or more than once in case a blocked signal is generated more than once before the process unblocks the signal. If the system delivers the signal more than once, we say that the signals are \nqueued\n. Most UNIX systems, however, do not queue signals unless they support the real-time extensions to POSIX.1. Instead, the UNIX kernel simply delivers the signal once. [p336]\n\n\nSection 10.20\n discusses queueing signals further.\n\n\nPOSIX.1 does not specify the order in which the signals are delivered to the process. The Rationale for POSIX.1 does suggest, however, that signals related to the current state of the process be delivered before other signals. (\nSIGSEGV\n is one such signal.)\n\n\nEach process has a \nsignal mask\n that defines the set of signals currently blocked from delivery to that process. This mask has one bit for each possible signal. If the bit is on for a given signal, that signal is currently blocked. A process can examine and change its current signal mask by calling \nsigprocmask\n (\nSection 10.12\n). Since it is possible for the number of signals to exceed the number of bits in an integer, POSIX.1 defines a data type, called \nsigset_t\n, that holds a \nsignal set\n. The signal mask is stored in one of these signal sets. The five functions that operate on signal sets are described in \nSection 10.11\n.\n\n\nkill\n and \nraise\n Functions\n\n\n\n\nThe \nkill\n function sends a signal to a process or a group of processes.\n\n\nThe \nraise\n function allows a process to send a signal to itself.\n\n\nThe \nraise\n function was originally defined by ISO C. POSIX.1 includes it to align itself with the ISO C standard, but POSIX.1 extends the specification of raise to deal with threads. Since ISO C does not deal with multiple processes, it could not define a function, such as \nkill\n, that requires a process ID argument.\n\n\n\n\n\n\n\n\n#include \nsignal.h\n\n\n\nint\n \nkill\n(\npid_t\n \npid\n,\n \nint\n \nsigno\n);\n\n\nint\n \nraise\n(\nint\n \nsigno\n);\n\n\n\n/* Both return: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe call:\n\n\nraise\n(\nsigno\n);\n\n\n\n\n\n\nis equivalent to the call:\n\n\nkill\n(\ngetpid\n(),\n \nsigno\n);\n\n\n\n\n\n\nThere are four different conditions for the \npid\n argument to kill:\n\n\n\n\npid\n \n 0. The signal is sent to the process whose process ID is \npid\n.\n\n\npid\n == 0 The signal is sent to all processes whose process group ID equals the process group ID of the sender and for which the sender has permission to send the signal.\n\n\npid\n \n 0. The signal is sent to all processes whose process group ID equals the absolute value of \npid\n and for which the sender has permission to send the signal.\n\n\npid\n == \u22121. The signal is sent to all processes on the system for which the sender has permission to send the signal.\n\n\n\n\nNote that the term \nall processes\n in the four conditions above excludes an implementation-defined set of system processes, including kernel processes and \ninit\n (pid 1).\n\n\nA process needs permission to send a signal to another process:\n\n\n\n\nThe superuser can send a signal to any process.\n\n\nFor other users, the real or effective user ID of the sender has to equal the real or effective user ID of the receiver. If the implementation supports \n_POSIX_SAVED_IDS\n, the saved set-user-ID of the receiver is checked instead of its effective user ID.\n\n\nOne special case for the permission testing also exists: if the signal being sent is \nSIGCONT\n,aprocess can send it to any other process in the same session.\n\n\n\n\nSome other notes on the \nkill\n function:\n\n\n\n\nPOSIX.1 defines signal number 0 as the null signal. If the \nsigno\n argument is 0, then the normal error checking is performed by \nkill\n, but no signal is sent. This technique is often used to determine if a specific process still exists. If we send the process the null signal and it doesn\u2019t exist, \nkill\n returns \u22121 and \nerrno\n is set to \nESRCH\n. Be aware, however, that UNIX systems recycle process IDs after some amount of time, so the existence of a process with a given process ID does not necessarily mean that it\u2019s the process that you think it is.\n\n\nThe test for process existence is not atomic. By the time that \nkill\n returns the answer to the caller, the process in question might have exited, so the answer is of limited value.\n\n\nIf the call to \nkill\n causes the signal to be generated for the calling process and if the signal is not blocked, either \nsigno\n or some other pending, unblocked signal is delivered to the process before \nkill\n returns. For additional conditions that occur with threads, see \nSection 12.8\n.\n\n\n\n\nalarm\n and \npause\n Functions\n\n\nThe \nalarm\n function sets a timer that will expire at a specified time in the future. When the timer expires, the \nSIGALRM\n signal is generated. If we ignore or don\u2019t catch this signal, its default action is to terminate the process.\n\n\n#include \nunistd.h\n\n\n\nunsigned\n \nint\n \nalarm\n(\nunsigned\n \nint\n \nseconds\n);\n\n\n\n/* Returns: 0 or number of seconds until previously set alarm */\n\n\n\n\n\n\n\n\nThe \nseconds\n value is the number of clock seconds in the future when the signal should be generated. When that time occurs, the signal is generated by the kernel, although additional time could elapse before the process gets control to handle the signal, because of processor scheduling delays.\n\n\nThere is only one of these alarm clocks per process. If \nalarm\n is called with a previously registered alarm clock not yet expired, then:\n\n\nThe number of seconds left for previous alarm clock is returned as the value of this function.\n\n\nThe previous alarm clock is replaced by the new value.\n\n\n\n\n\n\nIf a previously registered alarm clock for the process has not yet expired and if the seconds value is 0, the previous alarm clock is canceled. The number of seconds left for that previous alarm clock is still returned as the value of the function.\n\n\n\n\nAlthough the default action for \nSIGALRM\n is to terminate the process, most processes that use an alarm clock catch this signal, which can perform whatever cleanup is required before terminating if the process wants to terminate. \nIf we intend to catch \nSIGALRM\n, we need to be careful to install its signal handler before calling \nalarm\n. If we call \nalarm\n first and are sent \nSIGALRM\n before we can install the signal handler, our process will terminate.\n\n\nThe \npause\n function suspends the calling process until a signal is caught.\n\n\n#include \nunistd.h\n\n\n\nint\n \npause\n(\nvoid\n);\n\n\n\n/* Returns: \u22121 with errno set to EINTR */\n\n\n\n\n\n\nThe only time \npause\n returns is if a signal handler is executed and that handler returns. In that case, \npause\n returns \u22121 with \nerrno\n set to \nEINTR\n.\n\n\nsleep1\n example\n\n\nUsing \nalarm\n and \npause\n, we can put a process to sleep for a specified amount of time. The following implementation of \nsleep1\n is incomplete and has problems:\n\n\nsignals/sleep1.c\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just return to wake up the pause */\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep1\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nreturn\n(\nseconds\n);\n\n    \nalarm\n(\nseconds\n);\n     \n/* start the timer */\n\n    \npause\n();\n            \n/* next caught signal wakes us up */\n\n    \nreturn\n(\nalarm\n(\n0\n));\n   \n/* turn off timer, return unslept time */\n\n\n}\n\n\n\n\n\n\nThis simple implementation has three problems:\n\n\n\n\nIf the caller already has an alarm set, that alarm is erased by the first call to \nalarm\n.\n We can correct this by looking at \nalarm\n\u2019s return value:\n\n\nIf the number of seconds until some previously set alarm is less than the argument, then we should wait only until the existing alarm expires.\n\n\nIf the previously set alarm will go off after ours, then before returning we should reset this alarm to occur at its designated time in the future.\n\n\n\n\n\n\nWe have modified the disposition for \nSIGALRM\n.\n If we\u2019re writing a function for others to call, we should save the disposition when our function is called and restore it when we\u2019re done. We can correct this by saving the return value from \nsignal\n and resetting the disposition before our function returns.\n\n\nThere is a race condition between the first call to \nalarm\n and the call to \npause\n.  On a busy system, it\u2019s possible for the alarm to go off and the signal handler to be called before we call pause. If that happens, the caller is suspended forever in the call to \npause\n (assuming that some other signal isn\u2019t caught).\n\n\n\n\nsleep2\n example: using \nsetjmp\n and \nlongjmp\n\n\nThe following example corrects problem 3 as described above using \nsetjmp\n. The problem 3 can also be corrected using \nsigprocmask\n and \nsigsuspend\n, as described in \nSection 10.19\n.\n\n\nsignals/sleep2.c\n\n\n#include    \nsetjmp.h\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nstatic\n \njmp_buf\n  \nenv_alrm\n;\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nlongjmp\n(\nenv_alrm\n,\n \n1\n);\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep2\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nreturn\n(\nseconds\n);\n\n    \nif\n \n(\nsetjmp\n(\nenv_alrm\n)\n \n==\n \n0\n)\n \n{\n\n        \nalarm\n(\nseconds\n);\n     \n/* start the timer */\n\n        \npause\n();\n            \n/* next caught signal wakes us up */\n\n    \n}\n\n    \nreturn\n(\nalarm\n(\n0\n));\n       \n/* turn off timer, return unslept time */\n\n\n}\n\n\n\n\n\n\nThe \nsleep2\n function avoids the race condition. Even if the \npause\n is never executed, the \nsleep2\n function returns when the \nSIGALRM\n occurs.\n\n\nsleep2\n's interaction with other signals\n\n\nThere is another subtle problem with the \nsleep2\n function involving its interaction with other signals. If the \nSIGALRM\n interrupts some other signal handler, then when we call \nlongjmp\n, we abort the other signal handler, as shown in the following code:\n\n\nsignals/tsleep2.c\n\n\n#include \napue.h\n\n\n\nunsigned\n \nint\n    \nsleep2\n(\nunsigned\n \nint\n);\n\n\nstatic\n \nvoid\n     \nsig_int\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nunsigned\n \nint\n    \nunslept\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nunslept\n \n=\n \nsleep2\n(\n5\n);\n\n    \nprintf\n(\nsleep2 returned: %u\n\\n\n,\n \nunslept\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nint\n             \ni\n,\n \nj\n;\n\n    \nvolatile\n \nint\n    \nk\n;\n\n\n/*\n\n\n     * Tune these loops to run for more than 5 seconds\n\n\n     * on whatever system this test program is run.\n\n\n     */\n\n    \nprintf\n(\n\\n\nsig_int starting\n\\n\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \n300000\n;\n \ni\n++\n)\n\n        \nfor\n \n(\nj\n \n=\n \n0\n;\n \nj\n \n \n4000\n;\n \nj\n++\n)\n\n            \nk\n \n+=\n \ni\n \n*\n \nj\n;\n\n    \nprintf\n(\nsig_int finished\n\\n\n);\n\n\n}\n\n\n\n\n\n\nThe loop in the \nSIGINT\n handler was written so that it executes for longer than 5 seconds on one of the systems used by the author. We simply want it to execute longer than the argument to \nsleep2\n. The integer \nk\n is declared as \nvolatile\n to prevent an optimizing compiler from discarding the loop.\n\n\nRun this program and interrupt the sleep by typing the interrupt character:\n\n\n$ ./a.out\n\n\n\u02c6C                 # we type the interrupt character\n\n\nsig_int starting\n\n\nsleep2 returned: 0\n\n\n\n\n\n\nThe \nlongjmp\n from the \nsleep2\n function aborted the other signal handler, \nsig_int\n, even though it wasn\u2019t finished.\n\n\nThe above examples of \nsleep1\n and \nsleep2\n show the pitfalls in dealing naively with signals. The following sections will show ways around all these problems, so we can handle signals reliably, without interfering with other pieces of code.\n\n\nImplementing a timeout using \nalarm\n\n\nA common use for \nalarm\n, in addition to implementing the \nsleep\n function, is to put an upper time limit on operations that can block. For example, if we have a \nread\n operation on a device that can block (slow device, as described in \nSection 10.5\n), we might want the \nread\n to time out after some amount of time. The following example reads one line from standard input (with a timeout) and writes it to standard.\n\n\nsignals/read1.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_alrm\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n\n    \nalarm\n(\n10\n);\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n    \nalarm\n(\n0\n);\n\n\n    \nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just return to interrupt the read */\n\n\n}\n\n\n\n\n\n\nThough this code is common in UNIX applications, it has two problems:\n\n\n\n\nThere is a a race condition between the first call to \nalarm\n and the call to \nread\n, similar to the first \nalarm\n and \npause\n example in \nearly this section\n. If the kernel blocks the process between these two function calls for longer than the alarm period, the \nread\n could block forever, though most operations of this type use a long alarm period (a minute or more) making this unlikely.\n\n\nIf system calls are automatically restarted, the \nread\n is not interrupted when the \nSIGALRM\n signal handler returns. In this case, the timeout does nothing.\n\n\n\n\nImplementing a timeout with \nalarm\n and \nlongjmp\n\n\nsignals/read2.c\n\n\n#include \napue.h\n\n\n#include \nsetjmp.h\n\n\n\nstatic\n \nvoid\n     \nsig_alrm\n(\nint\n);\n\n\nstatic\n \njmp_buf\n  \nenv_alrm\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nline\n[\nMAXLINE\n];\n\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n    \nif\n \n(\nsetjmp\n(\nenv_alrm\n)\n \n!=\n \n0\n)\n\n        \nerr_quit\n(\nread timeout\n);\n\n\n    \nalarm\n(\n10\n);\n\n    \nif\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nline\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n    \nalarm\n(\n0\n);\n\n\n    \nwrite\n(\nSTDOUT_FILENO\n,\n \nline\n,\n \nn\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nlongjmp\n(\nenv_alrm\n,\n \n1\n);\n\n\n}\n\n\n\n\n\n\nThis version works as expected, regardless of whether the system restarts interrupted system calls. However, we still have the problem of interactions with other signal handlers, \nas described previously\n.\n\n\nIf we want to set a time limit on an I/O operation, we need to use \nlongjmp\n, as shown previously, while recognizing its possible interaction with other signal handlers. Another option is to use the \nselect\n or \npoll\n functions described in \nSection 14.4\n.\n\n\nSignal Sets\n\n\nA \nsignal set\n is a data type to represent multiple signals. This data type is used with functions like \nsigprocmask\n to tell the kernel not to allow any of the signals in the set to occur. As mentioned earlier, the number of different signals can exceed the number of bits in an integer, so in general we can\u2019t use an integer to represent the set with one bit per signal.\n\n\nPOSIX.1 defines the data type \nsigset_t\n to contain a signal set and the following five functions to manipulate signal sets.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigemptyset\n(\nsigset_t\n \n*\nset\n);\n\n\nint\n \nsigfillset\n(\nsigset_t\n \n*\nset\n);\n\n\nint\n \nsigaddset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\nint\n \nsigdelset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\n\n/* All four return: 0 if OK, \u22121 on error */\n\n\n\nint\n \nsigismember\n(\nconst\n \nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n);\n\n\n/* Returns: 1 if true, 0 if false, \u22121 on error */\n\n\n\n\n\n\n\n\nsigemptyset\n initializes the signal set pointed to by \nset\n so that all signals are excluded.\n\n\nsigfillset\n initializes the signal set so that all signals are included.\n\n\nsigaddset\n adds a single signal to an existing set.\n\n\nsigdelset\n removes a single signal from a set.\n\n\n\n\nAll applications have to call either \nsigemptyset\n or \nsigfillset\n once for each signal set, before using the signal set, because we cannot assume that the C initialization for external and static variables (0) corresponds to the implementation of signal sets on a given system.\n\n\nIn all the functions that take a signal set as an argument, we always pass the address of the signal set as the argument.\n\n\nImplementation of signal sets\n\n\nIf the implementation has fewer signals than bits in an integer,asignal set can be implemented using one bit per signal. This section assumes that an implementation has 31 signals and 32-bit integers. The \nsigemptyset\n function zeros the integer, and the \nsigfillset\n function turns on all the bits in the integer. These two functions can be implemented as macros in the \nsignal.h\n header:\n\n\n#define sigemptyset(ptr) (*(ptr) = 0)\n\n\n#define sigfillset(ptr) (*(ptr) = ~(sigset_t)0, 0)\n\n\n\n\n\n\nNote that \nsigfillset\n must return 0, in addition to setting all the bits on in the signal set, so we use C\u2019s comma operator, which returns the value after the comma as the value of the expression.\n\n\nUsing this implementation, \nsigaddset\n turns on a single bit and \nsigdelset\n turns off a single bit; \nsigismember\n tests a certain bit. Since no signal is ever numbered 0, we subtract 1 from the signal number to obtain the bit to manipulate.\n\n\nsignals/setops.c\n\n\n#include    \nsignal.h\n\n\n#include    \nerrno.h\n\n\n\n/*\n\n\n * \nsignal.h\n usually defines NSIG to include signal number 0.\n\n\n */\n\n\n#define SIGBAD(signo)   ((signo) \n= 0 || (signo) \n= NSIG)\n\n\n\nint\n\n\nsigaddset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \n*\nset\n \n|=\n \n1\n \n \n(\nsigno\n \n-\n \n1\n);\n       \n/* turn bit on */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\nint\n\n\nsigdelset\n(\nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \n*\nset\n \n=\n \n~\n(\n1\n \n \n(\nsigno\n \n-\n \n1\n));\n    \n/* turn bit off */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\nint\n\n\nsigismember\n(\nconst\n \nsigset_t\n \n*\nset\n,\n \nint\n \nsigno\n)\n\n\n{\n\n    \nif\n \n(\nSIGBAD\n(\nsigno\n))\n \n{\n\n        \nerrno\n \n=\n \nEINVAL\n;\n\n        \nreturn\n(\n-\n1\n);\n\n    \n}\n\n    \nreturn\n((\n*\nset\n \n \n(\n1\n \n \n(\nsigno\n \n-\n \n1\n)))\n \n!=\n \n0\n);\n\n\n}\n\n\n\n\n\n\nsigprocmask\n Function\n\n\nAs discussed in \nSection 10.8\n, the signal mask of a process is the set of signals currently blocked from delivery to that process. A process can examine its signal mask, change its signal mask, or perform both operations in one step by calling the following function.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigprocmask\n(\nint\n \nhow\n,\n \nconst\n \nsigset_t\n \n*\nrestrict\n \nset\n,\n\n                \nsigset_t\n \n*\nrestrict\n \noset\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nIf \noset\n is a non-null pointer, the current signal mask for the process is returned through \noset\n.\n\n\nIf \nset\n is a non-null pointer, the \nhow\n argument indicates how the current signal mask is modified; if \nset\n is a null pointer, the signal mask of the process is not changed, and \nhow\n is ignored.\n\n\n\n\nThe \nhow\n argument is one in the following table:\n\n\n\n\n\n\n\n\nhow\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSIG_BLOCK\n\n\nThe new signal mask for the process is the union of its current signal mask and the signal set pointed to by \nset\n. That is, \nset\n contains the additional signals that we want to block.\n\n\n\n\n\n\nSIG_UNBLOCK\n\n\nThe new signal mask for the process is the intersection of its current signal mask and the complement of the signal set pointed to by \nset\n. That is, \nset\n contains the signals that we want to unblock.\n\n\n\n\n\n\nSIG_SETMASK\n\n\nThe new signal mask for the process is replaced by the value of the signal set pointed to by \nset\n.\n\n\n\n\n\n\n\n\n\n\n\n\nAfter calling \nsigprocmask\n, if any unblocked signals are pending, at least one of these signals is delivered to the process before \nsigprocmask\n returns.\n\n\nNote that the \nsigprocmask\n function is defined only for single-threaded processes. A separate function, discussed in \nSection 12.8\n is provided to manipulate a thread\u2019s signal mask in a multithreaded process.\n\n\nThe following example shows a function that prints the names of the signals in the signal mask of the calling process.\n\n\nlib/prmask.c\n\n\n#include \napue.h\n\n\n#include \nerrno.h\n\n\n\nvoid\n\n\npr_mask\n(\nconst\n \nchar\n \n*\nstr\n)\n\n\n{\n\n    \nsigset_t\n    \nsigset\n;\n\n    \nint\n         \nerrno_save\n;\n\n\n    \nerrno_save\n \n=\n \nerrno\n;\n     \n/* we can be called by signal handlers */\n\n    \nif\n \n(\nsigprocmask\n(\n0\n,\n \nNULL\n,\n \nsigset\n)\n \n \n0\n)\n \n{\n\n        \nerr_ret\n(\nsigprocmask error\n);\n\n    \n}\n \nelse\n \n{\n\n        \nprintf\n(\n%s\n,\n \nstr\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGINT\n))\n\n            \nprintf\n(\n SIGINT\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGQUIT\n))\n\n            \nprintf\n(\n SIGQUIT\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGUSR1\n))\n\n            \nprintf\n(\n SIGUSR1\n);\n\n        \nif\n \n(\nsigismember\n(\nsigset\n,\n \nSIGALRM\n))\n\n            \nprintf\n(\n SIGALRM\n);\n\n\n        \n/* remaining signals can go here  */\n\n\n        \nprintf\n(\n\\n\n);\n\n    \n}\n\n\n    \nerrno\n \n=\n \nerrno_save\n;\n     \n/* restore errno */\n\n\n}\n\n\n\n\n\n\nsigpending\n Function\n\n\nThe \nsigpending\n function returns the set of signals that are blocked from delivery and currently pending for the calling process. The set of signals is returned through the \nset\n argument.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigpending\n(\nsigset_t\n \n*\nset\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nExample of \nsigpending\n and other signal features\n\n\nThe example below shows many of the signal features that have been described.\n\n\nsignals/critical.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_quit\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \npendmask\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nsig_quit\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt catch SIGQUIT\n);\n\n\n    \n/*\n\n\n     * Block SIGQUIT and save current signal mask.\n\n\n     */\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGQUIT\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \nsleep\n(\n5\n);\n   \n/* SIGQUIT here will remain pending */\n\n\n    \nif\n \n(\nsigpending\n(\npendmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nsigpending error\n);\n\n    \nif\n \n(\nsigismember\n(\npendmask\n,\n \nSIGQUIT\n))\n\n        \nprintf\n(\n\\n\nSIGQUIT pending\n\\n\n);\n\n\n    \n/*\n\n\n     * Restore signal mask which unblocks SIGQUIT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n    \nprintf\n(\nSIGQUIT unblocked\n\\n\n);\n\n\n    \nsleep\n(\n5\n);\n   \n/* SIGQUIT here will terminate with core file */\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_quit\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGQUIT\n\\n\n);\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nSIG_DFL\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\ncan\nt reset SIGQUIT\n);\n\n\n}\n\n\n\n\n\n\nRun this program:\n\n\n$ ./a.out\n\n\n\u02c6\\                    # generate signal once (before 5 seconds are up)\n\n\nSIGQUIT               # pending after return from sleep\n\n\ncaught SIGQUIT        # in signal handler\n\n\nSIGQUIT unblocked     # after return from sigprocmask\n\n\n\u02c6\\Quit(coredump)      # generate signal again\n\n\n$ ./a.out\n\n\n\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\\u02c6\\  # generate signal 10 times (before 5 seconds are up)\n\n\nSIGQUIT pending\n\n\ncaught SIGQUIT        # signal is generated only once\n\n\nSIGQUIT unblocked\n\n\n\u02c6\\Quit(coredump)      # generate signal again\n\n\n\n\n\n\n[p349]\n\n\nSome notes from this example:\n\n\n\n\nWe saved the old mask when we blocked the signal. To unblock the signal, we did a \nSIG_SETMASK\n of the old mask. Alternatively, we could \nSIG_UNBLOCK\n only the signal that we had blocked. Be aware, however, if we write a function that can be called by others and if we need to block a signal in our function, we can\u2019t use \nSIG_UNBLOCK\n to unblock the signal. In this case, we have to use \nSIG_SETMASK\n and restore the signal mask to its prior value, because it\u2019s possible that the caller had specifically blocked this signal before calling our function. We\u2019ll see an example of this in the \nsystem\n function in \nSection 10.18\n.\n\n\nWhen we run the program the second time, we generate the quit signal ten times while the process is asleep, yet the signal is delivered only once to the process when it\u2019s unblocked. This demonstrates that signals are not queued on this system\n\n\n\n\nsigaction\n Function\n\n\nThe \nsigaction\n function allows us to examine or modify (or both) the action associated with a particular signal. This function supersedes the \nsignal\n function from earlier releases of the UNIX System. Indeed, at the end of this section, we show an implementation of \nsignal\n using \nsigaction\n.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigaction\n(\nint\n \nsigno\n,\n \nconst\n \nstruct\n \nsigaction\n \n*\nrestrict\n \nact\n,\n\n              \nstruct\n \nsigaction\n \n*\nrestrict\n \noact\n);\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\n\n\nThe argument \nsigno\n is the signal number whose action we are examining or modifying.\n\n\nIf the \nact\n pointer is non-null, we are modifying the action.\n\n\nIf the \noact\n pointer is non-null, the system returns the previous action for the signal through the \noact\n pointer\n\n\n\n\nThis function uses the following structure:\n\n\nstruct\n \nsigaction\n \n{\n\n    \nvoid\n \n(\n*\nsa_handler\n)(\nint\n);\n  \n/* addr of signal handler, */\n\n                              \n/* or SIG_IGN, or SIG_DFL */\n\n    \nsigset_t\n \nsa_mask\n;\n         \n/* additional signals to block */\n\n    \nint\n \nsa_flags\n;\n             \n/* signal options, Figure 10.16 */\n\n\n    \n/* alternate handler */\n\n    \nvoid\n \n(\n*\nsa_sigaction\n)(\nint\n,\n \nsiginfo_t\n \n*\n,\n \nvoid\n \n*\n);\n\n\n};\n\n\n\n\n\n\nIf the \nsa_handler\n field contains the address of a signal-catching function (rather than \nSIG_IGN\n or \nSIG_DFL\n), then the \nsa_mask\n field specifies a set of signals that are added to the signal mask of the process before the signal-catching function is called. If and when the signal-catching function returns, the signal mask of the process is reset to its previous value. This enables us to block certain signals whenever a signal handler is invoked. \nThe operating system includes the signal being delivered in the signal mask when the handler is invoked. Hence, we are guaranteed that whenever we are processing a given signal, another occurrence of that same signal is blocked until we\u2019re finished processing the first occurrence.\n Additional occurrences of the same signal are usually not queued (\nSection 10.8\n). If the signal occurs five times while it is blocked, when we unblock the signal, the signal-handling function for that signal will usually be invoked only one time.\n\n\nOnce we install an action for a given signal, that action remains installed until we explicitly change it by calling \nsigaction\n. [p350]\n\n\nThe \nsa_flags\n field of the act structure specifies various options for the handling of this signal. The table below details the meaning of these options when set.\n\n\nThe \nsa_sigaction\n field is an alternative signal handler used when the \nSA_SIGINFO\n flag is used with \nsigaction\n. Implementations might use the same storage for both the \nsa_sigaction\n field and the \nsa_handler\n field, so applications can use only one of these fields at a time.\n\n\nOption flags (\nsa_flags\n) for the handling of each signal:\n\n\n\n\n\n\n\n\nOption\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSA_INTERRUPT\n\n\n\n\n\n\nx\n\n\n\n\n\n\nSystem calls interrupted by this signal are not automatically restarted (the XSI default for \nsigaction\n). See \nSection 10.5\n.\n\n\n\n\n\n\nSA_NOCLDSTOP\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf \nsigno\n is \nSIGCHLD\n, do not generate this signal when a child process stops (job control). This signal is still generated, of course, when a child terminates (but see the \nSA_NOCLDWAIT\n option below). When the XSI option is supported, \nSIGCHLD\n won\u2019t be sent when a stopped child continues if this flag is set.\n\n\n\n\n\n\nSA_NOCLDWAIT\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf \nsigno\n is \nSIGCHLD\n, this option prevents the system from creating zombie processes when children of the calling process terminate. If it subsequently calls \nwait\n, the calling process blocks until all its child processes have terminated and then returns \u22121 with \nerrno\n set to \nECHILD\n. (\nSection 10.7\n)\n\n\n\n\n\n\nSA_NODEFER\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nWhen this signal is caught, the signal is not automatically blocked by the system while the signal-catching function executes (unless the signal is also included in \nsa_mask\n). Note that this type of operation corresponds to the earlier unreliable signals.\n\n\n\n\n\n\nSA_ONSTACK\n\n\nXSI\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nIf an alternative stack has been declared with \nsigaltstack(2)\n, this signal is delivered to the process on the alternative stack.\n\n\n\n\n\n\nSA_RESETHAND\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nThe disposition for this signal is reset to \nSIG_DFL\n, and the \nSA_SIGINFO\n flag is cleared on entry to the signal-catching function. Note that this type of operation corresponds to the earlier unreliable signals. The disposition for the two signals \nSIGILL\n and \nSIGTRAP\n can\u2019t be reset automatically, however. Setting this flag can optionally cause sigaction to behave as if \nSA_NODEFER\n is also set.\n\n\n\n\n\n\nSA_RESTART\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nSystem calls interrupted by this signal are automatically restarted. (\nSection 10.5\n)\n\n\n\n\n\n\nSA_SIGINFO\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nThis option provides additional information to a signal handler: a pointer to a \nsiginfo\n structure and a pointer to an identifier for the process context.\n\n\n\n\n\n\n\n\nNormally, the signal handler is called as:\n\n\nvoid\n \nhandler\n(\nint\n \nsigno\n);\n\n\n\n\n\n\nIf the \nSA_SIGINFO\n flag is set, the signal handler is called as:\n\n\nvoid\n \nhandler\n(\nint\n \nsigno\n,\n \nsiginfo_t\n \n*\ninfo\n,\n \nvoid\n \n*\ncontext\n);\n\n\n\n\n\n\nThe \nsiginfo\n structure contains information about why the signal was generated. All POSIX.1-compliant implementations must include at least the \nsi_signo\n and \nsi_code\n members. Additionally, implementations that are XSI compliant contain at least the following fields:\n\n\nstruct\n \nsiginfo\n \n{\n\n    \nint\n \nsi_signo\n;\n \n/* signal number */\n\n    \nint\n \nsi_errno\n;\n \n/* if nonzero, errno value from errno.h */\n\n    \nint\n \nsi_code\n;\n \n/* additional info (depends on signal) */\n\n    \npid_t\n \nsi_pid\n;\n \n/* sending process ID */\n\n    \nuid_t\n \nsi_uid\n;\n \n/* sending process real user ID */\n\n    \nvoid\n \n*\nsi_addr\n;\n \n/* address that caused the fault */\n\n    \nint\n \nsi_status\n;\n \n/* exit value or signal number */\n\n    \nunion\n \nsigval\n \nsi_value\n;\n \n/* application-specific value */\n\n    \n/* possibly other fields also */\n\n\n};\n\n\n\n\n\n\nThe \nsigval\n union contains the following fields:\n\n\nint\n \nsival_int\n;\n\n\nvoid\n \n*\nsival_ptr\n;\n\n\n\n\n\n\nApplications pass an integer value in \nsi_value.sival_int\n or pass a pointer value in \nsi_value.sival_ptr\n when delivering signals.\n\n\nIf the signal is \nSIGCHLD\n, then the \nsi_pid\n, \nsi_status\n, and \nsi_uid\n fields will be set.\nIf the signal is \nSIGBUS\n, \nSIGILL\n, \nSIGFPE\n, or \nSIGSEGV\n, then the \nsi_addr\n contains the address responsible for the fault.\nThe \nsi_errno\n field contains the error number corresponding to the condition that caused the signal to be generated.\n\n\nThe table shows values of \nsi_code\n for various signals, as defined by the Single UNIX Specification:\n\n\n\n\nThe \ncontext\n argument to the signal handler is a typeless pointer that can be cast to a \nucontext_t\n structure identifying the process context at the time of signal delivery. This structure contains at least the following fields:\n\n\nucontext_t\n \n*\nuc_link\n;\n    \n/* pointer to context resumed when */\n\n                        \n/* this context returns */\n\n\nsigset_t\n \nuc_sigmask\n;\n    \n/* signals blocked when this context */\n\n                        \n/* is active */\n\n\nstack_t\n \nuc_stack\n;\n       \n/* stack used by this context */\n\n\nmcontext_t\n \nuc_mcontext\n;\n \n/* machine-specific representation of */\n\n                        \n/* saved context */\n\n\n\n\n\n\nThe \nuc_stack\n field describes the stack used by the current context. It contains at least the following members:\n\n\nvoid\n \n*\nss_sp\n;\n \n/* stack base or pointer */\n\n\nsize_t\n \nss_size\n;\n \n/* stack size */\n\n\nint\n \nss_flags\n;\n \n/* flags */\n\n\n\n\n\n\nWhen an implementation supports the real-time signal extensions, signal handlers established with the \nSA_SIGINFO\n flag will result in signals being queued reliably. A separate range of reserved signal numbers is available for real-time application use. Applications can pass information along with the signal by using the sigqueue function (\nSection 10.20\n).\n\n\nExample: \nsignal\n Function\n\n\nThe following is the implementation of the \nsignal\n function using \nsigaction\n. [p354]\n\n\nlib/signal.c\n\n\n#include \napue.h\n\n\n\n/* Reliable version of signal(), using POSIX sigaction().  */\n\n\nSigfunc\n \n*\n\n\nsignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGALRM\n)\n \n{\n\n\n#ifdef  SA_INTERRUPT\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n\n\n#endif\n\n    \n}\n \nelse\n \n{\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_RESTART\n;\n\n    \n}\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n\n\n\n\n\n\nWe must use \nsigemptyset\n to initialize the \nsa_mask\n member of the structure since we\u2019re not guaranteed that \nact.sa_mask = 0\n does the same thing.\n\n\nWe intentionally set the \nSA_RESTART\n flag for all signals other than \nSIGALRM\n, so that any system call interrupted by these other signals will be automatically restarted. The reason we don\u2019t want \nSIGALRM\n restarted is to allow us to set a timeout for I/O operations. (\nFigure 10.10\n)\n\n\nSome older systems, such as SunOS, define the \nSA_INTERRUPT\n flag. These systems restart interrupted system calls by default, so specifying this flag causes system calls to be interrupted. Linux defines the \nSA_INTERRUPT\n flag for compatibility with applications that use it, but by default does not restart system calls when the signal handler is installed with \nsigaction\n. The Single UNIX Specification specifies that the \nsigaction\n function not restart interrupted system calls unless the \nSA_RESTART\n flag is specified.\n\n\n\n\nExample: \nsignal_intr\n Function\n\n\nThe following code shows a version of the \nsignal\n function that tries to prevent any interrupted system calls from being restarted.\n\n\nlib/signalintr.c\n\n\n#include \napue.h\n\n\n\nSigfunc\n \n*\n\n\nsignal_intr\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n\n#ifdef  SA_INTERRUPT\n\n    \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n\n\n#endif\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n\n\n\n\nFor improved portability, we specify the \nSA_INTERRUPT\n flag, if defined by the system, to prevent interrupted system calls from being restarted.\n\n\nsigsetjmp\n and \nsiglongjmp\n Functions\n\n\nsetjmp\n and \nlongjmp\n functions (\nSection 7.10\n) can be used for nonlocal branching. The \nlongjmp\n function is often called from a signal handler to return to the main loop of a program, instead of returning from the handler. (\nFigure 10.8\n and \nFigure 10.11\n).\n\n\nHowever, there is a problem in calling \nlongjmp\n. When a signal is caught, the signal-catching function is entered, with the current signal automatically being added to the signal mask of the process. This prevents subsequent occurrences of that signal from interrupting the signal handler. If we \nlongjmp\n out of the signal handler, what happens to the signal mask for the process depends on the platform:\n\n\n\n\nUnder FreeBSD 8.0 and Mac OS X 10.6.8, \nsetjmp\n and \nlongjmp\n save and restore the signal mask.\n\n\nLinux 3.2.0 and Solaris 10, however, do not save and restore the signal mask, although Linux supports an option to provide BSD behavior.\n\n\nFreeBSD and Mac OS X provide the functions \n_setjmp\n and \n_longjmp\n, which do not save and restore the signal mask.\n\n\n\n\nTo allow either form of behavior, POSIX.1 does not specify the effect of \nsetjmp\n and \nlongjmp\n on signal masks. Instead, two new functions, \nsigsetjmp\n and \nsiglongjmp\n, are defined by POSIX.1. These two functions should always be used when branching from a signal handler.\n\n\n#include \nsetjmp.h\n\n\n\nint\n \nsigsetjmp\n(\nsigjmp_buf\n \nenv\n,\n \nint\n \nsavemask\n);\n\n\n/* Returns: 0 if called directly, nonzero if returning from a call to siglongjmp */\n\n\n\nvoid\n \nsiglongjmp\n(\nsigjmp_buf\n \nenv\n,\n \nint\n \nval\n);\n\n\n\n\n\n\nThe only difference between these functions and the \nsetjmp\n and \nlongjmp\n functions is that \nsigsetjmp\n has an additional argument. If \nsavemask\n is nonzero, then \nsigsetjmp\n also saves the current signal mask of the process in \nenv\n. When \nsiglongjmp\n is called, if the \nenv\n argument was saved by a call to \nsigsetjmp\n with a nonzero \nsavemask\n, then \nsiglongjmp\n restores the saved signal mask.\n\n\nsignals/mask.c\n\n\n#include \napue.h\n\n\n#include \nsetjmp.h\n\n\n#include \ntime.h\n\n\n\nstatic\n \nvoid\n                     \nsig_usr1\n(\nint\n);\n\n\nstatic\n \nvoid\n                     \nsig_alrm\n(\nint\n);\n\n\nstatic\n \nsigjmp_buf\n               \njmpbuf\n;\n\n\nstatic\n \nvolatile\n \nsig_atomic_t\n    \ncanjump\n;\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr1\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR1) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGALRM\n,\n \nsig_alrm\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGALRM) error\n);\n\n\n    \npr_mask\n(\nstarting main: \n);\n     \n/* {Prog prmask} */\n\n\n    \nif\n \n(\nsigsetjmp\n(\njmpbuf\n,\n \n1\n))\n \n{\n\n\n        \npr_mask\n(\nending main: \n);\n\n\n        \nexit\n(\n0\n);\n\n    \n}\n\n    \ncanjump\n \n=\n \n1\n;\n    \n/* now sigsetjmp() is OK */\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n\n        \npause\n();\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_usr1\n(\nint\n \nsigno\n)\n\n\n{\n\n    \ntime_t\n  \nstarttime\n;\n\n\n    \nif\n \n(\ncanjump\n \n==\n \n0\n)\n\n        \nreturn\n;\n     \n/* unexpected signal, ignore */\n\n\n    \npr_mask\n(\nstarting sig_usr1: \n);\n\n\n    \nalarm\n(\n3\n);\n               \n/* SIGALRM in 3 seconds */\n\n    \nstarttime\n \n=\n \ntime\n(\nNULL\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n             \n/* busy wait for 5 seconds */\n\n        \nif\n \n(\ntime\n(\nNULL\n)\n \n \nstarttime\n \n+\n \n5\n)\n\n            \nbreak\n;\n\n\n    \npr_mask\n(\nfinishing sig_usr1: \n);\n\n\n    \ncanjump\n \n=\n \n0\n;\n\n    \nsiglongjmp\n(\njmpbuf\n,\n \n1\n);\n  \n/* jump back to main, don\nt return */\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npr_mask\n(\nin sig_alrm: \n);\n\n\n}\n\n\n\n\n\n\n\n\nWe set the variable \ncanjump\n to a nonzero value only after we\u2019ve called \nsigsetjmp\n. This variable is examined in the signal handler, and \nsiglongjmp\n is called only if the flag \ncanjump\n is nonzero. This technique provides protection against the signal handler being called at some earlier or later time, when the jump buffer hasn\u2019t been initialized by \nsigsetjmp\n. This technique should be used whenever \nsiglongjmp\n is called from a signal handler, but is not required with longjmp in normal C code. Since a signal can occur at any time, therefore we need the added protection in a signal handler.\n\n\nWe use the data type \nsig_atomic_t\n, which is defined by the ISO C standard to be the type of variable that can be written without being interrupted.\n\n\nThis means that a variable of type \nsig_atomic_t\n should not extend across page boundaries on a system with virtual memory and can be accessed with a single machine instruction, for example.\n\n\nWe always include the ISO type qualifier \nvolatile\n for these data types as well, since the variable is being accessed by two different threads of control: the \nmain\n function and the asynchronously executing signal handler.\n\n\n\n\n\n\n\n\nWe can divide the following figure into three parts:\n\n\n\n\nLeft part (corresponding to \nmain\n)\n\n\nCenter part (\nsig_usr1\n)\n\n\nRight part (\nsig_alrm\n).\n\n\n\n\nWhile the process is executing in the left part, its signal mask is 0 (no signals are blocked). While executing in the center part, its signal mask is \nSIGUSR1\n. While executing in the right part, its signal mask is \nSIGUSR1\n|\nSIGALRM\n.\n\n\n\n\nThe output of the program:\n\n\n$ ./a.out \n             # start process in background\n\n\nstarting main:\n\n\n[1] 531                 # the job-control shell prints its process ID\n\n\n$ kill -USR1 531        # send the process SIGUSR1\n\n\nstarting sig_usr1: SIGUSR1\n\n\n$ in sig_alrm: SIGUSR1 SIGALRM\n\n\nfinishing sig_usr1: SIGUSR1\n\n\nending main:\n\n\n                        # just press RETURN\n\n\n[1] + Done ./a.out \n\n\n\n\n\n\nThe output is what we expect: when a signal handler is invoked, the signal being caught is added to the current signal mask of the process. The original mask is restored when the signal handler returns. Also, \nsiglongjmp\n restores the signal mask that was saved by \nsigsetjmp\n.\n\n\nsigsuspend\n Function\n\n\nWe have seen how we can change the signal mask for a process to block and unblock selected signals. We can use this technique to protect critical regions of code that we don\u2019t want interrupted by a signal. But what if we want to unblock a signal and then \npause\n, waiting for the previously blocked signal to occur? Assuming that the signal is \nSIGINT\n, the incorrect way to do this is:\n\n\n  \nsigset_t\n \nnewmask\n,\n \noldmask\n;\n\n\n  \nsigemptyset\n(\nnewmask\n);\n\n  \nsigaddset\n(\nnewmask\n,\n \nSIGINT\n);\n\n\n  \n/* block SIGINT and save current signal mask */\n\n  \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n      \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n  \n/* critical region of code */\n\n\n  \n/* restore signal mask, which unblocks SIGINT */\n\n  \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n      \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n  \n/* window is open */\n\n  \npause\n();\n \n/* wait for signal to occur */\n\n\n  \n/* continue processing */\n\n\n\n\n\n\nIf the signal is sent to the process while it is blocked, the signal delivery will be deferred until the signal is unblocked. To the application, this can look as if the signal occurs between the unblocking and the \npause\n (depending on how the kernel implements signals). If this happens, or if the signal does occur between the unblocking and the \npause\n, we have a problem. Any occurrence of the signal in this window of time is lost, in the sense that we might not see the signal again, in which case the \npause\n will block indefinitely. This is another problem with the earlier unreliable signals.\n\n\nTo correct this problem, we need a way to both restore the signal mask and put the process to sleep in a single atomic operation. This feature is provided by the \nsigsuspend\n function.\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigsuspend\n(\nconst\n \nsigset_t\n \n*\nsigmask\n);\n\n\n\n/* Returns: \u22121 with errno set to EINTR */\n\n\n\n\n\n\nThe signal mask of the process is set to the value pointed to by \nsigmask\n. Then the process is suspended until a signal is caught or until a signal occurs that terminates the process. If a signal is caught and if the signal handler returns, then \nsigsuspend\n returns, and the signal mask of the process is set to its value before the call to \nsigsuspend\n.\n\n\nExample of \nsigsuspend\n to protect a critial region\n\n\nThe following code shows the correct way to protect a critical region of code from a specific signal.\n\n\nsignals/suspend1.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n \nsig_int\n(\nint\n);\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \nwaitmask\n;\n\n\n    \npr_mask\n(\nprogram start: \n);\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nsigemptyset\n(\nwaitmask\n);\n\n    \nsigaddset\n(\nwaitmask\n,\n \nSIGUSR1\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGINT\n);\n\n\n    \n/*\n\n\n     * Block SIGINT and save current signal mask.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \n/*\n\n\n     * Critical region of code.\n\n\n     */\n\n    \npr_mask\n(\nin critical region: \n);\n\n\n    \n/*\n\n\n     * Pause, allowing all signals except SIGUSR1.\n\n\n     */\n\n    \nif\n \n(\nsigsuspend\n(\nwaitmask\n)\n \n!=\n \n-\n1\n)\n\n        \nerr_sys\n(\nsigsuspend error\n);\n\n\n    \npr_mask\n(\nafter return from sigsuspend: \n);\n\n\n    \n/*\n\n\n     * Reset signal mask which unblocks SIGINT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n    \n/*\n\n\n     * And continue processing ...\n\n\n     */\n\n    \npr_mask\n(\nprogram exit: \n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npr_mask\n(\n\\n\nin sig_int: \n);\n\n\n}\n\n\n\n\n\n\nWhen \nsigsuspend\n returns, it sets the signal mask to its value before the cal SIGINT signal will be blocked, so we restore the signal mask to the value\nthat we saved earlier (oldmask).\n\n\nRunning the program produces the following output:\n\n\n$ ./a.out\n\n\nprogram start:\n\n\nin critical region: SIGINT\n\n\n\u02c6C                          # type the interrupt character\n\n\nin sig_int: SIGINT SIGUSR1\n\n\nafter return from sigsuspend: SIGINT\n\n\nprogram exit:\n\n\n\n\n\n\nExample of \nsigsuspend\n to wait for a signal handler to set a global variable\n\n\nIn the following program, we catch both the interrupt signal and the quit signal, but want to wake up the main routine only when the quit signal is caught.\n\n\nsignals/suspend2.c\n\n\n#include \napue.h\n\n\n\nvolatile\n \nsig_atomic_t\n   \nquitflag\n;\n   \n/* set nonzero by signal handler */\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n  \n/* one signal handler for SIGINT and SIGQUIT */\n\n\n{\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGINT\n)\n\n        \nprintf\n(\n\\n\ninterrupt\n\\n\n);\n\n    \nelse\n \nif\n \n(\nsigno\n \n==\n \nSIGQUIT\n)\n\n        \nquitflag\n \n=\n \n1\n;\n   \n/* set flag for main loop */\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nsigset_t\n    \nnewmask\n,\n \noldmask\n,\n \nzeromask\n;\n\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGQUIT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGQUIT) error\n);\n\n\n    \nsigemptyset\n(\nzeromask\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGQUIT\n);\n\n\n    \n/*\n\n\n     * Block SIGQUIT and save current signal mask.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n    \nwhile\n \n(\nquitflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n\n\n    \n/*\n\n\n     * SIGQUIT has been caught and is now blocked; do whatever.\n\n\n     */\n\n    \nquitflag\n \n=\n \n0\n;\n\n\n    \n/*\n\n\n     * Reset signal mask which unblocks SIGQUIT.\n\n\n     */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nSample output from this program is:\n\n\n$ ./a.out\n\n\n\u02c6C           # type the interrupt character\n\n\ninterrupt\n\n\n\u02c6C           # type the interrupt character again\n\n\ninterrupt\n\n\n\u02c6C           # and again\n\n\ninterrupt\n\n\n\u02c6\\ $         # now terminate with the quit character\n\n\n\n\n\n\nExample of signals that synchronize a parent and child\n\n\nThis example shows how signals can be used to synchronize a parent and child. The following example shows implementations of the five routines \nTELL_WAIT\n, \nTELL_PARENT\n, \nTELL_CHILD\n, \nWAIT_PARENT\n, and \nWAIT_CHILD\n from \nSection 8.9\n.\n\n\nlib/tellwait.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvolatile\n \nsig_atomic_t\n \nsigflag\n;\n \n/* set nonzero by sig handler */\n\n\nstatic\n \nsigset_t\n \nnewmask\n,\n \noldmask\n,\n \nzeromask\n;\n\n\n\nstatic\n \nvoid\n\n\nsig_usr\n(\nint\n \nsigno\n)\n  \n/* one signal handler for SIGUSR1 and SIGUSR2 */\n\n\n{\n\n    \nsigflag\n \n=\n \n1\n;\n\n\n}\n\n\n\nvoid\n\n\nTELL_WAIT\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGUSR1\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR1) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGUSR2\n,\n \nsig_usr\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGUSR2) error\n);\n\n    \nsigemptyset\n(\nzeromask\n);\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGUSR1\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGUSR2\n);\n\n\n    \n/* Block SIGUSR1 and SIGUSR2, and save current signal mask */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_BLOCK error\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_PARENT\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nkill\n(\npid\n,\n \nSIGUSR2\n);\n     \n/* tell parent we\nre done */\n\n\n}\n\n\n\nvoid\n\n\nWAIT_PARENT\n(\nvoid\n)\n\n\n{\n\n    \nwhile\n \n(\nsigflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n  \n/* and wait for parent */\n\n    \nsigflag\n \n=\n \n0\n;\n\n\n    \n/* Reset signal mask to original value */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n}\n\n\n\nvoid\n\n\nTELL_CHILD\n(\npid_t\n \npid\n)\n\n\n{\n\n    \nkill\n(\npid\n,\n \nSIGUSR1\n);\n         \n/* tell child we\nre done */\n\n\n}\n\n\n\nvoid\n\n\nWAIT_CHILD\n(\nvoid\n)\n\n\n{\n\n    \nwhile\n \n(\nsigflag\n \n==\n \n0\n)\n\n        \nsigsuspend\n(\nzeromask\n);\n  \n/* and wait for child */\n\n    \nsigflag\n \n=\n \n0\n;\n\n\n    \n/* Reset signal mask to original value */\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nSIG_SETMASK error\n);\n\n\n}\n\n\n\n\n\n\nIn the example, two user-defined signals are used: \nSIGUSR1\n is sent by the parent to the child, and \nSIGUSR2\n is sent by the child to the parent.\n\n\nThe \nsigsuspend\n function is fine if we want to go to sleep while we\u2019re waiting for a signal to occur. If we want to call other system functions while we\u2019re waiting, the only solution is to use multiple threads and dedicate a separate thread to handling signals (\nSection 12.8\n).\n\n\nWithout using threads, the best we can do is to set a global variable in the signal handler when the signal occurs. For example, if we catch both \nSIGINT\n and \nSIGALRM\n and install the signal handlers using the \nsignal_intr\n function\n, the signals will interrupt any slow system call that is blocked. The signals are most likely to occur when we\u2019re blocked in a call to the \nread\n function waiting for input from a slow device.  (This is especially true for \nSIGALRM\n, since we set the alarm clock to prevent us from waiting forever for input.) The code to handle this looks similar to the following:\n\n\n    \nif\n \n(\nintr_flag\n)\n      \n/* flag set by our SIGINT handler */\n\n        \nhandle_intr\n();\n\n    \nif\n \n(\nalrm_flag\n)\n      \n/* flag set by our SIGALRM handler */\n\n        \nhandle_alrm\n();\n\n\n    \n/* signals occurring in here are lost */\n\n\n    \nwhile\n \n(\nread\n(\n \n...\n \n)\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n \n{\n\n            \nif\n \n(\nalrm_flag\n)\n\n            \nhandle_alrm\n();\n\n            \nelse\n \nif\n \n(\nintr_flag\n)\n\n            \nhandle_intr\n();\n\n        \n}\n \nelse\n \n{\n\n            \n/* some other error */\n\n            \n}\n\n        \n}\n \nelse\n \nif\n \n(\nn\n \n==\n \n0\n)\n \n{\n\n            \n/* end of file */\n\n        \n}\n \nelse\n \n{\n\n            \n/* process input */\n\n    \n}\n\n\n\n\n\n\nWe test each of the global flags before calling \nread\n and again if \nread\n returns an interrupted system call error. The problem occurs if either signal is caught between the first two if statements and the subsequent call to read. Signals occurring in here are lost, as indicated by the code comment. The signal handlers are called, and they set the appropriate global variable, but the \nread\n never returns (unless some data is ready to be read).\n\n\nWhat we would like to be able to do is the following sequence of steps, in order.\n\n\n\n\nBlock \nSIGINT\n and \nSIGALRM\n.\n\n\nTest the two global variables to see whether either signal has occurred and, if so, handle the condition.\n\n\nCall \nread\n (or any other system function) and unblock the two signals, as an atomic operation.\n\n\n\n\nThe \nsigsuspend\n function helps us only if step 3 is a \npause\n operation.\n\n\nabort\n Function\n\n\nThe \nabort\n function causes abnormal program termination.\n\n\n#include \nstdlib.h\n\n\n\nvoid\n \nabort\n(\nvoid\n);\n\n\n\n/* This function never returns */\n\n\n\n\n\n\nThe \nabort\n function sends the \nSIGABRT\n signal to the caller. Processes should not ignore this signal. ISO C states that calling abort will deliver an unsuccessful termination notification to the host environment by calling \nraise(SIGABRT)\n.\n\n\n[p365]\n\n\nISO C:\n\n\n\n\nIf the signal is caught and the signal handler returns, \nabort\n still doesn\u2019t return to its caller. If this signal is caught, the only way the signal handler can\u2019t return is if it calls \nexit\n, \n_exit\n, \n_Exit\n, \nlongjmp\n, or \nsiglongjmp\n.\n\n\nIt is up to the implementation as to whether output streams are flushed and whether temporary files (\nSection 5.13\n) are deleted.\n\n\n\n\nPOSIX.1:\n\n\n\n\nabort\n overrides the blocking or ignoring of the signal by the process.\n\n\nThe intent of letting the process catch the \nSIGABRT\n is to allow it to perform any cleanup that it wants to do before the process terminates.\n\n\nIf the process doesn\u2019t terminate itself from this signal handler, when the signal handler returns, \nabort\n terminates the process.\n\n\nAn implementation is allowed to call \nfclose\n on open standard I/O streams before terminating if the call to abort terminates the process.\n\n\n\n\nSince most UNIX System implementations of \ntmpfile\n call \nunlink\n immediately after creating the file, the ISO C warning about temporary files does not usually concern us. [p366]\n\n\nThe following is an implementation of the \nabort\n function as specified by POSIX.1:\n\n\n#include \nsignal.h\n\n\n#include \nstdio.h\n\n\n#include \nstdlib.h\n\n\n#include \nunistd.h\n\n\n\nvoid\n\n\nabort\n(\nvoid\n)\n         \n/* POSIX-style abort() function */\n\n\n{\n\n    \nsigset_t\n            \nmask\n;\n\n    \nstruct\n \nsigaction\n    \naction\n;\n\n\n    \n/* Caller can\nt ignore SIGABRT, if so reset to default */\n\n    \nsigaction\n(\nSIGABRT\n,\n \nNULL\n,\n \naction\n);\n\n    \nif\n \n(\naction\n.\nsa_handler\n \n==\n \nSIG_IGN\n)\n \n{\n\n        \naction\n.\nsa_handler\n \n=\n \nSIG_DFL\n;\n\n        \nsigaction\n(\nSIGABRT\n,\n \naction\n,\n \nNULL\n);\n\n    \n}\n\n    \nif\n \n(\naction\n.\nsa_handler\n \n==\n \nSIG_DFL\n)\n\n        \nfflush\n(\nNULL\n);\n           \n/* flush all open stdio streams */\n\n\n    \n/* Caller can\nt block SIGABRT; make sure it\ns unblocked */\n\n    \nsigfillset\n(\nmask\n);\n\n    \nsigdelset\n(\nmask\n,\n \nSIGABRT\n);\n  \n/* mask has only SIGABRT turned off */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \nmask\n,\n \nNULL\n);\n\n    \nkill\n(\ngetpid\n(),\n \nSIGABRT\n);\n    \n/* send the signal */\n\n\n    \n/* If we\nre here, process caught SIGABRT and returned */\n\n    \nfflush\n(\nNULL\n);\n               \n/* flush all open stdio streams */\n\n    \naction\n.\nsa_handler\n \n=\n \nSIG_DFL\n;\n\n    \nsigaction\n(\nSIGABRT\n,\n \naction\n,\n \nNULL\n);\n  \n/* reset to default */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \nmask\n,\n \nNULL\n);\n  \n/* just in case ... */\n\n    \nkill\n(\ngetpid\n(),\n \nSIGABRT\n);\n                \n/* and one more time */\n\n    \nexit\n(\n1\n);\n    \n/* this should never be executed ... */\n\n\n}\n\n\n\n\n\n\n\n\nThis implementation of \nabort\n first check whether the default action will occur; if so, it flush all the standard I/O streams. This is not equivalent to calling \nfclose\n on all the open streams (since it just flushes them and doesn\u2019t close them), but when the process terminates, the system closes all open files.\n\n\nIf the process catches the signal and returns, we flush all the streams again, since the process could have generated more output.\n\n\nThe only condition we don\u2019t handle is the case where the process catches the signal and calls \n_exit\n or \n_Exit\n. In this case, any unflushed standard I/O buffers in memory are discarded. (We assume that a caller that does this doesn\u2019t want the buffers flushed.)\n\n\nAs mentioned in \nSection 10.9\n, if calling \nkill\n causes the signal to be generated for the caller, and if the signal is not blocked, then the signal (or some other pending, unlocked signal) is delivered to the process before \nkill\n returns. We block all signals except \nSIGABRT\n, so we know that if the call to \nkill\n returns, the process caught the signal and the signal handler returned.\n\n\n\n\nsystem\n Function\n\n\nSection 8.13\n showed an implementation of the \nsystem\n function, which did not do any signal handling. POSIX.1 requires that system ignore \nSIGINT\n and \nSIGQUIT\n and block \nSIGCHLD\n. Before showing a version that handles these signals correctly, let\u2019s see why we need to worry about signal handling.\n\n\nExample of \nsystem\n invoking \ned\n editor\n\n\nThe program (Figure 10.26) shown below uses the \nsystem\n function from \nSection 8.13\n to invoke the \ned(1)\n editor. It is an interactive program that catches the interrupt and quit signals. If \ned\n is invoked from a shell and type the interrupt character, it catches the interrupt signal and prints a question mark. The \ned\n program also sets the disposition of the quit signal so that it is ignored.\n\n\nsignals/systest2.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n\n\nsig_int\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGINT\n\\n\n);\n\n\n}\n\n\n\nstatic\n \nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \nprintf\n(\ncaught SIGCHLD\n\\n\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nif\n \n(\nsignal\n(\nSIGINT\n,\n \nsig_int\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGINT) error\n);\n\n    \nif\n \n(\nsignal\n(\nSIGCHLD\n,\n \nsig_chld\n)\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal(SIGCHLD) error\n);\n\n    \nif\n \n(\nsystem\n(\n/bin/ed\n)\n \n \n0\n)\n\n        \nerr_sys\n(\nsystem() error\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis program catches both \nSIGINT\n and \nSIGCHLD\n. If we invoke the program, we get:\n\n\n$ ./a.out\n\n\na                         # append text to the editor\u2019s buffer\n\n\nHere is one line of text\n\n\n.                         # period on a line by itself stops append mode\n\n\n1,$p                      # print first through last lines of buffer to see what\u2019s there\n\n\nHere is one line of text\n\n\nw temp.foo                # write the buffer to a file\n\n\n25                        # editor says it wrote 25 bytes\n\n\nq                         # and leave the editor\n\n\ncaught SIGCHLD\n\n\n\n\n\n\n\n\nWhen the editor terminates, the kernel sends the \nSIGCHLD\n signal to the parent (the \na.out\n process) and it is caught and returned from the signal handler. The parent should be catching the \nSIGCHLD\n signal because it has created its own children, so that it knows when its children have terminated.\n\n\nThe delivery of the \nSIGCHLD\n signal in the parent should be blocked while the \nsystem\n function is executing\n, as specified by POSIX.1. Otherwise, when the child created by \nsystem\n terminates, it would fool the caller of \nsystem\n into thinking that one of its own children terminated. The caller would then use one of the \nwait\n functions to get the termination status of the child, thereby preventing the \nsystem\n function from being able to obtain the child\u2019s termination status for its return value.\n\n\n\n\nIf we run the program again, this time sending the editor an interrupt signal, we get\n\n\n$ ./a.out\n\n\na                # append text to the editor\u2019s buffer\n\n\nhello, world\n\n\n.                # period on a line by itself stops append mode\n\n\n1,$p             # print first through last lines to see what\u2019s there\n\n\nhello, world\n\n\nw temp.foo       # write the buffer to a file\n\n\n13               # editor says it wrote 13 bytes\n\n\n\u02c6C               # type the interrupt character\n\n\n?                # editor catches signal, prints question mark\n\n\ncaught SIGINT    # and so does the parent process\n\n\nq                # leave editor\n\n\ncaught SIGCHLD\n\n\n\n\n\n\nAs mentioned in \nSection 9.6\n, typing the interrupt character causes the interrupt signal to be sent to all the processes in the foreground process group. The following figure shows the arrangement of the processes when the editor is running.\n\n\n\n\nIn this example:\n\n\nSIGINT\n is sent to all three foreground processes (the shell ignores it) and both the \na.out\n process and the editor catch the signal. When running another program with the \nsystem\n function, we shouldn\u2019t have both the parent and the child catching the two terminal-generated signals: interrupt and quit. Instead, these two signals should be sent to the program that is running: the child. Since the command that is executed by system can be an interactive command (the \ned\n program in this example) and since the caller of \nsystem\n gives up control while the program executes, waiting for it to finish, \nthe caller of \nsystem\n should not be receiving these two terminal-generated signals.\n For this reason, POSIX.1 specifies that \nthe \nsystem\n function should ignore the \nSIGINT\n and \nSIGQUIT\n signals while waiting for the command to complete.\n\n\nImplementation of \nsystem\n with signal handling\n\n\nThe program below shows an implementation of the system function with the required signal handling.\n\n\nsignals/system.c\n\n\n#include    \nsys/wait.h\n\n\n#include    \nerrno.h\n\n\n#include    \nsignal.h\n\n\n#include    \nunistd.h\n\n\n\nint\n\n\nsystem\n(\nconst\n \nchar\n \n*\ncmdstring\n)\n   \n/* with appropriate signal handling */\n\n\n{\n\n    \npid_t\n               \npid\n;\n\n    \nint\n                 \nstatus\n;\n\n    \nstruct\n \nsigaction\n    \nignore\n,\n \nsaveintr\n,\n \nsavequit\n;\n\n    \nsigset_t\n            \nchldmask\n,\n \nsavemask\n;\n\n\n    \nif\n \n(\ncmdstring\n \n==\n \nNULL\n)\n\n        \nreturn\n(\n1\n);\n      \n/* always a command processor with UNIX */\n\n\n    \nignore\n.\nsa_handler\n \n=\n \nSIG_IGN\n;\n    \n/* ignore SIGINT and SIGQUIT */\n\n    \nsigemptyset\n(\nignore\n.\nsa_mask\n);\n\n    \nignore\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigaction\n(\nSIGINT\n,\n \nignore\n,\n \nsaveintr\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigaction\n(\nSIGQUIT\n,\n \nignore\n,\n \nsavequit\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nsigemptyset\n(\nchldmask\n);\n         \n/* now block SIGCHLD */\n\n    \nsigaddset\n(\nchldmask\n,\n \nSIGCHLD\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_BLOCK\n,\n \nchldmask\n,\n \nsavemask\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n        \nstatus\n \n=\n \n-\n1\n;\n    \n/* probably out of processes */\n\n    \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n          \n/* child */\n\n        \n/* restore previous signal actions \n reset signal mask */\n\n        \nsigaction\n(\nSIGINT\n,\n \nsaveintr\n,\n \nNULL\n);\n\n        \nsigaction\n(\nSIGQUIT\n,\n \nsavequit\n,\n \nNULL\n);\n\n        \nsigprocmask\n(\nSIG_SETMASK\n,\n \nsavemask\n,\n \nNULL\n);\n\n\n        \nexecl\n(\n/bin/sh\n,\n \nsh\n,\n \n-c\n,\n \ncmdstring\n,\n \n(\nchar\n \n*\n)\n0\n);\n\n        \n_exit\n(\n127\n);\n     \n/* exec error */\n\n    \n}\n \nelse\n \n{\n                        \n/* parent */\n\n        \nwhile\n \n(\nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n \n \n0\n)\n\n            \nif\n \n(\nerrno\n \n!=\n \nEINTR\n)\n \n{\n\n                \nstatus\n \n=\n \n-\n1\n;\n \n/* error other than EINTR from waitpid() */\n\n                \nbreak\n;\n\n            \n}\n\n    \n}\n\n\n    \n/* restore previous signal actions \n reset signal mask */\n\n    \nif\n \n(\nsigaction\n(\nSIGINT\n,\n \nsaveintr\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigaction\n(\nSIGQUIT\n,\n \nsavequit\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n    \nif\n \n(\nsigprocmask\n(\nSIG_SETMASK\n,\n \nsavemask\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nreturn\n(\n-\n1\n);\n\n\n    \nreturn\n(\nstatus\n);\n\n\n}\n\n\n\n\n\n\nThis implementation of \nsystem\n differs from the previous flawed one in the following ways:\n\n\n\n\nNo signal is sent to the calling process when we type the interrupt or quit character.\n\n\nWhen the \ned\n command exits, \nSIGCHLD\n is not sent to the calling process. Instead, it is blocked until we unblock it in the last call to \nsigprocmask\n, after the \nsystem\n function retrieves the child\u2019s termination status by calling \nwaitpid\n.\n\n\n\n\nPOSIX.1 states that if \nwait\n or \nwaitpid\n returns the status of a child process while \nSIGCHLD\n is pending, then \nSIGCHLD\n should not be delivered to the process unless the status of another child process is also available. FreeBSD 8.0, Mac OS X 10.6.8, and Solaris 10 all implement this semantic, while Linux 3.2.0 doesn\u2019t. In Linux, \nSIGCHLD\n remains pending after the \nsystem\n function calls \nwaitpid\n; when the signal is unblocked, it is delivered to the caller. If we called \nwait\n in the \nsig_chld\n function in \nFigure 10.26\n, a Linux system would return \u22121 with \nerrno\n set to \nECHILD\n, since the \nsystem\n function already retrieved the termination status of the child.\n\n\nMany older texts show the ignoring of the interrupt and quit signals as follows:\n\n\n  \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n \n{\n\n      \nerr_sys\n(\nfork error\n);\n\n  \n}\n \nelse\n \nif\n \n(\npid\n \n==\n \n0\n)\n \n{\n\n    \n/* child */\n\n    \nexecl\n(...);\n\n    \n_exit\n(\n127\n);\n\n  \n}\n\n\n  \n/* parent */\n\n  \nold_intr\n \n=\n \nsignal\n(\nSIGINT\n,\n \nSIG_IGN\n);\n\n  \nold_quit\n \n=\n \nsignal\n(\nSIGQUIT\n,\n \nSIG_IGN\n);\n\n  \nwaitpid\n(\npid\n,\n \nstatus\n,\n \n0\n)\n\n  \nsignal\n(\nSIGINT\n,\n \nold_intr\n);\n\n  \nsignal\n(\nSIGQUIT\n,\n \nold_quit\n);\n\n\n\n\n\n\nThe problem with this sequence of code is that we have no guarantee after the \nfork\n regarding whether the parent or child runs first. If the child runs first and the parent doesn\u2019t run for some time after, an interrupt signal might be generated before the parent is able to change its disposition to be ignored. For this reason, in the implementation of \nsystem\n, we change the disposition of the signals before the \nfork\n.\n\n\nNote that we have to reset the dispositions of these two signals in the child before the call to \nexecl\n. This allows execl to change their dispositions to the default, based on the caller\u2019s dispositions, as described in \nSection 8.10\n.\n\n\nReturn Value from \nsystem\n\n\nThe return value from \nsystem\n is the termination status of the shell, which isn\u2019t always the termination status of the command string. [p371]\n\n\nRun the program in \nFigure 8.24\n and send some signals to the command that\u2019s executing:\n\n\n$ tsys \nsleep 30\n\n\n\u02c6Cnormal termination, exit status = 130  # we press the interrupt key\n\n\n$ tsys \nsleep 30\n\n\n\u02c6\\sh: 946                                # Quit we press the quit key\n\n\nnormal termination, exit status = 131\n\n\n\n\n\n\nWhen we terminate the \nsleep\n call with the interrupt signal, the \npr_exit\n function (Figure 8.5) thinks that it terminated normally. The same thing happens when we kill the \nsleep\n call with the quit key. This is because the Bourne shell has a poorly documented feature in which its termination status is 128 plus the signal number, when the command it was executing is terminated by a signal. [p372]\n\n\nTry a similar example, but this time we\u2019ll send a signal directly to the shell and see what is returned by system:\n\n\n$ tsys \nsleep 30\n \n      # start it in background this time\n\n\n9257\n\n\n$ ps -f                  # look at the process IDs\n\n\nUID PID PPID TTY TIME CMD\n\n\nsar 9260 949 pts/5 0:00 ps -f\n\n\nsar 9258 9257 pts/5 0:00 sh -c sleep 30\n\n\nsar 949 947 pts/5 0:01 /bin/sh\n\n\nsar 9257 949 pts/5 0:00 tsys sleep 30\n\n\nsar 9259 9258 pts/5 0:00 sleep 30\n\n\n$ kill -KILL 9258        # kill the shell itself\n\n\nabnormal termination, signal number = 9\n\n\n\n\n\n\nWe can see that the return value from system reports an abnormal termination only when the shell itself terminates abnormally.\n\n\nOther shells behave differently when handling terminal-generated signals, such as \nSIGINT\n and \nSIGQUIT\n. With \nbash\n and \ndash\n, for example, pressing the interrupt or quit key will result in an exit status indicating abnormal termination with the corresponding signal number. However, if we find our process executing \nsleep\n and send it a signal directly, so that the signal goes only to the individual process instead of the entire foreground process group, we will find that these shells behave like the Bourne shell and exit with a normal termination status of 128 plus the signal number.\n\n\nWhen writing programs that use the \nsystem\n function, be sure to interpret the return value correctly. If you call \nfork\n, \nexec\n, and \nwait\n yourself, the termination status is not the same as if you call system.\n\n\nsleep\n, \nnanosleep\n, and \nclock_nanosleep\n Functions\n\n\n#include \nunistd.h\n\n\n\nunsigned\n \nint\n \nsleep\n(\nunsigned\n \nint\n \nseconds\n);\n\n\n\n/* Returns: 0 or number of unslept seconds */\n\n\n\n\n\n\nThe \nsleep\n function causes the calling process to be suspended until either:\n\n\n\n\nThe amount of wall clock time specified by seconds has elapsed. In this case, the return value is 0.\n\n\nA signal is caught by the process and the signal handler returns. In this case the return value is the number of unslept seconds (the requested time minus the actual time slept).\n\n\n\n\nAs with an \nalarm\n signal, the actual return may occur at a time later than requested because of other system activity.\n\n\nAlthough sleep can be implemented with the \nalarm\n function (\nSection 10.10\n), this isn\u2019t required. If \nalarm\n is used, there can be interactions between the two functions. The POSIX.1 standard leaves all these interactions unspecified.\n\n\nFreeBSD 8.0, Linux 3.2.0, Mac OS X 10.6.8, and Solaris 10 implement \nsleep\n using the \nnanosleep\n function, which allows the implementation to be independent of signals and the alarm timer.\n\n\nThe follow example shows an implementation of the POSIX.1 \nsleep\n function. This function is a modification of \nFigure 10.7\n, which handles signals reliably, avoiding the race condition in the earlier implementation, but does not handle any interactions with previously set alarms.\n\n\nlib/sleep.c\n\n\n#include \napue.h\n\n\n\nstatic\n \nvoid\n\n\nsig_alrm\n(\nint\n \nsigno\n)\n\n\n{\n\n    \n/* nothing to do, just returning wakes up sigsuspend() */\n\n\n}\n\n\n\nunsigned\n \nint\n\n\nsleep\n(\nunsigned\n \nint\n \nseconds\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nnewact\n,\n \noldact\n;\n\n    \nsigset_t\n            \nnewmask\n,\n \noldmask\n,\n \nsuspmask\n;\n\n    \nunsigned\n \nint\n        \nunslept\n;\n\n\n    \n/* set our handler, save previous information */\n\n    \nnewact\n.\nsa_handler\n \n=\n \nsig_alrm\n;\n\n    \nsigemptyset\n(\nnewact\n.\nsa_mask\n);\n\n    \nnewact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nsigaction\n(\nSIGALRM\n,\n \nnewact\n,\n \noldact\n);\n\n\n    \n/* block SIGALRM and save current signal mask */\n\n    \nsigemptyset\n(\nnewmask\n);\n\n    \nsigaddset\n(\nnewmask\n,\n \nSIGALRM\n);\n\n    \nsigprocmask\n(\nSIG_BLOCK\n,\n \nnewmask\n,\n \noldmask\n);\n\n\n    \nalarm\n(\nseconds\n);\n\n    \nsuspmask\n \n=\n \noldmask\n;\n\n\n    \n/* make sure SIGALRM isn\nt blocked */\n\n    \nsigdelset\n(\nsuspmask\n,\n \nSIGALRM\n);\n\n\n    \n/* wait for any signal to be caught */\n\n    \nsigsuspend\n(\nsuspmask\n);\n\n\n    \n/* some signal has been caught, SIGALRM is now blocked */\n\n\n    \nunslept\n \n=\n \nalarm\n(\n0\n);\n\n\n    \n/* reset previous action */\n\n    \nsigaction\n(\nSIGALRM\n,\n \noldact\n,\n \nNULL\n);\n\n\n    \n/* reset signal mask, which unblocks SIGALRM */\n\n    \nsigprocmask\n(\nSIG_SETMASK\n,\n \noldmask\n,\n \nNULL\n);\n\n    \nreturn\n(\nunslept\n);\n\n\n}\n\n\n\n\n\n\nThis code doesn't use any form of nonlocal branching (as in \nFigure 10.8\n to avoid the race condition between alarm and pause), so there is no effect on other signal handlers that may be executing when the \nSIGALRM\n is handled.\n\n\nThe \nnanosleep\n function is similar to the \nsleep\n function, but provides nanosecond-level granularity.\n\n\n#include \ntime.h\n\n\n\nint\n \nnanosleep\n(\nconst\n \nstruct\n \ntimespec\n \n*\nreqtp\n,\n \nstruct\n \ntimespec\n \n*\nremtp\n);\n\n\n\n/* Returns: 0 if slept for requested time or \u22121 on error */\n\n\n\n\n\n\nThis function suspends the calling process until either the requested time has elapsed or the function is interrupted by a signal.\n\n\nArguments:\n\n\n\n\nThe \nreqtp\n parameter specifies the amount of time to sleep in seconds and nanoseconds.\n\n\nThe \nremtp\n parameter. If the sleep interval is interrupted by a signal and the process doesn\u2019t terminate, the \ntimespec\n structure pointed to by the \nremtp\n parameter will be set to the amount of time left in the sleep interval. We can set this parameter to NULL if we are uninterested in the time unslept.\n\n\n\n\nNotes on \nnanosleep\n:\n\n\n\n\nIf the system doesn\u2019t support nanosecond granularity, the requested time is rounded up.\n\n\nBecause the nanosleep function doesn\u2019t involve the generation of any signals, we can use it without worrying about interactions with other functions.\n\n\n\n\nThe \nclock_nanosleep\n function provides the capability to suspend the calling thread using a delay time relative to a particular clock, using multiple system clocks (\nSection 6.10\n)\n\n\n#include \ntime.h\n\n\n\nint\n \nclock_nanosleep\n(\nclockid_t\n \nclock_id\n,\n \nint\n \nflags\n,\n\n                    \nconst\n \nstruct\n \ntimespec\n \n*\nreqtp\n,\n \nstruct\n \ntimespec\n \n*\nremtp\n);\n\n\n\n/* Returns: 0 if slept for requested time or error number on failure */\n\n\n\n\n\n\nArguments:\n\n\n\n\nThe \nclock_id\n argument specifies the clock against which the time delay is evaluated. Identifiers for clocks are listed in \nFigure 6.8\n.\n\n\nThe \nflags\n argument is used to control whether the delay is absolute or relative.\n\n\nWhen flags is set to 0, the sleep time is relative (how long we want to sleep).\n\n\nWhen it is set to \nTIMER_ABSTIME\n, the sleep time is absolute (we want to sleep until the clock reaches the specified time).\n\n\n\n\n\n\nThe \nreqtp\n and \nremtp\n arguments are the same as in the \nnanosleep\n function. However:\n\n\nWhen we use an absolute time, the \nremtp\n argument is unused, because it isn\u2019t needed.\n\n\nWe can reuse the same value for the \nreqtp\n argument for additional calls to \nclock_nanosleep\n until the clock reaches the specified absolute time value.\n\n\n\n\n\n\n\n\nExcept for error returns, the call:\n\n\nclock_nanosleep\n(\nCLOCK_REALTIME\n,\n \n0\n,\n \nreqtp\n,\n \nremtp\n);\n\n\n\n\n\n\nhas the same effect as the call:\n\n\nnanosleep\n(\nreqtp\n,\n \nremtp\n);\n\n\n\n\n\n\nSome applications require precision with how long they sleep, and a relative sleep time can lead to sleeping longer than desired. Using an absolute time improves the precision, even though a time-sharing process scheduler makes no guarantee that our task will execute immediately after our sleep time has ended. [p375]\n\n\nsigqueue\n Function\n\n\nAs discussed in \nSection 10.8\n, most UNIX systems don\u2019t queue signals. With the real-time extensions to POSIX.1, some systems began adding support for queueing signals. With SUSv4, the queued signal functionality has moved from the real-time extensions to the base specification.\n\n\nThese extensions allow applications to pass more information along with the delivery (\nSection 10.14\n). This information is embedded in a \nsiginfo\n structure.\n\n\nTo use queued signals we have to do the following:\n\n\n\n\nSpecify the \nSA_SIGINFO\n flag when we install a signal handler using the \nsigaction\n function. Without this flag, it is left up to the implementation whether the signal is queued.\n\n\nProvide a signal handler in the \nsa_sigaction\n member of the \nsigaction\n structure instead of using the usual \nsa_handler\n field. Implementations might allow us to use the \nsa_handler\n field, but we won\u2019t be able to obtain the extra information sent with the \nsigqueue\n function.\n\n\nUse the \nsigqueue\n function to send signals.\n\n\n\n\n#include \nsignal.h\n\n\n\nint\n \nsigqueue\n(\npid_t\n \npid\n,\n \nint\n \nsigno\n,\n \nconst\n \nunion\n \nsigval\n \nvalue\n)\n\n\n\n/* Returns: 0 if OK, \u22121 on error */\n\n\n\n\n\n\nThe \nsigqueue\n function is similar to the \nkill\n function, except that:\n\n\n\n\nWe can only direct signals to a single process\n\n\nWe can use the \nvalue\n argument to transmit either an integer or a pointer value to the signal handler.\n\n\n\n\nSignals can\u2019t be queued infinitely. When the SIGQUEUE_MAX limit (\nPOSIX Limits\n) is reached, \nsigqueue\n can fail with \nerrno\n set to\n\nEAGAIN\n.\n\n\nWith the real-time signal enhancements, other signal numbers between \nSIGRTMIN\n and \nSIGRTMAX\n inclusive can be queued, and the  default action for these signals is to terminate the process. [p376]\n\n\nThe table below summarizes behavior of queued signals on various platforms:\n\n\n\n\n\n\n\n\nBehavior\n\n\nSUS\n\n\nFreeBSD\n\n\nLinux\n\n\nMac OS X\n\n\nSolaris\n\n\n\n\n\n\n\n\n\n\nsupports \nsigqueue\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\nx\n\n\n\n\n\n\nqueues other signals besides SIGRTMIN to SIGRTMAX\n\n\noptional\n\n\nx\n\n\n\n\n\n\nx\n\n\n\n\n\n\nqueues signals even if the caller doesn\u2019t use the \nSA_SIGINFO\n\n\noptional\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\n\n\n\n\nJob-Control Signals\n\n\nPOSIX.1 considers six to be job-control signals:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSIGCHLD\n\n\nChild process has stopped or terminated.\n\n\n\n\n\n\nSIGCONT\n\n\nContinue process, if stopped.\n\n\n\n\n\n\nSIGSTOP\n\n\nStop signal (can\u2019t be caught or ignored).\n\n\n\n\n\n\nSIGTSTP\n\n\nInteractive stop signal.\n\n\n\n\n\n\nSIGTTIN\n\n\nRead from controlling terminal by background process group member.\n\n\n\n\n\n\nSIGTTOU\n\n\nWrite to controlling terminal by a background process group member.\n\n\n\n\n\n\n\n\nThe following program demonstrates the normal sequence of code used when a program handles job control.\n\n\nsignals/sigtstp.c\n\n\n#include \napue.h\n\n\n\n#define BUFFSIZE    1024\n\n\n\nstatic\n \nvoid\n\n\nsig_tstp\n(\nint\n \nsigno\n)\n \n/* signal handler for SIGTSTP */\n\n\n{\n\n    \nsigset_t\n    \nmask\n;\n\n\n    \n/* ... move cursor to lower left corner, reset tty mode ... */\n\n\n    \n/*\n\n\n     * Unblock SIGTSTP, since it\ns blocked while we\nre handling it.\n\n\n     */\n\n    \nsigemptyset\n(\nmask\n);\n\n    \nsigaddset\n(\nmask\n,\n \nSIGTSTP\n);\n\n    \nsigprocmask\n(\nSIG_UNBLOCK\n,\n \nmask\n,\n \nNULL\n);\n\n\n    \nsignal\n(\nSIGTSTP\n,\n \nSIG_DFL\n);\n   \n/* reset disposition to default */\n\n\n    \nkill\n(\ngetpid\n(),\n \nSIGTSTP\n);\n    \n/* and send the signal to ourself */\n\n\n    \n/* we won\nt return from the kill until we\nre continued */\n\n\n    \nsignal\n(\nSIGTSTP\n,\n \nsig_tstp\n);\n  \n/* reestablish signal handler */\n\n\n    \n/* ... reset tty mode, redraw screen ... */\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nn\n;\n\n    \nchar\n    \nbuf\n[\nBUFFSIZE\n];\n\n\n    \n/*\n\n\n     * Only catch SIGTSTP if we\nre running with a job-control shell.\n\n\n     */\n\n    \nif\n \n(\nsignal\n(\nSIGTSTP\n,\n \nSIG_IGN\n)\n \n==\n \nSIG_DFL\n)\n\n        \nsignal\n(\nSIGTSTP\n,\n \nsig_tstp\n);\n\n\n    \nwhile\n \n((\nn\n \n=\n \nread\n(\nSTDIN_FILENO\n,\n \nbuf\n,\n \nBUFFSIZE\n))\n \n \n0\n)\n\n        \nif\n \n(\nwrite\n(\nSTDOUT_FILENO\n,\n \nbuf\n,\n \nn\n)\n \n!=\n \nn\n)\n\n            \nerr_sys\n(\nwrite error\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nread error\n);\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis program does the following:\n\n\n\n\nWhen the program starts, it arranges to catch the \nSIGTSTP\n signal only if the signal\u2019s disposition is \nSIG_DFL\n. The reason is that \nwhen the program is started by a shell that doesn\u2019t support job control (\n/bin/sh\n, for example), the signal\u2019s disposition should be set to \nSIG_IGN\n. In fact, the shell doesn\u2019t explicitly ignore this signal; \ninit\n sets the disposition of the three job-control signals (\nSIGTSTP\n, \nSIGTTIN\n, and \nSIGTTOU\n) to \nSIG_IGN\n. This disposition is then inherited by all login shells. Only a job-control shell should reset the disposition of these three signals to \nSIG_DFL\n.\n\n\nWhen we type the suspend character, the process receives the \nSIGTSTP\n signal and the signal handler is invoked. At this point, we would do any terminal-related processing: move the cursor to the lower-left corner, restore the terminal mode, etc.\n\n\nAfter resetting the disposition of \nSIGSTOP\n to its default (stop the process) and unblocking it, we send ourself the \nSIGSTOP\n signal (\nkill(getpid(), SIGTSTP);\n). We have to unblock it since we\u2019re currently handling that same signal, and the system blocks it automatically while it\u2019s being caught.\n\n\nAt this point, the system stops the process. It is continued only when it receives (usually from the job-control shell, in response to an interactive \nfg\n command) a \nSIGCONT\n signal.\n\n\nWe don\u2019t catch \nSIGCONT\n since its default disposition is to continue the stopped process; when this happens, the program continues as though it returned from the \nkill\n function. When the program is continued, we reset the disposition for the \nSIGTSTP\n signal and do any terminal processing (as indicated in the comments).\n\n\n\n\nSignal Names and Numbers\n\n\nThis section discusses how to map between signal numbers and names. Some systems provide the array:\n\n\nextern\n \nchar\n \n*\nsys_siglist\n[];\n\n\n\n\n\n\nThe array index is the signal number, giving a pointer to the character string name of the signal. [p379]\n\n\nTo print the signal's character string in a portable manner, use the \npsignal\n function:\n\n\n#include \nsignal.h\n\n\n\nvoid\n \npsignal\n(\nint\n \nsigno\n,\n \nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nThe string \nmsg\n (which normally includes the name of the program) is output to the standard error, followed by a colon and a space, followed by a description of the signal, followed by a newline. If \nmsg\n is \nNULL\n, then only the description is written to the standard error. This function is similar to \nperror\n (\nSection 1.7\n).\n\n\nIf you have a \nsiginfo\n structure from an alternative \nsigaction\n signal handler, you can print the signal information with the \npsiginfo\n function.\n\n\n#include \nsignal.h\n\n\n\nvoid\n \npsiginfo\n(\nconst\n \nsiginfo_t\n \n*\ninfo\n,\n \nconst\n \nchar\n \n*\nmsg\n);\n\n\n\n\n\n\nYou can use the \nstrsignal\n function if you only need the string description of the signal. This function is similar to \nstrerror\n (\nSection 1.7\n).\n\n\n#include \nstring.h\n\n\n\nchar\n \n*\nstrsignal\n(\nint\n \nsigno\n);\n\n\n\n/* Returns: a pointer to a string describing the signal */\n\n\n\n\n\n\nSummary\n\n\nAn understanding of signal handling is essential to advanced UNIX System programming. This chapter has taken a long and thorough look at UNIX System signals, from previous implementations to the POSIX.1 reliable-signal concept and all the related functions, followed by POSIX.1 \nabort\n, \nsystem\n, and \nsleep\n functions.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\n[p324] on some macro constants in \nsignal.h\n:\n\n\n\n\nThese constants can be used in place of the \"pointer to a function that takes an integer argument and returns nothing\", the second argument to \nsignal\n, and the return value from \nsignal\n. The three values used for these constants need not be \u22121, 0, and 1. They must be three values that can never be the address of any declarable function. Most UNIX systems use the values shown.\n\n\n\n\nWhy is the macro in the form \nSIG_ERR (void (*)())-1\n and the like?\n\n\nSolution:\n\n\nThey are integer that cast into an address which means the \"pointer to a function that takes an integer argument and returns nothing\". \nvoid (*)()\n tells the compiler to ignore type-checking for the parameters. See:\n\n\n\n\nStack Overflow\n\n\n\n\n[p359] on unblocking signals:\n\n\n\n\nIf the signal is sent to the process while it is blocked, the signal delivery will be deferred until the signal is unblocked. To the application, this can look as if the signal occurs between the unblocking and the \npause\n (depending on how the kernel implements signals). If this happens, or if the signal does occur between the unblocking and the \npause\n, we have a problem. Any occurrence of the signal in this window of time is lost, in the sense that we might not see the signal again, in which case the \npause\n will block indefinitely. This is another problem with the earlier unreliable signals.\n\n\n\n\nWhat is exactly the window? Shouldn't be the unblocked signals delivered to the process? Not fully understood.", 
            "title": "Chapter 10. Signals"
        }, 
        {
            "location": "/apue/ch11/", 
            "text": "Chapter 11. Threads\n\n\nIntroduction\n\n\nProcesses are discussed in earlier chapters. A limited amount of sharing can occur between related processes.\n\n\nThis chapter looks inside a process further to see how to use multiple threads of control (or simply threads) to perform multiple tasks within the environment of a single process. All threads within a single process have access to the same process components, such as file descriptors and memory.\n\n\nThis chapter is concluded with synchronization mechanisms available to prevent multiple threads from viewing inconsistencies in their shared resources.\n\n\nThread Concepts\n\n\nWith multiple threads of control, the programs can more than one thing at a time within a single process, with each thread handling a separate task. This approach can have several benefits:\n\n\n\n\nWe can simplify code that deals with asynchronous events by assigning a separate thread to handle each event type, while each thread can then handle its event using a synchronous programming model. A synchronous programming model is much simpler than an asynchronous one.\n\n\nMultiple processes have to use complex mechanisms provided by the operating system to share memory and file descriptors. Threads, in contrast, automatically have access to the same memory address space and file descriptors\n\n\nThe processing of independent tasks can be interleaved by assigning a separate thread per task (only if they don\u2019t depend on the processing performed by each other), so that overall program throughput can be improved. (A single-threaded process has to implicitly serializes those tasks.)\n\n\nInteractive programs can be improved in response time by using multiple threads to separate the portions of the program that deal with user input and output from the other parts of the program.\n\n\n\n\nThe benefits of a multithreaded programming model can be realized on multiprocessor or multicore systems, and even on uniprocessor systems. A program can be simplified using threads regardless of the number of processors, since that doesn\u2019t affect the program structure. As long as your program has to block when serializing tasks, there are improvements in response time and throughput when running on a uniprocessor, because some threads might be able to run while others are blocked.\n\n\nA thread consists of the information necessary to represent an execution context within a process:\n\n\n\n\nThread ID\n: identifies the thread within a process\n\n\nSet of register values\n\n\nStack\n\n\nScheduling priority and policy,\n\n\nSignal mask\n\n\nAn errno variable (\nSection 1.7\n)\n\n\nThread-specific data (\nSection 12.6\n).\n\n\n\n\nEverything within a process is sharable among the threads in a process:\n\n\n\n\nText of the executable program\n\n\nThe program\u2019s global and heap memory\n\n\nStacks\n\n\nFile descriptors.\n\n\n\n\nThe threads interfaces of this chapter are from POSIX.1-2001, known as \npthreads\n for \"POSIX threads\". The feature test macro for POSIX threads is \n_POSIX_THREADS\n. Applications can either use this in an \n#ifdef\n test to determine at compile time whether threads are supported or call \nsysconf\n with the \n_SC_THREADS\n constant to determine this at runtime. [p384]\n\n\nThread Identification\n\n\nUnlike the process ID, which is unique in the system, the thread ID has significance only within the context of the process to which it belongs.\n\n\nA thread ID is represented by the \npthread_t\n data type. Implementations are allowed to use a structure to represent the \npthread_t\n data type, so portable implementations can\u2019t treat them as integers (process ID's \npid_t\n data type is a non-negative integer). The \npthread_equal\n function (below) must be used to compare two thread IDs. A consequence of allowing the \npthread_t\n data type to be a structure is that there is no portable way to print its value. Linux 3.2.0 uses an unsigned long integer for the \npthread_t\n data type. FreeBSD 8.0 and Mac OS X 10.6.8 use a pointer to the \npthread\n structure for the \npthread_t\n data type.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_equal\n(\npthread_t\n \ntid1\n,\n \npthread_t\n \ntid2\n);\n\n\n\n/* Returns: nonzero if equal, 0 otherwise */\n\n\n\n\n\n\nA thread can obtain its own thread ID by calling the pthread_self function.\n\n\n#include \npthread.h\n\n\n\npthread_t\n \npthread_self\n(\nvoid\n);\n\n\n\nReturns\n:\n \nthe\n \nthread\n \nID\n \nof\n \nthe\n \ncalling\n \nthread\n\n\n\n\n\n\nThis function can be used with \npthread_equal\n when a thread needs to identify data structures that are tagged with its thread ID. For example, a single master thread places new jobs on a work queue. A pool of three worker threads removes jobs from the queue. Instead of allowing each thread to process whichever job is at the head of the queue, the master thread controls job assignment by placing the ID of the thread that should process the job in each job structure. Each worker thread then removes only jobs that are tagged with its own thread ID. This situation is illustrated below:\n\n\n\n\nThread Creation\n\n\nThe traditional UNIX process model (one thread of control per process) is conceptually the same as a threads-based model whereby each process is made up of only one thread. As the program runs, its behavior should be indistinguishable from the traditional process, until it creates more threads of control. [p385] Additional threads can be created by calling the \npthread_create\n function:\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_create\n(\npthread_t\n \n*\nrestrict\n \ntidp\n,\n\n                   \nconst\n \npthread_attr_t\n \n*\nrestrict\n \nattr\n,\n\n                   \nvoid\n \n*\n(\n*\nstart_rtn\n)(\nvoid\n \n*\n),\n \nvoid\n \n*\nrestrict\n \narg\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nThe memory location pointed to by \ntidp\n is set to the thread ID of the newly created thread when \npthread_create\n returns successfully.\n\n\nThe \nattr\n argument is used to customize various thread attributes (detailed in \nSection 12.3\n). This chapter sets this to \nNULL\n to create a thread with the default attributes.\n\n\nThe newly created thread starts running at the address of the \nstart_rtn\n function.\n\n\nThe \narg\n is a pointer to the single argument passed to the \nstart_rtn\n. If you need to pass more than one argument to the \nstart_rtn\n function, then you need to store them in a structure and pass the address of the structure in \narg\n.\n\n\n\n\nWhen a thread is created, there is no guarantee whether the newly created thread or the calling thread. \nThe newly created thread has access to the process address space and inherits the calling thread\u2019s floating-point environment (\nfenv.h\n) and signal mask; however, the set of pending signals for the thread is cleared.\n\n\nThe following example creates one thread and prints the process and thread IDs of the new thread and the initial thread:\n\n\nthreads/threadid.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\npthread_t\n \nntid\n;\n\n\n\nvoid\n\n\nprintids\n(\nconst\n \nchar\n \n*\ns\n)\n\n\n{\n\n    \npid_t\n       \npid\n;\n\n    \npthread_t\n   \ntid\n;\n\n\n    \npid\n \n=\n \ngetpid\n();\n\n    \ntid\n \n=\n \npthread_self\n();\n\n    \nprintf\n(\n%s pid %lu tid %lu (0x%lx)\n\\n\n,\n \ns\n,\n \n(\nunsigned\n \nlong\n)\npid\n,\n\n      \n(\nunsigned\n \nlong\n)\ntid\n,\n \n(\nunsigned\n \nlong\n)\ntid\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintids\n(\nnew thread: \n);\n\n    \nreturn\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nerr\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\nntid\n,\n \nNULL\n,\n \nthr_fn\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread\n);\n\n    \nprintids\n(\nmain thread:\n);\n\n    \nsleep\n(\n1\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThis example handles the races between the main thread and the new thread as follows:\n\n\n\n\nFirst is the need to sleep in the main thread. Without sleep, the main thread might exit, thereby terminating the entire process before the new thread\ngets a chance to run. This behavior is dependent on the operating system\u2019s threads implementation and scheduling algorithms\n\n\nSecond, the new thread obtains its thread ID by calling \npthread_self\n instead of reading it out of shared memory or receiving it as an argument to its thread-start routine. If the new thread runs before the main thread returns from calling \npthread_create\n, then the new thread will see the uninitialized contents of \nntid\n instead of the thread ID. [p387-388]\n\n\n\n\nThread Termination\n\n\nIf any thread within a process calls \nexit\n, \n_Exit\n, or \n_exit\n, then the entire process terminates. Similarly, when the default action is to terminate the process, a signal sent to a thread will terminate the entire process.\n\n\nA single thread can exit in three ways, without terminating the entire process:\n\n\n\n\nThe thread can simply return from the start routine. The return value is the thread\u2019s exit code.\n\n\nThe thread can be canceled by another thread in the same process.\n\n\nThe thread can call \npthread_exit\n.\n\n\n\n\nThe \npthread_exit\n and \npthread_join\n functions\n\n\n#include \npthread.h\n\n\n\nvoid\n \npthread_exit\n(\nvoid\n \n*\nrval_ptr\n);\n\n\n\n\n\n\nThe \nrval_ptr\n argument is a typeless pointer is available to other threads in the process by calling the \npthread_join\n function.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_join\n(\npthread_t\n \nthread\n,\n \nvoid\n \n**\nrval_ptr\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe thread that calls \npthread_join\n will block until the specified thread calls \npthread_exit\n, returns from its start routine, or is canceled. If the thread simply returned from its start routine, \nrval_ptr\n will contain the return code. If the thread was canceled, the memory location specified by \nrval_ptr\n is set to \nPTHREAD_CANCELED\n.\n\n\nBy calling \npthread_join\n, we automatically place the thread with which we\u2019re joining in the detached state so that its resources can be recovered.  If the thread was already in the detached state, \npthread_join\n can fail, returning \nEINVAL\n.\n\n\nIf we\u2019re not interested in a thread\u2019s return value, we can set \nrval_ptr\n to \nNULL\n.\n\n\nThe following example shows how to fetch the exit code from a thread that has terminated:\n\n\nthreads/exitstatus.c\n\n\n[p389-390]\n\n\nThe typeless pointer passed to \npthread_create\n and \npthread_exit\n can be used to pass the address of a structure containing more complex information.\n\n\nIf the structure was allocated on the caller\u2019s stack, the memory contents might have changed by the time the structure is used. If a thread allocates a structure on its stack and passes a pointer to this structure to \npthread_exit\n, then the stack might be destroyed and its memory reused for something else by the time the caller of \npthread_join\n tries to use it.\n\n\nThe following example shows the problem with using an automatic variable (allocated on the stack) as the argument to \npthread_exit\n:\n\n\nthreads/badexit2.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n \na\n,\n \nb\n,\n \nc\n,\n \nd\n;\n\n\n};\n\n\n\nvoid\n\n\nprintfoo\n(\nconst\n \nchar\n \n*\ns\n,\n \nconst\n \nstruct\n \nfoo\n \n*\nfp\n)\n\n\n{\n\n    \nprintf\n(\n%s\n,\n \ns\n);\n\n    \nprintf\n(\n  structure at 0x%lx\n\\n\n,\n \n(\nunsigned\n \nlong\n)\nfp\n);\n\n    \nprintf\n(\n  foo.a = %d\n\\n\n,\n \nfp\n-\na\n);\n\n    \nprintf\n(\n  foo.b = %d\n\\n\n,\n \nfp\n-\nb\n);\n\n    \nprintf\n(\n  foo.c = %d\n\\n\n,\n \nfp\n-\nc\n);\n\n    \nprintf\n(\n  foo.d = %d\n\\n\n,\n \nfp\n-\nd\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn1\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nstruct\n \nfoo\n  \nfoo\n \n=\n \n{\n1\n,\n \n2\n,\n \n3\n,\n \n4\n};\n\n\n    \nprintfoo\n(\nthread 1:\n\\n\n,\n \nfoo\n);\n\n    \npthread_exit\n((\nvoid\n \n*\n)\nfoo\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn2\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 2: ID is %lu\n\\n\n,\n \n(\nunsigned\n \nlong\n)\npthread_self\n());\n\n    \npthread_exit\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n         \nerr\n;\n\n    \npthread_t\n   \ntid1\n,\n \ntid2\n;\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\ntid1\n,\n \nNULL\n,\n \nthr_fn1\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 1\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid1\n,\n \n(\nvoid\n \n*\n)\nfp\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 1\n);\n\n    \nsleep\n(\n1\n);\n\n    \nprintf\n(\nparent starting second thread\n\\n\n);\n\n    \nerr\n \n=\n \npthread_create\n(\ntid2\n,\n \nNULL\n,\n \nthr_fn2\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 2\n);\n\n    \nsleep\n(\n1\n);\n\n    \nprintfoo\n(\nparent:\n\\n\n,\n \nfp\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWhen we run this program on Linux, we get:\n\n\n$ ./a.out\n\n\nthread 1:\n\n\nstructure at 0x7f2c83682ed0\n\n\nfoo.a = 1\n\n\nfoo.b = 2\n\n\nfoo.c = 3\n\n\nfoo.d = 4\n\n\nparent starting second thread\n\n\nthread 2: ID is 139829159933696\n\n\nparent:\n\n\nstructure at 0x7f2c83682ed0\n\n\nfoo.a = -2090321472\n\n\nfoo.b = 32556\n\n\nfoo.c = 1\n\n\nfoo.d = 0\n\n\n\n\n\n\nThe contents of the structure (allocated on the stack of thread \ntid1\n) have changed by the time the main thread can access the structure. Note how the stack of the second thread (\ntid2\n) has overwritten the first thread\u2019s stack. To solve this problem, we can either use a global structure or allocate the structure using \nmalloc\n.\n\n\nThe \npthread_cancel\n function\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cancel\n(\npthread_t\n \ntid\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nBy default, \npthread_cancel\n will cause the thread specified by \ntid\n to behave as if it had called \npthread_exit\n with an argument of \nPTHREAD_CANCELED\n, though a thread can ignore or otherwise control how it is canceled.\n\n\npthread_cancel\n doesn\u2019t wait for the thread to terminate; it merely makes the request.\n\n\n\n\nThe \npthread_cleanup_push\n and \npthread_cleanup_pop\n functions\n\n\nA thread can arrange for functions to be called when it exits, similar to the way that the \natexit\n function (\nSection 7.3\n). The functions are known as \nthread cleanup handlers\n. More than one cleanup handler can be established for a thread. The handlers are recorded in a stack, which means that they are executed in the reverse order from that with which they were registered.\n\n\n#include \npthread.h\n\n\n\nvoid\n \npthread_cleanup_push\n(\nvoid\n \n(\n*\nrtn\n)(\nvoid\n \n*\n),\n \nvoid\n \n*\narg\n);\n\n\nvoid\n \npthread_cleanup_pop\n(\nint\n \nexecute\n);\n\n\n\n\n\n\nThe \npthread_cleanup_push\n function schedules the cleanup function, \nrtn\n, to be called with the single argument, \narg\n, when the thread performs one of the following actions:\n\n\n\n\nMakes a call to \npthread_exit\n\n\nResponds to a cancellation request\n\n\nMakes a call to \npthread_cleanup_pop\n with a nonzero execute argument\n\n\n\n\nIf the \nexecute\n argument is set to zero, the cleanup function is not called.\n\n\npthread_cleanup_pop\n removes the cleanup handler established by the last call to \npthread_cleanup_push\n.\n\n\nBecause they can be implemented as macros, they must be used in matched pairs within the same scope in a thread. The macro definition of \npthread_cleanup_push\n can include a \n{\n character, in which case the matching \n}\n character is in the \npthread_cleanup_pop\n definition.\n\n\nThe following example shows how to use thread cleanup handlers. We need to match calls to \npthread_cleanup_pop\n with the calls to \npthread_cleanup_push\n; otherwise, the program might not compile. [p394]\n\n\nthreads/cleanup.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nvoid\n\n\ncleanup\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\ncleanup: %s\n\\n\n,\n \n(\nchar\n \n*\n)\narg\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn1\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 1 start\n\\n\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 1 first handler\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 1 second handler\n);\n\n    \nprintf\n(\nthread 1 push complete\n\\n\n);\n\n    \nif\n \n(\narg\n)\n\n        \nreturn\n((\nvoid\n \n*\n)\n1\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \nreturn\n((\nvoid\n \n*\n)\n1\n);\n\n\n}\n\n\n\nvoid\n \n*\n\n\nthr_fn2\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nprintf\n(\nthread 2 start\n\\n\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 2 first handler\n);\n\n    \npthread_cleanup_push\n(\ncleanup\n,\n \nthread 2 second handler\n);\n\n    \nprintf\n(\nthread 2 push complete\n\\n\n);\n\n    \nif\n \n(\narg\n)\n\n        \npthread_exit\n((\nvoid\n \n*\n)\n2\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_cleanup_pop\n(\n0\n);\n\n    \npthread_exit\n((\nvoid\n \n*\n)\n2\n);\n\n\n}\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n         \nerr\n;\n\n    \npthread_t\n   \ntid1\n,\n \ntid2\n;\n\n    \nvoid\n        \n*\ntret\n;\n\n\n    \nerr\n \n=\n \npthread_create\n(\ntid1\n,\n \nNULL\n,\n \nthr_fn1\n,\n \n(\nvoid\n \n*\n)\n1\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 1\n);\n\n    \nerr\n \n=\n \npthread_create\n(\ntid2\n,\n \nNULL\n,\n \nthr_fn2\n,\n \n(\nvoid\n \n*\n)\n1\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt create thread 2\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid1\n,\n \ntret\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 1\n);\n\n    \nprintf\n(\nthread 1 exit code %ld\n\\n\n,\n \n(\nlong\n)\ntret\n);\n\n    \nerr\n \n=\n \npthread_join\n(\ntid2\n,\n \ntret\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nerr_exit\n(\nerr\n,\n \ncan\nt join with thread 2\n);\n\n    \nprintf\n(\nthread 2 exit code %ld\n\\n\n,\n \n(\nlong\n)\ntret\n);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nRunning the program  on Linux gives us:\n\n\n$ ./a.out\n\n\nthread 1 start\n\n\nthread 1 push complete\n\n\nthread 2 start\n\n\nthread 2 push complete\n\n\ncleanup: thread 2 second handler\n\n\ncleanup: thread 2 first handler\n\n\nthread 1 exit code 1\n\n\nthread 2 exit code 2\n\n\n\n\n\n\nNote that if the thread terminates by returning from its start routine, its cleanup handlers are not called. [p396]\n\n\nThe table below summarize similarities between the thread functions and the process functions.\n\n\n\n\n\n\n\n\nProcess primitive\n\n\nThread primitive\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nfork\n\n\npthread_create\n\n\ncreate a new flow of control\n\n\n\n\n\n\nexit\n\n\npthread_exit\n\n\nexit from an existing flow of control\n\n\n\n\n\n\nwaitpid\n\n\npthread_join\n\n\nget exit status from flow of control\n\n\n\n\n\n\natexit\n\n\npthread_cleanup_push\n\n\nregister function to be called at exit from flow of control\n\n\n\n\n\n\ngetpid\n\n\npthread_self\n\n\nget ID for flow of control\n\n\n\n\n\n\nabort\n\n\npthread_cancel\n\n\nrequest abnormal termination of flow of control\n\n\n\n\n\n\n\n\nThe \npthread_detach\n function\n\n\nBy default, a thread\u2019s termination status is retained until we call \npthread_join\n for that thread. A thread\u2019s underlying storage can be reclaimed immediately on termination if the thread has been detached. After a thread is detached, we can\u2019t use the \npthread_join\n function to wait for its termination status, because calling \npthread_join\n for a detached thread results in undefined behavior. We can detach a thread by calling \npthread_detach\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_detach\n(\npthread_t\n \ntid\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nWe can create a thread that is already in the detached state by modifying the thread attributes we pass to \npthread_create\n. This is detailed in the next chapter.\n\n\nThread Synchronization\n\n\nWhen multiple threads of control share the same memory, one thread can modify a variable that other threads can read or modify, thus we need to synchronize the threads to ensure that they don\u2019t use an invalid value when accessing the variable\u2019s memory contents.\n\n\nWhen one thread modifies a variable, other threads can potentially see inconsistencies when reading the value of that variable. On processor architectures in which the modification takes more than one memory cycle, this can happen when the memory read is interleaved between the memory write cycles.\n\n\nIn the following figure, thread A reads the variable and then writes a new value to it, but the write operation takes two memory cycles.  If thread B reads the same variable between the two write cycles, it will see an inconsistent value:\n\n\n\n\nTo solve this problem, the threads have to use a lock that will allow only one thread to access the variable at a time, as show in the following figure:\n\n\n\n\n\n\nIf thread B wants to read the variable, it acquires a lock.\n\n\nWhen thread A updates the variable, it acquires the same lock. Thus thread B will be unable to read the variable until thread A releases the lock.\n\n\n\n\nWe also need to synchronize two or more threads that might try to modify the same variable at the same time.\n\n\nFor example (as in the following figure), the increment operation is usually broken down into three steps.\n\n\n\n\nRead the memory location into a register.\n\n\nIncrement the value in the register.\n\n\nWrite the new value back to the memory location.\n\n\n\n\n\n\nIf two threads try to increment the same variable at almost the same time without synchronizing with each other, the results can be inconsistent. [p398]\n\n\nThere is no race if one of the following (assumed) condition occurs:\n\n\n\n\nThe modification is atomic.\n\n\n(In the previous example) The increment takes only one memory cycle.\n\n\nData always appears to be \nsequentially consistent\n.\n\n\n\n\nOur operations are sequentially consistent when multiple threads can\u2019t observe inconsistencies in our data. In modern computer systems, memory accesses take multiple bus cycles, and multiprocessors generally interleave bus cycles among multiple processors, so we aren\u2019t guaranteed that our data is sequentially consistent.\n\n\n[p399]\n\n\nBesides the computer architecture, races can arise from the ways in which our programs use variables, creating places where it is possible to view inconsistencies. For example, we might increment a variable and then make a decision based on its value. The combination of the increment step and the decision-making step isn\u2019t atomic, which opens a window where inconsistencies can arise.\n\n\nMutexes\n\n\nWe can protect our data and ensure access by only one thread at a time by using the pthreads mutual-exclusion interfaces. A \nmutex\n is basically a lock that we set (lock) before accessing a shared resource and release (unlock) when we\u2019re done.\n\n\n\n\nWhile it is set, any other thread that tries to set it will block until we release it.\n\n\nIf more than one thread is blocked when we unlock the mutex, then all threads blocked on the lock will be made runnable, and the first one to run will be able to set the lock. The others will see that the mutex is still locked and go back to waiting for it to become available again.\n\n\n\n\nIn this way, only one thread will proceed at a time.\n\n\n[p400]\n\n\nA mutex variable is represented by the \npthread_mutex_t\n data type. Before we can use a mutex variable, we must first initialize it by either setting it to the constant \nPTHREAD_MUTEX_INITIALIZER\n (for statically allocated mutexes only) or calling \npthread_mutex_init\n. If we allocate the mutex dynamically (by calling \nmalloc\n, for example), then we need to call \npthread_mutex_destroy\n before freeing the memory.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_mutex_init\n(\npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                       \nconst\n \npthread_mutexattr_t\n \n*\nrestrict\n \nattr\n);\n\n\n\nint\n \npthread_mutex_destroy\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nTo initialize a mutex with the default attributes, we set \nattr\n to \nNULL\n (mutex attributes is discussed \nSection 12.4\n).\n\n\nTo lock a mutex, we call \npthread_mutex_lock\n. If the mutex is already locked, the calling thread will block until the mutex is unlocked. To unlock a mutex, we call \npthread_mutex_unlock\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_mutex_lock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\nint\n \npthread_mutex_trylock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\nint\n \npthread_mutex_unlock\n(\npthread_mutex_t\n \n*\nmutex\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\nIf a thread can\u2019t afford to block, it can use \npthread_mutex_trylock\n to lock the mutex conditionally. If the mutex is unlocked at the time \npthread_mutex_trylock\n is called, then \npthread_mutex_trylock\n will lock the mutex without blocking and return 0. Otherwise, \npthread_mutex_trylock\n will fail, returning \nEBUSY\n without locking the mutex.\n\n\nThe following example illustrates a mutex used to protect a data structure. When more than one thread needs to access a dynamically allocated object, we can embed a reference count in the object to ensure that we don\u2019t free its memory before all threads are done using it.\n\n\nthreads/mutex1.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n \n*\nfp\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \n/* ... continue initialization ... */\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nif\n \n(\n--\nfp\n-\nf_count\n \n==\n \n0\n)\n \n{\n \n/* last reference */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nWe lock the mutex before incrementing the reference count, decrementing the reference count, and checking whether the reference count reaches zero.\n\n\nNo locking is necessary when we initialize the reference count to 1 in the \nfoo_alloc\n function, because the allocating thread is the only reference to it so far.\n If we were to place the structure on a list at this point, it could be found by other threads, so we would need to lock it first.\n\n\n\n\nBefore using the object, threads are expected to add a reference to it by calling \nfoo_hold\n. When they are done, they must call \nfoo_rele\n to release the reference. When the last reference is released, the object\u2019s memory is freed.\n\n\nIn this example, we have ignored how threads find an object before calling \nfoo_hold\n. Even though the reference count is zero, it would be a mistake for \nfoo_rele\n to free the object\u2019s memory if another thread is blocked on the mutex in a call to \nfoo_hold\n. We can avoid this problem by ensuring that the object can\u2019t be found before freeing its memory. We\u2019ll see how to do this in the examples that follow.\n\n\nDeadlock Avoidance\n\n\nA thread will deadlock itself if it tries to lock the same mutex twice. There are less obvious ways to create deadlocks with mutexes. For example, when we use more than one mutex in our programs, a deadlock can occur if we allow one thread to hold a mutex and block while trying to lock a second mutex at the same time that another thread holding the second mutex tries to lock the first mutex. Neither thread can proceed, because each needs a resource that is held by the other.\n\n\nDeadlocks can be avoided by carefully controlling the order in which mutexes are locked. For example, assume that you have two mutexes, A and B, that you need to lock at the same time. If all threads always lock mutex A before mutex B (vice versa), no deadlock can occur from the use of the two mutexes (but you can still deadlock on other resources). You\u2019ll have the potential for a deadlock only when one thread attempts to lock the mutexes in the opposite order from another thread.\n\n\nAnother approach when many locks and data structures are involved (it is difficult to apply the previous approach) is that you might be able to release your locks and try again at a later time. You can use the \npthread_mutex_trylock\n interface to avoid deadlocking in this case. If you are already holding locks and \npthread_mutex_trylock\n is successful, then you can proceed. If it can\u2019t acquire the lock, however, you can release the locks you already hold, clean up, and try again later.\n\n\nExample of two mutexes\n\n\nIn the following example which shows the use of two mutexes, we avoid deadlocks by ensuring that when we need to acquire two mutexes at the same time, we always lock them in the same order. The second mutex protects a hash list that we use to keep track of the foo data structures. Thus the hashlock mutex protects both the fh hash table and the \nf_next\n hash link field in the foo structure. The \nf_lock\n mutex in the foo structure protects access to the remainder of the foo structure\u2019s fields.\n\n\nthreads/mutex2.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\n#define NHASH 29\n\n\n#define HASH(id) (((unsigned long)id)%NHASH)\n\n\n\nstruct\n \nfoo\n \n*\nfh\n[\nNHASH\n];\n\n\n\npthread_mutex_t\n \nhashlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \nstruct\n \nfoo\n     \n*\nf_next\n;\n \n/* protected by hashlock */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \nidx\n \n=\n \nHASH\n(\nid\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \nfp\n-\nf_next\n \n=\n \nfh\n[\nidx\n];\n\n        \nfh\n[\nidx\n]\n \n=\n \nfp\n;\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \n/* ... continue initialization ... */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n\n}\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_find\n(\nint\n \nid\n)\n \n/* find an existing object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfor\n \n(\nfp\n \n=\n \nfh\n[\nHASH\n(\nid\n)];\n \nfp\n \n!=\n \nNULL\n;\n \nfp\n \n=\n \nfp\n-\nf_next\n)\n \n{\n\n        \nif\n \n(\nfp\n-\nf_id\n \n==\n \nid\n)\n \n{\n\n            \nfoo_hold\n(\nfp\n);\n\n            \nbreak\n;\n\n        \n}\n\n    \n}\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\ntfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n    \nif\n \n(\nfp\n-\nf_count\n \n==\n \n1\n)\n \n{\n \n/* last reference */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \n/* need to recheck the condition */\n\n        \nif\n \n(\nfp\n-\nf_count\n \n!=\n \n1\n)\n \n{\n\n            \nfp\n-\nf_count\n--\n;\n\n            \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n            \npthread_mutex_unlock\n(\nhashlock\n);\n\n            \nreturn\n;\n\n        \n}\n\n        \n/* remove from list */\n\n        \nidx\n \n=\n \nHASH\n(\nfp\n-\nf_id\n);\n\n        \ntfp\n \n=\n \nfh\n[\nidx\n];\n\n        \nif\n \n(\ntfp\n \n==\n \nfp\n)\n \n{\n\n            \nfh\n[\nidx\n]\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n \nelse\n \n{\n\n            \nwhile\n \n(\ntfp\n-\nf_next\n \n!=\n \nfp\n)\n\n                \ntfp\n \n=\n \ntfp\n-\nf_next\n;\n\n            \ntfp\n-\nf_next\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \nfp\n-\nf_count\n--\n;\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nComparing \nthreads/mutex2.c\n with \nthreads/mutex1.c\n, we can see;\n\n\n\n\nThe allocation function \nfoo_alloc\n now locks the hash list lock, adds the new structure to a hash bucket, and \nbefore unlocking the hash list lock, locks the mutex in the new structure.\n Since the new structure is placed on a global list, other threads can find it, so we need to block them if they try to access the new structure, until we are done initializing it.\n\n\nThe \nfoo_find\n function locks the hash list lock and searches for the requested structure. If it is found, we increase the reference count and return a pointer to the structure. This follows the lock ordering by locking the hash list lock in \nfoo_find\n before \nfoo_hold\n locks the foo structure\u2019s f_lock mutex.\n\n\nWith two locks, the \nfoo_rele\n function is more complicated. If this is the last reference, we need to unlock the structure mutex so that we can acquire the hash list lock, since we\u2019ll need to remove the structure from the hash list. Then we reacquire the structure mutex. Because we could have blocked since the last time we held the structure mutex, we need to recheck the condition to see whether we still need to free the structure. If another thread found the structure and added a reference to it while we blocked to honor the lock ordering, we simply need to decrement the reference count, unlock everything, and return.\n\n\n\n\nExample of two mutexes (simplified)\n\n\nWe can simplify the previous example considerably by using the hash list lock to protect the structure reference count. The structure mutex can be used to protect everything else in the \nfoo\n structure.\n\n\nthreads/mutex3.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\n#define NHASH 29\n\n\n#define HASH(id) (((unsigned long)id)%NHASH)\n\n\n\nstruct\n \nfoo\n \n*\nfh\n[\nNHASH\n];\n\n\npthread_mutex_t\n \nhashlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nstruct\n \nfoo\n \n{\n\n    \nint\n             \nf_count\n;\n \n/* protected by hashlock */\n\n    \npthread_mutex_t\n \nf_lock\n;\n\n    \nint\n             \nf_id\n;\n\n    \nstruct\n \nfoo\n     \n*\nf_next\n;\n \n/* protected by hashlock */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_alloc\n(\nint\n \nid\n)\n \n/* allocate the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \nif\n \n((\nfp\n \n=\n \nmalloc\n(\nsizeof\n(\nstruct\n \nfoo\n)))\n \n!=\n \nNULL\n)\n \n{\n\n        \nfp\n-\nf_count\n \n=\n \n1\n;\n\n        \nfp\n-\nf_id\n \n=\n \nid\n;\n\n        \nif\n \n(\npthread_mutex_init\n(\nfp\n-\nf_lock\n,\n \nNULL\n)\n \n!=\n \n0\n)\n \n{\n\n            \nfree\n(\nfp\n);\n\n            \nreturn\n(\nNULL\n);\n\n        \n}\n\n        \nidx\n \n=\n \nHASH\n(\nid\n);\n\n        \npthread_mutex_lock\n(\nhashlock\n);\n\n        \nfp\n-\nf_next\n \n=\n \nfh\n[\nidx\n];\n\n        \nfh\n[\nidx\n]\n \n=\n \nfp\n;\n\n        \npthread_mutex_lock\n(\nfp\n-\nf_lock\n);\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \n/* ... continue initialization ... */\n\n        \npthread_mutex_unlock\n(\nfp\n-\nf_lock\n);\n\n    \n}\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_hold\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* add a reference to the object */\n\n\n{\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfp\n-\nf_count\n++\n;\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n\n}\n\n\n\nstruct\n \nfoo\n \n*\n\n\nfoo_find\n(\nint\n \nid\n)\n \n/* find an existing object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\nfp\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nfor\n \n(\nfp\n \n=\n \nfh\n[\nHASH\n(\nid\n)];\n \nfp\n \n!=\n \nNULL\n;\n \nfp\n \n=\n \nfp\n-\nf_next\n)\n \n{\n\n        \nif\n \n(\nfp\n-\nf_id\n \n==\n \nid\n)\n \n{\n\n            \nfp\n-\nf_count\n++\n;\n\n            \nbreak\n;\n\n        \n}\n\n    \n}\n\n    \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \nreturn\n(\nfp\n);\n\n\n}\n\n\n\nvoid\n\n\nfoo_rele\n(\nstruct\n \nfoo\n \n*\nfp\n)\n \n/* release a reference to the object */\n\n\n{\n\n    \nstruct\n \nfoo\n  \n*\ntfp\n;\n\n    \nint\n         \nidx\n;\n\n\n    \npthread_mutex_lock\n(\nhashlock\n);\n\n    \nif\n \n(\n--\nfp\n-\nf_count\n \n==\n \n0\n)\n \n{\n \n/* last reference, remove from list */\n\n        \nidx\n \n=\n \nHASH\n(\nfp\n-\nf_id\n);\n\n        \ntfp\n \n=\n \nfh\n[\nidx\n];\n\n        \nif\n \n(\ntfp\n \n==\n \nfp\n)\n \n{\n\n            \nfh\n[\nidx\n]\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n \nelse\n \n{\n\n            \nwhile\n \n(\ntfp\n-\nf_next\n \n!=\n \nfp\n)\n\n                \ntfp\n \n=\n \ntfp\n-\nf_next\n;\n\n            \ntfp\n-\nf_next\n \n=\n \nfp\n-\nf_next\n;\n\n        \n}\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n        \npthread_mutex_destroy\n(\nfp\n-\nf_lock\n);\n\n        \nfree\n(\nfp\n);\n\n    \n}\n \nelse\n \n{\n\n        \npthread_mutex_unlock\n(\nhashlock\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nIn this example, we solved the lock-ordering issues surrounding the hash list and the reference count when we use the same lock for both purposes. Multithreaded software design involves these types of trade-offs:\n\n\n\n\nIf the locking granularity is too coarse, you end up with too many threads blocking behind the same locks, with little improvement possible from concurrency.\n\n\nIf the locking granularity is too fine, then you suffer bad performance from excess locking overhead, and you end up with complex code.\n\n\n\n\nAs a programmer, you need to find the correct balance between code complexity and performance, while still satisfying your locking requirements.\n\n\npthread_mutex_timedlock\n Function\n\n\nThe \npthread_mutex_timedlock\n function allows us to bound the time that a thread blocks when a mutex it is trying to acquire is already locked is equivalent to \npthread_mutex_lock\n, but if the timeout value is reached, \npthread_mutex_timedlock\n will return the error code \nETIMEDOUT\n without locking the mutex:\n\n\n#include \npthread.h\n\n\n#include \ntime.h\n\n\n\nint\n \npthread_mutex_timedlock\n(\npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                            \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n\n/* Returns: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe timeout is represented by the \ntimespec\n structure (seconds and nanoseconds) and is \nabsolute time\n.\n\n\nThe following example uses \npthread_mutex_timedlock\n to avoid blocking indefinitely:\n\n\nthreads/timedlock.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n\nint\n\n\nmain\n(\nvoid\n)\n\n\n{\n\n    \nint\n \nerr\n;\n\n    \nstruct\n \ntimespec\n \ntout\n;\n\n    \nstruct\n \ntm\n \n*\ntmp\n;\n\n    \nchar\n \nbuf\n[\n64\n];\n\n    \npthread_mutex_t\n \nlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n    \npthread_mutex_lock\n(\nlock\n);\n\n    \nprintf\n(\nmutex is locked\n\\n\n);\n\n    \nclock_gettime\n(\nCLOCK_REALTIME\n,\n \ntout\n);\n\n    \ntmp\n \n=\n \nlocaltime\n(\ntout\n.\ntv_sec\n);\n\n    \nstrftime\n(\nbuf\n,\n \nsizeof\n(\nbuf\n),\n \n%r\n,\n \ntmp\n);\n\n    \nprintf\n(\ncurrent time is %s\n\\n\n,\n \nbuf\n);\n\n    \ntout\n.\ntv_sec\n \n+=\n \n10\n;\n  \n/* 10 seconds from now */\n\n    \n/* caution: this could lead to deadlock */\n\n    \nerr\n \n=\n \npthread_mutex_timedlock\n(\nlock\n,\n \ntout\n);\n\n    \nclock_gettime\n(\nCLOCK_REALTIME\n,\n \ntout\n);\n\n    \ntmp\n \n=\n \nlocaltime\n(\ntout\n.\ntv_sec\n);\n\n    \nstrftime\n(\nbuf\n,\n \nsizeof\n(\nbuf\n),\n \n%r\n,\n \ntmp\n);\n\n    \nprintf\n(\nthe time is now %s\n\\n\n,\n \nbuf\n);\n\n    \nif\n \n(\nerr\n \n==\n \n0\n)\n\n        \nprintf\n(\nmutex locked again!\n\\n\n);\n\n    \nelse\n\n        \nprintf\n(\ncan\nt lock mutex again: %s\n\\n\n,\n \nstrerror\n(\nerr\n));\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe following is the output:\n\n\n$ ./a.out\n\n\nmutex is locked\n\n\ncurrent time is 11:41:58 AM\n\n\nthe time is now 11:42:08 AM\n\n\ncan\u2019t lock mutex again: Connection timed out\n\n\n\n\n\n\nThis strategy is not recommended in practice, because it can lead to deadlock.\n\n\nMac OS X 10.6.8 doesn\u2019t support \npthread_mutex_timedlock\n yet, but FreeBSD 8.0, Linux 3.2.0, and Solaris 10 do support it.\n\n\nReader\u2013Writer Locks\n\n\nThe state of a mutex is either locked or unlocked, and only one thread can lock it at a time. A reader\u2013writer lock (also called shared\u2013exclusive lock) has three possible states:\n\n\n\n\nLocked in read mode (also called locked in shared mode)\n\n\nLocked in write mode (also called locked in exclusive mode)\n\n\nUnlocked\nOnly one thread at a time can hold a reader\u2013writer lock in write mode, but multiple threads can hold a reader\u2013writer lock in read mode at the same time.\n\n\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_init\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                        \nconst\n \npthread_rwlockattr_t\n \n*\nrestrict\n \nattr\n);\n\n\n\nint\n \npthread_rwlock_destroy\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nA reader\u2013writer lock is initialized by \npthread_rwlock_init\n. A \nNULL\n value of \nattr\n indicates default attributes.\n\n\nBefore freeing the memory backing a reader\u2013writer lock, we need to call \npthread_rwlock_destroy\n to clean it up. If \npthread_rwlock_init\n allocated any resources for the reader\u2013writer lock, \npthread_rwlock_destroy\n frees those resources. If we free the memory backing a reader\u2013writer lock without first calling \npthread_rwlock_destroy\n, any resources assigned to the lock will be lost (see \nDoubts and Solutions\n).\n\n\nA reader\u2013writer lock can be read locked, write locked and unlocked with the following functions:\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_rdlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_wrlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_unlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nImplementations might limit the number of times a reader\u2013writer lock can be locked in shared mode, so we need to check the return value of \npthread_rwlock_rdlock\n.\n\n\npthread_rwlock_wrlock\n and \npthread_rwlock_unlock\n have error returns and technically we should always check for errors when we call functions that can potentially fail. However, if we design our locking properly, we don\u2019t need to check for errors. [p410]\n\n\n\n\nThe SUS also defines conditional versions of the reader\u2013writer locking primitives.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_rwlock_tryrdlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\nint\n \npthread_rwlock_trywrlock\n(\npthread_rwlock_t\n \n*\nrwlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nWhen the lock can be acquired, these functions return 0. Otherwise, they return the error \nEBUSY\n. These functions can be used to avoid deadlocks in situations where conforming to a lock hierarchy is difficult.\n\n\nThe program below illustrates the use of reader\u2013writer locks. A queue of job requests is protected by a single reader\u2013writer lock. This example shows a possible implementation of \nFigure 11.1\n, whereby multiple worker threads obtain jobs assigned to them by a single master thread.\n\n\nthreads/rwlock.c\n\n\n#include \nstdlib.h\n\n\n#include \npthread.h\n\n\n\nstruct\n \njob\n \n{\n\n    \nstruct\n \njob\n \n*\nj_next\n;\n\n    \nstruct\n \njob\n \n*\nj_prev\n;\n\n    \npthread_t\n   \nj_id\n;\n   \n/* tells which thread handles this job */\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nqueue\n \n{\n\n    \nstruct\n \njob\n      \n*\nq_head\n;\n\n    \nstruct\n \njob\n      \n*\nq_tail\n;\n\n    \npthread_rwlock_t\n \nq_lock\n;\n\n\n};\n\n\n\n/*\n\n\n * Initialize a queue.\n\n\n */\n\n\nint\n\n\nqueue_init\n(\nstruct\n \nqueue\n \n*\nqp\n)\n\n\n{\n\n    \nint\n \nerr\n;\n\n\n    \nqp\n-\nq_head\n \n=\n \nNULL\n;\n\n    \nqp\n-\nq_tail\n \n=\n \nNULL\n;\n\n    \nerr\n \n=\n \npthread_rwlock_init\n(\nqp\n-\nq_lock\n,\n \nNULL\n);\n\n    \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n        \nreturn\n(\nerr\n);\n\n    \n/* ... continue initialization ... */\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\n/*\n\n\n * Insert a job at the head of the queue.\n\n\n */\n\n\nvoid\n\n\njob_insert\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \njp\n-\nj_next\n \n=\n \nqp\n-\nq_head\n;\n\n    \njp\n-\nj_prev\n \n=\n \nNULL\n;\n\n    \nif\n \n(\nqp\n-\nq_head\n \n!=\n \nNULL\n)\n\n        \nqp\n-\nq_head\n-\nj_prev\n \n=\n \njp\n;\n\n    \nelse\n\n        \nqp\n-\nq_tail\n \n=\n \njp\n;\n    \n/* list was empty */\n\n    \nqp\n-\nq_head\n \n=\n \njp\n;\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Append a job on the tail of the queue.\n\n\n */\n\n\nvoid\n\n\njob_append\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \njp\n-\nj_next\n \n=\n \nNULL\n;\n\n    \njp\n-\nj_prev\n \n=\n \nqp\n-\nq_tail\n;\n\n    \nif\n \n(\nqp\n-\nq_tail\n \n!=\n \nNULL\n)\n\n        \nqp\n-\nq_tail\n-\nj_next\n \n=\n \njp\n;\n\n    \nelse\n\n        \nqp\n-\nq_head\n \n=\n \njp\n;\n    \n/* list was empty */\n\n    \nqp\n-\nq_tail\n \n=\n \njp\n;\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Remove the given job from a queue.\n\n\n */\n\n\nvoid\n\n\njob_remove\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \nstruct\n \njob\n \n*\njp\n)\n\n\n{\n\n    \npthread_rwlock_wrlock\n(\nqp\n-\nq_lock\n);\n\n    \nif\n \n(\njp\n \n==\n \nqp\n-\nq_head\n)\n \n{\n\n        \nqp\n-\nq_head\n \n=\n \njp\n-\nj_next\n;\n\n        \nif\n \n(\nqp\n-\nq_tail\n \n==\n \njp\n)\n\n            \nqp\n-\nq_tail\n \n=\n \nNULL\n;\n\n        \nelse\n\n            \njp\n-\nj_next\n-\nj_prev\n \n=\n \njp\n-\nj_prev\n;\n\n    \n}\n \nelse\n \nif\n \n(\njp\n \n==\n \nqp\n-\nq_tail\n)\n \n{\n\n        \nqp\n-\nq_tail\n \n=\n \njp\n-\nj_prev\n;\n\n        \njp\n-\nj_prev\n-\nj_next\n \n=\n \njp\n-\nj_next\n;\n\n    \n}\n \nelse\n \n{\n\n        \njp\n-\nj_prev\n-\nj_next\n \n=\n \njp\n-\nj_next\n;\n\n        \njp\n-\nj_next\n-\nj_prev\n \n=\n \njp\n-\nj_prev\n;\n\n    \n}\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n\n}\n\n\n\n/*\n\n\n * Find a job for the given thread ID.\n\n\n */\n\n\nstruct\n \njob\n \n*\n\n\njob_find\n(\nstruct\n \nqueue\n \n*\nqp\n,\n \npthread_t\n \nid\n)\n\n\n{\n\n    \nstruct\n \njob\n \n*\njp\n;\n\n\n    \nif\n \n(\npthread_rwlock_rdlock\n(\nqp\n-\nq_lock\n)\n \n!=\n \n0\n)\n\n        \nreturn\n(\nNULL\n);\n\n\n    \nfor\n \n(\njp\n \n=\n \nqp\n-\nq_head\n;\n \njp\n \n!=\n \nNULL\n;\n \njp\n \n=\n \njp\n-\nj_next\n)\n\n        \nif\n \n(\npthread_equal\n(\njp\n-\nj_id\n,\n \nid\n))\n\n            \nbreak\n;\n\n\n    \npthread_rwlock_unlock\n(\nqp\n-\nq_lock\n);\n\n    \nreturn\n(\njp\n);\n\n\n}\n\n\n\n\n\n\nIn this example, we lock the queue\u2019s reader\u2013writer lock in write mode whenever we need to add a job to the queue or remove a job from the queue. Whenever we search the queue, we grab the lock in read mode, allowing all the worker threads to search the queue concurrently. Using a reader\u2013writer lock will improve performance in this case only if threads search the queue much more frequently than they add or remove jobs. The worker threads take only those jobs that match their thread ID off the queue. Since the job structures are used only by one thread at a time, they don\u2019t need any extra locking.\n\n\nReader\u2013Writer Locking with Timeouts\n\n\nAs with mutexes, the SUS provides functions to lock reader\u2013writer locks with a timeout to give applications a way to avoid blocking\nindefinitely while trying to acquire a reader\u2013writer lock.\n\n\n#include \npthread.h\n\n\n#include \ntime.h\n\n\n\nint\n \npthread_rwlock_timedrdlock\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                               \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\nint\n \npthread_rwlock_timedwrlock\n(\npthread_rwlock_t\n \n*\nrestrict\n \nrwlock\n,\n\n                               \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe \ntsptr\n argument points to a \ntimespec\n structure specifying the time at which the thread should stop blocking. If they can\u2019t acquire the lock, these functions return the \nETIMEDOUT\n error when the timeout expires. Like the \npthread_mutex_timedlock\n function, the timeout specifies an absolute time, not a relative one.\n\n\nCondition Variables\n\n\nCondition variables are another synchronization mechanism available to threads. These synchronization objects provide a place for threads to rendezvous. When used with mutexes, condition variables allow threads to wait in a race-free way for arbitrary conditions to occur.\n\n\nThe condition itself is protected by a mutex. A thread must first lock the mutex to change the condition state. Other threads will not notice the change until they acquire the mutex, because the mutex must be locked to be able to evaluate the condition.\n\n\nA condition variable, represented by the pthread_cond_t data type, must be initialized and can be initialized in two ways:\n\n\n\n\nAssign the constant \nPTHREAD_COND_INITIALIZER\n to a statically allocated condition\n\n\nUse the \npthread_cond_init\n function to initialize a dynamically allocated condition\n\n\n\n\npthread_cond_destroy\n deinitializes a condition variable before freeing its underlying memory.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_init\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                      \nconst\n \npthread_condattr_t\n \n*\nrestrict\n \nattr\n);\n\n\nint\n \npthread_cond_destroy\n(\npthread_cond_t\n \n*\ncond\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nUnless using nondefault attributes, the \nattr\n argument to \npthread_cond_init\n can be set to \nNULL\n.\n\n\nWe use \npthread_cond_wait\n to wait for a condition to be true. A variant \npthread_cond_timedwait\n is provided to return an error code if the condition hasn\u2019t been satisfied in the specified amount of time.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_wait\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                      \npthread_mutex_t\n \n*\nrestrict\n \nmutex\n);\n\n\n\nint\n \npthread_cond_timedwait\n(\npthread_cond_t\n \n*\nrestrict\n \ncond\n,\n\n                           \npthread_mutex_t\n \n*\nrestrict\n \nmutex\n,\n\n                           \nconst\n \nstruct\n \ntimespec\n \n*\nrestrict\n \ntsptr\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nThe mutex passed to \npthread_cond_wait\n protects the condition. \nThe caller passes the locked mutex to the function, which then atomically places the calling thread on the list of threads waiting for the condition and unlocks the mutex. This closes the window between the time that the condition is checked and the time that the thread goes to sleep waiting for the condition to change, so that the thread doesn\u2019t miss a change in the condition. When \npthread_cond_wait\n returns, the mutex is again locked.\n\n\nThe \npthread_cond_timedwait\n function provides the same functionality as the \npthread_cond_wait\n function with the addition of the timeout (\ntsptr\n). The timeout value specifies how long we are willing to wait expressed as a \ntimespec\n structure, as an absolute time instead of a relative time, as in the \nexample\n of \npthread_mutex_timedlock\n.\n\n\nAlternatively to the \nclock_gettime\n function, we can use the \ngettimeofday\n function to get the current time expressed as a timeval structure and translate it into a \ntimespec\n structure. The following function can be used to obtain the absolute time for the timeout value\n\n\nthreads/maketimeout.c\n\n\n#include \nsys/time.h\n\n\n#include \nstdlib.h\n\n\n\nvoid\n\n\nmaketimeout\n(\nstruct\n \ntimespec\n \n*\ntsp\n,\n \nlong\n \nminutes\n)\n\n\n{\n\n    \nstruct\n \ntimeval\n \nnow\n;\n\n\n    \n/* get the current time */\n\n    \ngettimeofday\n(\nnow\n,\n \nNULL\n);\n\n    \ntsp\n-\ntv_sec\n \n=\n \nnow\n.\ntv_sec\n;\n\n    \ntsp\n-\ntv_nsec\n \n=\n \nnow\n.\ntv_usec\n \n*\n \n1000\n;\n \n/* usec to nsec */\n\n    \n/* add the offset to get timeout value */\n\n    \ntsp\n-\ntv_sec\n \n+=\n \nminutes\n \n*\n \n60\n;\n\n\n}\n\n\n\n\n\n\nIf the timeout expires without the condition occurring, \npthread_cond_timedwait\n will reacquire the mutex and return the error \nETIMEDOUT\n. When it returns from a successful call to \npthread_cond_wait\n or \npthread_cond_timedwait\n, a thread needs to reevaluate the condition, since another thread might have run and already changed the condition.\n\n\nThere are two functions to notify threads that a condition has been satisfied. The \npthread_cond_signal\n function will wake up at least one thread waiting on a condition (The POSIX specification allows for implementations of \npthread_cond_signal\n to wake up more than one thread, to make the implementation simpler.), whereas the \npthread_cond_broadcast\n function will wake up all threads waiting on a condition.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_cond_signal\n(\npthread_cond_t\n \n*\ncond\n);\n\n\nint\n \npthread_cond_broadcast\n(\npthread_cond_t\n \n*\ncond\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\nWhen we call \npthread_cond_signal\n or \npthread_cond_broadcast\n, we are said to be signaling the thread or condition. We have to be careful to signal the threads only after changing the state of the condition.\n\n\nThe following example shows how to use a condition variable and a mutex together to synchronize threads.\n\n\nthreads/condvar.c\n\n\n#include \npthread.h\n\n\n\nstruct\n \nmsg\n \n{\n\n    \nstruct\n \nmsg\n \n*\nm_next\n;\n\n    \n/* ... more stuff here ... */\n\n\n};\n\n\n\nstruct\n \nmsg\n \n*\nworkq\n;\n\n\n\npthread_cond_t\n \nqready\n \n=\n \nPTHREAD_COND_INITIALIZER\n;\n\n\n\npthread_mutex_t\n \nqlock\n \n=\n \nPTHREAD_MUTEX_INITIALIZER\n;\n\n\n\nvoid\n\n\nprocess_msg\n(\nvoid\n)\n\n\n{\n\n    \nstruct\n \nmsg\n \n*\nmp\n;\n\n\n    \nfor\n \n(;;)\n \n{\n\n        \npthread_mutex_lock\n(\nqlock\n);\n\n        \nwhile\n \n(\nworkq\n \n==\n \nNULL\n)\n\n            \npthread_cond_wait\n(\nqready\n,\n \nqlock\n);\n\n        \nmp\n \n=\n \nworkq\n;\n\n        \nworkq\n \n=\n \nmp\n-\nm_next\n;\n\n        \npthread_mutex_unlock\n(\nqlock\n);\n\n        \n/* now process the message mp */\n\n    \n}\n\n\n}\n\n\n\nvoid\n\n\nenqueue_msg\n(\nstruct\n \nmsg\n \n*\nmp\n)\n\n\n{\n\n    \npthread_mutex_lock\n(\nqlock\n);\n\n    \nmp\n-\nm_next\n \n=\n \nworkq\n;\n\n    \nworkq\n \n=\n \nmp\n;\n\n    \npthread_mutex_unlock\n(\nqlock\n);\n\n    \npthread_cond_signal\n(\nqready\n);\n\n\n}\n\n\n\n\n\n\n\n\nThe condition is the state of the work queue.\n\n\nWe protect the condition with a mutex and evaluate the condition in a \nwhile\n loop.\n\n\nWhen we put a message on the work queue, we need to hold the mutex, but we don\u2019t need to hold the mutex when we signal the waiting threads.\n\n\nAs long as it is okay for a thread to pull the message off the queue before we call \npthread_cond_signal\n, we can do this after releasing the mutex. Since we check the condition in a \nwhile\n loop, this doesn\u2019t present a problem; a thread will wake up, find that the queue is still empty, and go back to waiting again. If the code couldn\u2019t tolerate this race, we would need to hold the mutex when we signal the threads.\n\n\n\n\nSpin Locks\n\n\nA \nspin lock\n is like a mutex, except that instead of blocking a process by sleeping, the process is blocked by busy-waiting (spinning) until the lock can be acquired. \nA spin lock could be used in situations where locks are held for short periods of times and threads don\u2019t want to incur the cost of being descheduled.\n\n\nSpin locks are often used as low-level primitives to implement other types of locks. They can be implemented efficiently using \ntest-and-set\n instructions. Although efficient, they can lead to wasting CPU resources: while a thread is spinning and waiting for a lock to become available, the CPU can\u2019t do anything else. \nThis is why spin locks should be held only for short periods of time.\n\n\n\n\nKernel-space\n. Spin locks are useful when used in a nonpreemptive kernel. Besides providing a mutual exclusion mechanism, they block interrupts so an interrupt handler can\u2019t deadlock the system by trying to acquire a spin lock that is already locked (think of interrupts as another type of preemption). In these types of kernels, interrupt handlers can\u2019t sleep, so the only synchronization primitives they can use are spin locks.\n\n\nUser-space\n. Spin locks are not as useful unless you are running in a realtime scheduling class that doesn\u2019t allow preemption. User-level threads running in a time-sharing scheduling class can be descheduled when their time quantum expires or when a thread with a higher scheduling priority becomes runnable. In these cases, if a thread is holding a spin lock, it will be put to sleep and other threads blocked on the lock will continue spinning longer than intended.\n\n\n\n\nMany mutex implementations are efficient: using mutex locks is equivalent to using spin locks in terms of an application's performance. Some mutex implementations will spin for a limited amount of time trying to acquire the mutex, and only sleep when the spin count threshold is reached. These factors, combined with faster context switch in modern processors, make spin locks useful only in limited circumstances. [p417]\n\n\nSimilar to mutex (we can replace one with the other), we can initialize a spin lock with the \npthread_spin_init\n function. To deinitialize a spin lock, we can call the \npthread_spin_destroy\n function.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_spin_init\n(\npthread_spinlock_t\n \n*\nlock\n,\n \nint\n \npshared\n);\n\n\nint\n \npthread_spin_destroy\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nOnly one attribute is specified for spin locks, which matters only if the platform supports the Thread Process-Shared Synchronization option.\n\n\nThe \npshared\n argument represents the process-shared attribute, which indicates how the spin lock will be acquired.\n\n\nIf it is set to \nPTHREAD_PROCESS_SHARED\n, then the spin lock can be acquired by threads that have access to the lock\u2019s underlying memory, even if those threads are from different processes.\n\n\nOtherwise, the \npshared\n argument is set to \nPTHREAD_PROCESS_PRIVATE\n and the spin lock can be accessed only from threads within the process that initialized it.\n\n\n\n\n\n\n\n\nTo lock the spin lock, we can call either of the following:\n\n \npthread_spin_lock\n, which will spin until the lock is acquired\n\n pthread_spin_trylock, which will return the \nEBUSY\n error if the lock can\u2019t be acquired immediately. \nNote that \npthread_spin_trylock\n doesn\u2019t spin.\n\n\nRegardless of how it was locked, a spin lock can be unlocked by calling \npthread_spin_unlock\n.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_spin_lock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\nint\n \npthread_spin_trylock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\nint\n \npthread_spin_unlock\n(\npthread_spinlock_t\n \n*\nlock\n);\n\n\n\n/* All return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\nIf a spin lock is currently unlocked, then the \npthread_spin_lock\n function can lock it without spinning.\n\n\nIf the thread already has it locked, the results are undefined. The call to \npthread_spin_lock\n could fail with the \nEDEADLK\n error (or some other error), or the call could spin indefinitely. The behavior depends on the implementation.\n\n\nIf we try to unlock a spin lock that is not locked, the results are also undefined.\n\n\n\n\nIf either \npthread_spin_lock\n or \npthread_spin_trylock\n returns 0, then the spin lock is locked. We need to be careful not to call any functions that might sleep while holding the spin lock. Otherwise, other threads trying to acquire it will spin, wasting CPU resources.\n\n\nBarriers\n\n\nBarriers are a synchronization mechanism to coordinate multiple threads working in parallel. A barrier allows each thread to wait until all cooperating\nthreads have reached the same point, and then continue executing from there. The \npthread_join\n function acts as a barrier to allow one thread to wait until another thread exits.\n\n\nBarrier objects are more general. They allow an arbitrary number of threads to wait until all of the threads have completed processing, but \nthe threads don\u2019t have to exit. They can continue working after all threads have reached the barrier.\n\n\nThe \npthread_barrier_init\n function initializes a barrier, and \npthread_barrier_destroy\n function deinitializes a barrier.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_barrier_init\n(\npthread_barrier_t\n \n*\nrestrict\n \nbarrier\n,\n\n                         \nconst\n \npthread_barrierattr_t\n \n*\nrestrict\n \nattr\n,\n\n                         \nunsigned\n \nint\n \ncount\n);\n\n\nint\n \npthread_barrier_destroy\n(\npthread_barrier_t\n \n*\nbarrier\n);\n\n\n\n/* Both return: 0 if OK, error number on failure */\n\n\n\n\n\n\n\n\n\n\nThe \ncount\n argument for \npthread_barrier_init\n specifies the number of threads that must reach the barrier before all of the threads will be allowed to continue.\n\n\n\n\n\n\nThe \nattr\n argument specifies the attributes of the barrier object (\nNULL\n for default attributes).\n\n\n\n\n\n\nIf the \npthread_barrier_init\n function allocated any resources for the barrier, the resources will be freed when we deinitialize the barrier by calling the \npthread_barrier_destroy\n function.\n\n\nThe \npthread_barrier_wait\n function indicates that a thread is done with its work and is ready to wait for all the other threads to catch up.\n\n\n#include \npthread.h\n\n\n\nint\n \npthread_barrier_wait\n(\npthread_barrier_t\n \n*\nbarrier\n);\n\n\n\n/* Returns: 0 or PTHREAD_BARRIER_SERIAL_THREAD if OK, error number on failure */\n\n\n\n\n\n\nThe thread calling \npthread_barrier_wait\n is put to sleep if the barrier count (set in the call to \npthread_barrier_init\n) is not yet satisfied. If the thread is the last one to call \npthread_barrier_wait\n, thereby satisfying the barrier count, all of the threads are awakened.\n\n\nTo one arbitrary thread, it will appear as if the \npthread_barrier_wait\n function returned a value of \nPTHREAD_BARRIER_SERIAL_THREAD\n. The remaining threads see a return value of 0. This allows one thread to continue as the master to act on the results of the work done by all of the other threads.\n\n\n\n\nOnce the barrier count is reached and the threads are unblocked, the barrier can be used again.\n\n\nThe barrier count can\u2019t be changed unless we call the \npthread_barrier_destroy\n function followed by the \npthread_barrier_init\n function with a different count.\n\n\n\n\nThe following example shows how a barrier can be used to synchronize threads cooperating on a single task.\n\n\nthreads/barrier.c\n\n\n#include \napue.h\n\n\n#include \npthread.h\n\n\n#include \nlimits.h\n\n\n#include \nsys/time.h\n\n\n\n#define NTHR   8                \n/* number of threads */\n\n\n#define NUMNUM 8000000L         \n/* number of numbers to sort */\n\n\n#define TNUM   (NUMNUM/NTHR)    \n/* number to sort per thread */\n\n\n\nlong\n \nnums\n[\nNUMNUM\n];\n\n\nlong\n \nsnums\n[\nNUMNUM\n];\n\n\n\npthread_barrier_t\n \nb\n;\n\n\n\n#ifdef SOLARIS\n\n\n#define heapsort qsort\n\n\n#else\n\n\nextern\n \nint\n \nheapsort\n(\nvoid\n \n*\n,\n \nsize_t\n,\n \nsize_t\n,\n\n                    \nint\n \n(\n*\n)(\nconst\n \nvoid\n \n*\n,\n \nconst\n \nvoid\n \n*\n));\n\n\n#endif\n\n\n\n/*\n\n\n * Compare two long integers (helper function for heapsort)\n\n\n */\n\n\nint\n\n\ncomplong\n(\nconst\n \nvoid\n \n*\narg1\n,\n \nconst\n \nvoid\n \n*\narg2\n)\n\n\n{\n\n    \nlong\n \nl1\n \n=\n \n*\n(\nlong\n \n*\n)\narg1\n;\n\n    \nlong\n \nl2\n \n=\n \n*\n(\nlong\n \n*\n)\narg2\n;\n\n\n    \nif\n \n(\nl1\n \n==\n \nl2\n)\n\n        \nreturn\n \n0\n;\n\n    \nelse\n \nif\n \n(\nl1\n \n \nl2\n)\n\n        \nreturn\n \n-\n1\n;\n\n    \nelse\n\n        \nreturn\n \n1\n;\n\n\n}\n\n\n\n/*\n\n\n * Worker thread to sort a portion of the set of numbers.\n\n\n */\n\n\nvoid\n \n*\n\n\nthr_fn\n(\nvoid\n \n*\narg\n)\n\n\n{\n\n    \nlong\n    \nidx\n \n=\n \n(\nlong\n)\narg\n;\n\n\n    \nheapsort\n(\nnums\n[\nidx\n],\n \nTNUM\n,\n \nsizeof\n(\nlong\n),\n \ncomplong\n);\n\n    \npthread_barrier_wait\n(\nb\n);\n\n\n    \n/*\n\n\n     * Go off and perform more work ...\n\n\n     */\n\n    \nreturn\n((\nvoid\n \n*\n)\n0\n);\n\n\n}\n\n\n\n/*\n\n\n * Merge the results of the individual sorted ranges.\n\n\n */\n\n\nvoid\n\n\nmerge\n()\n\n\n{\n\n    \nlong\n    \nidx\n[\nNTHR\n];\n\n    \nlong\n    \ni\n,\n \nminidx\n,\n \nsidx\n,\n \nnum\n;\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n\n        \nidx\n[\ni\n]\n \n=\n \ni\n \n*\n \nTNUM\n;\n\n    \nfor\n \n(\nsidx\n \n=\n \n0\n;\n \nsidx\n \n \nNUMNUM\n;\n \nsidx\n++\n)\n \n{\n\n        \nnum\n \n=\n \nLONG_MAX\n;\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n \n{\n\n            \nif\n \n((\nidx\n[\ni\n]\n \n \n(\ni\n+\n1\n)\n*\nTNUM\n)\n \n \n(\nnums\n[\nidx\n[\ni\n]]\n \n \nnum\n))\n \n{\n\n                \nnum\n \n=\n \nnums\n[\nidx\n[\ni\n]];\n\n                \nminidx\n \n=\n \ni\n;\n\n            \n}\n\n        \n}\n\n        \nsnums\n[\nsidx\n]\n \n=\n \nnums\n[\nidx\n[\nminidx\n]];\n\n        \nidx\n[\nminidx\n]\n++\n;\n\n    \n}\n\n\n}\n\n\n\nint\n\n\nmain\n()\n\n\n{\n\n    \nunsigned\n \nlong\n   \ni\n;\n\n    \nstruct\n \ntimeval\n  \nstart\n,\n \nend\n;\n\n    \nlong\n \nlong\n       \nstartusec\n,\n \nendusec\n;\n\n    \ndouble\n          \nelapsed\n;\n\n    \nint\n             \nerr\n;\n\n    \npthread_t\n       \ntid\n;\n\n\n    \n/*\n\n\n     * Create the initial set of numbers to sort.\n\n\n     */\n\n    \nsrandom\n(\n1\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNUMNUM\n;\n \ni\n++\n)\n\n        \nnums\n[\ni\n]\n \n=\n \nrandom\n();\n\n\n    \n/*\n\n\n     * Create 8 threads to sort the numbers.\n\n\n     */\n\n    \ngettimeofday\n(\nstart\n,\n \nNULL\n);\n\n    \npthread_barrier_init\n(\nb\n,\n \nNULL\n,\n \nNTHR\n+\n1\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNTHR\n;\n \ni\n++\n)\n \n{\n\n        \nerr\n \n=\n \npthread_create\n(\ntid\n,\n \nNULL\n,\n \nthr_fn\n,\n \n(\nvoid\n \n*\n)(\ni\n \n*\n \nTNUM\n));\n\n        \nif\n \n(\nerr\n \n!=\n \n0\n)\n\n            \nerr_exit\n(\nerr\n,\n \ncan\nt create thread\n);\n\n    \n}\n\n    \npthread_barrier_wait\n(\nb\n);\n\n    \nmerge\n();\n\n    \ngettimeofday\n(\nend\n,\n \nNULL\n);\n\n\n    \n/*\n\n\n     * Print the sorted list.\n\n\n     */\n\n    \nstartusec\n \n=\n \nstart\n.\ntv_sec\n \n*\n \n1000000\n \n+\n \nstart\n.\ntv_usec\n;\n\n    \nendusec\n \n=\n \nend\n.\ntv_sec\n \n*\n \n1000000\n \n+\n \nend\n.\ntv_usec\n;\n\n    \nelapsed\n \n=\n \n(\ndouble\n)(\nendusec\n \n-\n \nstartusec\n)\n \n/\n \n1000000.0\n;\n\n    \nprintf\n(\nsort took %.4f seconds\n\\n\n,\n \nelapsed\n);\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nNUMNUM\n;\n \ni\n++\n)\n\n        \nprintf\n(\n%ld\n\\n\n,\n \nsnums\n[\ni\n]);\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nIn this example:\n\n We use eight threads to divide the job of sorting 8 million numbers.  Each thread sorts 1 million numbers using the heapsort algorithm. Then the main thread calls a function to merge the results.\n\n We don\u2019t need to use the \nPTHREAD_BARRIER_SERIAL_THREAD\n return value from \npthread_barrier_wait\n to decide which thread merges the results, because we use the main thread for this task. That is why \nwe specify the barrier count as one more than the number of worker threads; the main thread counts as one waiter.\n\n\nThis example shows the use of a barrier in a simplified situation where the threads perform only one task. In more realistic situations, the worker threads will continue with other activities after the call to \npthread_barrier_wait\n returns.\n\n\n[p422]\n\n\nSummary\n\n\nThis chapter introduces the concept of threads and discussed the POSIX.1 primitives available to create and destroy them. We also introduced the problem of thread synchronization. We discussed five fundamental synchronization mechanisms: mutexes, reader\u2013writer locks, condition variables, spin locks, and barriers; and we saw how to use them to protect shared resources.\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np409-410 on Reader\u2013Writer Locks\n\n\n\n\nIf we free the memory backing a reader\u2013writer lock without first calling \npthread_rwlock_destroy\n, any resources assigned to the lock will be lost.\n\n\n\n\n\"any resources assigned to the lock will be lost\" probably means a form of \nresource leak\n.\n\n\np409 on \nPTHREAD_BARRIER_SERIAL_THREAD.\n\n\n\n\nTo one arbitrary thread, it will appear as if the \npthread_barrier_wait\n function returned a value of \nPTHREAD_BARRIER_SERIAL_THREAD\n. The remaining threads see a return value of 0.\n\n\n\n\n\"one arbitrary thread\" means \"one unspecified thread\". As in \npthread_barrier_wait\n:\n\n\nUpon successful completion, the \npthread_barrier_wait()\n function shall return \nPTHREAD_BARRIER_SERIAL_THREAD\n for a single (arbitrary) thread synchronized at the barrier and zero for each of the other threads.", 
            "title": "Chapter 11. Threads"
        }, 
        {
            "location": "/apue/ch12/", 
            "text": "Chapter 12. Thread Control\n\n\nIntroduction\n\n\nThis chapter discusses the details of controlling thread behavior by looking at thread attributes and synchronization primitive attributes, followed by how threads can keep data private from other threads in the same process.", 
            "title": "Chapter 12. Thread Control"
        }, 
        {
            "location": "/apue/ch13/", 
            "text": "Chapter 13. Daemon Processes\n\n\nIntroduction\n\n\nDaemons are processes that are often started when the system is bootstrapped and terminate only when the system is shut down. Because they don\u2019t\nhave a controlling terminal, they run in the background. UNIX systems have numerous daemons that perform day-to-day activities.\n\n\nThis chapter details the process structure of daemons and explores how to write a daemon. Since a daemon does not have a controlling terminal, we need to see how a daemon can report error conditions when something goes wrong.\n\n\nDaemon Characteristics\n\n\nThis section describes some common system daemons with the concepts of process groups, controlling terminals, and sessions as described in \nChapter 9\n.\n\n\nps -axj\n\n\n\n\n\n\n\nThe \n-a\n option shows the status of processes owned by others.\n\n\nThe \n-x\n option shows processes that don\u2019t have a controlling terminal.\n\n\nThe \n-j\n option displays the job-related information:\n\n\nSession ID\n\n\nProcess group ID\n\n\nControlling terminal\n\n\nTerminal process group ID\n\n\n\n\n\n\n\n\nThe output from \nps\n on Linux 3.2.0 looks like:\n\n\nUID PID PPID    PGID    SID TTY CMD\nroot    1   0   1   1   ?   /sbin/init\nroot    2   0   0   0   ?   [kthreadd]\nroot    3   2   0   0   ?   [ksoftirqd/0]\nroot    6   2   0   0   ?   [migration/0]\nroot    7   2   0   0   ?   [watchdog/0]\nroot    21  2   0   0   ?   [cpuset]\nroot    22  2   0   0   ?   [khelper]\nroot    26  2   0   0   ?   [sync_supers]\nroot    27  2   0   0   ?   [bdi-default]\nroot    29  2   0   0   ?   [kblockd]\nroot    35  2   0   0   ?   [kswapd0]\nroot    49  2   0   0   ?   [scsi_eh_0]\nroot    256 2   0   0   ?   [jbd2/sda5-8]\nroot    257 2   0   0   ?   [ext4-dio-unwrit]\nsyslog  847 1   843 843 ?   rsyslogd -c5\nroot    906 1   906 906 ?   /usr/sbin/cupsd -F\nroot    1037    1   1037    1037    ?   /usr/sbin/inetd\nroot    1067    1   1067    1067    ?   cron\ndaemon  1068    1   1068    1068    ?   atd\nroot    8196    1   8196    8196    ?   /usr/sbin/sshd -D\nroot    13047   2   0   0   ?   [kworker/1:0]\nroot    14596   2   0   0   ?   [flush-8:0]\nroot    26464   1   26464   26464   ?   rpcbind -w\nstatd   28490   1   28490   28490   ?   rpc.statd -L\nroot    28553   2   0   0   ?   [rpciod]\nroot    28554   2   0   0   ?   [nfsiod]\nroot    28561   1   28561   28561   ?   rpc.idmapd\nroot    28761   2   0   0   ?   [lockd]\nroot    28764   2   0   0   ?   [nfsd]\nroot    28775   1   28775   28775   ?   /usr/sbin/rpc.mountd --manage-gids\n\n\n\n\n\nThe column headings, in order, are:\n\n\n\n\nUser ID\n\n\nProcess ID\n\n\nParent process ID\n\n\nProcess group ID\n\n\nSession ID\n\n\nTerminal name\n\n\nCommand string\n\n\n\n\nThe system processes in this output depend on the operating system implementation. Anything with a parent process ID of 0 is usually a kernel process (started as part of the system bootstrap procedure), except \ninit\n, which is a user-level command started by the kernel at boot time. Kernel processes are special and generally exist for the entire lifetime of the system. They run with superuser privileges and have no controlling terminal and no command line.\n\n\nIn the (above) sample \nps\n output, kernel daemons has their names in square brackets.\n\n\n\n\nkthreadd\n is a special kernel process on Linux that creates other kernel process, and thus appears as the parent of other kernel daemons. A kernel component, which need to run in a process context but isn't invoked from the context of a user-level process, will usually have its own kernel daemon. For example:\n\n\nkswapd\n: pageout daemon. It supports the virtual memory subsystem by writing dirty pages to disk slowly over time, so the pages can be reclaimed.\n\n\nflush\n.\n\n\nThis daemon flushes dirty pages to disk when available memory reaches a configured minimum threshold.\n\n\nIt also flushes dirty pages back to disk at regular intervals to decrease data loss in the event of a system failure.\n\n\nSeveral flush daemons can exist with one for each backing device. The sample output \nflush-8:0\n means the backing device is identified by its major device number (8) and its minor device number (0).\n\n\n\n\n\n\nThe \nsync_supers\n daemon periodically flushes file system metadata to disk.\n\n\nThe \njbd\n daemon helps implement the journal in the \next4\n file system\n\n\n\n\n\n\ninit\n (\nlaunchd\n on Mac OS X), usually Process 1, is a system daemon responsible for, among other things, starting system services specific to various run levels.\n\n\nrpcbind\n provides the service of \nmapping RPC\n (Remote Procedure Call) program numbers to network port numbers.\n\n\nThe \nnfsd\n, \nnfsiod\n, \nlockd\n, \nrpciod\n, \nrpc.idmapd\n, \nrpc.statd\n, and \nrpc.mountd\n daemons provide support for the \nNetwork File System\n (NFS). Note that the first four are kernel daemons, while the last three are user-level daemons.\n\n\nrsyslogd\n can log system messages of any program. The messages may be printed on a console device and/or written to a file.\n\n\ncron\n executes commands at regularly scheduled dates and times. Numerous system administration tasks are handled by cron running programs at regularly intervals.\n\n\natd\n, similar to \ncron\n, allows users to execute jobs at specified times, only once.\n\n\ncupsd\n is a print spooler that handles print requests on the system.\n\n\nsshd\n provides secure remote login and execution facilities.\n\n\n\n\nSome notes:\n\n\n\n\nMost of the daemons run with superuser (root) privileges.\n\n\nNone of the daemons has a controlling terminal: the terminal name is set to a question mark. The kernel daemons are started without a controlling terminal. The lack of a controlling terminal in the user-level daemons is probably the result of the daemons having called \nsetsid\n. Most of the user-level daemons are process group leaders and session leaders, and are the only processes in their process group and session. (The one exception is \nrsyslogd\n.)\n\n\nThe parent of the user-level daemons is the \ninit\n process.\n\n\n\n\nCoding Rules\n\n\nThis section states basic rules to coding a daemon prevent unwanted interactions from happening, followed by a function \ndaemonize\n, that implements these rules.\n\n\n\n\nCall \numask\n to set the file mode creation mask\n to a known value, usually 0.\n\n\nIf the daemon process creates files, it may want to set specific permissions.\n\n\nOn the other hand, if the daemon calls library functions that result in files being created, then it might make sense to set the file mode create mask to a more restrictive value (such as 007), since the library functions might not allow the caller to specify the permissions through an explicit argument.\n\n\n\n\n\n\nCall \nfork\n and have the parent \nexit\n. This does several things:\n\n\nIf the daemon was started as a simple shell command, having the parent terminate makes the shell think that the command is done\n\n\nThe child inherits the process group ID of the parent but gets a new process ID, so we\u2019re guaranteed that the child is not a process group leader. This is a prerequisite for the call to \nsetsid\n that is done next. (See \nEnsuring the successful call of setsid\n in Chapter 9)\n\n\n\n\n\n\n\n\nCall \nsetsid\n to create a new session\n. The three steps listed in \nSection 9.5\n occur. The process:\n\n\n\n\nbecomes the leader of a new session,\n\n\nbecomes the leader of a new process group,\n\n\nand is disassociated from its controlling terminal.\n\n\n\n\nUnder System V\u2013based systems, some people recommend calling \nfork\n again at this point, terminating the parent, and continuing the daemon in the child. This guarantees that the daemon is not a session leader, which prevents it from acquiring a controlling terminal under the System V rules (\nSection 9.6\n). Alternatively, to avoid acquiring a controlling terminal, be sure to specify \nO_NOCTTY\n whenever opening a terminal device.\n\n\n\n\n\n\nChange the current working directory to the root directory.\n The current working directory inherited from the parent could be on a mounted file system.  Since daemons normally exist until the system is rebooted, if the daemon stays on a mounted file system, that file system cannot be unmounted.\n\n\nAlternatively, some daemons might change the current working directory to a specific location where they will do all their work. For example, a line printer spooling daemon might change its working directory to its spool directory.\n\n\n\n\n\n\nUnneeded file descriptors should be closed.\n This prevents the daemon from holding open any descriptors that it may have inherited from its parent (which could be a shell or some other process). We can use our \nopen_max\n function or the \ngetrlimit\n function (\nSection 7.11\n) to determine the highest descriptor and close all descriptors up to that value.\n\n\n\n\nSome daemons open file descriptors 0, 1, and 2 to \n/dev/null\n so that any library routines that try to read from standard input or write to standard output or standard error will have no effect. [p466-467]\n\n\n\n\nThe code below shows the \ndaemonize\n function that can be called from a program that wants to initialize itself as a daemon.\n\n\ndaemons/init.c\n\n\n#include \napue.h\n\n\n#include \nsyslog.h\n\n\n#include \nfcntl.h\n\n\n#include \nsys/resource.h\n\n\n\nvoid\n\n\ndaemonize\n(\nconst\n \nchar\n \n*\ncmd\n)\n\n\n{\n\n    \nint\n \ni\n,\n \nfd0\n,\n \nfd1\n,\n \nfd2\n;\n\n    \npid_t\n \npid\n;\n\n    \nstruct\n \nrlimit\n \nrl\n;\n\n    \nstruct\n \nsigaction\n \nsa\n;\n\n\n    \n/*\n\n\n     * Clear file creation mask.\n\n\n     */\n\n    \numask\n(\n0\n);\n\n\n    \n/*\n\n\n     * Get maximum number of file descriptors.\n\n\n     */\n\n    \nif\n \n(\ngetrlimit\n(\nRLIMIT_NOFILE\n,\n \nrl\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt get file limit\n,\n \ncmd\n);\n\n\n    \n/*\n\n\n     * Become a session leader to lose controlling TTY.\n\n\n     */\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt fork\n,\n \ncmd\n);\n\n    \nelse\n \nif\n \n(\npid\n \n!=\n \n0\n)\n \n/* parent */\n\n        \nexit\n(\n0\n);\n\n    \nsetsid\n();\n\n\n    \n/*\n\n\n     * Ensure future opens won\nt allocate controlling TTYs.\n\n\n     */\n\n    \nsa\n.\nsa_handler\n \n=\n \nSIG_IGN\n;\n\n    \nsigemptyset\n(\nsa\n.\nsa_mask\n);\n\n    \nsa\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigaction\n(\nSIGHUP\n,\n \nsa\n,\n \nNULL\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt ignore SIGHUP\n,\n \ncmd\n);\n\n    \nif\n \n((\npid\n \n=\n \nfork\n())\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt fork\n,\n \ncmd\n);\n\n    \nelse\n \nif\n \n(\npid\n \n!=\n \n0\n)\n \n/* parent */\n\n        \nexit\n(\n0\n);\n\n\n    \n/*\n\n\n     * Change the current working directory to the root so\n\n\n     * we won\nt prevent file systems from being unmounted.\n\n\n     */\n\n    \nif\n \n(\nchdir\n(\n/\n)\n \n \n0\n)\n\n        \nerr_quit\n(\n%s: can\nt change directory to /\n,\n \ncmd\n);\n\n\n    \n/*\n\n\n     * Close all open file descriptors.\n\n\n     */\n\n    \nif\n \n(\nrl\n.\nrlim_max\n \n==\n \nRLIM_INFINITY\n)\n\n        \nrl\n.\nrlim_max\n \n=\n \n1024\n;\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nrl\n.\nrlim_max\n;\n \ni\n++\n)\n\n        \nclose\n(\ni\n);\n\n\n    \n/*\n\n\n     * Attach file descriptors 0, 1, and 2 to /dev/null.\n\n\n     */\n\n    \nfd0\n \n=\n \nopen\n(\n/dev/null\n,\n \nO_RDWR\n);\n\n    \nfd1\n \n=\n \ndup\n(\n0\n);\n\n    \nfd2\n \n=\n \ndup\n(\n0\n);\n\n\n    \n/*\n\n\n     * Initialize the log file.\n\n\n     */\n\n    \nopenlog\n(\ncmd\n,\n \nLOG_CONS\n,\n \nLOG_DAEMON\n);\n\n    \nif\n \n(\nfd0\n \n!=\n \n0\n \n||\n \nfd1\n \n!=\n \n1\n \n||\n \nfd2\n \n!=\n \n2\n)\n \n{\n\n        \nsyslog\n(\nLOG_ERR\n,\n \nunexpected file descriptors %d %d %d\n,\n\n          \nfd0\n,\n \nfd1\n,\n \nfd2\n);\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nIf the \ndaemonize\n function is called from a \nmain\n program that then goes to sleep, we can check the status of the daemon with the \nps\n command:\n\n\n$ ./a.out\n\n\n$ ps -efj\n\n\nUID PID PPID PGID SID TTY CMD\n\n\nsar 13800 1 13799 13799 ? ./a.out\n\n\n$ ps -efj | grep 13799\n\n\nsar 13800 1 13799 13799 ? ./a.out\n\n\n\n\n\n\nWe can also use ps to verify that no active process exists with ID 13799. This means that our daemon is in an orphaned process group and is not a session leader and, therefore, has no chance of allocating a controlling terminal. This is a result of performing the second \nfork\n in the \ndaemonize\n function. We can see that our daemon has been initialized correctly.\n\n\nError Logging\n\n\nOne problem a daemon has is how to handle error messages. It cannot (simply) write to:\n\n\n\n\nStandard error: it shouldn't have a controlling terminal.\n\n\nConsole device: on many workstations the console device runs a windowing system.\n\n\nSeparate files: it's a headache to keep up which daemon writes to which log file and to check these files on a regular basis.\n\n\n\n\nA central daemon error-logging facility is required. The BSD \nsyslog\n facility has been widely used since 4.2BSD. Most daemons use this facility. The following figure illustrates its structure:\n\n\n\n\nThere are three ways to generate log messages:\n\n\n\n\nKernel routines can call the \nlog\n function. These messages can be read by any user process that \nopen\ns and \nread\ns the \n/dev/klog\n device.\n\n\nMost user processes (daemons) call the \nsyslog(3)\n function to generate log messages. This causes the message to be sent to the UNIX domain datagram socket \n/dev/log\n.\n\n\nA user process on this host or some other host that is connected to this host by a TCP/IP network, can send log messages to UDP port 514. Note that the \nsyslog\n function never generates these UDP datagrams: they require explicit network programming by the process generating the log message.\n\n\n\n\nThe \nsyslogd\n daemon reads all three forms of log messages. On start-up, this daemon reads a configuration file, usually \n/etc/syslog.conf\n, which determines where different classes of messages are to be sent. For example, urgent messages can be sent to the system administrator (if logged in) and printed on the console, whereas warnings may be logged to a file.\n\n\n#include \nsyslog.h\n\n\n\nvoid\n \nopenlog\n(\nconst\n \nchar\n \n*\nident\n,\n \nint\n \noption\n,\n \nint\n \nfacility\n);\n\n\nvoid\n \nsyslog\n(\nint\n \npriority\n,\n \nconst\n \nchar\n \n*\nformat\n,\n \n...);\n\n\nvoid\n \ncloselog\n(\nvoid\n);\n\n\nint\n \nsetlogmask\n(\nint\n \nmaskpri\n);\n\n\n\n/* Returns: previous log priority mask value */\n\n\n\n\n\n\n\n\nCalling \nopenlog\n is optional. If it\u2019s not called, the first time syslog is called, openlog is called automatically.\n\n\n\n\nCalling \ncloselog\n is also optional. It closes the descriptor being used to communicate with the syslogd daemon.\n\n\n\n\n\n\nThe \nopenlog\n function:\n\n\n\n\nindent\n argument is the name of the program.\n\n\noption\n argument is a bitmask specifying various options. (see the table below)\n\n\nfacility\n argument lets the configuration file specify that messages from different facilities are to be handled differently. If we don\u2019t call \nopenlog\n, or if we call it with a facility of 0, we can still specify the facility as part of the priority argument to syslog.  (see the table below)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\noption\n\n\nXSI\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_CONS\n\n\nx\n\n\nIf the log message can\u2019t be sent to \nsyslogd\n via the UNIX domain datagram, the message is written to the console instead.\n\n\n\n\n\n\nLOG_NDELAY\n\n\nx\n\n\nOpen the UNIX domain datagram socket to the \nsyslogd\n daemon immediately; don\u2019t wait until the first message is logged. Normally, the socket is not opened until the first message is logged.\n\n\n\n\n\n\nLOG_NOWAIT\n\n\nx\n\n\nDo not wait for child processes that might have been created in the process of logging the message. This prevents conflicts with applications that catch \nSIGCHLD\n, since the application might have retrieved the child\u2019s status by the time that syslog calls wait.\n\n\n\n\n\n\nLOG_ODELAY\n\n\nx\n\n\nDelay the opening of the connection to the \nsyslogd\n daemon until the first message is logged.\n\n\n\n\n\n\nLOG_PERROR\n\n\n\n\nWrite the log message to standard error in addition to sending it to \nsyslogd\n.  (Unavailable on Solaris.)\n\n\n\n\n\n\nLOG_PID\n\n\nx\n\n\nLog the process ID with each message. This is intended for daemons that fork a child process to handle different requests (as compared to daemons, such as \nsyslogd\n, that never call \nfork\n).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfacility\n\n\nXSI\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_AUDIT\n\n\n\n\nthe audit facility\n\n\n\n\n\n\nLOG_AUTH\n\n\n\n\nauthorization programs: \nlogin\n, \nsu\n, \ngetty\n, ...\n\n\n\n\n\n\nLOG_AUTHPRIV\n\n\n\n\nsame as \nLOG_AUTH\n, but logged to file with restricted permissions\n\n\n\n\n\n\nLOG_CONSOLE\n\n\n\n\nmessages written to \n/dev/console\n\n\n\n\n\n\nLOG_CRON\n\n\n\n\ncron and at\n\n\n\n\n\n\nLOG_DAEMON\n\n\n\n\nsystem daemons: \ninetd\n, \nrouted\n, ...\n\n\n\n\n\n\nLOG_FTP\n\n\n\n\nthe FTP daemon (\nftpd\n)\n\n\n\n\n\n\nLOG_KERN\n\n\n\n\nmessages generated by the kernel\n\n\n\n\n\n\nLOG_LOCAL0\n ~ \nLOG_LOCAL7\n\n\nx\n\n\nreserved for local use\n\n\n\n\n\n\nLOG_LPR\n\n\n\n\nline printer system: \nlpd\n, \nlpc\n, ...\n\n\n\n\n\n\nLOG_MAIL\n\n\n\n\nthe mail system\n\n\n\n\n\n\nLOG_NEWS\n\n\n\n\nthe Usenet network news system\n\n\n\n\n\n\nLOG_NTP\n\n\n\n\nthe network time protocol system\n\n\n\n\n\n\nLOG_SECURITY\n\n\n\n\nthe security subsystem\n\n\n\n\n\n\nLOG_SYSLOG\n\n\n\n\nthe syslogd daemon itself\n\n\n\n\n\n\nLOG_USER\n\n\n\n\n\n\n\n\n\n\nLOG_UUCP\n\n\n\n\nthe UUCP system\n\n\n\n\n\n\n\n\n\n\nThe \nsyslog\n function:\n\n\nThe \npriority\n argument is a combination of the \nfacility\n and a \nlevel\n (shown in the table below). These \nlevel\ns are ordered by priority, from highest to lowest.\n\n\nThe \nformat\n argument and any remaining arguments are passed to the \nvsprintf\n function for formatting. Any occurrences of the characters \n%m\n are first replaced with the error message string (\nstrerror\n) corresponding to the value of \nerrno\n.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlevel\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nLOG_EMERG\n\n\nemergency (system is unusable) (highest priority)\n\n\n\n\n\n\nLOG_ALERT\n\n\ncondition that must be fixed immediately\n\n\n\n\n\n\nLOG_CRIT\n\n\ncritical condition (e.g., hard device error)\n\n\n\n\n\n\nLOG_ERR\n\n\nerror condition\n\n\n\n\n\n\nLOG_WARNING\n\n\nwarning condition\n\n\n\n\n\n\nLOG_NOTICE\n\n\nnormal, but significant condition\n\n\n\n\n\n\nLOG_INFO\n\n\ninformational message\n\n\n\n\n\n\nLOG_DEBUG\n\n\ndebug message (lowest priority)\n\n\n\n\n\n\n\n\n\n\nThe \nsetlogmask\n function sets the log priority mask (\"logmask\") for the process and returns the previous mask. When the log priority mask is set, messages are not logged unless their priority is set in the log priority mask.\n\n\n\n\nThe \nlogger(1)\n program is also provided by many systems as a way to send log messages to the \nsyslog\n facility. The \nlogger\n command is intended for a shell script running noninteractively that needs to generate log messages.\n\n\nIn addition to \nsyslog\n, many platforms provide a variant that handles variable argument lists.\n\n\n#include \nsyslog.h\n\n\n#include \nstdarg.h\n\n\n\nvoid\n \nvsyslog\n(\nint\n \npriority\n,\n \nconst\n \nchar\n \n*\nformat\n,\n \nva_list\n \narg\n);\n\n\n\n\n\n\nMost \nsyslogd\n implementations will queue messages for a short time. If a duplicate message arrives during this period, the syslog daemon will not write it to the log. Instead, the daemon prints a message similar to \"last message repeated N times\".\n\n\nExample of \nsyslog\n\n\nIn a line printer spooler daemon, you might encounter the sequence:\n\n\nopenlog\n(\nlpd\n,\n \nLOG_PID\n,\n \nLOG_LPR\n);\n\n\nsyslog\n(\nLOG_ERR\n,\n \nopen error for %s: %m\n,\n \nfilename\n);\n\n\n\n\n\n\nThe first call to \nopenlog\n sets the \nident\n string to the program name, specifies that the process ID should always be printed, and sets the default facility to the line printer system. The call to \nsyslog\n specifies an error condition and a message string. If we had not called \nopenlog\n, the second call could have been:\n\n\nsyslog\n(\nLOG_ERR\n \n|\n \nLOG_LPR\n,\n \nopen error for %s: %m\n,\n \nfilename\n);\n\n\n\n\n\n\nHere, we specify the \npriority\n argument as a combination of a \nlevel\n and a \nfacility\n.\n\n\nSingle-Instance Daemons\n\n\nSome daemons are implemented so that only a single copy of the daemon should be running at a time for proper operation. This kind of daemon might need exclusive access to a device. For example of the \ncron\n daemon, if multiple instances were running, each copy might try to start a single scheduled operation, resulting in duplicate operations and probably an error.\n\n\nThe file- and record-locking mechanism (\nSection 14.3\n) is a way to ensure that only one copy of a daemon is running. If each daemon creates a file with a fixed name and places a write lock on the entire file, only one such write lock will be allowed to be created. Successive attempts to create write locks will fail, serving as an indication to successive copies of the daemon that another instance is already running.\n\n\n[p473]\n\n\nExample of using file locking to ensure single copy of daemon\n\n\ndaemons/single.c\n\n\n#include \nunistd.h\n\n\n#include \nstdlib.h\n\n\n#include \nfcntl.h\n\n\n#include \nsyslog.h\n\n\n#include \nstring.h\n\n\n#include \nerrno.h\n\n\n#include \nstdio.h\n\n\n#include \nsys/stat.h\n\n\n\n#define LOCKFILE \n/var/run/daemon.pid\n\n\n#define LOCKMODE (S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH)\n\n\n\nextern\n \nint\n \nlockfile\n(\nint\n);\n\n\n\nint\n\n\nalready_running\n(\nvoid\n)\n\n\n{\n\n    \nint\n     \nfd\n;\n\n    \nchar\n    \nbuf\n[\n16\n];\n\n\n    \nfd\n \n=\n \nopen\n(\nLOCKFILE\n,\n \nO_RDWR\n|\nO_CREAT\n,\n \nLOCKMODE\n);\n\n    \nif\n \n(\nfd\n \n \n0\n)\n \n{\n\n        \nsyslog\n(\nLOG_ERR\n,\n \ncan\nt open %s: %s\n,\n \nLOCKFILE\n,\n \nstrerror\n(\nerrno\n));\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n    \nif\n \n(\nlockfile\n(\nfd\n)\n \n \n0\n)\n \n{\n\n        \nif\n \n(\nerrno\n \n==\n \nEACCES\n \n||\n \nerrno\n \n==\n \nEAGAIN\n)\n \n{\n\n            \nclose\n(\nfd\n);\n\n            \nreturn\n(\n1\n);\n\n        \n}\n\n        \nsyslog\n(\nLOG_ERR\n,\n \ncan\nt lock %s: %s\n,\n \nLOCKFILE\n,\n \nstrerror\n(\nerrno\n));\n\n        \nexit\n(\n1\n);\n\n    \n}\n\n    \nftruncate\n(\nfd\n,\n \n0\n);\n\n    \nsprintf\n(\nbuf\n,\n \n%ld\n,\n \n(\nlong\n)\ngetpid\n());\n\n    \nwrite\n(\nfd\n,\n \nbuf\n,\n \nstrlen\n(\nbuf\n)\n+\n1\n);\n\n    \nreturn\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nEach copy of the daemon will try to create a file and write its process ID in the file.  This will allow administrators to identify the process easily. If the file is already locked, the lockfile function will fail with \nerrno\n set to \nEACCES\n or \nEAGAIN\n, so we return 1, indicating that the daemon is already running. Otherwise, we truncate the file, write our process ID to it, and return 0.\n\n\n[p474]\n\n\nDaemon Conventions\n\n\nClient\u2013Server Model", 
            "title": "Chapter 13. Daemon Processes"
        }, 
        {
            "location": "/apue/ch14/", 
            "text": "Chapter 14. Advanced I/O", 
            "title": "Chapter 14. Advanced I/O"
        }, 
        {
            "location": "/apue/ch15/", 
            "text": "Chapter 15. Interprocess Communication\n\n\nThis chapter discusses other techniques for processes to communicate with one another: interprocess communication (IPC).\n\n\nThe figure below summarizes the various forms of IPC that are supported by the four implementations discussed in this text.\n\n\n\n\n\n\nThe \"SUS\" column allows an implementation to support full-duplex pipes, but requires only half-duplex pipes.\n\n\n\"(full)\" shows implementations that support half-duplex pipes by using full-duplex pipes.\n\n\nThe bullet means that basic functionality is supported.\n\n\n\"UDS\" means that the feature of full-duplex pipes can be provided through UNIX domain sockets\n\n\n\n\n[p533-534]\n\n\nThe first ten forms of IPC in the figure above are usually restricted to IPC between processes on the same host. The final two rows: sockets and STREAMS, are the only two forms that are generally supported for IPC between processes on different hosts.\n\n\nThis chapter dicusses classical IPC: pipes, FIFOs, message queues, semaphores, and shared memory.\n\n\nPipes", 
            "title": "Chapter 15. Interprocess Communication"
        }, 
        {
            "location": "/lkd/ch1/", 
            "text": "Chapter 1. Introduction to the Linux Kernel\n\n\nOverview of Operating Systems and Kernels\n\n\nIn Linux, we can generalize that each processor is doing exactly one of three things at any given moment:\n\n\n\n\nIn user-space, executing user code in a process\n\n\nIn kernel-space, in process context, executing on behalf of a specific process\n\n\nIn kernel-space, in interrupt context, not associated with a process, handling an interrupt\n\n\n\n\nLinux Versus Classic Unix Kernels\n\n\nNotable differences exist between the Linux kernel and classic Unix systems:\n\n\n\n\nLinux supports the dynamic loading of kernel modules.Although the Linux kernel is monolithic, it can dynamically load and unload kernel code on demand.\n\n\nLinux has symmetrical multiprocessor (SMP) support.\n\n\nThe Linux kernel is preemptive.\n\n\nLinux takes an interesting approach to thread support: It does not differentiate between threads and normal processes.To the kernel, all processes are the same (some just happen to share resources).\n\n\nLinux provides an object-oriented device model with device classes, hot-pluggable events, and a user-space device filesystem (sysfs).\n\n\nLinux ignores some common Unix features that the kernel developers consider poorly designed, such as STREAMS, or standards that are impossible to cleanly implement.\n\n\nLinux is free in every sense of the word\n\n\n\n\nLinux Kernel Versions\n\n\nLinux kernels come in two flavors: stable and development. \n\n\n\n\nThe Linux Kernel Development Community\n\n\nThe main forum for this community is the Linux Kernel Mailing List (oft-shortened to \nlkml\n). Subscription information is available at \nhttp://vger.kernel.org\n.", 
            "title": "Chapter 1. Introduction to the Linux Kernel"
        }, 
        {
            "location": "/lkd/ch2/", 
            "text": "Chapter 2. Getting Started with the Kernel\n\n\nObtaining the Kernel Source\n\n\nUsing Git\n\n\n$ \ngit clone git://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux-2.6.git\n\n\n\n\n\nInstalling the Kernel Source\n\n\n$ \ntar xvjf linux-x.y.z.tar.bz2\n\n\n\n\n\nUsing Patches\n\n\nThroughout the Linux kernel community, patches are the \nlingua franca\n of communication. You will distribute your code changes in patches and receive code from others as patches. Incremental patches provide an easy way to move from one kernel tree to the next\n\n\n$ \npatch \u2013p1 \n ../patch-x.y.z\n\n\n\n\n\nThe Kernel Source Tree\n\n\n\n\n\n\n\n\nDirectory\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\narch\n\n\nArchitecture-specific source\n\n\n\n\n\n\nblock\n\n\nBlock I/O layer\n\n\n\n\n\n\ncrypto\n\n\nCrypto API\n\n\n\n\n\n\nDocumentation\n\n\nKernel source documentation\n\n\n\n\n\n\ndrivers\n\n\nDevice drivers\n\n\n\n\n\n\nfirmware\n\n\nDevice firmware needed to use certain drivers\n\n\n\n\n\n\nfs\n\n\nThe VFS and the individual filesystems\n\n\n\n\n\n\ninclude\n\n\nKernel headers\n\n\n\n\n\n\ninit\n\n\nKernel boot and initialization\n\n\n\n\n\n\nipc\n\n\nInterprocess communication code\n\n\n\n\n\n\nkernel\n\n\nCore subsystems, such as the scheduler\n\n\n\n\n\n\nlib\n\n\nHelper routines\n\n\n\n\n\n\nmm\n\n\nMemory management subsystem and the VM\n\n\n\n\n\n\nnet\n\n\nNetworking subsystem\n\n\n\n\n\n\nsamples\n\n\nSample, demonstrative code\n\n\n\n\n\n\nscripts\n\n\nScripts used to build the kernel\n\n\n\n\n\n\nsecurity\n\n\nLinux Security Module\n\n\n\n\n\n\nsound\n\n\nSound subsystem\n\n\n\n\n\n\nusr\n\n\nEarly user-space code (called initramfs)\n\n\n\n\n\n\ntools\n\n\nTools helpful for developing Linux\n\n\n\n\n\n\nvirt\n\n\nVirtualization infrastructure\n\n\n\n\n\n\n\n\nBuilding the Kernel\n\n\nConfiguring the Kernel\n\n\n$ \nmake config  \n# text-based\n\n\n$ \nmake menuconfig  \n# ncurses-based\n\n\n$ \nmake gconfig  \n# gtk+-based\n\n\n\n\n\n\nCreates a configuration based on the defaults for your architecture:\n\n\n$ \nmake defconfig\n\n\n\n\n\nAfter making changes to your configuration file, or when using an existing configuration\nfile on a new kernel tree, you can validate and update the configuration:\n\n\n$ \nmake oldconfig\n\n\n\n\n\nYou should always run this before building a kernel.\n\n\nAfter the kernel configuration is set, you can build it with a single command:\n\n\n$ \nmake\n\n\n\n\n\nSpawning Multiple Build Jobs\n\n\nTo build the kernel with multiple make jobs, use\n\n\n$ \nmake -jn\n\n\n\n\n\nHere, \nn\n is the number of jobs to spawn. \n\n\nInstalling the New Kernel\n\n\nHow it is installed is architecture- and boot loader-dependent.\n\n\nAs an example, on an x86 system using grub, you would copy \narch/i386/boot/bzImage\n to /boot, name it something like vmlinuz-\nversion\n, and edit \n/boot/grub/grub.conf\n, adding a new entry for the new kernel. \n\n\nInstalling modules is automated and architecture-independent. As root, run:\n\n\n% make modules_install\n\n\n\n\n\n\nA Beast of a Different Nature\n\n\n\n\nThe kernel has access to neither the C library nor the standard C headers.\n\n\nThe kernel is coded in GNU C.\n\n\nThe kernel lacks the memory protection afforded to user-space.\n\n\nThe kernel cannot easily execute floating-point operations.\n\n\nThe kernel has a small per-process fixed-size stack.\n\n\nBecause the kernel has asynchronous interrupts, is preemptive, and supports SMP, synchronization and concurrency are major concerns within the kernel.\n\n\nPortability is important.\n\n\n\n\nNo libc or Standard Headers\n\n\nUnlike a user-space application, the kernel is not linked against the standard C library. The primary reason is speed and size. The full C library\u2014or even a decent subset of it; it is too large and too inefficient for the kernel.\n\n\nMany of the usual libc functions are implemented inside the kernel. For example, the common string manipulation functions are in \nlib/string.c\n. Just include the header file \nlinux/string.h\n and have at them.\n\n\nA set of architecture-specific header files are located in \narch/\narchitecture\n/include/asm\n in the kernel source tree. For example, if compiling for the x86 architecture, your architecture-specific headers are in \narch/x86/include/asm\n. Source code includes these headers via just the \nasm/\n prefix, for example \nasm/ioctl.h\n.\n\n\nprintk()\n\n\nOf the missing functions, the most familiar is \nprintf(\n). The kernel does not have access to \nprintf()\n, but it does provide \nprintk()\n, which works pretty much the same as its more familiar cousin. The \nprintk()\n function copies the formatted string into the kernel log buffer, which is normally read by the syslog program. Usage is similar to \nprintf()\n:\n\n\nprintk\n(\nHello world! A string \n%s\n and an integer \n%d\n\\n\n,\n \nstr\n,\n \ni\n);\n\n\n\n\n\n\nOne notable difference is that \nprintk()\n enables you to specify a priority flag.This flag is used by syslogd to decide where to display kernel messages.\n\n\nprintk\n(\nKERN_ERR\n \nthis is an error!\n\\n\n);\n\n\n\n\n\n\nNote there is no comma between \nKERN_ERR\n and the printed message. The priority flag is a preprocessor-define representing a string literal, which is concatenated onto the printed message during compilation.\n\n\nGNU C\n\n\nThe kernel is not programmed in strict ANSI C. The kernel developers make use of various language extensions available in \ngcc\n. They use both ISO C991 and GNU C extensions to the C language. \n\n\nInline Functions\n\n\nBoth C99 and GNU C support \ninline functions\n. An inline function is inserted inline into each function call site. This eliminates the overhead of function invocation and return (register saving and restore) and allows for potentially greater optimization as the compiler can optimize both the caller and the called function as one. Kernel developers use inline functions for small time-critical functions.\n\n\nAn inline function is declared when the keywords \nstatic\n and inline are used as part of the function definition. For example\n\n\nstatic\n \ninline\n \nvoid\n \nwolf\n(\nunsigned\n \nlong\n \ntail_size\n)\n\n\n\n\n\n\nInline Assembly\n\n\nThe gcc C compiler enables the embedding of assembly instructions in otherwise normal C functions.\n\n\nunsigned\n \nint\n \nlow\n,\n \nhigh\n;\n\n\nasm\n \nvolatile\n(\nrdtsc\n \n:\n \n=a\n \n(\nlow\n),\n \n=d\n \n(\nhigh\n));\n\n\n/* low and high now contain the lower and upper 32-bits of the 64-bit tsc */\n\n\n\n\n\n\nBranch Annotation\n\n\nThe gcc C compiler has a built-in directive that optimizes conditional branches as either very likely taken or very unlikely taken. The kernel wraps the directive in easy-to-use macros, \nlikely()\n and \nunlikely()\n. \n\n\nNo Memory Protection\n\n\nWhen a user-space application attempts an illegal memory access, the kernel can trap the error, send the \nSIGSEGV\n signal, and kill the process. If the kernel attempts an illegal memory access, however, the results are less controlled. Memory violations in the kernel result in an \noops\n, which is a major kernel error. \n\n\nNo (Easy) Use of Floating Point\n\n\nWhen using floating-point instructions kernel normally catches a trap and then initiates the transition from integer to floating point mode. Unlike user-space, the kernel does not have the luxury of seamless support for floating point because it cannot easily trap itself. Using a floating point inside the kernel requires manually saving and restoring the floating point registers. Except in the rare cases, no floating-point operations are in the kernel.\n\n\nSmall, Fixed-Size Stack\n\n\nUser-space has a large stack that can dynamically grow. \n\n\nThe kernel stack is neither large nor dynamic; it is small and fixed in size. The exact size of the kernel\u2019s stack varies by architecture. On x86, the stack size is configurable at compile-time and can be either 4KB or 8KB.\n\n\nSynchronization and Concurrency\n\n\nA number of properties of the kernel allow for concurrent access of shared resources and thus require synchronization to prevent races.\n\n\n\n\nLinux is a preemptive multitasking operating system. Processes are scheduled and rescheduled at the whim of the kernel\u2019s process scheduler.The kernel must synchronize between these tasks.\n\n\nLinux supports symmetrical multiprocessing (SMP).Therefore, without proper protection, kernel code executing simultaneously on two or more processors can concurrently access the same resource.\n\n\nInterrupts occur asynchronously with respect to the currently executing code.  Therefore, without proper protection, an interrupt can occur in the midst of accessing a resource, and the interrupt handler can then access the same resource.\n\n\nThe Linux kernel is preemptive. Therefore, without protection, kernel code can be preempted in favor of different code that then accesses the same resource.\n\n\n\n\nTypical solutions to race conditions include spinlocks and semaphores.\n\n\nImportance of Portability\n\n\nLinux is a portable operating system and should remain one. This means that architecture-independent C code must correctly compile and run on a wide range of systems, and that architecturedependent code must be properly segregated in system-specific directories in the kernel source tree.", 
            "title": "Chapter 2. Getting Started with the Kernel"
        }, 
        {
            "location": "/lkd/ch3/", 
            "text": "Chapter 3. Process Management\n\n\nThis chapter introduces the concept of the \nprocess\n. The process management is a crucial part of any operating system kernel, including Linux.\n\n\nThe Process\n\n\nA process is a program (object code stored on some media) in the midst of execution.\n\n\nBesides the executing program code (\ntext section\n in Unix), processes also include a set of resources:\n\n\n\n\nOpen files\n\n\nPending signals\n\n\nInternal kernel data\n\n\nProcessor state\n\n\nMemory address space with one or more memory mappings\n\n\nThread(s) of execution\n\n\nData section containing global variables\n\n\n\n\nThreads of execution\n\n\nThreads of execution, often shortened to \nthreads\n,  are the objects of activity within the process.\n\n\nEach thread includes:\n\n\n\n\nProgram counter\n\n\nProcess stack\n\n\nSet of processor registers\n\n\n\n\nThe kernel schedules individual threads, not processes. \nLinux does not differentiate between threads and processes. To Linux, a thread is just a special kind of process.\n\n\nVirtualized processor and virtual memory\n\n\nOn modern operating systems, processes provide two virtualizations: a \nvirtualized processor\n and \nvirtual memory\n.\n\n\n\n\nThe virtual processor gives the process the illusion that it alone monopolizes the system, despite possibly sharing the processor among hundreds of other processes. See \nChapter 4. Process Scheduling\n.\n\n\nVirtual memory lets the process allocate and manage memory as if it alone owned all the memory in the system. See \nChapter 12. Memory Management\n\n\n\n\nThreads share the virtual memory abstraction\n, whereas each receives its own virtualized processor.\n\n\nLife of a process\n\n\nA process is an active program and related resources:\n\n\n\n\nTwo or more processes can exist that are executing the \nsame\n program.\n\n\nTwo or more processes can exist that share various resources, such as open files or an address space.\n\n\n\n\nfork, exec, exit and wait\n\n\nIn Linux, the \nfork()\n system call creates a new process by duplicating an existing one.\n\n\n\n\nThe process that calls \nfork()\n is the parent, whereas the new process is the child.\n\n\nThe parent resumes execution and the child starts execution at the same place: where the call to \nfork()\n returns.\n\n\nThe \nfork()\n system call \nreturns from the kernel twice: once in the parent process and again in the newborn child.\n\n\n\n\nThe \nexec()\n family of function calls creates a new address space and loads a new program into the newborn child immediately after a fork. In contemporary Linux kernels, \nfork()\n is actually implemented via the \nclone()\n system call\n, which is discussed in a following section.\n\n\nThe \nexit()\n system call terminates the process and frees all its resources. A parent process can inquire about the status of a terminated child via the \nwait4()\n system call. A process can wait for the termination of a specific process. \nWhen a process exits, it is placed into a special zombie state that represents terminated processes until the parent calls \nwait()\n or \nwaitpid()\n.\n The kernel implements the \nwait4()\n system call. Linux systems, via the C library, typically provide the \nwait()\n, \nwaitpid()\n, \nwait3()\n, and \nwait4()\n functions.\n\n\nProcess Descriptor and the Task Structure\n\n\nAnother name for a process is a \ntask\n. The Linux kernel internally refers to processes as tasks. In this book, the terms are used interchangeably, though \n\"task\" generally refers to a process from the kernel\u2019s point of view.\n\n\nThe kernel stores the list of processes in a circular doubly linked list called the \ntask list\n.\n\n\nA \nprocess descriptor\n of the type \nstruct task_struct\n (defined in \nlinux/sched.h\n) is an element in the task list. It contains all the information about a specific process.\n\n\nThe \ntask_struct\n is a relatively large data structure, at around 1.7 kilobytes on a 32-bit machine. The process descriptor contains the data that describes the executing program: open files, the process\u2019s address space, pending signals, the process\u2019s state, etc. See the figure below.\n\n\n\n\nAllocating the Process Descriptor\n\n\nThe \ntask_struct\n structure is allocated via the \nslab allocator\n to provide object reuse and cache coloring (see \nChapter 12\n). The structure \nstruct thread_info\n lives at the bottom of the stack (for stacks that grow down) and at the top of the stack (for stacks that grow up)\n\n\n\n\nErrata\n: \"struct thread_struct\" should read \"struct thread_info\"\n\n\nThe \nthread_info\n structure is defined on x86 in \nasm/thread_info.h\n (see below code). Each task\u2019s \nthread_info\n structure is allocated at the end of its stack.The task element of the structure is a pointer to the task\u2019s actual \ntask_struct\n:\n\n\n\n\narch/x86/include/asm/thread_info.h\n\n\n\n\nstruct\n \nthread_info\n \n{\n\n    \nstruct\n \ntask_struct\n \n*\ntask\n;\n\n    \nstruct\n \nexec_domain\n \n*\nexec_domain\n;\n\n    \n__u32\n \nflags\n;\n\n    \n__u32\n \nstatus\n;\n\n    \n__u32\n \ncpu\n;\n\n    \nint\n \npreempt_count\n;\n\n    \nmm_segment_t\n \naddr_limit\n;\n\n    \nstruct\n \nrestart_block\n \nrestart_block\n;\n\n    \nvoid\n \n*\nsysenter_return\n;\n\n    \nint\n \nuaccess_err\n;\n\n\n};\n\n\n\n\n\n\nStoring the Process Descriptor\n\n\nThe \nprocess identification\n (PID) is numerical value, represented by the \nopaque type\n \npid_t\n (typically \nint\n), for the system to identify processes. The default maximum value is only 32,768 (that of a \nshort int\n), although the value optionally can be increased as high as four million (this is controlled in \nlinux/threads.h\n). The kernel stores this value as \npid\n inside each process descriptor. [p26]\n\n\nLarge servers may require many more than 32,768 (maximum value) processes. \nThe lower the value, the sooner the values will wrap around, destroying the useful notion that higher values indicate later-run processes than lower values.\n The administrator may increase the maximum value via \n/proc/sys/kernel/pid_max\n.\n\n\nInside the kernel, tasks are typically referenced directly by a pointer to their \ntask_struct\n structure. In fact, most kernel code that deals with processes works directly with \nstruct task_struct\n. Consequently, it is useful to be able to quickly look up the process descriptor of the currently executing task, which is done via the \ncurrent\n macro. This macro must be independently implemented by each architecture:\n\n\n\n\nSome architectures save a pointer to the \ntask_struct\n structure of the currently running process in a register, enabling for efficient access.\n\n\nOther architectures, such as x86 (which has few registers to waste), make use of the fact that struct \nthread_info\n is stored on the kernel stack to calculate the location of \nthread_info\n and subsequently the \ntask_struct\n.\n\n\n\n\nThe \ncurrent_thread_info()\n function\n\n\nOn x86, \ncurrent\n is calculated by masking out the 13 least-significant bits of the stack pointer to obtain the \nthread_info\n structure. This is done by the \ncurrent_thread_info()\n function (\narch/x86/include/asm/thread_info.h#L184\n). The assembly is shown here:\n\n\nmovl\n \n$\n-\n8192\n,\n \n%\neax\n\n\nandl\n \n%\nesp\n,\n \n%\neax\n\n\n\n\n\n\nThis assumes that the stack size is 8KB. When 4KB stacks are enabled, 4096 is used in lieu of 8192.\n\n\ncurrent\n dereferences the task member of \nthread_info\n to return the \ntask_struct\n:\n\n\n\n\ninclude/asm-generic/current.h\n\n\n\n\ncurrent_thread_info\n()\n-\ntask\n;\n\n\n\n\n\n\nProcess State\n\n\nThe \nstate\n field of the process descriptor describes the current condition of the process.\n\n\n\n\nEach process on the system is in exactly one of five different states. This value is represented by one of five flags:\n\n\n\n\nTASK_RUNNING\n: The process is runnable; it is either currently running or on a runqueue waiting to run. This is the only possible state for a process executing in user-space; it can also apply to a process in kernel-space that is actively running.\n\n\nTASK_INTERRUPTIBLE\n: The process is sleeping (blocked), waiting for some condition to exist. The process also awakes prematurely and becomes runnable if it receives a signal.\n\n\nTASK_UNINTERRUPTIBLE\n: This state is identical to \nTASK_INTERRUPTIBLE\n except that it does not wake up and become runnable if it receives a signal. This is used in situations where the process must wait without interruption or when the event is expected to occur quite quickly. Because the task does not respond to signals in this state, \nTASK_UNINTERRUPTIBLE\n is less often used than \nTASK_INTERRUPTIBLE\n.\n\n\n__TASK_TRACED\n: The process is being traced by another process, such as a debugger, via \nptrace\n.\n\n\n__TASK_STOPPED\n: Process execution has stopped; the task is not running nor is it eligible to run. This occurs if the task receives the \nSIGSTOP\n, \nSIGTSTP\n, \nSIGTTIN\n, or \nSIGTTOU\n signal or if it receives any signal while it is being debugged.\n\n\n\n\nManipulating the Current Process State\n\n\nKernel code often needs to change a process\u2019s state. The preferred mechanism is using:\n\n\nset_task_state\n(\ntask\n,\n \nstate\n);\n \n/* set task \u2018task\u2019 to state \u2018state\u2019 */\n\n\n\n\n\n\nThis function sets the given task to the given state. If applicable, it also provides a memory barrier to force ordering on other processors (only needed on SMP systems). Otherwise, it is equivalent to:\n\n\ntask\n-\nstate\n \n=\n \nstate\n;\n\n\n\n\n\n\nThe method \nset_current_state(state)\n is synonymous to \nset_task_state(current, state)\n. See \nlinux/sched.h\n for the implementation of these and related functions.\n\n\n\n\ninclude/linux/sched.h#L226\n\n\n\n\nProcess Context\n\n\nThe program code is read in from an \nexecutable file\n and executed within the program\u2019s address space.\n\n\n\n\nUser-space\n: Normal program execution occurs in user-space.\n\n\nKernel-space\n: When a program executes a system call or triggers an exception, it enters kernel-space. At this point, the kernel is said to be \"executing on behalf of the process\" and is in \nprocess context\n. When in process context, the \ncurrent\n macro is valid.\n\n\nOther than process context there is \ninterrupt context\n (discussed in \nChapter 7\n. In interrupt context, the system is not running on behalf of a process but is executing an interrupt handler. No process is tied to interrupt handlers.\n\n\n\n\n\n\n\n\nUpon exiting the kernel, the process resumes execution in user-space, unless a higher-priority process has become runnable in the interim, in which case the scheduler is invoked to select the higher priority process.\n\n\nA process can begin executing in kernel-space only through one of the following well-defined interfaces:\n\n\n\n\nSystem calls\n\n\nException handlers\n\n\n\n\nThe Process Family Tree\n\n\nAll processes are descendants of the \ninit\n process (PID 1). The kernel starts init in the last step of the boot process. The init process reads the system \ninitscripts\n and executes more programs, eventually completing the boot process.\n\n\n\n\nEvery process on the system has exactly one \nparent\n.\n\n\nEvery process has zero or more \nchildren\n.\n\n\nProcesses that are all direct children of the same parent are called \nsiblings\n.\n\n\n\n\n\n\n[UTLK p87-88]\n\n\nThe pointers (\nnext\n and \nprev\n) in a \nlist_head\n field store the addresses of other \nlist_head\n fields rather than the addresses of the whole data structures in which the \nlist_head\n structure is included. See figure below:\n\n\n\n\n\n\ninclude/linux/list.h\n\n\n\n\n\n\nThe relationship between processes is stored in the process descriptor.\n\n\nEach \ntask_struct\n (\ninclude/linux/sched.h#L1170\n) has:\n\n\n\n\nparent\n: pointer to the parent's \ntask_struct\n\n\nchildren\n: list of children (\nstruct list_head\n)\n\n\n\n\nTo obtain the process descriptor of a given process's parent:\n\n\nstruct\n \ntask_struct\n \n*\nmy_parent\n \n=\n \ncurrent\n-\nparent\n;\n\n\n\n\n\n\nTo iterate over a process\u2019s children:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\nstruct\n \nlist_head\n \n*\nlist\n;\n\n\n\nlist_for_each\n(\nlist\n,\n \ncurrent\n-\nchildren\n)\n \n{\n\n    \ntask\n \n=\n \nlist_entry\n(\nlist\n,\n \nstruct\n \ntask_struct\n,\n \nsibling\n);\n\n    \n/* task now points to one of current\u2019s children */\n\n\n}\n\n\n\n\n\n\n\n\nlist_for_each\n: \ninclude/linux/list.h#L367\n\n\n\n\nThe \ninit\n task\u2019s process descriptor is statically allocated as \ninit_task\n. The following code will always succeed:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\n\nfor\n \n(\ntask\n \n=\n \ncurrent\n;\n \ntask\n \n!=\n \ninit_task\n;\n \ntask\n \n=\n \ntask\n-\nparent\n)\n\n\n;\n\n\n/* task now points to init */\n\n\n\n\n\n\nYou can follow the process hierarchy from any one process in the system to any other.  Oftentimes, it is desirable simply to iterate over all processes in the system. This is easy because the task list is a circular, doubly linked list.\n\n\nTo obtain the next task in the list, given any valid task, use:\n\n\nlist_entry\n(\ntask\n-\ntasks\n.\nnext\n,\n \nstruct\n \ntask_struct\n,\n \ntasks\n)\n\n\n\n\n\n\nTo obtain the previous task works the same way:\n\n\nlist_entry\n(\ntask\n-\ntasks\n.\nprev\n,\n \nstruct\n \ntask_struct\n,\n \ntasks\n)\n\n\n\n\n\n\n\n\nlist_entry\n: \ninclude/linux/list.h\n\n\n\n\nThese two routines are provided by the macros \nnext_task(task)\n and \nprev_task(task)\n. (See \nDoubts and Solutions\n)\n\n\nThe macro \nfor_each_process(task)\n iterates over the entire task list. On each iteration, task points to the next task in the list:\n\n\nstruct\n \ntask_struct\n \n*\ntask\n;\n\n\n\nfor_each_process\n(\ntask\n)\n \n{\n\n    \n/* this pointlessly prints the name and PID of each task */\n\n    \nprintk\n(\n\u201c\n%\ns\n[\n%\nd\n]\n\\\nn\n\u201d\n,\n \ntask\n-\ncomm\n,\n \ntask\n-\npid\n);\n\n\n}\n\n\n\n\n\n\n\n\nfor_each_process\n: \ninclude/linux/sched.h#L2139\n\n\n\n\nIt is expensive to iterate over every task in a system with many processes; code should have good reason (and no alternative) before doing so.\n\n\nProcess Creation\n\n\nMost operating systems implement a \nspawn\n mechanism to create a new process in a new address space, read in an executable, and begin executing it. Unix separates these steps into two distinct functions: \nfork()\n and \nexec()\n.\n\n\n\n\nfork()\n: creates a child process that is a copy of the current task. It differs from the parent only in its PID, its PPID (parent\u2019s PID), and certain resources and statistics (e.g. pending signals) which are not inherited.\n\n\nexec()\n: loads a new executable into the address space and begins executing it.\n\n\n\n\nCopy-on-Write\n\n\nIf upon \nfork()\n all resources owned by the parent are duplicated and the copy is given to the child, it is naive and inefficient in that it copies much data that might otherwise be shared. Worse still, if the new process were to immediately execute a new image, all that copying would go to waste.\n\n\nIn Linux, \nfork()\n is implemented through the use of copy-on-write pages.\n\n\nCopy-on-write\n (COW) can delay or prevent copying data. Rather than duplicating the process address space, the parent and the child can share a single copy.\n\n\n\n\nIf the data is written to, it is marked and a duplicate is made and each process receives a unique copy. The duplication of resources occurs only when they are written; until then, they are shared read-only.\n\n\nIn the case that the pages are never written (if \nexec()\n is called immediately after \nfork()\n), they never need to be copied.\n\n\n\n\nThe only overhead incurred by \nfork()\n is the duplication of the parent\u2019s page tables and the creation of a unique process descriptor for the child. In the common case that a process executes a new executable image immediately after forking, this optimization prevents the wasted copying of large amounts of data (with the address space, easily tens of megabytes). This is an important optimization because the Unix philosophy encourages quick process execution.\n\n\nForking\n\n\nLinux implements \nfork()\n via the \nclone()\n system call which takes a series of flags that specify which resources the parent and child process should share.\n\n\n\n\nThe \nfork()\n, \nvfork()\n, and \n__clone()\n library calls all invoke the \nclone()\n system call with the requisite flags.\n\n\nThe \nclone()\n system call calls \ndo_fork()\n.\n\n\n\n\nThe bulk of the work in forking is handled by \ndo_fork()\n, which is defined in \nkernel/fork.c\n. \ndo_fork()\n function calls \ncopy_process()\n and then starts the process running.\n\n\n\n\ndo_fork()\n: \nkernel/fork.c#L1354\n\n\ncopy_process()\n: \nkernel/fork.c#L957\n\n\n\n\nThe interesting work is done by \ncopy_process()\n:\n\n\n\n\nIt calls \ndup_task_struct()\n that creates following for the new process with identical values to those of the current task:\n\n\nKernel stack\n\n\nthread_info\n structure\n\n\ntask_struct\n\n\n(At this point, the child and parent process descriptors are identical)\n\n\n\n\n\n\nIt then checks that the new child will not exceed the resource limits on the number of processes for the current user.\n\n\nVarious members of the process descriptor are cleared or set to initial values, \nto differentiate the child from its parent.\n\n\nMembers of the process descriptor not inherited are primarily statistically information.\n\n\nThe bulk of the values in \ntask_struct\n remain unchanged.\n\n\n\n\n\n\nThe child\u2019s state is set to \nTASK_UNINTERRUPTIBLE\n to ensure that it does not yet run.\n\n\nIt calls \ncopy_flags()\n to update the flags member of the \ntask_struct\n (per process flags: \ninclude/linux/sched.h#L1693\n).\n\n\nThe \nPF_SUPERPRIV\n flag, which denotes whether a task used superuser privileges, is cleared\n\n\nThe \nPF_FORKNOEXEC\n flag, which denotes a process that has not called \nexec()\n, is set.\n\n\n\n\n\n\nIt calls \nalloc_pid()\n to assign an available PID to the new task.\n\n\nDepending on the flags passed to \nclone()\n, \ncopy_process()\n either duplicates or shares:\n\n\nOpen files\n\n\nFilesystem information\n\n\nSignal handlers\n\n\nProcess address space\n\n\nNamespace\n\n\n(These resources are typically shared between threads in a given process; otherwise they are unique and thus copied here)\n\n\n\n\n\n\nFinally, \ncopy_process()\n cleans up and returns to the caller \na pointer to the new child\n.\n\n\n\n\nBack in \ndo_fork()\n, if \ncopy_process()\n returns successfully, the new child is woken up and run.\n\n\nDeliberately, the kernel runs the child process first. In the case of the child calling \nexec()\n immediately, this eliminates any copy-on-write overhead that would occur if the parent ran first and began writing to the address space.\n\n\nvfork()\n\n\nThe \nvfork()\n system call has the same effect as \nfork()\n, except that the page table entries of the parent process are not copied. The child executes as the sole thread in the parent\u2019s address space, and the parent is blocked until the child either calls \nexec()\n or exits. The child is not allowed to write to the address space. [p33]\n\n\nToday, with copy-on-write and child-runs-first semantics, the only benefit to \nvfork()\n is not copying the parent page tables entries. [p33]\n\n\nThe \nvfork()\n system call is implemented via a special flag to the \nclone()\n system call:\n\n\n\n\nIn \ncopy_process()\n, the \ntask_struct\n member \nvfork_done\n is set to NULL.\n\n\nIn \ndo_fork()\n, if the special flag was given, \nvfork_done\n is pointed at a specific address.\n\n\nAfter the child is first run, the parent (instead of returning) waits for the child to signal it through the \nvfork_done\n pointer.\n\n\nIn the \nmm_release()\n function, which is used when a task exits a memory address space, \nvfork_done\n is checked to see whether it is NULL. If it is not, the parent is signaled.\n\n\nBack in \ndo_fork()\n, the parent wakes up and returns.\n\n\n\n\nIf this all goes as planned, the child is now executing in a new address space, and the parent is again executing in its original address space. The overhead is lower, but the implementation is not pretty.\n\n\nThe Linux Implementation of Threads\n\n\n\n\nThreads are a programming abstraction that provide multiple threads of execution within the same program in a shared memory address space.\n\n\nThreads can also share open files and other resources.\n\n\nThreads enable \nconcurrent programming\n and, on multiple processor systems, true \nparallelism\n.\n\n\n\n\nLinux has a unique implementation of threads:\n\n\n\n\nTo the Linux kernel, there is no concept of a thread. Linux implements all threads as standard processes.\n\n\nThe kernel does not provide any special scheduling semantics or data structures to represent threads. Instead, a thread is merely a process that shares certain resources with other processes.\n\n\nEach thread has a unique \ntask_struct\n and appears to the kernel as a normal process. Threads just happen to share resources, such as an address space, with other processes.\n\n\n\n\nThis approach to threads contrasts greatly with operating systems such as Microsoft Windows or Sun Solaris, which have explicit kernel support for threads (and sometimes call threads lightweight processes). [p34]\n\n\nCreating Threads\n\n\nThreads are created the same as normal tasks, with the exception that the \nclone()\n system call is passed flags corresponding to the specific resources to be shared:\n\n\nclone\n(\nCLONE_VM\n \n|\n \nCLONE_FS\n \n|\n \nCLONE_FILES\n \n|\n \nCLONE_SIGHAND\n,\n \n0\n);\n\n\n\n\n\n\nThe above code is identical to \nfork()\n except that the address space (\nCLONE_VM\n), filesystem resources (\nCLONE_FS\n), file descriptors (\nCLONE_FILES\n), and signal handlers (\nCLONE_SIGHAND\n) are shared.\n\n\nfork()\n can be implemented as:\n\n\nclone\n(\nSIGCHLD\n,\n \n0\n);\n\n\n\n\n\n\nvfork()\n is implemented as:\n\n\nclone\n(\nCLONE_VFORK\n \n|\n \nCLONE_VM\n \n|\n \nSIGCHLD\n,\n \n0\n);\n\n\n\n\n\n\nThe flags, which are defined in \nlinux/sched.h\n (\ninclude/linux/sched.h#L5\n),  to \nclone()\n specify the behavior of the new process and detail what resources the parent and child will share.\n\n\n\n\n\n\n\n\nFlag\n\n\nMeaning\n\n\n\n\n\n\n\n\n\n\nCLONE_FILES\n\n\nParent and child share open files.\n\n\n\n\n\n\nCLONE_FS\n\n\nParent and child share filesystem information.\n\n\n\n\n\n\nCLONE_IDLETASK\n\n\nSet PID to zero (used only by the idle tasks).\n\n\n\n\n\n\nCLONE_NEWNS\n\n\nCreate a new namespace for the child.\n\n\n\n\n\n\nCLONE_PARENT\n\n\nChild is to have same parent as its parent.\n\n\n\n\n\n\nCLONE_PTRACE\n\n\nContinue tracing child.\n\n\n\n\n\n\nCLONE_SETTID\n\n\nWrite the TID back to user-space.\n\n\n\n\n\n\nCLONE_SETTLS\n\n\nCreate a new TLS (thread-local storage) for the child.\n\n\n\n\n\n\nCLONE_SIGHAND\n\n\nParent and child share signal handlers and blocked signals.\n\n\n\n\n\n\nCLONE_SYSVSEM\n\n\nParent and child share System V SEM_UNDO semantics.\n\n\n\n\n\n\nCLONE_THREAD\n\n\nParent and child are in the same thread group.\n\n\n\n\n\n\nCLONE_VFORK\n\n\nvfork() was used and the parent will sleep until the child wakes it.\n\n\n\n\n\n\nCLONE_UNTRACED\n\n\nDo not let the tracing process force CLONE_PTRACE on the child.\n\n\n\n\n\n\nCLONE_STOP\n\n\nStart process in the TASK_STOPPED state.\n\n\n\n\n\n\nCLONE_CHILD_CLEARTID\n\n\nClear the TID in the child.\n\n\n\n\n\n\nCLONE_CHILD_SETTID\n\n\nSet the TID in the child.\n\n\n\n\n\n\nCLONE_PARENT_SETTID\n\n\nSet the TID in the parent.\n\n\n\n\n\n\nCLONE_VM\n\n\nParent and child share address space.\n\n\n\n\n\n\n\n\nKernel Threads\n\n\nKernel threads\n are standard processes that exist solely in kernel-space. They are useful for the kernel to perform some operations in the background.\n\n\nDifference from normal threads:\n\n\n\n\nKernel threads do not have an address space. Their \nmm\n pointer, which points at their address space, is \nNULL\n.\n\n\nKernel threads operate only in kernel-space and do not context switch into user-space.\n\n\n\n\nSimilarity with normal threads:\n\n\n\n\nKernel threads are schedulable and preemptable.\n\n\n\n\nLinux delegates several tasks to kernel threads, most notably the \nflush\n tasks and the \nksoftirqd\n task. Use \nps -ef\n command to see them.\n\n\n\n\nKernel threads are created on system boot by other kernel threads.\n\n\nA kernel thread can be created only by another kernel thread. The kernel handles this automatically by forking all new kernel threads off of the \nkthreadd\n kernel process.\n\n\n\n\nThe interfaces of kernel threads defined in \nlinux/kthread.h\n (\ninclude/linux/kthread.h\n)\n\n\nkthread_create()\n spawns a new kernel thread from an existing one:\n\n\nstruct task_struct *kthread_create(int (*threadfn)(void *data),\n                                   void *data,\n                                   const char namefmt[],\n                                   ...)\n\n\n\n\n\nThe new task is created via the \nclone()\n system call by the \nkthread\n kernel process:\n\n\n\n\nThe new process will run the \nthreadfn\n function, which is passed the data argument.\n\n\nThe process will be named \nnamefmt\n, which takes printf-style formatting arguments in the variable argument list.\n\n\nThe process is created in an unrunnable state; it will not start running until explicitly woken up via \nwake_up_process()\n.\n\n\n\n\nA process can be created and made runnable with a single function, \nkthread_run()\n:\n\n\nstruct\n \ntask_struct\n \n*\nkthread_run\n(\nint\n \n(\n*\nthreadfn\n)(\nvoid\n \n*\ndata\n),\n\n                                \nvoid\n \n*\ndata\n,\n\n                                \nconst\n \nchar\n \nnamefmt\n[],\n\n                                \n...)\n\n\n\n\n\n\nThis routine (\nkthread_run()\n), implemented as a macro, simply calls both \nkthread_create()\n and \nwake_up_process()\n:\n\n\n#define kthread_run(threadfn, data, namefmt, ...)                 \\\n\n\n({                                                                \\\n\n\n    struct task_struct *k;                                        \\\n\n\n                                                                  \\\n\n\n    k = kthread_create(threadfn, data, namefmt, ## __VA_ARGS__);  \\\n\n\n    if (!IS_ERR(k))                                               \\\n\n\n        wake_up_process(k);                                       \\\n\n\n    k;                                                            \\\n\n\n})\n\n\n\n\n\n\nWhen started, a kernel thread continues to exist until it calls \ndo_exit()\n or another part of the kernel calls \nkthread_stop()\n, passing in the address of the \ntask_struct\n structure returned by \nkthread_create()\n:\n\n\nint\n \nkthread_stop\n(\nstruct\n \ntask_struct\n \n*\nk\n)\n\n\n\n\n\n\nProcess Termination\n\n\nWhen a process terminates, the kernel releases the resources owned by the process and notifies the child\u2019s parent of its demise.\n\n\nSelf-induced process termination occurs when the process calls the \nexit()\n system call, which is either:\n\n\n\n\nExplicitly: the process calls \nexit()\n system call.\n\n\nImplicitly: the process return from the main subroutine of any program. The C compiler places a call to \nexit()\n after \nmain()\n returns.\n\n\n\n\nInvoluntary process termination occurs when the process receives a signal or exception it cannot handle or ignore.\n\n\nRegardless of how a process terminates, the bulk of the work is handled by \ndo_exit()\n, defined in \nkernel/exit.c\n (\nkernel/exit.c#L900\n), which does the following:\n\n\n\n\nIt sets the \nPF_EXITING\n flag in the flags member of the \ntask_struct\n.\n\n\nIt calls \ndel_timer_sync()\n to remove any kernel timers. Upon return, it is guaranteed that no timer is queued and that no timer handler is running.\n\n\nIf BSD process accounting is enabled, \ndo_exit()\n calls \nacct_update_integrals()\n to write out accounting information.\n\n\nIt calls \nexit_mm()\n to release the \nmm_struct\n held by this process. If no other process is using this address space (if the address space is not shared) the kernel then destroys it.\n\n\nIt calls \nexit_sem()\n. If the process is queued waiting for an IPC semaphore, it is dequeued here.\n\n\nIt then calls \nexit_files()\n and \nexit_fs()\n to decrement the usage count of objects related to file descriptors and filesystem data, respectively.\n\n\nIt sets the task\u2019s exit code (stored in the \nexit_code\n member of the \ntask_struct\n) to that provided by \nexit()\n or whatever kernel mechanism forced the termination. \nThe exit code is stored here for optional retrieval by the parent.\n\n\nIt send signals and reparents children:\n\n\nCalls \nexit_notify()\n to send signals to the task\u2019s parent\n\n\nReparents any of the task\u2019s children to another thread in their thread group or the init process\n\n\nSets the task\u2019s exit state (stored in \nexit_state\n in the \ntask_struct\n structure) to \nEXIT_ZOMBIE\n.\n\n\n\n\n\n\nIt calls \nschedule()\n to switch to a new process.\n\n\nBecause the process is now not schedulable, this is the last code the task will ever execute. \ndo_exit()\n never returns.\n\n\n\n\n\n\n\n\nAt this point:\n\n\n\n\nAll objects associated with the task (assuming the task was the sole user) are freed.\n\n\nThe task is not runnable (and no longer has an address space in which to run) and is in the \nEXIT_ZOMBIE\n exit state.\n\n\nThe only memory it occupies is its kernel stack, the \nthread_info\n structure, and the \ntask_struct\n structure.\n\n\nThe task exists solely to provide information to its parent. After the parent retrieves the information, or notifies the kernel that it is uninterested, the remaining memory held by the process is freed and returned to the system for use.\n\n\n\n\nRemoving the Process Descriptor\n\n\nAfter \ndo_exit()\n completes, the process descriptor for the terminated process still exists, but the process is a zombie and is unable to run.\n\n\nCleaning up after a process and removing its process descriptor are separate steps. This enables the system to obtain information about a child process after it has terminated.\n\n\nThe terminated child\u2019s \ntask_struct\n is deallocated after any of the following:\n\n\n\n\nThe parent has obtained information on its terminated child.\n\n\nThe parent has signified to the kernel that it does not care (about the terminated child).\n\n\n\n\nThe \nwait()\n family of functions are implemented via a system call \nwait4()\n.\n\n\nThe standard behavior is to suspend execution of the calling task until one of its children exits, at which time the function returns with the PID of the exited child. On return, a pointer (as an argument to a \nwait()\n function) holds the exit code of the terminated child. [p38]\n\n\nrelease_task()\n is invoked to finally deallocate the process descriptor:\n\n\n\n\nIt calls \n__exit_signal()\n, which calls \n__unhash_process()\n, which in turns calls detach_pid() to remove the process from the pidhash and remove the process from the task list.\n\n\n__exit_signal()\n releases any remaining resources used by the now dead process and finalizes statistics and bookkeeping.\n\n\nIf the task was the last member of a thread group, and the leader is a zombie, then \nrelease_task()\n notifies the zombie leader\u2019s parent.\n\n\nrelease_task()\n calls \nput_task_struct()\n to free the pages containing the process\u2019s kernel stack and \nthread_info\n structure and deallocate the slab cache containing the \ntask_struct\n.\n\n\n\n\nAt this point, the process descriptor and all resources belonging solely to the process have been freed.\n\n\nThe Dilemma of the Parentless Task\n\n\nIf a parent exits before its children, any of its child tasks must be reparented to a new process, otherwise parentless terminated processes would forever remain zombies, wasting system memory.\n\n\nThe solution is to reparent a task\u2019s children on exit to another process in the current thread group, or (if that fails) the init process.\n\n\ndo_exit()\n calls \nexit_notify()\n, which calls \nforget_original_parent()\n, which calls \nfind_new_reaper()\n to perform the reparenting:\n\n\nstatic\n \nstruct\n \ntask_struct\n \n*\nfind_new_reaper\n(\nstruct\n \ntask_struct\n \n*\nfather\n)\n\n\n{\n\n    \nstruct\n \npid_namespace\n \n*\npid_ns\n \n=\n \ntask_active_pid_ns\n(\nfather\n);\n\n    \nstruct\n \ntask_struct\n \n*\nthread\n;\n\n\n    \nthread\n \n=\n \nfather\n;\n\n    \nwhile_each_thread\n(\nfather\n,\n \nthread\n)\n \n{\n\n      \nif\n \n(\nthread\n-\nflags\n \n \nPF_EXITING\n)\n\n          \ncontinue\n;\n\n      \nif\n \n(\nunlikely\n(\npid_ns\n-\nchild_reaper\n \n==\n \nfather\n))\n\n          \npid_ns\n-\nchild_reaper\n \n=\n \nthread\n;\n\n      \nreturn\n \nthread\n;\n\n    \n}\n\n\n    \nif\n \n(\nunlikely\n(\npid_ns\n-\nchild_reaper\n \n==\n \nfather\n))\n \n{\n\n        \nwrite_unlock_irq\n(\ntasklist_lock\n);\n\n        \nif\n \n(\nunlikely\n(\npid_ns\n \n==\n \ninit_pid_ns\n))\n\n        \npanic\n(\nAttempted to kill init!\n);\n\n\n        \nzap_pid_ns_processes\n(\npid_ns\n);\n\n        \nwrite_lock_irq\n(\ntasklist_lock\n);\n\n\n        \n/*\n\n\n        * We can not clear -\nchild_reaper or leave it alone.\n\n\n        * There may by stealth EXIT_DEAD tasks on -\nchildren,\n\n\n        * forget_original_parent() must move them somewhere.\n\n\n        */\n\n        \npid_ns\n-\nchild_reaper\n \n=\n \ninit_pid_ns\n.\nchild_reaper\n;\n\n    \n}\n\n\n    \nreturn\n \npid_ns\n-\nchild_reaper\n;\n\n\n}\n\n\n\n\n\n\nThe above code attempts to find and return another task in the process\u2019s thread group. If another task is not in the thread group, it finds and returns the \ninit\n process.\n\n\nAfter a suitable new parent for the children is found, each child needs to be located and reparented to \nreaper\n:\n\n\nreaper\n \n=\n \nfind_new_reaper\n(\nfather\n);\n\n\nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \nfather\n-\nchildren\n,\n \nsibling\n)\n \n{\n\n    \np\n-\nreal_parent\n \n=\n \nreaper\n;\n\n    \nif\n \n(\np\n-\nparent\n \n==\n \nfather\n)\n \n{\n\n        \nBUG_ON\n(\np\n-\nptrace\n);\n\n        \np\n-\nparent\n \n=\n \np\n-\nreal_parent\n;\n\n    \n}\n\n    \nreparent_thread\n(\np\n,\n \nfather\n);\n\n\n}\n\n\n\n\n\n\nptrace_exit_finish()\n is then called to do the same reparenting but to a list of \nptraced\n children:\n\n\nvoid\n \nexit_ptrace\n(\nstruct\n \ntask_struct\n \n*\ntracer\n)\n\n\n{\n\n    \nstruct\n \ntask_struct\n \n*\np\n,\n \n*\nn\n;\n\n    \nLIST_HEAD\n(\nptrace_dead\n);\n\n\n    \nwrite_lock_irq\n(\ntasklist_lock\n);\n\n    \nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \ntracer\n-\nptraced\n,\n \nptrace_entry\n)\n \n{\n\n        \nif\n \n(\n__ptrace_detach\n(\ntracer\n,\n \np\n))\n\n        \nlist_add\n(\np\n-\nptrace_entry\n,\n \nptrace_dead\n);\n\n    \n}\n\n    \nwrite_unlock_irq\n(\ntasklist_lock\n);\n\n\n    \nBUG_ON\n(\n!\nlist_empty\n(\ntracer\n-\nptraced\n));\n\n\n    \nlist_for_each_entry_safe\n(\np\n,\n \nn\n,\n \nptrace_dead\n,\n \nptrace_entry\n)\n \n{\n\n    \nlist_del_init\n(\np\n-\nptrace_entry\n);\n\n    \nrelease_task\n(\np\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWhen a task is \nptraced\n, it is temporarily reparented to the debugging process. When the task\u2019s parent exits, however, it must be reparented along with its other siblings. In previous kernels, this resulted in a loop over every process in the system looking for children. The solution is simply to keep a separate list of a process\u2019s children being ptraced, reducing the search for one\u2019s children from every process to just two relatively small lists\n\n\nAfter the process are successfully reparented, there is no risk of stray zombie processes. The \ninit\n process routinely calls \nwait()\n on its children, cleaning up any zombies assigned to it.\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\n\n\nThese two routines are provided by the macros \nnext_task(task)\n and \nprev_task(task)\n, respectively.\n\n\n\n\nI didn't find any relevant appearance for \nprev_task\n macro in the \nLinux 2.6.34.7 source code\n.", 
            "title": "Chapter 3. Process Management"
        }, 
        {
            "location": "/lkd/ch4/", 
            "text": "Chapter 4. Process Scheduling\n\n\nThis chapter discusses the \nprocess scheduler\n, the kernel subsystem that puts those processes to work.\n\n\nThe process scheduler (or simply the scheduler) divides the finite resource of processor time between the runnable processes on a system. It is responsible for best utilizing the system and giving users the impression that multiple processes are executing simultaneously. [p41]\n\n\nTo best utilize processor time, assuming there are runnable processes, a process should always be running. If there are more \nrunnable\n processes than processors in a system, some processes will not be running at a given moment. These processes are \nwaiting to run\n. Deciding which process runs next, given a set of runnable processes, is the fundamental decision that the scheduler must make.\n\n\nMultitasking\n\n\nA \nmultitasking\n operating system is one that can simultaneously interleave execution of more than one process.\n\n\n\n\nOn single processor machines, this gives the illusion of multiple processes running concurrently.\n\n\nOn multiprocessor machines, this enables processes to actually run concurrently, in parallel, on different processors.\n\n\n\n\nOn either type of machine, it also enables many processes to \nblock\n or \nsleep\n. Although these processes are in memory, they are not \nrunnable\n. These processes utilize the kernel to wait until some event (keyboard input, network data, passage of time, and so on) occurs. [p41]\n\n\nMultitasking operating systems come in two flavors:\n\n\n\n\nCooperative multitasking\n\n\nPreemptive multitasking\n\n\n\n\nPreemptive multitasking\n\n\nLinux, like all Unix variants and most modern operating systems, implements preemptive multitasking. In preemptive multitasking, the scheduler decides\nwhen a process is to cease running and a new process is to begin running.\n\n\n\n\nPreemption\n: the act of involuntarily suspending a running process.\n\n\nTimeslice\n of a process: the time the process runs before it is preempted is usually predetermined.\n\n\nManaging the timeslice enables the scheduler to make global scheduling decisions for the system and prevents any one process from monopolizing the processor.\n\n\nOn many modern operating systems, the timeslice is dynamically calculated as a function of process behavior and configurable system policy.\n\n\nLinux\u2019s unique \"fair\" scheduler does not employ timeslices \nper se\n, to interesting effect.\n\n\n\n\n\n\n\n\nCooperative multitasking\n\n\nIn cooperative multitasking, a process does not stop running until it voluntarily decides to do so. The act of a process voluntarily suspending itself is called \nyielding\n, but the operating system cannot enforce this.\n\n\nThe shortcomings of this approach are manifest:\n\n\n\n\nThe scheduler cannot make global decisions regarding how long processes run;\n\n\nProcesses can monopolize the processor for longer than the user desires;\n\n\nA hung process that never yields can potentially bring down the entire system.\n\n\n\n\n[p42]\n\n\nLinux\u2019s Process Scheduler\n\n\nFrom Linux\u2019s first version in 1991 through the 2.4 kernel series, the Linux scheduler was simple in design. It was easy to understand, but scaled poorly in light of many runnable processes or many processors.\n\n\nDuring the 2.5 kernel development series, the \nO(1) scheduler\n solved the shortcomings of the previous Linux scheduler and introduced powerful new features and performance characteristics. By introducing a constant-time algorithm for timeslice calculation and per-processor runqueues, it rectified the design limitations of the earlier scheduler.\n\n\nHowever, the O(1) scheduler had several pathological failures related to scheduling latency-sensitive applications (interactive processes). Thus, although the O(1) scheduler was ideal for large server workloads, which lack interactive processes, it performed below par on desktop systems, where interactive applications are the \nraison d\u2019\u00eatre\n.\n\n\nBeginning in the 2.6 kernel series, developers introduced new process schedulers aimed at improving the interactive performance of the O(1) scheduler. The most notable of these was the \nRotating Staircase Deadline\n scheduler, which introduced the concept of \nfair scheduling\n, borrowed from queuing theory, to Linux\u2019s process scheduler. This concept was the inspiration for the O(1) scheduler\u2019s eventual replacement in kernel version 2.6.23, the \nCompletely Fair Scheduler\n (CFS).\n\n\nThis chapter discusses the fundamentals of scheduler design and how they apply to the Completely Fair Scheduler and its goals, design, implementation, algorithms, and related system calls. We also discuss the O(1) scheduler because its implementation is a more \"classic\" Unix process scheduler model.\n\n\nPolicy\n\n\nPolicy is the behavior of the scheduler that determines what runs when.\n\n\nI/O-Bound Versus Processor-Bound Processes\n\n\nProcesses can be classified as either \nI/O-bound\n or \nprocessor-bound\n.\n\n\n\n\nAn \nI/O-bound process\n spends much of its time submitting and waiting on I/O requests. Such a process is runnable for only short durations, because it eventually blocks waiting on more I/O.\n\n\n\"I/O\" means any type of blockable resource, such as keyboard input or network I/O, and not just disk I/O. Most graphical user interface (GUI) applications are I/O-bound, even if they never read from or write to the disk, because they spend most of their time waiting on user interaction via the keyboard and mouse.\n\n\n\n\n\n\nProcessor-bound processes\n spend much of their time executing code. Thet tend to run until they are preempted because they do not block on I/O requests very often. System response does not dictate that the scheduler run them often. A scheduler policy for processor-bound processes tends to run such processes less frequently but for longer durations.\n\n\nExamples of processor-bound processes include: a program executing an infinite loop, \nssh-keygen\n, \nMATLAB\n.\n\n\n\n\n\n\n\n\nThese classifications are not mutually exclusive. Processes can exhibit both behaviors simultaneously:\n\n\n\n\nThe X Window server is both processor and I/O intense.\n\n\nA word processor can be I/O-bound but dive into periods of intense processor action.\n\n\n\n\nThe scheduling policy in a system must attempt to satisfy two conflicting goals:\n\n\n\n\nFast process response time (low latency)\n\n\nMaximal system utilization (high throughput)\n\n\n\n\nFavoring I/O-bound over processor-bound\n\n\nSchedulers often employ complex algorithms to determine the most worthwhile process to run while not compromising fairness to other processes with lower priority. [p43-44]\n\n\n\n\nThe scheduler policy in Unix systems tends to explicitly favor I/O-bound processes, thus providing good process response time.\n\n\nLinux, aiming to provide good interactive response and desktop performance, optimizes for process response (low latency), thus favoring I/O-bound processes over processor-bound processes. This is done in a creative manner that does not neglect processor-bound processes.\n\n\n\n\nProcess Priority\n\n\nThe \npriority-based\n scheduling is a common type of scheduling algorithm, which isn\u2019t exactly implemented on Linux. It means that processes with a higher priority run before those with a lower priority, whereas processes with the same priority are scheduled \nround-robin\n (one after the next, repeating). On some systems, processes with a higher priority also receive a longer timeslice. The runnable process with timeslice remaining and the highest priority always runs. [p44]\n\n\nnice value and real-time priority\n\n\nThe Linux kernel implements two separate priority ranges:\n\n\n\n\nnice value\n (a number from \u201320 to +19 with a default of 0) is the standard priority range used in all Unix systems:\n\n\nProcesses with a lower nice value (higher priority) receive a larger proportion of the system\u2019s processor, and vice versa.\n\n\nIn Linux, the nice value is a control over the \nproportion\n of timeslice. In other Unix-based systems, such as Mac OS X, the nice value is a control over the \nabsolute\n timeslice allotted to a process;\n\n\nThe \nps -el\n command lists processes with their nice values.\n\n\n\n\n\n\nReal-time priority\n (configurable values that by default range from 0 to 99)\n\n\nHigher real-time priority values correspond to a greater priority.\n\n\nAll real-time processes are at a higher priority than normal processes.\n\n\nLinux implements real-time priorities in accordance with the relevant Unix standards, specifically POSIX.1b.\n\n\nThe \nps -eo state,uid,pid,ppid,rtprio,time,comm\n command lists processes and their real-time priority. A value of \u201c-\u201d means the process is not real-time.\n\n\n\n\n\n\n\n\nTimeslice\n\n\nThe \ntimeslice\n is the numeric value that represents how long a task can run until it is preempted.\n\n\n\n\nToo long a timeslice causes the system to have poor interactive performance.\n\n\nToo short a timeslice causes significant amounts of processor time to be wasted on the overhead of switching processes.\n\n\n\n\nThe conflicting goals of I/O bound versus processor-bound processes:\n\n\n\n\nI/O-bound processes do not need longer timeslices (although they do like to run often)\n\n\nProcessor-bound processes crave long timeslices (to keep their caches hot).\n\n\n\n\nTimeslice on Linux\n\n\nLinux\u2019s CFS scheduler does not directly assign timeslices to processes, but assigns processes a \nproportion\n of the processor. The amount of processor time that a process receives is a function of the load of the system. This assigned proportion is further affected by each process\u2019s nice value. The nice value acts as a weight, changing the proportion of the processor time each process receives. Processes with higher nice values (a lower priority) receive a deflationary weight, yielding them a smaller proportion of the processor, and vice versa.\n\n\nWith the CFS scheduler, whether the process runs immediately (preempting the currently running process) is a function of how much of a proportion of the processor the newly runnable processor has consumed. If it has consumed a smaller proportion of the processor than the currently executing process, it runs immediately\n\n\nThe Scheduling Policy in Action\n\n\nConsider a system with two runnable tasks: a text editor (I/O-bound) and a video encoder (processor-bound). [p45-46]\n\n\nIdeally, the scheduler gives the text editor a larger proportion of the available processor than the video encoder, because the text editor is interactive. We have two goals for the text editor:\n\n\n\n\nWe want the text editor to have a large amount of processor time available to it; not because it needs a lot of processor (it does not) but because we want it to always have processor time available the moment it needs it.\n\n\nWe want the text editor to preempt the video encoder the moment it wakes up (say, when the user presses a key). This can ensure the text editor has good \ninteractive performance\n and is responsive to user input.\n\n\n\n\nHow the above two goals achieved\n\n\n\n\nInstead of assigning the text editor a specific priority and timeslice, the Linux guarantees the text editor a specific proportion of the processor. If the two are the only processes with same nice values, each would be guaranteed half of the processor\u2019s time (the proportion is 50%). Because the text editor spends most of its time blocked, waiting for user key presses, it does not use anywhere near 50% of the processor. Conversely, the video encoder is free to use more than its allotted 50%, enabling it to finish the encoding quickly.\n\n\nWhen the editor wakes up, CFS notes that it is allotted 50% of the processor but has used considerably less, and thus determines that the text editor has run for \nless time\n than the video encoder. Attempting to give all processes a fair share of the processor, it then preempts the video encoder and enables the text editor to run. [p46]\n\n\n\n\nThe Linux Scheduling Algorithm\n\n\nScheduler Classes\n\n\nThe Linux scheduler is modular, enabling different algorithms to schedule different types of processes.This modularity is called \nscheduler classes\n. The base scheduler code, which is defined in \nkernel/sched.c\n, iterates over each scheduler class in order of priority.The highest priority scheduler class that has a runnable process wins, selecting who runs next.\n\n\nThe Completely Fair Scheduler (CFS) is the registered scheduler class for normal processes, called \nSCHED_NORMAL\n in Linux (and \nSCHED_OTHER\n in POSIX).  CFS is defined in \nkernel/sched_fair.c\n. The rest of this section discusses the CFS algorithm.\n\n\nProcess Scheduling in Unix Systems\n\n\nTo discuss fair scheduling, we must first describe how traditional Unix systems schedule processes.\n\n\nModern process schedulers have two common concepts: process priority and timeslice. Processes with a higher priority run more frequently and (on many systems) receive a higher timeslice. On Unix, the priority is exported to user-space in the form of nice values. This in practice leads to several problems:\n\n\n\n\nMapping nice values onto timeslices requires a decision about what absolute timeslice to allot each nice value, which leads to suboptimal switching behavior. [p47]\n\n\nNicing (down) a process by a relative nice value has wildly different effects depending on the starting nice value. [p47-48]\n\n\nAbsolute timeslice timeslice must be some integer multiple of the timer tick, which introduces several problems. [p48]\n\n\nHandling process wake up in a priority-based scheduler that wants to optimize for interactive tasks may cause the scheduler providing one process an unfair amount of processor time, at the expense of the rest of the system. [p48]\n\n\n\n\nThe approach taken by CFS is a radical (for process schedulers) rethinking of timeslice allotment: Do away with timeslices completely and assign each process a proportion of the processor. CFS thus yields constant fairness but a variable switching rate.\n\n\nFair Scheduling\n\n\nCFS is based on a simple concept: Model process scheduling as if the system had an ideal, perfectly multitasking processor. In such a system, each process would receive 1/\nn\n of the processor\u2019s time, where \nn\n is the number of runnable processes, and we\u2019d schedule them for infinitely small durations, so that in any measurable period we\u2019d have run all \nn\n processes for the same amount of time. [p48]\n\n\nIt is not efficient to run processes for infinitely small durations; there is a switching cost to preempting one process for another: the overhead of swapping one process for another and the effects on caches. CFS will run each process for some amount of time, round-robin, selecting next the process that has run the least. Rather than assign each process a timeslice, CFS calculates how long a process should run as a function of the total number of runnable processes. Instead of using the nice value to calculate a timeslice, CFS uses the nice value to weight the proportion of processor a process is to receive. [p49]\n\n\nEach process runs for a \"timeslice\" proportional to its weight divided by the total weight of all runnable threads.\n CFS sets a target for its\napproximation of the \"infinitely small\" scheduling duration in perfect multitasking. This target is called the \ntargeted latency\n. Smaller targets yield better interactivity and a closer approximation to perfect multitasking, at the expense of higher switching costs and thus worse overall throughput.  CFS imposes a floor on the timeslice assigned to each process, called the \nminimum granularity\n (by default 1 millisecond). Even as the number of runnable processes approaches infinity, each will run for at least 1 millisecond, to ensure there is a ceiling on the incurred switching costs\n\n\nFor the nice value on weighting the proportion, consider the case of two runnable processes with disimilar nice values. One with the default nice value (zero) and one with a nice value of 5. In this case, the weights work out to about a 1\u20443 penalty for the nice-5 process. If our target latency is again 20 milliseconds, our two processes will receive 15 milliseconds and 5 milliseconds each of processor time, respectively. Put generally, the proportion of processor time that any process receives is determined only by the relative difference in niceness between it and the other runnable processes.  The nice values, instead of yielding additive increases to timeslices, yield geometric differences. [p49-50]\n\n\nThe Linux Scheduling Implementation\n\n\nCFS\u2019s actual implementation lives in \nkernel/sched_fair.c\n. Specifically,\nthis sections discusses four components of CFS:\n\n\n\n\nTime Accounting\n\n\nProcess Selection\n\n\nThe Scheduler Entry Point\n\n\nSleeping and Waking Up\n\n\n\n\nTime Accounting\n\n\nAll process schedulers must account for the time that a process runs. On each tick of the system clock, the timeslice is decremented by the tick period.When the timeslice reaches zero, the process is preempted in favor of another runnable process with a nonzero timeslice.\n\n\nThe Scheduler Entity Structure\n\n\nCFS does not have the notion of a timeslice, but it must still keep account for the time that each process runs. [p50]\n\n\nCFS uses the \nscheduler entity structure\n, \nstruct sched_entity\n, defined in \nlinux/sched.h\n (\ninclude/linux/sched.h#L1090\n), to keep track of process accounting:\n\n\nstruct\n \nsched_entity\n \n{\n\n    \nstruct\n \nload_weight\n \nload\n;\n\n    \nstruct\n \nrb_node\n \nrun_node\n;\n\n    \nstruct\n \nlist_head\n \ngroup_node\n;\n\n    \nunsigned\n \nint\n \non_rq\n;\n\n    \nu64\n \nexec_start\n;\n\n    \nu64\n \nsum_exec_runtime\n;\n\n    \nu64\n \nvruntime\n;\n\n    \nu64\n \nprev_sum_exec_runtime\n;\n\n    \nu64\n \nlast_wakeup\n;\n\n    \nu64\n \navg_overlap\n;\n\n    \nu64\n \nnr_migrations\n;\n\n    \nu64\n \nstart_runtime\n;\n\n    \nu64\n \navg_wakeup\n;\n\n\n\n/* many stat variables elided, enabled only if CONFIG_SCHEDSTATS is set */\n\n\n};\n\n\n\n\n\n\nThe scheduler entity structure is embedded in the process descriptor, \nstruct task_stuct\n, as a member variable named \nse\n (\ninclude/linux/sched.h#L1188\n).\n\n\nMapping of nice value to weight\n *\n\n\nThe mapping of nice to weight is defined in the \nprio_to_weight\n constant array (\nkernel/sched.c#L1362\n). The weight is roughly equivalent to \n1024/(1.25)^(nice)\n.\n\n\nstatic\n \nconst\n \nint\n \nprio_to_weight\n[\n40\n]\n \n=\n \n{\n\n \n/* -20 */\n     \n88761\n,\n     \n71755\n,\n     \n56483\n,\n     \n46273\n,\n     \n36291\n,\n\n \n/* -15 */\n     \n29154\n,\n     \n23254\n,\n     \n18705\n,\n     \n14949\n,\n     \n11916\n,\n\n \n/* -10 */\n      \n9548\n,\n      \n7620\n,\n      \n6100\n,\n      \n4904\n,\n      \n3906\n,\n\n \n/*  -5 */\n      \n3121\n,\n      \n2501\n,\n      \n1991\n,\n      \n1586\n,\n      \n1277\n,\n\n \n/*   0 */\n      \n1024\n,\n       \n820\n,\n       \n655\n,\n       \n526\n,\n       \n423\n,\n\n \n/*   5 */\n       \n335\n,\n       \n272\n,\n       \n215\n,\n       \n172\n,\n       \n137\n,\n\n \n/*  10 */\n       \n110\n,\n        \n87\n,\n        \n70\n,\n        \n56\n,\n        \n45\n,\n\n \n/*  15 */\n        \n36\n,\n        \n29\n,\n        \n23\n,\n        \n18\n,\n        \n15\n,\n\n\n};\n\n\n\n\n\n\nThe Virtual Runtime\n\n\nThe \nvruntime\n variable stores the \nvirtual runtime\n of a process, which is the actual runtime (the amount of time spent running) normalized (or weighted) by the number of runnable processes. The virtual runtime\u2019s units are nanoseconds and therefore \nvruntime\n is decoupled from the timer tick. Because processors are not capable of perfect multitasking and we must run each process in succession, CFS uses vruntime to account for how long a process has run and thus how much longer it ought to run.\n\n\nThe function \nupdate_curr()\n, defined in \nkernel/sched_fair.c\n (\nkernel/sched_fair.c#L518\n), manages this accounting:\n\n\nstatic\n \nvoid\n \nupdate_curr\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n)\n\n\n{\n\n    \nstruct\n \nsched_entity\n \n*\ncurr\n \n=\n \ncfs_rq\n-\ncurr\n;\n\n    \nu64\n \nnow\n \n=\n \nrq_of\n(\ncfs_rq\n)\n-\nclock\n;\n\n    \nunsigned\n \nlong\n \ndelta_exec\n;\n\n\n    \nif\n \n(\nunlikely\n(\n!\ncurr\n))\n\n        \nreturn\n;\n\n\n    \n/*\n\n\n     * Get the amount of time the current task was running\n\n\n     * since the last time we changed load (this cannot\n\n\n     * overflow on 32 bits):\n\n\n     */\n\n    \ndelta_exec\n \n=\n \n(\nunsigned\n \nlong\n)(\nnow\n \n-\n \ncurr\n-\nexec_start\n);\n\n    \nif\n \n(\n!\ndelta_exec\n)\n\n        \nreturn\n;\n\n\n    \n__update_curr\n(\ncfs_rq\n,\n \ncurr\n,\n \ndelta_exec\n);\n\n    \ncurr\n-\nexec_start\n \n=\n \nnow\n;\n\n\n    \nif\n \n(\nentity_is_task\n(\ncurr\n))\n \n{\n\n        \nstruct\n \ntask_struct\n \n*\ncurtask\n \n=\n \ntask_of\n(\ncurr\n);\n\n\n        \ntrace_sched_stat_runtime\n(\ncurtask\n,\n \ndelta_exec\n,\n \ncurr\n-\nvruntime\n);\n\n        \ncpuacct_charge\n(\ncurtask\n,\n \ndelta_exec\n);\n\n        \naccount_group_exec_runtime\n(\ncurtask\n,\n \ndelta_exec\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nupdate_curr()\n calculates the execution time of the current process and stores that value in \ndelta_exec\n. It then passes that runtime to \n__update_curr()\n, which weights the time by the number of runnable processes. The current process\u2019s vruntime is then incremented by the weighted value:\n\n\n/*\n\n\n * Update the current task\ns runtime statistics. Skip current tasks that\n\n\n * are not in our scheduling class.\n\n\n */\n\n\nstatic\n \ninline\n \nvoid\n\n\n__update_curr\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\ncurr\n,\n\n          \nunsigned\n \nlong\n \ndelta_exec\n)\n\n\n{\n\n    \nunsigned\n \nlong\n \ndelta_exec_weighted\n;\n\n\n    \nschedstat_set\n(\ncurr\n-\nexec_max\n,\n \nmax\n((\nu64\n)\ndelta_exec\n,\n \ncurr\n-\nexec_max\n));\n\n\n    \ncurr\n-\nsum_exec_runtime\n \n+=\n \ndelta_exec\n;\n\n    \nschedstat_add\n(\ncfs_rq\n,\n \nexec_clock\n,\n \ndelta_exec\n);\n\n    \ndelta_exec_weighted\n \n=\n \ncalc_delta_fair\n(\ndelta_exec\n,\n \ncurr\n);\n\n\n    \ncurr\n-\nvruntime\n \n+=\n \ndelta_exec_weighted\n;\n\n    \nupdate_min_vruntime\n(\ncfs_rq\n);\n\n\n}\n\n\n\n\n\n\nupdate_curr()\n is invoked periodically by the system timer and also whenever a process becomes runnable or blocks, becoming unrunnable. In this manner, vruntime is an accurate measure of the runtime of a given process and an indicator of what process should run next.\n\n\nThe \ncalc_delta_fair()\n function\n\n\n__update_curr()\n calls \ncalc_delta_fair()\n, which in turn calls \ncalc_delta_mine()\n (if \nse-\nload.weight\n does not equal \nNICE_0_LOAD\n) to calculate the weighted value:\n\n\nkernel/sched_fair.c#L431\n\n\n/*\n\n\n * delta /= w\n\n\n */\n\n\nstatic\n \ninline\n \nunsigned\n \nlong\n\n\ncalc_delta_fair\n(\nunsigned\n \nlong\n \ndelta\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nif\n \n(\nunlikely\n(\nse\n-\nload\n.\nweight\n \n!=\n \nNICE_0_LOAD\n))\n\n        \ndelta\n \n=\n \ncalc_delta_mine\n(\ndelta\n,\n \nNICE_0_LOAD\n,\n \nse\n-\nload\n);\n\n\n    \nreturn\n \ndelta\n;\n\n\n}\n\n\n\n\n\n\nkernel/sched.c#L1300\n\n\n/*\n\n\n * delta *= weight / lw\n\n\n */\n\n\nstatic\n \nunsigned\n \nlong\n\n\ncalc_delta_mine\n(\nunsigned\n \nlong\n \ndelta_exec\n,\n \nunsigned\n \nlong\n \nweight\n,\n\n        \nstruct\n \nload_weight\n \n*\nlw\n)\n\n\n{\n\n    \nu64\n \ntmp\n;\n\n\n    \nif\n \n(\n!\nlw\n-\ninv_weight\n)\n \n{\n\n        \nif\n \n(\nBITS_PER_LONG\n \n \n32\n \n \nunlikely\n(\nlw\n-\nweight\n \n=\n \nWMULT_CONST\n))\n\n            \nlw\n-\ninv_weight\n \n=\n \n1\n;\n\n        \nelse\n\n            \nlw\n-\ninv_weight\n \n=\n \n1\n \n+\n \n(\nWMULT_CONST\n-\nlw\n-\nweight\n/\n2\n)\n\n                \n/\n \n(\nlw\n-\nweight\n+\n1\n);\n\n    \n}\n\n\n    \ntmp\n \n=\n \n(\nu64\n)\ndelta_exec\n \n*\n \nweight\n;\n\n    \n/*\n\n\n     * Check whether we\nd overflow the 64-bit multiplication:\n\n\n     */\n\n    \nif\n \n(\nunlikely\n(\ntmp\n \n \nWMULT_CONST\n))\n\n        \ntmp\n \n=\n \nSRR\n(\nSRR\n(\ntmp\n,\n \nWMULT_SHIFT\n/\n2\n)\n \n*\n \nlw\n-\ninv_weight\n,\n\n            \nWMULT_SHIFT\n/\n2\n);\n\n    \nelse\n\n        \ntmp\n \n=\n \nSRR\n(\ntmp\n \n*\n \nlw\n-\ninv_weight\n,\n \nWMULT_SHIFT\n);\n\n\n    \nreturn\n \n(\nunsigned\n \nlong\n)\nmin\n(\ntmp\n,\n \n(\nu64\n)(\nunsigned\n \nlong\n)\nLONG_MAX\n);\n\n\n}\n\n\n\n\n\n\nThis can be summarized as:\n\n\ndelta_exec_weighted = delta_exec * NICE_0_LOAD / se-\nload\n\n\n\n\n\nFor division details, see \nExplanation of the calc_delta_mine function\n.\n\n\nProcess Selection\n\n\nCFS attempts to balance a process\u2019s virtual runtime with a simple rule: \nwhen deciding what process to run next, it picks the process with the smallest \nvruntime\n.\n\n\nCFS uses a \nred-black tree\n to manage the list of runnable processes and efficiently find the process with the smallest \nvruntime\n. A red-black tree, called an \nrbtree\n in Linux (\ninclude/linux/rbtree.h\n, \nlib/rbtree.c\n), is a type of \nself-balancing binary search tree\n. It is a data structure that store nodes of arbitrary data, identified by a specific key, and that they enable efficient search for a given key. Specifically, obtaining a node identified by a given key is logarithmic in time as a function of total nodes in the tree.\n\n\nPicking the Next Task\n\n\nThe process that CFS wants to run next, which is the process with the smallest \nvruntime\n, is the leftmost node in the tree. If you follow the tree from the root down through the left child, and continue moving to the left until you reach a leaf node, you find the process with the smallest \nvruntime\n. CFS\u2019s process selection algorithm is thus summed up as \"run the process represented by the leftmost node in the rbtree.\" [p53]\n\n\nThe function that performs this selection is \n__pick_next_entity()\n, defined in \nkernel/sched_fair.c\n(\nkernel/sched_fair.c#L377\n):\n\n\nstatic\n \nstruct\n \nsched_entity\n \n*\n__pick_next_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n)\n\n\n{\n\n    \nstruct\n \nrb_node\n \n*\nleft\n \n=\n \ncfs_rq\n-\nrb_leftmost\n;\n\n\n    \nif\n \n(\n!\nleft\n)\n\n        \nreturn\n \nNULL\n;\n\n\n    \nreturn\n \nrb_entry\n(\nleft\n,\n \nstruct\n \nsched_entity\n,\n \nrun_node\n);\n\n\n}\n\n\n\n\n\n\nNote that \n__pick_next_entity()\n does not actually traverse the tree to find the leftmost node, because the value is cached by \nrb_leftmost\n, though it is efficient to walk the tree to find the leftmost node (\nO(height of tree)\n, which is \nO(log N)\n for \nN\n nodes if the tree is balanced).\n\n\nThe return value from this function is the process that CFS next runs. If the function returns NULL, there is no leftmost node, and thus no nodes in the tree. In that case, there are no runnable processes, and CFS schedules the idle task.\n\n\nAdding Processes to the Tree\n\n\nCFS adds processes to the rbtree and caches the leftmost node, when a process becomes runnable (wakes up) or is first created via \nfork()\n. Adding processes to the tree is performed by \nenqueue_entity()\n:\n\n\nkernel/sched_fair.c#L773\n\n\nstatic\n \nvoid\n\n\nenqueue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n,\n \nint\n \nflags\n)\n\n\n{\n\n    \n/*\n\n\n     * Update the normalized vruntime before updating min_vruntime\n\n\n     * through callig update_curr().\n\n\n     */\n\n    \nif\n \n(\n!\n(\nflags\n \n \nENQUEUE_WAKEUP\n)\n \n||\n \n(\nflags\n \n \nENQUEUE_MIGRATE\n))\n\n        \nse\n-\nvruntime\n \n+=\n \ncfs_rq\n-\nmin_vruntime\n;\n\n\n    \n/*\n\n\n     * Update run-time statistics of the \ncurrent\n.\n\n\n     */\n\n    \nupdate_curr\n(\ncfs_rq\n);\n\n    \naccount_entity_enqueue\n(\ncfs_rq\n,\n \nse\n);\n\n\n    \nif\n \n(\nflags\n \n \nENQUEUE_WAKEUP\n)\n \n{\n\n        \nplace_entity\n(\ncfs_rq\n,\n \nse\n,\n \n0\n);\n\n        \nenqueue_sleeper\n(\ncfs_rq\n,\n \nse\n);\n\n    \n}\n\n\n    \nupdate_stats_enqueue\n(\ncfs_rq\n,\n \nse\n);\n\n    \ncheck_spread\n(\ncfs_rq\n,\n \nse\n);\n\n    \nif\n \n(\nse\n \n!=\n \ncfs_rq\n-\ncurr\n)\n\n        \n__enqueue_entity\n(\ncfs_rq\n,\n \nse\n);\n\n\n}\n\n\n\n\n\n\nThis function updates the runtime and other statistics and then invokes \n__enqueue_entity()\n to perform the actual heavy lifting of inserting the entry into the red-black tree.\n\n\nkernel/sched_fair.c#L328\n\n\n/*\n\n\n * Enqueue an entity into the rb-tree:\n\n\n */\n\n\nstatic\n \nvoid\n \n__enqueue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nstruct\n \nrb_node\n \n**\nlink\n \n=\n \ncfs_rq\n-\ntasks_timeline\n.\nrb_node\n;\n\n    \nstruct\n \nrb_node\n \n*\nparent\n \n=\n \nNULL\n;\n\n    \nstruct\n \nsched_entity\n \n*\nentry\n;\n\n    \ns64\n \nkey\n \n=\n \nentity_key\n(\ncfs_rq\n,\n \nse\n);\n\n    \nint\n \nleftmost\n \n=\n \n1\n;\n\n\n    \n/*\n\n\n     * Find the right place in the rbtree:\n\n\n     */\n\n    \nwhile\n \n(\n*\nlink\n)\n \n{\n\n        \nparent\n \n=\n \n*\nlink\n;\n\n        \nentry\n \n=\n \nrb_entry\n(\nparent\n,\n \nstruct\n \nsched_entity\n,\n \nrun_node\n);\n\n        \n/*\n\n\n         * We dont care about collisions. Nodes with\n\n\n         * the same key stay together.\n\n\n         */\n\n        \nif\n \n(\nkey\n \n \nentity_key\n(\ncfs_rq\n,\n \nentry\n))\n \n{\n\n            \nlink\n \n=\n \nparent\n-\nrb_left\n;\n\n        \n}\n \nelse\n \n{\n\n            \nlink\n \n=\n \nparent\n-\nrb_right\n;\n\n            \nleftmost\n \n=\n \n0\n;\n\n        \n}\n\n    \n}\n\n\n    \n/*\n\n\n     * Maintain a cache of leftmost tree entries (it is frequently\n\n\n     * used):\n\n\n     */\n\n    \nif\n \n(\nleftmost\n)\n\n        \ncfs_rq\n-\nrb_leftmost\n \n=\n \nse\n-\nrun_node\n;\n\n\n    \nrb_link_node\n(\nse\n-\nrun_node\n,\n \nparent\n,\n \nlink\n);\n\n    \nrb_insert_color\n(\nse\n-\nrun_node\n,\n \ncfs_rq\n-\ntasks_timeline\n);\n\n\n}\n\n\n\n\n\n\nThis function traverses the tree in the \nwhile()\n loop to search for a matching key (inserted process\u2019s \nvruntime\n). It moves to the left child if the key is smaller than the current node\u2019s key and to the right child if the key is larger.  If it ever moves to the right, even once, it knows the inserted process cannot be the new leftmost node, and it sets leftmost to zero. If it moves only to the left, \nleftmost\n remains one, and we have a new leftmost node and can update the cache by setting \nrb_leftmost\n to the inserted process. When out of the loop, the function calls \nrb_link_node()\n on the parent node, making the inserted process the new child. The function \nrb_insert_color()\n updates the self-balancing properties of the tree.\n\n\nRemoving Processes from the Tree\n\n\nCFS removes processes from the red-black tree when a process blocks (becomes unrunnable) or terminates (ceases to exist):\n\n\nkernel/sched_fair.c#L815\n\n\nstatic\n \nvoid\n\n\ndequeue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n,\n \nint\n \nsleep\n)\n\n\n{\n\n    \n/*\n\n\n     * Update run-time statistics of the \ncurrent\n.\n\n\n     */\n\n    \nupdate_curr\n(\ncfs_rq\n);\n\n\n    \nupdate_stats_dequeue\n(\ncfs_rq\n,\n \nse\n);\n\n    \nclear_buddies\n(\ncfs_rq\n,\n \nse\n);\n\n\n    \nif\n \n(\nse\n \n!=\n \ncfs_rq\n-\ncurr\n)\n\n        \n__dequeue_entity\n(\ncfs_rq\n,\n \nse\n);\n\n    \naccount_entity_dequeue\n(\ncfs_rq\n,\n \nse\n);\n\n    \nupdate_min_vruntime\n(\ncfs_rq\n);\n\n\n    \n/*\n\n\n     * Normalize the entity after updating the min_vruntime because the\n\n\n     * update can refer to the -\ncurr item and we need to reflect this\n\n\n     * movement in our normalized position.\n\n\n     */\n\n    \nif\n \n(\n!\nsleep\n)\n\n        \nse\n-\nvruntime\n \n-=\n \ncfs_rq\n-\nmin_vruntime\n;\n\n\n}\n\n\n\n\n\n\nSimilarly, the real work is performed by a helper function, \n__dequeue_entity()\n:\n\n\nstatic\n \nvoid\n \n__dequeue_entity\n(\nstruct\n \ncfs_rq\n \n*\ncfs_rq\n,\n \nstruct\n \nsched_entity\n \n*\nse\n)\n\n\n{\n\n    \nif\n \n(\ncfs_rq\n-\nrb_leftmost\n \n==\n \nse\n-\nrun_node\n)\n \n{\n\n        \nstruct\n \nrb_node\n \n*\nnext_node\n;\n\n\n        \nnext_node\n \n=\n \nrb_next\n(\nse\n-\nrun_node\n);\n\n        \ncfs_rq\n-\nrb_leftmost\n \n=\n \nnext_node\n;\n\n    \n}\n\n\n    \nrb_erase\n(\nse\n-\nrun_node\n,\n \ncfs_rq\n-\ntasks_timeline\n);\n\n\n}\n\n\n\n\n\n\nRemoving a process from the tree is much simpler because the rbtree implementation provides the \nrb_erase()\n function that performs all the work. The rest of this function updates the \nrb_leftmost\n cache. If the process-to-remove is the leftmost node, the function invokes \nrb_next()\n to find what would be the next node in an in-order traversal. This is what will be the leftmost node when the current leftmost node is removed.\n\n\nThe Scheduler Entry Point\n\n\nThe main entry point into the process schedule is the function \nschedule()\n, defined in \nkernel/sched.c\n (\nkernel/sched.c#L3701\n). This is the function that the rest of the kernel uses to invoke the process scheduler, deciding which process to run and then running it.\n\n\nschedule()\n is generic to scheduler classes. It finds the highest priority scheduler class with a runnable process and asks it what to run next.\n Thus, \nschedule()\n is simple. The only important part of the function is its invocation of \npick_next_task()\n, defined in \nkernel/sched.c\n (\nkernel/sched.c#L3670\n), which goes through each scheduler class, starting with the highest priority, and selects the highest priority process in the highest priority class:\n\n\n/*\n\n\n * Pick up the highest-prio task:\n\n\n */\n\n\nstatic\n \ninline\n \nstruct\n \ntask_struct\n \n*\n\n\npick_next_task\n(\nstruct\n \nrq\n \n*\nrq\n)\n\n\n{\n\n    \nconst\n \nstruct\n \nsched_class\n \n*\nclass\n;\n\n    \nstruct\n \ntask_struct\n \n*\np\n;\n\n\n    \n/*\n\n\n     * Optimization: we know that if all tasks are in\n\n\n     * the fair class we can call that function directly:\n\n\n     */\n\n    \nif\n \n(\nlikely\n(\nrq\n-\nnr_running\n \n==\n \nrq\n-\ncfs\n.\nnr_running\n))\n \n{\n\n        \np\n \n=\n \nfair_sched_class\n.\npick_next_task\n(\nrq\n);\n\n        \nif\n \n(\nlikely\n(\np\n))\n\n            \nreturn\n \np\n;\n\n    \n}\n\n\n    \nclass\n \n=\n \nsched_class_highest\n;\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \np\n \n=\n \nclass\n-\npick_next_task\n(\nrq\n);\n\n        \nif\n \n(\np\n)\n\n            \nreturn\n \np\n;\n\n        \n/*\n\n\n         * Will never be NULL as the idle class always\n\n\n         * returns a non-NULL p:\n\n\n         */\n\n        \nclass\n \n=\n \nclass\n-\nnext\n;\n\n    \n}\n\n\n}\n\n\n\n\n\n\nNote the optimization at the beginning of the function. CFS is the scheduler class for normal processes, and most systems run mostly normal processes, there is a small hack to quickly select the next CFS-provided process if the number of runnable processes is equal to the number of CFS runnable processes (which suggests that all runnable processes are provided by CFS).\n\n\nThe core of the function is the \nfor()\n loop, which iterates over each class in priority order, starting with the highest priority class. Each class implements the \npick_next_task()\n function, which returns a pointer to its next runnable process or, if there is not one, \nNULL\n.The first class to return a non-\nNULL\n value has selected the next runnable process. CFS\u2019s implementation of \npick_next_task()\n calls \npick_next_entity()\n, which in turn calls the \n__pick_next_entity()\n function (see \nPicking the Next Task\n in the previous section).\n\n\nfair_sched_class\n scheduler class\n *\n\n\nfair_sched_class\n is a \nstruct sched_class\n (defined in \ninclude/linux/sched.h\n) structure defined in \nkernel/sched_fair.c\n (\nkernel/sched_fair.c#L3688\n). \nkernel/sched_fair.c\n is included by \nkernel/sched.c\n (\nkernel/sched.c#L1936\n), so \nfair_sched_class\n is avaialble to the \npick_next_task\n function in \n/kernel/sched.c\n.\n\n\nSleeping and Waking Up\n\n\nTasks that are sleeping (blocked) are in a special non-runnable state. [p58]\n\n\nA task sleeps while it is waiting for some event, which may be:\n\n\n\n\na specified amount of time;\n\n\nmore data from a file I/O;\n\n\nanother hardware event\n\n\n\n\nA task can also involuntarily go to sleep when it tries to obtain a contended semaphore in the kernel.\n\n\nWhatever the case, the kernel behavior is the same. The task does the following in turn:\n\n\n\n\nmarks itself as sleeping,\n\n\nputs itself on a wait queue,\n\n\nremoves itself from the red-black tree of runnable,\n\n\nand calls \nschedule()\n to select a new process to execute.\n\n\n\n\nWaking back up is the inverse: The task is set as runnable, removed from the wait queue, and added back to the red-black tree.\n\n\nTwo states are associated with sleeping:\n\n\n\n\nTASK_INTERRUPTIBLE\n\n\nTASK_UNINTERRUPTIBLE\n\n\n\n\nThey differ only in that tasks in the \nTASK_UNINTERRUPTIBLE\n state ignore signals, whereas tasks in the \nTASK_INTERRUPTIBLE\n state wake up prematurely and respond to a signal if one is issued. Both types of sleeping tasks sit on a wait queue, waiting for an event to occur, and are not runnable.\n\n\nWait Queues\n\n\nSleeping is handled via wait queues. A wait queue is a simple list of processes waiting for an event to occur.\n\n\nWait queues are represented in the kernel by \nwake_queue_head_t\n. They are created statically via \nDECLARE_WAITQUEUE()\n or dynamically via \ninit_waitqueue_head()\n. Processes put themselves on a wait queue and mark themselves not runnable. When the event associated with the wait queue occurs, the processes on the queue are awakened.\n\n\nIt is important to implement sleeping and waking correctly, to avoid race conditions. Otherwise, it is possible to go to sleep after the condition becomes true, in which case the task might sleep indefinitely. Therefore, the recommended method for sleeping in the kernel is a bit more complicated:\n\n\n/* `q\n is the wait queue we wish to sleep on */\n\n\nDEFINE_WAIT\n(\nwait\n);\n\n\n\nadd_wait_queue\n(\nq\n,\n \nwait\n);\n\n\nwhile\n \n(\n!\ncondition\n)\n \n{\n \n/* condition is the event that we are waiting for */\n\n    \nprepare_to_wait\n(\nq\n,\n \nwait\n,\n \nTASK_INTERRUPTIBLE\n);\n\n    \nif\n \n(\nsignal_pending\n(\ncurrent\n))\n\n        \n/* handle signal */\n\n    \nschedule\n();\n\n\n}\n\n\nfinish_wait\n(\nq\n,\n \nwait\n);\n\n\n\n\n\n\nThe task performs the following steps to add itself to a wait queue:\n\n\n\n\nCreates a wait queue entry via the macro \nDEFINE_WAIT()\n.\n\n\nAdds itself to a wait queue via \nadd_wait_queue()\n. This wait queue awakens the process when the condition for which it is waiting occurs. Of course, there needs to be code elsewhere that calls wake_up() on the queue when the event actually does occur.\n\n\nCalls \nprepare_to_wait()\n to change the process state to either \nTASK_INTERRUPTIBLE\n or \nTASK_UNINTERRUPTIBLE\n. This function also adds the task back to the wait queue if necessary, which is needed on subsequent iterations of the loop.\n\n\nIf the state is set to \nTASK_INTERRUPTIBLE\n, a signal wakes the process up. This is called a \nspurious wake up\n (a wake-up not caused by the occurrence of the event). So check and handle signals.\n\n\nWhen the task awakens, it again checks whether the condition is true. If it is, it exits the loop. Otherwise, it again calls \nschedule()\n and repeats.\n\n\nAfter the condition is true, the task sets itself to \nTASK_RUNNING\n and removes itself from the wait queue via \nfinish_wait()\n.\n\n\n\n\nIf the condition occurs before the task goes to sleep, the loop terminates, and the task does not erroneously go to sleep. Note that kernel code often has to perform various other tasks in the body of the loop. For example, it might need to release locks before calling \nschedule()\n and reacquire them after or react to other events.\n\n\nThe function \ninotify_read()\n in \nfs/notify/inotify/inotify_user.c\n, which handles reading from the inotify file descriptor, is a straightforward example of using wait queues:\n\n\nstatic\n \nssize_t\n \ninotify_read\n(\nstruct\n \nfile\n \n*\nfile\n,\n \nchar\n \n__user\n \n*\nbuf\n,\n\n                \nsize_t\n \ncount\n,\n \nloff_t\n \n*\npos\n)\n\n\n{\n\n    \nstruct\n \nfsnotify_group\n \n*\ngroup\n;\n\n    \nstruct\n \nfsnotify_event\n \n*\nkevent\n;\n\n    \nchar\n \n__user\n \n*\nstart\n;\n\n    \nint\n \nret\n;\n\n    \nDEFINE_WAIT\n(\nwait\n);\n\n\n    \nstart\n \n=\n \nbuf\n;\n\n    \ngroup\n \n=\n \nfile\n-\nprivate_data\n;\n\n\n    \nwhile\n \n(\n1\n)\n \n{\n\n        \nprepare_to_wait\n(\ngroup\n-\nnotification_waitq\n,\n \nwait\n,\n \nTASK_INTERRUPTIBLE\n);\n\n\n        \nmutex_lock\n(\ngroup\n-\nnotification_mutex\n);\n\n        \nkevent\n \n=\n \nget_one_event\n(\ngroup\n,\n \ncount\n);\n\n        \nmutex_unlock\n(\ngroup\n-\nnotification_mutex\n);\n\n\n        \nif\n \n(\nkevent\n)\n \n{\n\n            \nret\n \n=\n \nPTR_ERR\n(\nkevent\n);\n\n            \nif\n \n(\nIS_ERR\n(\nkevent\n))\n\n                \nbreak\n;\n\n            \nret\n \n=\n \ncopy_event_to_user\n(\ngroup\n,\n \nkevent\n,\n \nbuf\n);\n\n            \nfsnotify_put_event\n(\nkevent\n);\n\n            \nif\n \n(\nret\n \n \n0\n)\n\n                \nbreak\n;\n\n            \nbuf\n \n+=\n \nret\n;\n\n            \ncount\n \n-=\n \nret\n;\n\n            \ncontinue\n;\n\n        \n}\n\n\n        \nret\n \n=\n \n-\nEAGAIN\n;\n\n        \nif\n \n(\nfile\n-\nf_flags\n \n \nO_NONBLOCK\n)\n\n            \nbreak\n;\n\n        \nret\n \n=\n \n-\nEINTR\n;\n\n        \nif\n \n(\nsignal_pending\n(\ncurrent\n))\n\n            \nbreak\n;\n\n\n        \nif\n \n(\nstart\n \n!=\n \nbuf\n)\n\n            \nbreak\n;\n\n\n        \nschedule\n();\n\n    \n}\n\n\n    \nfinish_wait\n(\ngroup\n-\nnotification_waitq\n,\n \nwait\n);\n\n    \nif\n \n(\nstart\n \n!=\n \nbuf\n \n \nret\n \n!=\n \n-\nEFAULT\n)\n\n        \nret\n \n=\n \nbuf\n \n-\n \nstart\n;\n\n    \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\nSome notes of the function above:\n\n\n\n\nIt checks for the condition in the body of the \nwhile()\n loop, instead of in the \nwhile()\n statement itself, since checking the condition is complicated and requires grabbing locks.\n\n\nThe loop is terminated via \nbreak\n.\n\n\n\n\nWaking Up\n\n\nwake_up()\n wakes up all the tasks waiting on the given wait queue. It does the following:\n\n\n\n\nCalls \ntry_to_wake_up()\n, which sets the task\u2019s state to \nTASK_RUNNING\n\n\nCalls \nenqueue_task()\n to add the task to the red-black tree\n\n\nSets \nneed_resched\n if the awakened task\u2019s priority is higher than the priority of the current task. \nThe code that causes the event to occur typically calls \nwake_up()\n itself\n.\n\n\nFor example, when data arrives from the hard disk, the VFS calls \nwake_up()\n on the wait queue that holds the processes waiting for the data.\n\n\n\n\n\n\n\n\nSince there are spurious wake-ups, just because a task is awakened does not mean that the event for which the task is waiting has occurred. Sleeping should always be handled in a loop that ensures that the condition for which the task is waiting has indeed occurred.\nThe figure below depicts the relationship between each scheduler state.\n\n\n\n\nPreemption and Context Switching\n\n\nContext switching, the switching from one runnable task to another, is handled by the \ncontext_switch()\n function defined in \nkernel/sched.c\n. It is called by \nschedule()\n when a new process has been selected to run. It does two basic jobs:\n\n\n\n\nCalls \nswitch_mm()\n, declared in \nasm/mmu_context.h\n, to switch the virtual memory mapping from the previous process\u2019s to that of the new process.\n\n\nCalls \nswitch_to()\n, declared in \nasm/system.h\n, to switch the processor state from the previous process\u2019s to the current\u2019s. This involves saving and restoring stack information and the processor registers and any other architecture-specific state that must be managed and restored on a per-process basis.\n\n\n\n\nThe \nneed_resched\n flag *\n\n\nThe kernel must know when to call \nschedule()\n. If it called \nschedule()\n only when code explicitly did so, user-space programs could run indefinitely.\n\n\nThe kernel provides the \nneed_resched\n flag to signify whether a reschedule should be performed.\n\n\n\n\nThis flag is set by \nscheduler_tick()\n (in timer interrupt handler, see \nThe Timer Interrupt Handler\n) when a process should be preempted.\n\n\nThis flag is set by \ntry_to_wake_up()\n when a process that has a higher priority than the currently running process is awakened.\n\n\n\n\nThe kernel checks the flag, sees that it is set, and calls \nschedule()\n to switch to a new process. The flag is a message to the kernel that the scheduler should be invoked as soon as possible because another process deserves to run.\n\n\nUpon returning to user-space or returning from an interrupt, the \nneed_resched\n flag is checked. If it is set, the kernel invokes the scheduler before continuing.\n\n\nThe table below lists functions for accessing and manipulating \nneed_resched\n:\n\n\n\n\n\n\n\n\nFunction\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\nset_tsk_need_resched()\n\n\nSet the \nneed_resched\n flag in the given process.\n\n\n\n\n\n\nclear_tsk_need_resched()\n\n\nClear the \nneed_resched\n flag in the given process.\n\n\n\n\n\n\nneed_resched()\n\n\nTest the value of the \nneed_resched\n flag; return true if set and false otherwise.\n\n\n\n\n\n\n\n\nThe flag is per-process, and not simply global, because it is faster to access a value in the process descriptor (because of the speed of current and high probability of it being cache hot) than a global variable. Historically, the flag was global before the 2.2 kernel. In 2.2 and 2.4, the flag was an int inside the \ntask_struct\n. In 2.6, it was moved into a single bit of a special flag variable inside the \nthread_info\n structure (\narch/x86/include/asm/thread_info.h#L26\n).\n\n\nUser Preemption\n\n\nUser preemption occurs when the kernel is about to return to user-space, \nneed_resched\n is set, and therefore, the scheduler is invoked. If the kernel is returning to user-space, it knows it is in a safe quiescent state. In other words, if it is safe to continue executing the current task, it is also safe to pick a new task to execute.\n\n\nWhenever the kernel is preparing to return to user-space either on return from an interrupt or after a system call, the value of \nneed_resched\n is checked. If it is set, the scheduler is invoked to select a new (more fit) process to execute. Both the return paths for return from interrupt and return from system call are architecture-dependent and typically implemented in assembly in \nentry.S\n (which, aside from kernel entry code, also contains kernel exit code).\n\n\nIn conclusion, user preemption can occur:\n\n\n\n\nWhen returning to user-space from a system call\n\n\nWhen returning to user-space from an interrupt handler\n\n\n\n\nKernel Preemption\n\n\nIn non-preemptive kernels, kernel code runs until completion. That is, the scheduler cannot reschedule a task while it is in the kernel: kernel code is\nscheduled cooperatively, not preemptively. Kernel code runs until it finishes (returns to user-space) or explicitly blocks.\n\n\nThe Linux kernel (since 2.6), unlike most other Unix variants and many other operating systems, is a fully preemptive kernel. It is possible to preempt a task at any point, so long as the kernel is in a state in which it is safe to reschedule.\n\n\nThe kernel can preempt a task running in the kernel so long as it does not hold a lock. Locks are used as markers of regions of non-preemptibility. \nBecause the kernel is SMP-safe, if a lock is not held, the current code is reentrant and capable of being preempted.\n\n\nThe preemption counter \npreempt_count\n *\n\n\nTo support kernel preemption, preemption counter, \npreempt_count\n (\narch/x86/include/asm/thread_info.h#L32\n), was added to each process\u2019s \nthread_info\n. This counter begins at zero and increments once for each lock that is acquired and decrements once for each lock that is released.When the counter is zero, the kernel is preemptible. Upon return from interrupt, if returning to kernel-space, the kernel checks the values of \nneed_resched\n and \npreempt_count\n:\n\n\n\n\nIf \nneed_resched\n is set and \npreempt_count\n is zero, then a more important task is runnable, and it is safe to preempt. Thus, the scheduler is invoked.\n\n\nIf \npreempt_count\n is nonzero, a lock is held, and it is unsafe to reschedule. In that case, the interrupt returns as usual to the currently executing task.\n\n\n\n\nEnabling and disabling kernel preemption is sometimes required in kernel code (discussed in \nChapter 9\n).\n\n\nExplicit kernel preemption\n *\n\n\nKernel preemption can also occur explicitly, when a task in ther kernel does either of the following:\n\n\n\n\nBlocks,\n\n\nExplicitly calls \nschedule()\n.\n\n\n\n\nThis form of kernel preemption has always been supported because no additional logic is required to ensure that the kernel is in a state that is safe to preempt. It is assumed that the code that explicitly calls \nschedule()\n knows it is safe to reschedule.\n\n\nIn conclusion, kernel preemption can occur:\n\n\n\n\nWhen an interrupt handler exits, before returning to kernel-space\n\n\nWhen kernel code becomes preemptible again\n\n\nIf a task in the kernel explicitly calls \nschedule()\n\n\nIf a task in the kernel blocks (which results in a call to \nschedule()\n)\n\n\n\n\nReal-Time Scheduling Policies\n\n\nLinux provides two real-time scheduling policies:\n\n\n\n\nSCHED_FIFO\n\n\nSCHED_RR\n\nThe normal, not real-time scheduling policy is \nSCHED_NORMAL\n.\n\n\n\n\nVia the \nscheduling classes\n framework, these real-time policies are managed not by the Completely Fair Scheduler, but by a special real-time scheduler, defined in \nkernel/sched_rt.c\n.\n\n\nThe \nSCHED_FIFO\n policy *\n\n\nSCHED_FIFO\n implements a simple first-in, first-out scheduling algorithm without timeslices.\n\n\n\n\nA runnable \nSCHED_FIFO\n task is always scheduled over any \nSCHED_NORMAL\n tasks.\n\n\nWhen a \nSCHED_FIFO\n task becomes runnable, it continues to run until it blocks or explicitly yields the processor; it has no timeslice and can run indefinitely\n\n\nOnly a higher priority \nSCHED_FIFO\n or \nSCHED_RR\n task can preempt a \nSCHED_FIFO\n task.\n\n\nTwo or more \nSCHED_FIFO\n tasks at the same priority run round-robin, but only yielding the processor when they explicitly choose to do so.\n\n\nIf a \nSCHED_FIFO\n task is runnable, all other tasks at a lower priority cannot run until the \nSCHED_FIFO\n task becomes unrunnable.\n\n\n\n\nThe \nSCHED_RR\n policy *\n\n\nSCHED_RR\n is identical to \nSCHED_FIFO\n except that each process can run only until it exhausts a predetermined timeslice. In other words, \nSCHED_RR\n is \nSCHED_FIFO\n with timeslices. It is a real-time, round-robin scheduling algorithm.\n\n\n\n\nWhen a \nSCHED_RR\n task exhausts its timeslice, any other real-time processes at its priority are scheduled round-robin. The timeslice is used to allow only rescheduling of same-priority processes.\n\n\nAs with \nSCHED_FIFO\n, a higher-priority process always immediately preempts a lower-priority one, and a lower-priority process can never preempt a \nSCHED_RR\n task, even if its timeslice is exhausted.\n\n\n\n\nBoth real-time scheduling policies implement static priorities. The kernel does not calculate dynamic priority values for real-time tasks.This ensures that a real-time process at a given priority always preempts a process at a lower priority.\n\n\nHard real-time and soft real-time\n\n\n\n\nSoft real-time\n means that the kernel tries to schedule applications within timing deadlines, but the kernel does not promise to always achieve these goals.\n\n\nHard real-time\n systems are guaranteed to meet any scheduling requirements within certain limits.\n\n\n\n\nThe real-time scheduling policies in Linux provide soft real-time behavior. Linux makes no guarantees on the capability to schedule real-time tasks. Despite not having a design that guarantees hard real-time behavior, the real-time scheduling performance in Linux is quite good. The 2.6 Linux kernel is capable of meeting stringent timing requirements.\n\n\nReal-time priorities range inclusively from 0 to \nMAX_RT_PRIO\n - 1. By default, this range is 0 to 99, since \nMAX_RT_PRIO\n is 100. This priority space is shared with the nice values of \nSCHED_NORMAL\n tasks: They use the space from \nMAX_RT_PRIO\n to (\nMAX_RT_PRIO\n + 40).  By default, this means the \u201320 to +19 nice range maps directly onto the priority space from 100 to 139.\n\n\nDefault priority ranges:\n\n\n\n\n0 to 99: real-time priorities\n\n\n100 to 139: normal priorities\n\n\n\n\nScheduler-Related System Calls\n\n\nLinux provides a family of system calls for the management of scheduler parameters, which allow manipulation of process priority, scheduling policy, and processor affinity, \nyielding\n the processor to other tasks.\n\n\nThe table below lists the system calls with brief descriptions. Their implementation in the kernel is discussed in \nChapter 5\n.\n\n\n\n\n\n\n\n\nSystem Call\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nnice()\n\n\nSets a process\u2019s nice value\n\n\n\n\n\n\nsched_setscheduler()\n\n\nSets a process\u2019s scheduling policy\n\n\n\n\n\n\nsched_getscheduler()\n\n\nGets a process\u2019s scheduling policy\n\n\n\n\n\n\nsched_setparam()\n\n\nSets a process\u2019s real-time priority\n\n\n\n\n\n\nsched_getparam()\n\n\nGets a process\u2019s real-time priority\n\n\n\n\n\n\nsched_get_priority_max()\n\n\nGets the maximum real-time priority\n\n\n\n\n\n\nsched_get_priority_min()\n\n\nGets the minimum real-time priority\n\n\n\n\n\n\nsched_rr_get_interval()\n\n\nGets a process\u2019s timeslice value\n\n\n\n\n\n\nsched_setaffinity()\n\n\nSets a process\u2019s processor affinity\n\n\n\n\n\n\nsched_getaffinity()\n\n\nGets a process\u2019s processor affinity\n\n\n\n\n\n\nsched_yield()\n\n\nTemporarily yields the processor\n\n\n\n\n\n\n\n\nScheduling Policy and Priority-Related System Calls\n\n\n\n\nThe \nsched_setscheduler()\n and \nsched_getscheduler()\n system calls set and get a given process\u2019s scheduling policy and real-time priority. The major work  of these functions is merely to read or write the \npolicy\n and \nrt_priority\n values in the process\u2019s \ntask_struct\n. [p66]\n\n\nThe \nsched_setparam()\n and \nsched_getparam()\n system calls set and get a process\u2019s real-time priority. These calls merely encode \nrt_priority\n in a special \nsched_param\n structure (\ninclude/linux/sched.h#L46\n).\n\n\nThe calls \nsched_get_priority_max()\n and \nsched_get_priority_min()\n return the maximum and minimum priorities, respectively, for a given scheduling policy. The maximum priority for the real-time policies is \nMAX_USER_RT_PRIO\n minus one; the minimum is one.\n\n\nFor normal tasks, the \nnice()\n function increments the given process\u2019s static priority by the given amount.\n\n\nOnly root can provide a negative value, which lowers the nice value and increase the priority.\n\n\nThe \nnice()\n function calls the kernel\u2019s \nset_user_nice()\n function, which sets the \nstatic_prio\n and prio values in the task\u2019s \ntask_struct\n.\n\n\n\n\n\n\n\n\nProcessor Affinity System Calls\n\n\nThe Linux scheduler enforces hard processor affinity, which means that, aside from providing soft or natural affinity by attempting to keep processes on the same processor, the scheduler enables a user to enforce \"a task must remain on this subset of the available processors no matter what\".\n\n\nTThe hard affinity is stored as a bitmask in the task\u2019s \ntask_struct\n as \ncpus_allowed\n (\ninclude/linux/sched.h#L1210\n). The bitmask contains one bit per possible processor on the system. By default, all bits are set and, therefore, a process is potentially runnable on any processor. The following system calls set and get the bitmask:\n\n\n\n\nsched_setaffinity()\n sets a different bitmask of any combination of one or more bits.\n\n\nsched_getaffinity()\n returns the current \ncpus_allowed\n bitmask.\n\n\n\n\nThe kernel enforces hard affinity in a simple manner:\n\n\n\n\nWhen a process is initially created, it inherits its parent\u2019s affinity mask. Because the parent is running on an allowed processor, the child thus runs on an allowed processor.\n\n\nWhen a processor\u2019s affinity is changed, the kernel uses the \nmigration threads\n to push the task onto a legal processor. (See \nDoubts and Solutions\n)\n\n\nThe load balancer pulls tasks to only an allowed processor\n\n\n\n\nTherefore, a process only ever runs on a processor whose bit is set in the \ncpus_allowed\n field of its process descriptor.\n\n\nYielding Processor Time\n\n\nLinux provides the \nsched_yield()\n system call as a mechanism for a process to explicitly yield the processor to other waiting processes.\n\n\n\n\nsched_yield()\n removes the process from the active array (where it currently is, because it is running) and inserting it into the expired array. This has the effect of not only preempting the process and putting it at the end of its priority list, but also putting it on the expired list, which guarantees it will not run for a while.\n\n\nFor real-time tasks, which never expire, \nsched_yield()\n merely move them to the end of their priority list (and not insert them into the expired array).\n\n\n\n\n\n\n\n\nApplications and even kernel code should be certain they truly want to give up the processor before calling \nsched_yield()\n.\n\n\nKernel code, as a convenience, can call \nyield()\n, which ensures that the task\u2019s state is \nTASK_RUNNING\n and then call \nsched_yield()\n. User-space applications use the \nsched_yield()\n system call.\n\n\nConclusion\n\n\nMeeting the demands of process scheduling is nontrivial. A large number of runnable processes, scalability concerns, trade-offs between latency and throughput, and the demands of various workloads make a one-size-fits-all algorithm hard to achieve. Linux kernel\u2019s new CFS process scheduler, comes close to appeasing all parties and providing an optimal solution for most use cases with good scalability. [p67]\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np66 on Processor Affinity. \"migration threads\" and \"load balancer\" is not detailed.", 
            "title": "Chapter 4. Process Scheduling"
        }, 
        {
            "location": "/lkd/ch5/", 
            "text": "Chapter 5. System Calls\n\n\n\n\nLook at \nioctl()\n as an example of what not to do (when implementing a system call).\n\nRobert Love\n\n\n\n\nIn any modern operating system, the kernel provides a set of interfaces by which processes running in user-space can interact with the system. These interfaces give applications: [p69]\n\n\n\n\ncontrolled access to hardware,\n\n\na mechanism with which to create new processes and communicate with existing ones,\n\n\nand the capability to request other operating system resources.\n\n\n\n\nThe existence of these interfaces, and the fact that applications are not free to directly do whatever they want, is key to providing a stable system\n\n\nCommunicating with the Kernel\n\n\nSystem calls provide a layer between the hardware and user-space processes, which serves three primary purposes:\n\n\n\n\nProviding an abstracted hardware interface for userspace.\n\n\nFor example, when reading or writing from a file, applications are not concerned with the type of disk, media, or even the type of filesystem on which the file resides.\n\n\n\n\n\n\nEnsuring system security and stability.\n The kernel acts as a middleman between system resources and user-space, so it can arbitrate access based on permissions, users, and other criteria.\n\n\nFor example, this arbitration prevents applications from incorrectly using hardware, stealing other processes\u2019 resources, or otherwise doing harm to the system.\n\n\n\n\n\n\nA single common layer between user-space and the rest of the system allows for the virtualized system provided to processes.\n  It would be impossible to implement multitasking and virtual memory if applications were free to access access system resources without the kernel\u2019s knowledge. [p69]\n\n\n\n\nIn Linux, system calls are the only means user-space has of interfacing with the kernel and the only legal entry point into the kernel other than exceptions and traps. Other interfaces, such as device files or \n/proc\n, are ultimately accessed via system calls. Interestingly, Linux implements far fewer system calls than most systems.\n\n\nAPIs, POSIX, and the C Library\n\n\nAPIs *\n\n\nApplications are typically programmed against an Application Programming Interface (API) implemented in user-space, not directly to system calls, because no direct correlation is needed between the interfaces used by applications and the actual interface provided by the kernel.\n\n\nAn API defines a set of programming interfaces used by applications. Those interfaces can be:\n\n\n\n\nimplemented as a system call,\n\n\nimplemented through multiple system calls, or\n\n\nimplemented without the use of system calls at all.\n\n\n\n\nThe same API can exist on multiple systems and provide the same interface to applications while the implementation of the API itself can differ greatly from system to system.\n\n\nThe figure below shows relationship between a POSIX API, the C library, and system calls.\n\n\n\n\nPOSIX *\n\n\nThe most common APIs in the Unix world is based on POSIX. Technically, POSIX is composed of a series of standards from the \nIEEE\n that aim to provide a portable operating system standard roughly based on Unix. Linux strives to be POSIX- and SUSv3-compliant where applicable.\n\n\nOn most Unix systems, the POSIX-defined API calls have a strong correlation to the system calls. Some systems that are rather un-Unix, such as Microsoft Windows, offer POSIX-compatible libraries. [p70]\n\n\nThe C Library *\n\n\nThe system call interface in Linux, as with most Unix systems, is provided in part by the C library.\n\n\nThe C library implements the main API on Unix systems, including:\n\n\n\n\nThe standard C library\n\n\nThe system call interface\n\n\n\n\nThe C library is used by all C programs and, because of C\u2019s nature, is easily wrapped by other programming languages for use in their programs. The C library additionally provides the majority of the POSIX API.\n\n\nFrom the application programmer\u2019s point of view, system calls are irrelevant; all the programmer is concerned with is the API. Conversely, the kernel is concerned only with the system calls; what library calls and applications make use of the system calls is not of the kernel\u2019s concern. Nonetheless, it is important for the kernel to keep track of the potential uses of a system call and keep the system call as general and flexible as possible.\n\n\nA meme related to interfaces in Unix is \"Provide mechanism, not policy\". In other words, Unix system calls exist to provide a specific function in an abstract sense. The manner in which the function is used is not any of the kernel\u2019s business.\n\n\nSyscalls\n\n\nSystem calls\n (often called \nsyscalls\n in Linux) are typically accessed via function calls defined in the C library.\n\n\n\n\nThe functions can define zero, one, or more arguments (inputs) and might result in one or more side effects.\n\n\nAlthough nearly all system calls have a side effect (that is, they result in some change of the system\u2019s state), a few syscalls, such as \ngetpid()\n, merely return some data from the kernel.\n\n\n\n\n\n\nSystem calls also provide a return value of type \nlong\n (for compatibility with 64-bit architectures) that signifies success or error.\n\n\nUsually, although not always, a negative return value denotes an error.\n\n\nA return value of zero is usually (not always) a sign of success.\n\n\nThe C library (when a system call returns an error) writes a special error code into the global \nerrno\n variable, which can be translated into human-readable errors via library functions such as \nperror()\n.\n\n\n\n\n\n\nSystem calls have a defined behavior. (see the following example)\n\n\n\n\nThe system call \ngetpid()\n is defined to return an integer that is the current process\u2019s PID. The implementation of this syscall in the kernel is simple:\n\n\nSYSCALL_DEFINE0\n(\ngetpid\n)\n\n\n{\n\n    \nreturn\n \ntask_tgid_vnr\n(\ncurrent\n);\n \n// returns current-\ntgid\n\n\n}\n\n\n\n\n\n\nThe definition says nothing of the implementation. The kernel must provide the intended behavior of the system call but is free to do so with whatever implementation it wants as long as the result is correct. [p72]\n\n\nSYSCALL_DEFINE0\n is simply a macro that defines a system call with no parameters (hence the 0). The expanded code looks like this:\n\n\ninclude/linux/syscalls.h\n\n\nasmlinkage\n \nlong\n \nsys_getpid\n(\nvoid\n);\n\n\n\n\n\n\n\n\nThe \nasmlinkage\n modifier on the function definition is a directive to tell the compiler to look only on the stack for this function\u2019s arguments. This is a required modifier for all system calls.\n\n\nThe function returns a \nlong\n. For compatibility between 32- and 64-bit systems, system calls defined to return an \nint\n in user-space return a \nlong\n in the kernel.\n\n\nThe naming convention taken with all system calls in Linux is: System call \nbar()\n is implemented in the kernel as function \nsys_bar()\n.\n\n\n\n\nSystem Call Numbers\n\n\nIn Linux, each system call is assigned a unique \nsyscall number\n that is used to reference a specific system call. When a user-space process executes a system call, the syscall number identifies which syscall was executed; the process does not refer to the syscall by name.\n\n\n\n\nWhen assigned, the syscall number cannot change; otherwise, compiled applications will break.\n\n\nIf a system call is removed, its system call number cannot be recycled, or previously compiled code would aim to invoke one system call but would in reality invoke another.\n\n\nLinux provides a \"not implemented\" system call, \nsys_ni_syscall()\n, which does nothing except return \nENOSYS\n, the error corresponding to an invalid system call. This function is used to \"plug the hole\" in the rare event that a syscall is removed or otherwise made unavailable.\n\n\n\n\nThe kernel keeps a list of all registered system calls in the system call table, stored in \nsys_call_table\n, on x86-64 it is defined in \narch/x86/kernel/syscall_64.c\n.\n\n\nThe system call numbers are defined in the file \ninclude/asm-generic/unistd.h\n.\n\n\nSystem Call Performance\n\n\nSystem calls in Linux are faster than in many other operating systems, because of:\n\n\n\n\nLinux\u2019s fast context switch times: entering and exiting the kernel is a streamlined and simple affair\n\n\nSimplicity of the system call handler and the individual system calls themselves\n\n\n\n\nSystem Call Handler\n\n\nIt is not possible for user-space applications to execute kernel code directly. They cannot simply make a function call to a method existing in kernel-space because the kernel exists in a protected memory space. Otherwise, system security and stability would be nonexistent.\n\n\nUser-space applications signal the kernel that they want to execute a system call and have the system switch to kernel mode, where the system call can be executed in kernel-space by the kernel on behalf of the application. This mechanism is software interrupt: incur an exception, and the system will switch to kernel mode and execute the \nexception handler\n. The exception handler in this case is actually the \nsystem call handler\n.\n\n\nThe defined software interrupt on x86 is interrupt number 128, which is incurred via the \nint $0x80\n instruction. It triggers a switch to kernel mode and the execution of exception vector 128, which is the system call handler. The system call handler is the aptly named function \nsystem_call()\n. It is architecture-dependent; on x86-64 it is implemented in assembly in \nentry_64.S\n (\narch/x86/kernel/entry_64.S\n).\n\n\nRecently, x86 processors added a feature known as \nsysenter\n, which provides a faster, more specialized way of trapping into a kernel to execute a system call than using the \nint\n interrupt instruction. Support for this feature was quickly added to the kernel. Regardless of how the system call handler is invoked, however, the important notion is that somehow user-space causes an exception or trap to enter the kernel.\n\n\nDenoting the Correct System Call\n\n\nFor more details of Linux system call from the assembly perspective, see \nInterfacing with Linux\n.\n\n\nSimply entering kernel-space alone is not sufficient: the system call number must be passed into the kernel.\n\n\nOn x86, the syscall number is passed to the kernel via the \neax\n register:\n\n\n\n\nBefore causing the trap into the kernel, user-space sticks in \neax\n the number corresponding to the desired system call.\n\n\nThe system call handler then reads the value from \neax\n\n\n\n\nThe \nsystem_call()\n function checks the validity of the given system call number by comparing it to \nNR_syscalls\n. If it is larger than or equal to \nNR_syscalls\n, the function returns -\nENOSYS\n. Otherwise, the specified system call is invoked:\n\n\narch/x86/kernel/entry_64.S#L487\n\n\ncall\n \n*\nsys_call_table\n(,\n%rax\n,\n8\n)\n\n\n\n\n\n\nBecause each element in the system call table is 64 bits (8 bytes), the kernel multiplies the given system call number by eight to arrive at its location in the system call table. On x86-32, the code is similar, with the 8 replaced by 4.\n\n\n\n\nParameter Passing\n\n\nIn addition to the system call number, most syscalls require that one or more parameters be passed to them. User-space must relay the parameters to the kernel during the trap. The easiest way to do this is similar to how the syscall number is passed: The parameters are stored in registers. On x86-32, the registers \nebx\n, \necx\n, \nedx\n, \nesi\n, and \nedi\n contain, in order, the first five arguments. In the unlikely case of six or more arguments, a single register is used to hold a pointer to user-space where all the parameters are stored.\n\n\nThe return value is sent to user-space also via register. On x86, it is written into the \neax\n register.\n\n\nSystem Call Implementation\n\n\nThe actual implementation of a system call in Linux does not need to be concerned with the behavior of the system call handler. Thus, adding a new system call to Linux is relatively easy. The hard work lies in designing and implementing the system call; registering it with the kernel is simple.\n\n\nImplementing System Calls\n\n\nThe first step in implementing a system call is defining its purpose and the syscall should have exactly one purpose. Multiplexing syscalls (a single system call that does wildly different things depending on a flag argument) is discouraged in Linux. \nioctl()\n is an example of what \nnot\n to do.\n\n\nThink of the new system call\u2019s arguments, return value, and error codes. The system call should have a clean and simple interface with the smallest number of arguments possible.The semantics and behavior of a system call are important; they must not change, because existing applications will come to rely on them. Many system calls provide a flag argument to address forward compatibility. The flag is not used to multiplex different behavior across a single system call (which is not acceptable), but to enable new functionality and options without breaking backward compatibility or needing to add a new system call. [p75]\n\n\nDesign the system call to be as general as possible with an eye toward the future. \nThe \npurpose\n of the system call will remain constant but its \nuses\n may change.\n Remember the Unix motto: \"Provide mechanism, not policy.\" [p75]\n\n\nWhen you write a system call, you need to realize the need for portability and robustness, not just today but in the future.The basic Unix system calls have survived this test of time; most of them are just as useful and applicable today as they were 30 years ago!\n\n\nVerifying the Parameters\n\n\nSystem calls must carefully verify all their parameters to ensure that they are valid, legal and correct to guarantee the system\u2019s security and stability. [p75]\n\n\nOne of the most important checks is the validity of any pointers that the user provides. Before following a pointer into user-space, the system must ensure that:\n\n\n\n\nThe pointer points to a region of memory in user-space. Processes must not be able to trick the kernel into reading data in kernel-space on their behalf.\n\n\nThe pointer points to a region of memory in the process\u2019s address space.The process must not be able to trick the kernel into reading someone else\u2019s data.\n\n\nThe process must not be able to bypass memory access restrictions. If reading, the memory is marked readable. If writing, the memory is marked writable. If executing, the memory is marked executable.\n\n\n\n\nThe kernel provides two methods for performing the requisite checks and the desired copy to and from user-space. \nNote kernel code must never blindly follow a pointer into user-space. One of these two methods must always be used.\n\n\n\n\ncopy_to_user()\n is for writing into user-space. It takes three parameters:\n\n\nThe first argument is the destination memory address in the process\u2019s address space.\n\n\nThe second argument is the source pointer in kernel-space.\n\n\nThe third argument is the size in bytes of the data to copy.\n\n\n\n\n\n\ncopy_from_user()\n is for reading from user-space. It is analogous to \ncopy_to_user()\n. The function reads from the second parameter into the first parameter the number of bytes specified in the third parameter.\n\n\n\n\nBoth of these functions return the number of bytes they failed to copy on error. On success, they return zero. It is standard for the syscall to return \n-EFAULT\n in the case of such an error.\n\n\nThe following example \nsilly_copy()\n uses both \ncopy_from_user()\n and \ncopy_to_user()\n. It copies data from its first parameter into its second. This is suboptimal in that it involves an intermediate and extraneous copy into kernel-space for no gain. But it helps illustrate the point:\n\n\n/*\n\n\n* silly_copy - pointless syscall that copies the len bytes from\n\n\n* \u2018src\u2019 to \u2018dst\u2019 using the kernel as an intermediary in the copy.\n\n\n* Intended as an example of copying to and from the kernel.\n\n\n*/\n\n\nSYSCALL_DEFINE3\n(\nsilly_copy\n,\n\n                \nunsigned\n \nlong\n \n*\n,\n \nsrc\n,\n\n                \nunsigned\n \nlong\n \n*\n,\n \ndst\n,\n\n                \nunsigned\n \nlong\n \nlen\n)\n\n\n{\n\n    \nunsigned\n \nlong\n \nbuf\n;\n\n\n    \n/* copy src, which is in the user\u2019s address space, into buf */\n\n    \nif\n \n(\ncopy_from_user\n(\nbuf\n,\n \nsrc\n,\n \nlen\n))\n\n        \nreturn\n \n-\nEFAULT\n;\n\n\n    \n/* copy buf into dst, which is in the user\u2019s address space */\n\n    \nif\n \n(\ncopy_to_user\n(\ndst\n,\n \nbuf\n,\n \nlen\n))\n\n        \nreturn\n \n-\nEFAULT\n;\n\n\n    \n/* return amount of data copied */\n\n    \nreturn\n \nlen\n;\n\n\n}\n\n\n\n\n\n\nBoth \ncopy_to_user()\n and \ncopy_from_user()\n may block. This occurs, for example, if the page containing the user data is not in physical memory but is swapped to disk. In that case, the process sleeps until the page fault handler can bring the page from the swap file on disk into physical memory.\n\n\nA final possible check is for valid permission. In older versions of Linux, it was standard for syscalls that require root privilege to use \nsuser()\n. This function merely checked whether a user was root; this is now removed and a finer-grained \u201ccapabilities\u201d system is in place.\n\n\nThe new system enables specific access checks on specific resources. A call to \ncapable()\n with a valid capabilities flag returns nonzero if the caller holds the specified capability and zero otherwise. For example, \ncapable(CAP_SYS_NICE)\n checks whether the caller has the ability to modify nice values of other processes. By default, the superuser possesses all capabilities and nonroot possesses none.\n\n\nThe following example is the \nreboot()\n system call. Note how its first step is ensuring that the calling process has the \nCAP_SYS_REBOOT\n. If that one conditional statement were removed, any process could reboot the system.\n\n\nkernel/sys.c#L368\n\n\nSYSCALL_DEFINE4\n(\nreboot\n,\n \nint\n,\n \nmagic1\n,\n \nint\n,\n \nmagic2\n,\n \nunsigned\n \nint\n,\n \ncmd\n,\n\n        \nvoid\n \n__user\n \n*\n,\n \narg\n)\n\n\n{\n\n    \nchar\n \nbuffer\n[\n256\n];\n\n    \nint\n \nret\n \n=\n \n0\n;\n\n\n    \n/* We only trust the superuser with rebooting the system. */\n\n    \nif\n \n(\n!\ncapable\n(\nCAP_SYS_BOOT\n))\n\n        \nreturn\n \n-\nEPERM\n;\n\n\n    \n/* For safety, we require \nmagic\n arguments. */\n\n    \nif\n \n(\nmagic1\n \n!=\n \nLINUX_REBOOT_MAGIC1\n \n||\n\n        \n(\nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2\n \n\n                    \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2A\n \n\n            \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2B\n \n\n                    \nmagic2\n \n!=\n \nLINUX_REBOOT_MAGIC2C\n))\n\n        \nreturn\n \n-\nEINVAL\n;\n\n\n    \n/* Instead of trying to make the power_off code look like\n\n\n     * halt when pm_power_off is not set do it the easy way.\n\n\n     */\n\n    \nif\n \n((\ncmd\n \n==\n \nLINUX_REBOOT_CMD_POWER_OFF\n)\n \n \n!\npm_power_off\n)\n\n        \ncmd\n \n=\n \nLINUX_REBOOT_CMD_HALT\n;\n\n\n    \nmutex_lock\n(\nreboot_mutex\n);\n\n    \nswitch\n \n(\ncmd\n)\n \n{\n\n    \ncase\n \nLINUX_REBOOT_CMD_RESTART\n:\n\n        \nkernel_restart\n(\nNULL\n);\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_CAD_ON\n:\n\n        \nC_A_D\n \n=\n \n1\n;\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_CAD_OFF\n:\n\n        \nC_A_D\n \n=\n \n0\n;\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_HALT\n:\n\n        \nkernel_halt\n();\n\n        \ndo_exit\n(\n0\n);\n\n        \npanic\n(\ncannot halt\n);\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_POWER_OFF\n:\n\n        \nkernel_power_off\n();\n\n        \ndo_exit\n(\n0\n);\n\n        \nbreak\n;\n\n\n    \ncase\n \nLINUX_REBOOT_CMD_RESTART2\n:\n\n        \nif\n \n(\nstrncpy_from_user\n(\nbuffer\n[\n0\n],\n \narg\n,\n \nsizeof\n(\nbuffer\n)\n \n-\n \n1\n)\n \n \n0\n)\n \n{\n\n            \nret\n \n=\n \n-\nEFAULT\n;\n\n            \nbreak\n;\n\n        \n}\n\n        \nbuffer\n[\nsizeof\n(\nbuffer\n)\n \n-\n \n1\n]\n \n=\n \n\\0\n;\n\n\n        \nkernel_restart\n(\nbuffer\n);\n\n        \nbreak\n;\n\n\n\n#ifdef CONFIG_KEXEC\n\n    \ncase\n \nLINUX_REBOOT_CMD_KEXEC\n:\n\n        \nret\n \n=\n \nkernel_kexec\n();\n\n        \nbreak\n;\n\n\n#endif\n\n\n\n#ifdef CONFIG_HIBERNATION\n\n    \ncase\n \nLINUX_REBOOT_CMD_SW_SUSPEND\n:\n\n        \nret\n \n=\n \nhibernate\n();\n\n        \nbreak\n;\n\n\n#endif\n\n\n    \ndefault\n:\n\n        \nret\n \n=\n \n-\nEINVAL\n;\n\n        \nbreak\n;\n\n    \n}\n\n    \nmutex_unlock\n(\nreboot_mutex\n);\n\n    \nreturn\n \nret\n;\n\n\n}\n\n\n\n\n\n\nSee \nlinux/capability.h\n (\ninclude/linux/capability.h\n) for a list of all capabilities and what rights they entail.\n\n\nSystem Call Context\n\n\nThe kernel is in process context during the execution of a system call (\nChapter 3\n). The \ncurrent\n pointer points to the current task, which is the process that issued the syscall.\n\n\nIn process context, the kernel is capable of sleeping (for example, if the system call blocks on a call or explicitly calls \nschedule()\n) and is fully preemptible. These two points are important:\n\n\n\n\nThe capability to sleep\n means that system calls can make use of the majority of the kernel\u2019s functionality.\n\n\nThe capability to sleep greatly simplifies kernel programming (\nChapter 7\n)\n\n\nInterrupt handlers cannot sleep and thus are much more limited in what they can do than system calls running in process context.\n\n\n\n\n\n\nThe fact that \nprocess context is preemptible\n implies that, like user-space, the current task may be preempted by another task.\n\n\nBecause the new task may then execute the same system call, care must be exercised to ensure that system calls are reentrant.\n This is the same concern that symmetrical multiprocessing introduces. (Synchronizing reentrancy is covered in \nChapter 9\n).\n\n\n\n\n\n\n\n\nWhen the system call returns, control continues in \nsystem_call()\n, which ultimately switches to user-space and continues the execution of the user process.\n (\nFigure 5.2\n)\n\n\nFinal Steps in Binding a System Call\n\n\nIt is trivial to register a (official) system call after it is written:\n\n\n\n\nAdd an entry to the end of the system call table. This needs to be done for each architecture that supports the system call. The position of the syscall in the table, starting at zero, is its system call number.\n\n\nFor each supported architecture, define the syscall number in \nasm/unistd.h\n.\n\n\nCompile the syscall into the kernel image (as opposed to compiling as a module). This can be as simple as putting the system call in a relevant file in \nkernel/\n, such as \nsys.c\n, which is home to miscellaneous system calls.\n\n\n\n\nFor example of a fictional system call \nfoo()\n. We want to add \nsys_foo()\n to the system call table. For most architectures, the table is located in \nentry.S\n and looks like this (The new system call is then appended to the tail of this list):\n\n\nENTRY\n(\nsys_call_table\n)\n\n\n.\nlong\n \nsys_restart_syscall\n \n/* 0 */\n\n\n.\nlong\n \nsys_exit\n\n\n.\nlong\n \nsys_fork\n\n\n.\nlong\n \nsys_read\n\n\n.\nlong\n \nsys_write\n\n\n.\nlong\n \nsys_open\n \n/* 5 */\n\n\n...\n\n\n.\nlong\n \nsys_eventfd2\n\n\n.\nlong\n \nsys_epoll_create1\n\n\n.\nlong\n \nsys_dup3\n \n/* 330 */\n\n\n.\nlong\n \nsys_pipe2\n\n\n.\nlong\n \nsys_inotify_init1\n\n\n.\nlong\n \nsys_preadv\n\n\n.\nlong\n \nsys_pwritev\n\n\n.\nlong\n \nsys_rt_tgsigqueueinfo\n \n/* 335 */\n\n\n.\nlong\n \nsys_perf_event_open\n\n\n.\nlong\n \nsys_recvmmsg\n\n\n.\nlong\n \nsys_foo\n\n\n\n\n\n\nThough not explicitly specified, the system call is then given the next subsequent syscall number (338, in this case).\n\n\n\n\nFor each architecture you want to support, the system call must be added to the architecture\u2019s system call table.\n\n\nThe system call does not need to receive the same syscall number under each architecture, as the system call number is part of the architecture\u2019s unique ABI.\n\n\nUsually, you would want to make the system call available to each architecture.\n\n\nNote the convention of placing the number in a comment every five entries; this makes it easy to find out which syscall is assigned which number.\n\n\n\n\nNext, the system call number is added to \nasm/unistd.h\n like below:\n\n\n/*\n\n\n* This file contains the system call numbers.\n\n\n*/\n\n\n#define __NR_restart_syscall 0\n\n\n#define __NR_exit 1\n\n\n#define __NR_fork 2\n\n\n#define __NR_read 3\n\n\n#define __NR_write 4\n\n\n#define __NR_open 5\n\n\n...\n\n\n#define __NR_signalfd4 327\n\n\n#define __NR_eventfd2 328\n\n\n#define __NR_epoll_create1 329\n\n\n#define __NR_dup3 330\n\n\n#define __NR_pipe2 331\n\n\n#define __NR_inotify_init1 332\n\n\n#define __NR_preadv 333\n\n\n#define __NR_pwritev 334\n\n\n#define __NR_rt_tgsigqueueinfo 335\n\n\n#define __NR_perf_event_open 336\n\n\n#define __NR_recvmmsg 337\n\n\n#define __NR_foo\n\n\n\n\n\n\nFinally, the actual \nfoo()\n system call is implemented. Because the system call must be compiled into the core kernel image in all configurations, in this example we define it in \nkernel/sys.c\n. You should put it wherever the function is most relevant; for example, if the function is related to scheduling, you could define it in \nkernel/sched.c\n.\n\n\n#include \nasm/page.h\n\n\n\n/*\n\n\n* sys_foo \u2013 everyone\u2019s favorite system call.\n\n\n*\n\n\n* Returns the size of the per-process kernel stack.\n\n\n*/\n\n\nasmlinkage\n \nlong\n \nsys_foo\n(\nvoid\n)\n\n\n{\n\n    \nreturn\n \nTHREAD_SIZE\n;\n\n\n}\n\n\n\n\n\n\nBoot this kernel and user-space can invoke the \nfoo()\n system call\n\n\nAccessing the System Call from User-Space\n\n\nThe C library provides support for system calls. User applications can pull in function prototypes from the standard headers and link with the C library to use your system call. [p81]\n\n\nLinux provides a set of macros for wrapping access to system calls. It sets up the register contents and issues the trap instructions. These macros are named \n_syscalln()\n, where \nn\n is between 0 and 6. The number corresponds to the number of parameters passed into the syscall, because the macro needs to know how many parameters to push into registers.\n\n\nFor example, consider the system call \nopen()\n, defined as\n\n\nlong\n \nopen\n(\nconst\n \nchar\n \n*\nfilename\n,\n \nint\n \nflags\n,\n \nint\n \nmode\n)\n\n\n\n\n\n\nThe syscall macro to use this system call without explicit library support would be:\n\n\n#define __NR_open 5\n\n\n_syscall3\n(\nlong\n,\n \nopen\n,\n \nconst\n \nchar\n \n*\n,\n \nfilename\n,\n \nint\n,\n \nflags\n,\n \nint\n,\n \nmode\n)\n\n\n\n\n\n\nThe application can simply call \nopen()\n.\n\n\nAn macro has 2 + 2 \u00d7 \nn\n parameters:\n\n\n\n\nThe first parameter corresponds to the return type of the syscall.\n\n\nThe second is the name of the system call.\n\n\nThe remainder are type and name for each parameter in order of the system call.\n\n\n\n\nThe \n__NR_open\n (\narch/x86/include/asm/unistd_64.h#L19\n) is defined in \nasm/unistd.h\n; it is the system call number.\n\n\nThe \n_syscall3\n macro expands into a C function with inline assembly;\n the assembly performs the steps discussed in the previous section to push the system call number and parameters into the correct registers and issue the software interrupt to trap into the kernel. \nPlacing this macro in an application is all that is required to use the \nopen()\n system call.\n\n\nFor example of the \nfoo()\n system call, we can use it from an application like this:\n\n\n#define __NR_foo 283\n\n\n__syscall0\n(\nlong\n,\n \nfoo\n)\n\n\n\nint\n \nmain\n \n()\n\n\n{\n\n    \nlong\n \nstack_size\n;\n\n    \nstack_size\n \n=\n \nfoo\n \n();\n\n    \nprintf\n \n(\nThe kernel stack size is %ld\n\\n\n,\n \nstack_size\n);\n\n    \nreturn\n \n0\n;\n\n\n}\n\n\n\n\n\n\nWhy Not to Implement a System Call\n\n\nAdding new syscall is not encouraged, and you should otherwise exercise caution and restraint in adding one. [p82]o\n\n\nThe followings are pros and cons of implementing a new interface as a syscall:\n\n\n\n\nPros:\n\n\nSystem calls are simple to implement and easy to use.\n\n\nSystem call performance on Linux is fast.\n\n\n\n\n\n\nCons:\n\n\nYou need a syscall number, which needs to be officially assigned to you.\n\n\nAfter the system call is in a stable series kernel, it is written in stone. The interface cannot change without breaking user-space applications.\n\n\nEach architecture needs to separately register the system call and support it.\n\n\nSystem calls are not easily used from scripts and cannot be accessed directly from the filesystem.\n\n\nBecause you need an assigned syscall number, it is hard to maintain and use a system call outside of the master kernel tree.\n\n\nFor simple exchanges of information, a system call is overkill.\n\n\n\n\n\n\n\n\nThe alternatives to implementing a syscall:\n\n\n\n\nImplement a device node and \nread()\n and \nwrite()\n to it. Use \nioctl()\n to manipulate specific settings or retrieve specific information.\n\n\nCertain interfaces, such as semaphores, can be represented as file descriptors and manipulated as such.\n\n\nAdd the information as a file to the appropriate location in sysfs\n\n\n\n\nThe slow rate of addition of new system calls is a sign that Linux is a relatively stable and feature-complete operating system. [p83]\n\n\nConclusion\n\n\nIn this chapter discusses what system calls are and how they relate to library calls and the application programming interface (API). This includes how the Linux kernel implements system calls and the chain of events required to execute a system call: trapping into the kernel, transmitting the syscall number and any arguments, executing the correct system call function, and returning to user-space with the syscall\u2019s return value. [p83]", 
            "title": "Chapter 5. System Calls"
        }, 
        {
            "location": "/lkd/ch6/", 
            "text": "Chapter 6. Kernel Data Structures\n\n\nThis chapter introduces several built-in data structures for use in Linux kernel code: [p85]\n\n\n\n\nLinked lists\n\n\nQueues\n\n\nMaps\n\n\nBinary trees\n\n\n\n\nThese generic data structures are provided to encourage code reuse. Kernel developers should use these data structures whenever possible and not \"roll your own\" solutions.\n\n\nLinked Lists\n\n\nAs the simplest and most common data structure in the Linux kernel, a \nlinked list\n is a data structure that allows the storage and manipulation of a variable number of \nelements\n, called the \nnodes\n of the list.\n\n\nUnlike in a static array, the elements in a linked list are dynamically created and inserted into the list, which enables the management of a varying number of elements unknown at compile time. The elements do not necessarily occupy contiguous regions in memory and thus need to be linked together (each element in the list contains a pointer to the \nnext\n element).\n\n\nSingly and Doubly Linked Lists\n\n\nThe simplest data structure for a linked list is like:\n\n\n/* an element in a linked list */\n\n\nstruct\n \nlist_element\n \n{\n\n    \nvoid\n \n*\ndata\n;\n \n/* the payload */\n\n    \nstruct\n \nlist_element\n \n*\nnext\n;\n \n/* pointer to the next element */\n\n\n};\n\n\n\n\n\n\nThe following figure shows a linked list:\n\n\n\n\n\n\nA \nsingly linked lists\n: each element does not have a pointer to the \nprevious\n element.\n\n\nA \ndoubly linked lists\n: each element also contains a pointer to the \nprevious\n element (linked both forward and backward).\n\n\n\n\nA data structure representing a doubly linked list would look similar to this:\n\n\n/* an element in a linked list */\n\n\nstruct\n \nlist_element\n \n{\n\n    \nvoid\n \n*\ndata\n;\n \n/* the payload */\n\n    \nstruct\n \nlist_element\n \n*\nnext\n;\n \n/* pointer to the next element */\n\n    \nstruct\n \nlist_element\n \n*\nprev\n;\n \n/* pointer to the previous element */\n\n\n};\n\n\n\n\n\n\nThe following figure shows doubly linked list:\n\n\n\n\nCircular Linked Lists\n\n\nNormally, the last element in a linked list has no next element, so it is set to point to a special value, such as \nNULL\n. In a \ncircular linked list\n, last element does not point to a special value, but points back to the first value.\n\n\nCircular linked lists can come in both doubly and singly linked versions. In a circular doubly linked list, the first node\u2019s \"previous\" pointer points at the last node.\n\n\nThe following two figures are singly and doubly circular linked lists, respectively:\n\n\n\n\n\n\nMoving Through a Linked List\n\n\nTo move through a linked list, simply follow the next pointer of an element, and visit the next element. This is linear movement.\n\n\nLinked lists are ill-suited for use cases where random access is an important operation.\n Instead, you use linked lists when iterating over the whole list is important and the dynamic addition and removal of elements is required.\n\n\nIn linked list implementations:\n\n\n\n\nThe first element is often represented by a special pointer, \nhead\n, that enables easy access to the \"start\" of the list.\n\n\nIn a noncircular-linked list, the last element is delineated by its next pointer being \nNULL\n.\n\n\nIn a circular-linked list, the last element is delineated because it points to the \nhead\n element.\n\n\n\n\n[p87-88]\n\n\nThe Linux Kernel\u2019s Implementation\n\n\nThe Linux kernel\u2019s implementation is unique, in comparison to most linked list implementations including those described in the previous sections.\n\n\nThe common pattern for storing this structure in a linked list is to embed the list pointer in the structure. For example, to describe that member of the \nCanidae\n family:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nfox\n \n*\nnext\n;\n \n/* next fox in linked list */\n\n    \nstruct\n \nfox\n \n*\nprev\n;\n \n/* previous fox in linked list */\n\n\n};\n\n\n\n\n\n\nThe Linux kernel approach is different. Instead of turning the structure into a linked list, the Linux approach is to \"\nembed a linked list node in the structure\n\".\n\n\nThe Linked List Structure\n\n\nThe linked-list code is declared in the header file \nlinux/list.h\n (\ninclude/linux/list.h#L19\n) and the data structure is simple:\n\n\nstruct\n \nlist_head\n \n{\n\n    \nstruct\n \nlist_head\n \n*\nnext\n\n    \nstruct\n \nlist_head\n \n*\nprev\n;\n\n\n};\n\n\n\n\n\n\nThe utility is in \nhow\n the \nlist_head\n structure is used:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nlist_head\n \nlist\n;\n \n/* list of all fox structures */\n\n\n};\n\n\n\n\n\n\nWith this, \nlist.next\n in fox points to the next element, and \nlist.prev\n in fox points to the previous.\n\n\nThe kernel provides a family of routines to manipulate linked lists (for example, the \nlist_add()\n method adds a new node to an existing linked list). These methods accept only \nlist_head\n structures. \nUsing the macro \ncontainer_of()\n, we can easily find the parent structure containing any given member variable. In C, the offset of a given variable into a structure is fixed by the ABI at compile time.\n\n\ninclude/linux/kernel.h#L709\n\n\n#define container_of(ptr, type, member) ({ \\\n\n\n        const typeof( ((type *)0)-\nmember ) *__mptr = (ptr); \\\n\n\n        (type *)( (char *)__mptr - offsetof(type,member) );})\n\n\n\n\n\n\nUsing \ncontainer_of()\n, we can define a simple function to return the parent structure containing any \nlist_head\n:\n\n\ninclude/linux/list.h#L348\n\n\n#define list_entry(ptr, type, member) \\\n\n\n        container_of(ptr, type, member)\n\n\n\n\n\n\nWith \nlist_entry()\n, the kernel provides routines manipulate linked lists without knowing anything about the structures that the \nlist_head\n resides within.\n\n\nDefining a Linked List\n\n\nA \nlist_head\n is normally embedded inside your own structure:\n\n\nstruct\n \nfox\n \n{\n\n    \nunsigned\n \nlong\n \ntail_length\n;\n \n/* length in centimeters of tail */\n\n    \nunsigned\n \nlong\n \nweight\n;\n \n/* weight in kilograms */\n\n    \nbool\n \nis_fantastic\n;\n \n/* is this fox fantastic? */\n\n    \nstruct\n \nlist_head\n \nlist\n;\n \n/* list of all fox structures */\n\n\n};\n\n\n\n\n\n\nThe list needs to be initialized before it can be used. Because most of the elements of the linked list are created dynamically, the most common way of initializing the linked list is at runtime using \nINIT_LIST_HEAD\n:\n\n\nstruct\n \nfox\n \n*\nred_fox\n;\n\n\nred_fox\n \n=\n \nkmalloc\n(\nsizeof\n(\n*\nred_fox\n),\n \nGFP_KERNEL\n);\n\n\nred_fox\n-\ntail_length\n \n=\n \n40\n;\n\n\nred_fox\n-\nweight\n \n=\n \n6\n;\n\n\nred_fox\n-\nis_fantastic\n \n=\n \nfalse\n;\n\n\nINIT_LIST_HEAD\n(\nred_fox\n-\nlist\n);\n\n\n\n\n\n\nIf the structure is statically created at compile time, and you have a direct reference to it, you can simply do this (using \nLIST_HEAD_INIT\n):\n\n\nstruct\n \nfox\n \nred_fox\n \n=\n \n{\n\n    \n.\ntail_length\n \n=\n \n40\n,\n\n    \n.\nweight\n \n=\n \n6\n,\n\n    \n.\nlist\n \n=\n \nLIST_HEAD_INIT\n(\nred_fox\n.\nlist\n),\n\n\n};\n\n\n\n\n\n\nList Heads\n\n\nBut before we can use kernel\u2019s linked list routines to manage our structure, we need a canonical pointer to refer to the list as a whole: a \nhead\n pointer.\n\n\nSince each contains a \nlist_head\n, and we can iterate from any one node to the next. We need a special pointer that refers to your linked list, without being a list node itself. This special node is in fact a normal \nlist_head\n: [p90]\n\n\nstatic\n \nLIST_HEAD\n(\nfox_list\n);\n\n\n\n\n\n\nThis defines and initializes a \nlist_head\n named \nfox_list\n. The majority of the linked list routines accept one or two parameters: the \nhead\n node or the \nhead\n node plus an actual list node.\n\n\nManipulating Linked Lists\n\n\nThe kernel provides a family of functions to manipulate linked lists. They all take pointers to one or more \nlist_head\n structures. The functions are implemented as inline functions in generic C and can be found in \nlinux/list.h\n (\ninclude/linux/list.h\n).\n\n\nAll these functions are \nO(1)\n. This means they execute in constant time, regardless of the size of the list or any other inputs\n\n\nAdding a Node to a Linked List\n\n\nTo add a node to a linked list:\n\n\ninclude/linux/list.h#L64\n\n\nlist_add\n(\nstruct\n \nlist_head\n \n*\nnew\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function adds the new node to the given list immediately after the \nhead\n node. Because the list is circular and generally has no concept of first or last nodes, you can pass any element for head. If you pass the \"last\" element as \nhead\n, this function can be used to implement a stack.\n\n\nFor example, assume we had a new \nstruct fox\n to add to the \nfox_list\n list. We can do this:\n\n\nlist_add\n(\nf\n-\nlist\n,\n \nfox_list\n);\n\n\n\n\n\n\nTo add a node to the end of a linked list:\n\n\ninclude/linux/list.h#L78\n\n\nlist_add_tail\n(\nstruct\n \nlist_head\n \n*\nnew\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nIf you pass the \"first\" element as \nhead\n, this function can be used to implement a stack.\n\n\nDeleting a Node from a Linked List\n\n\nTo delete a node from a linked list, use \nlist_del()\n:\n\n\ninclude/linux/list.h#L103\n\n\nlist_del\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n\n\n\n\nThis function removes the element entry from the list. Note that \nlist_del\n does not free any memory belonging to \nentry\n or the data structure in which it is embedded;\n this function merely removes the element from the list. After calling this, you would typically destroy your data structure and the \nlist_head\n inside it.\n\n\nFor example, to delete the fox node we previous added to \nfox_list\n:\n\n\nlist_del\n(\nf\n-\nlist\n);\n\n\n\n\n\n\nIt simply receives a specific node and modifies the pointers of the previous and subsequent nodes such that the given node is no longer part of the list. The implementation is instructive:\n\n\ninclude/linux/list.h#L90\n\n\nstatic\n \ninline\n \nvoid\n \n__list_del\n(\nstruct\n \nlist_head\n \n*\nprev\n,\n \nstruct\n \nlist_head\n \n*\nnext\n)\n\n\n{\n\n    \nnext\n-\nprev\n \n=\n \nprev\n;\n\n    \nprev\n-\nnext\n \n=\n \nnext\n;\n\n\n}\n\n\n\nstatic\n \ninline\n \nvoid\n \nlist_del\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n{\n\n    \n__list_del\n(\nentry\n-\nprev\n,\n \nentry\n-\nnext\n);\n\n\n}\n\n\n\n\n\n\nTo delete a node from a linked list and reinitialize it, the kernel provides \nlist_del_init()\n:\n\n\ninclude/linux/list.h#L140\n\n\nlist_del_init\n(\nstruct\n \nlist_head\n \n*\nentry\n)\n\n\n\n\n\n\nThis function behaves the same as \nlist_del()\n, except it also reinitializes the given \nlist_head\n with the rationale that you no longer want the entry in the list, but you can reuse the data structure itself.\n\n\nMoving and Splicing Linked List Nodes\n\n\nTo move a node from one list to another:\n\n\ninclude/linux/list.h#L151\n\n\nlist_move\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function removes the list entry from its linked list and adds it to the given list after the \nhead\n element.\n\n\nTo move a node from one list to the end of another:\n\n\ninclude/linux/list.h#L162\n\n\nlist_move_tail\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function does the same as \nlist_move()\n, but inserts the list element before the head entry.\n\n\nTo check whether a list is empty:\n\n\ninclude/linux/list.h#L184\n\n\nlist_empty\n(\nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis returns nonzero if the given list is empty; otherwise, it returns zero.\n\n\nTo splice two unconnected lists together;\n\n\ninclude/linux/list.h#L290\n\n\nlist_splice\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function splices together two lists by inserting the list pointed to by \nlist\n to the given list after the element \nhead\n.\n\n\nTo splice two unconnected lists together and reinitialize the old list:\n\n\ninclude/linux/list.h#L302\n\n\nlist_splice_init\n(\nstruct\n \nlist_head\n \n*\nlist\n,\n \nstruct\n \nlist_head\n \n*\nhead\n)\n\n\n\n\n\n\nThis function works the same as \nlist_splice()\n, except that the emptied list pointed to by \nlist\n is reinitialized.\n\n\nIf you already have the \nnext\n and \nprev\n pointers available, you can save a couple cycles (specifically, the dereferences to get the pointers) by calling the internal list functions directly. For example, rather than call \nlist_del(list)\n, you can call \n__list_del(prev, next)\n. [p92]\n\n\nQueues\n\n\nMaps\n\n\nBinary Trees\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np91 on \nlist_add\n and \nlist_add_tail\n:\n\n\n\n\nIf you do pass the \"last\" element, however, this function (\nlist_add\n) can be used to implement a stack\n...\nThis function (\nlist_add_tail\n) can be used to implement a queue, however, if you pass the \"first\" element.\n\n\n\n\nImplementation details are required to understand this.", 
            "title": "Chapter 6. Kernel Data Structures"
        }, 
        {
            "location": "/unp/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nIntroduction\n\n\nThe \nclient\n and \nserver\n organization is used by most network-awared applications. Some complex applications also require \nasynchronous callback\n communication, where the server initiates a message to the client.\n\n\nunp.h\n header\n\n\n\n\nunp.h\n\n\n\n\nA Simple Daytime Client\n\n\ndaytimetcpcli.c\n\n\n\n\n\nCreate TCP socket\n\n\nThe \nsocket\n function creates an Internet (\nAF_INET\n) stream (\nSOCK_STREAM\n) socket, which is a fancy name for a TCP socket. The function returns a small integer descriptor to identify the socket.\n\n\nSpecify server's IP address and port\n\n\nThe IP address (\nsin_addr\n) and port number (\nsin_port\n) fields in the Internet socket address structure (\nsockaddr_in\n) must be in specific formats:\n\n\n\n\nhtons\n (host to network short): converts the binary port number\n\n\ninet_pton\n (presentation to numeric): convert the ASCII command-line argument (such as \n206.62.226.35\n when we ran this example) into the proper format.\n\n\n\n\nbzero\n is not an ANSI C function, but is used in this book instead of the ANSI C \nmemset\n function, because \nbzero\n is easier to remember (with only two arguments) than \nmemset\n (with three arguments).\n\n\nEstablish connection with server\n\n\n\n\nconnect\n\n\n\n\nIn the \nunp.h\n header, \nSA\n is defined to be \nstruct sockaddr\n, a generic socket address structure.\n\n\nRead and display server's reply\n\n\nWe must be careful when using TCP because it is a \nbyte-stream\n protocol with no record boundaries. Since we cannot assume that the server's reply will be returned by a single \nread\n, we always need to code the \nread\n in a loop when reading from a TCP socket.\n\n\nTerminate program\n\n\nexit\n terminates the program. Unix always closes all open descriptors when a process terminates.\n\n\nProtocol Independence\n\n\nThe above program is protocol-depdent on IPv4.\n\n\nIt is better to make a program protocol-independent by using the \ngetaddrinfo\n function.\n\n\nError Handling: Wrapper Functions\n\n\nWe can shorten our programs by defining a \nwrapper function\n that performs the actual function call, tests the return value, and terminates on an error.\n\n\nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n\n\n\n\nWith careful C coding, we could use macros instead of functions, providing a little run-time efficiency, but these wrapper functions are rarely the performance bottleneck of a program. This book uses these wrapper functions unless otherwise explicit error needs handling.\n\n\nUnix \nerrno\n Value\n\n\nThe value of \nerrno\n is set by a function only if an error occurs. All of the positive error values are constants with all-uppercase names beginning with \"E,\" and are normally defined in the \nsys/errno.h\n header. No error has a value of 0.\n\n\nStoring errno in a global variable does not work with multiple threads that share all global variables.\n\n\nA Simple Daytime Server\n\n\ndaytimetcpsrv.c\n\n\n\n\n\nCreate a TCP socket\n\n\nIdentical to the client code.\n\n\nBind server's well-known port to socket\n\n\n\n\nbind\n: the server's well-known port (13) is bound to the socket by calling \nbind\n\n\nINADDR_ANY\n allows the server to accept a client connection on any interface\n\n\n\n\nConvert socket to listening socket\n\n\n\n\nlisten\n: converts the socket into a listening socket, on which incoming connections from clients will be accepted by the kernel\n\n\nlistenfd\n in the code is called a \nlistening descriptor\n\n\n\n\nAccept client connection, send reply\n\n\n\n\naccept\n\n\nconnfd\n in the code is called a \nconnected descriptor\n for communication with the client. A new descriptor is returned by accept for each client that connects to our server.\n\n\n\n\nThis book uses this code style for infinite loop:\n\n\nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n    \n// . . .\n\n\n}\n\n\n\n\n\n\nsnprintf\n function\n\n\n\n\nsnprintf\n instead of \nsprintf\n\n\n\n\nSimilarly:\n\n\n\n\nfgets\n instead of \ngets\n\n\nstrncat\n or \nstrlcat\n instead of \nstrcat\n\n\nstrncpy\n or \nstrlcpy\n instead of a \nstrcpy\n\n\n\n\nTerminate connection\n\n\nclose\n initiates the normal TCP connection termination sequence: a FIN is sent in each direction and each FIN is acknowledged by the other end.\n\n\nThe server implemented in the above server code is:\n\n\n\n\nProtocol-dependent on IPv4\n\n\nHandles only one client at a time. If multiple client connections arrive at about the same time, the kernel queues them, up to some limit, and returns them to \naccept\n one at a time.\n\n\nCalled an \niterative server\n. A \nconcurrent server\n handles multiple clients at the same time.\n\n\n\n\nOSI Model\n\n\nSome terms mentioned:\n\n\n\n\nRaw socket\n: it is possible for an application to bypass the transport layer and use IPv4 or IPv6 directly\n\n\nXTI\n\n\n\n\nSockets provide the interface from the upper three layers of the OSI model into the transport layer:\n\n\n\n\nThe upper three layers handle all the details of the application. The lower four layers know little about the application, but handle all the communication details\n\n\nThe upper three layers form what is called a \nuser process\n while the lower four layers are normally provided as part of the operating system (OS) kernel\n\n\n\n\nBSD Networking History\n\n\nLinux does not fit into the Berkeley-derived classification: Its networking code and sockets API were developed from scratch.\n\n\nUnix Standards\n\n\nBackground on POSIX\n\n\n\n\nPOSIX: Portable Operating System Interface, developed by IEEE and adopted as standards by ISO and IEC (ISO/IEC)\n\n\n\n\nBackground on The Open Group\n\n\n\n\nSingle UNIX Specification\n\n\n\n\nInternet Engineering Task Force (IETF)\n\n\n64-Bit Architectures\n\n\n\n\nILP32\n: integers (I), long integers (L), and pointers (P) occupy 32 bits.\n\n\nLP64\n:only long integers (L) and pointers (P) require 64 bits.\n\n\n\n\nFrom a programming perspective, the LP64 model means we cannot assume that a pointer can be stored in an integer. We must also consider the effect of the LP64 model on existing APIs\n\n\nOn a 32-bit system, \nsize_t\n is a 32-bit value, but on a 64-bit system, it must be a 64-bit value, to take advantage of the larger addressing model. This means a 64-bit system will probably contain a typedef of \nsize_t\n to be an unsigned long.", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/unp/ch2/", 
            "text": "Chapter 2. The Transport Layer: TCP, UDP, and SCTP\n\n\nIntroduction\n\n\nThis chapter focuses on the transport layer: TCP, UDP, and Stream Control Transmission Protocol (SCTP). UDP is a simple, unreliable datagram protocol, while TCP is a sophisticated, reliable byte-stream protocol. SCTP is similar to TCP as a reliable transport protocol, but it also provides message boundaries, transport-level support for multihoming, and a way to minimize head-of-line blocking.\n\n\nThe Big Picture\n\n\nOverview of TCP/IP protocols:\n\n\n\n\n\n\n\n\nProtocol\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIPv4\n\n\nInternet Protocol version 4. IPv4 uses 32-bit addresses and provides packet delivery service for TCP, UDP, SCTP, ICMP, and IGMP.\n\n\n\n\n\n\nIPv6\n\n\nInternet Protocol version 6. IPv6 uses 128-bit addresses.\n\n\n\n\n\n\nTCP\n\n\nTransmission Control Protocol. TCP is a connection-oriented protocol that provides a reliable, full-duplex byte stream to its users\n\n\n\n\n\n\nUDP\n\n\nUser Datagram Protocol. UDP is a connectionless protocol, and UDP sockets are an example of datagram sockets.\n\n\n\n\n\n\nSCTP\n\n\nStream Control Transmission Protocol. SCTP is a connection-oriented protocol that provides a reliable full-duplex association\n\n\n\n\n\n\nICMP\n\n\nInternet Control Message Protocol. ICMP handles error and control information between routers and hosts.\n\n\n\n\n\n\nIGMP\n\n\nInternet Group Management Protocol. IGMP is used with multicasting.\n\n\n\n\n\n\nARP\n\n\nAddress Resolution Protocol. ARP maps an IPv4 address into a hardware address (such as an Ethernet address). ARP is normally used on broadcast networks such as Ethernet, \ntoken ring\n, and \nFDDI\n, and is not needed on point-to-point networks.\n\n\n\n\n\n\nRARP\n\n\nReverse Address Resolution Protocol. RARP maps a hardware address into an IPv4 address. It is sometimes used when a diskless node is booting.\n\n\n\n\n\n\nICMPv6\n\n\nInternet Control Message Protocol version 6. ICMPv6 combines the functionality of ICMPv4, IGMP, and ARP.\n\n\n\n\n\n\nBPF\n\n\nBSD packet filter\n. This interface provides access to the datalink layer. It is normally found on Berkeley-derived kernels.\n\n\n\n\n\n\nDLPI\n\n\nDatalink provider interface\n.\n\n\n\n\n\n\n\n\nUser Datagram Protocol (UDP)\n\n\n\n\nLack of reliability\n\n\nEach UDP datagram has a length\n\n\nConnectionless\n service\n\n\n\n\nTransmission Control Protocol (TCP)\n\n\n\n\nConnection\n: TCP provides connections between clients and servers. A TCP client establishes a connection with a server, exchanges data across the connection, and then terminates the connection.\n\n\nReliability\n: TCP requires acknowledgment when sending data. If an acknowledgment is not received, TCP automatically retransmits the data and waits a longer amount of time.\n\n\nRound-trip time\n (RTT): TCP estimates RTT between a client and server dynamically so that it knows how long to wait for an acknowledgment.\n\n\nSequencing\n: TCP associates a sequence number with every byte (\nsegment\n, unit of data that TCP passes to IP.) it sends. TCP reorders out-of-order segments and discards duplicate segments.\n\n\nFlow control\n\n\nFull-duplex\n: an application can send and receive data in both directions on a given connection at any time.\n\n\n\n\nStream Control Transmission Protocol (SCTP)\n\n\nLike TCP, SCTP provides reliability, sequencing, flow control, and full-duplex data transfer.\n\n\nUnlike TCP, SCTP provides:\n\n\n\n\nAssociation\n instead of \"connection\": An association refers to a communication between two systems, which may involve more than two addresses due to multihoming.\n\n\nMessage-oriented\n: provides sequenced delivery of individual records. Like UDP, the length of a record written by the sender is passed to the receiving application.\n\n\nMultihoming\n: allows a single SCTP endpoint to support multiple IP addresses. This feature can provide increased robustness against network failure.\n\n\n\n\nTCP Connection Establishment and Termination\n\n\nThree-Way Handshake\n\n\n\n\n\n\nServer: \npassive open\n, by calling \nsocket\n, \nbind\n, and \nlisten\n\n\nClient: \nactive open\n, by calling \nconnect\n. The client TCP to send a \"synchronize\" (SYN) segment with no data but it contains client's initial sequence number for the data to be sent on the connection.\n\n\nServer: acknowledges (ACK) client's SYN. The server sends its SYN and the ACK of the client's SYN in a single segment which also contains its own SYN containing the initial sequence number for the data to be sent on the connection.\n\n\nClient: acknowledges the server's SYN.\n\n\n\n\nThe client's initial sequence number as \nJ\n and the server's initial sequence number as \nK\n. The acknowledgment number in an ACK is the next expected sequence number for the end sending the ACK. Since a SYN occupies one byte of the sequence number space, the acknowledgment number in the ACK of each SYN is the initial sequence number plus one.\n\n\nTCP Options\n\n\n\n\nMSS option. The TCP sending the SYN announces its \nmaximum segment size\n (the maximum amount of data that it is willing to accept in each TCP segment)on this connection.\n\n\nWindow scale option. [p38]\n\n\nTimestamp option\n\n\n\n\nTCP Connection Termination\n\n\n\n\nIt takes four segments to terminate a connection:\n\n\n\n\nOne end calls \nclose\n first by sending a FIN segment to mean it is finished sending data. This is called \nactive close\n.\n\n\nThe other end that receives the FIN performs the \npassive close\n. The received FIN is acknowledged by TCP (sending an ACK segment). The receipt of the FIN is also passed to the application as an end-of-file.\n\n\nSometime later, the application that received the end-of-file will close its socket. This causes its TCP to send a FIN.\n\n\nThe TCP on the system that receives this final FIN (the end that did the active close) acknowledges the FIN\n\n\n\n\nA FIN occupies one byte of sequence number space just like a SYN. Therefore, the ACK of each FIN is the sequence number of the FIN plus one.\n\n\nTCP State Transition Diagram\n\n\n\n\nThere are 11 different states defined for a connection and the rules of TCP dictate the transitions from one state to another, based on the current state and the segment received in that state.\n\n\nWatching the Packets\n\n\n\n\nThe client in this example announces an MSS of 536 (\nminimum reassembly buffer size\n) and the server announces an MSS of 1,460 (typical for IPv4 on an Ethernet). It is okay for the MSS to be different in each direction. The acknowledgment of the client's request is sent with the server's reply. This is called \npiggybacking\n and will normally happen when the time it takes the server to process the request and generate the reply is less than around 200 ms. \nWith TCP, there would be eight segments of overhead. If UDP was used, only two packets would be exchanged.\n\n\n\n\nUDP removes all the reliability that TCP provides to the application.\n\n\nUDP avoids the overhead of TCP connection establishment and connection termination.\n\n\n\n\nTIME_WAIT State\n\n\nThe end that performs the active close goes through the TIME_WAIT state. The duration that this endpoint remains in the TIME_WAIT state is twice the \nmaximum segment lifetime\n (MSL), sometimes called 2MSL, which is between 1 and 4 minutes. The MSL is the maximum amount of time that any given IP datagram can live in a network. The IPv4 TTL field  IPv6 hop limit field have a maximum value 255. The assumption is made that a packet with the maximum hop limit of 255 cannot exist in a network for more than MSL seconds. [p43]\n\n\nTCP must handle \nlost duplicates\n (or \nwandering duplicate\n).\n\n\nThere are two reasons for the TIME_WAIT state:\n\n\n\n\nTo implement TCP's full-duplex connection termination reliably. If TCP is performing all the work necessary to terminate both directions of data flow cleanly for a connection (its full-duplex close), then it must correctly handle the loss of any of these four segments.\n\n\nTo allow old duplicate segments to expire in the network. When we successfully establish a TCP connection, all old duplicates from previous \nincarnations\n of the connection have expired in the network.\n\n\n\n\nPort Numbers\n\n\nAll three transport layers (UDP, SCTP and TCP) use 16-bit integer port numbers to differentiate between processes.\n\n\n\n\nThe \nwell-known ports\n: 0 through 1023.\n\n\nThe \nregistered ports\n: 1024 through 49151\n\n\nThe \ndynamic ports\n or \nprivate ports\n, 49152 through 65535. Also called \nephemeral ports\n.\n\n\n\n\n\n\nSome notes from the figure above:\n\n\n\n\nOn Unix, \nreserved port\n is any port less than 1024. These ports can only be assigned to a socket by an appropriately privileged process. All the IANA well-known ports are reserved ports. The server allocating this port must have superuser privileges when it starts.\n\n\nHistorically, Berkeley-derived implementations (starting with 4.3BSD) have allocated \nephemeral ports\n in the range 1024\u20135000. Many newer systems allocate ephemeral ports differently to provide more ephemeral ports, either using the IANA-defined ephemeral range or a larger range\n\n\n\n\nSocket Pair\n\n\n\n\nSocket pair\n: the four-tuple that defines the two endpoints of a TCP connection: the local IP address, local port, foreign IP address, and foreign port. A socket pair uniquely identifies every TCP connection on a network.\n\n\nSocket\n: two values (an IP address and a port number) that identify each endpoint.\n\n\n\n\nTCP Port Numbers and Concurrent Servers\n\n\n[p52-55]\n\n\nBuffer Sizes and Limitations\n\n\nFigures: \nIPv4 Header\n, \nIPv6 Header\n\n\n\n\nMaximum size of an IPv4 datagram: 65,535 bytes (including the header), because of the 16-bit total length field.\n\n\nMaximum size of an IPv6 datagram: 65,575 bytes (including the 40-byte IPv6 header), because of the 16-bit payload length field. IPv6 has a jumbo payload option, which extends the payload length field to 32 bits, but this option is supported only on datalinks with a \nmaximum transmission unit\n (MTU) that exceeds 65,535.\n\n\nMTU\n (maximum transmission unit): dictated by the hardware. Ethernet MTU is 1,500 bytes; Point-to-point links have a configurable MTU.\n\n\nMinimum link MTU for IPv4: 68 bytes. This permits a maximum-sized IPv4 header (20 bytes of fixed header, 40 bytes of options)  and minimum-sized fragment (the fragment offset is in units of 8 bytes) \n[errata]\n\n\nMinimum link MTU for IPv6: 1,280 bytes.\n\n\n\n\n\n\nPath MTU\n: smallest MTU in the path between two hosts. Today, the Ethernet MTU of 1,500 bytes is often the path MTU. The path MTU need not be the same in both directions between any two hosts because routing in the Internet is often asymmetric.\n\n\nFragmentation\n is performed by both IPv4 and IPv6 when the size of an IP datagram to be sent out an interface exceeds the link MTU. The fragments are not normally \nreassembled\n until they reach the final destination.\n\n\nIPv4: hosts perform fragmentation on datagrams that they generate and routers perform fragmentation on datagrams that they forward\n\n\nIPv6: only hosts perform fragmentation on datagrams that they generate; routers do not fragment datagrams that they are forwarding\n\n\nIPv4 header contains fields to handle fragmentation. IPv6 contains an option header with the fragmentation information.\n\n\n\n\n\n\n\"Don't Fragment\" (DF) bit in IPv4 header specifies that this datagram must not be fragmented, either by the sending host or by any router. A router that receives an IPv4 datagram with the DF bit set whose size exceeds the outgoing link's MTU generates an ICMPv4 \"destination unreachable, fragmentation needed but DF bit set\" error message.\n\n\nSince IPv6 routers do not perform fragmentation, there is an implied DF bit with every IPv6 datagram. When an IPv6 router receives a datagram whose size exceeds the outgoing link's MTU, it generates an ICMPv6 \"packet too big\" error message\n\n\nPath MTU discovery\n uses IPv4 DF bit and its implied IPv6 counterpart. Path MTU discovery is optional with IPv4, but IPv6 implementations all either support path MTU discovery or always send using the minimum MTU. [p55]\n\n\n\n\n\n\nMinimum reassembly buffer size\n: the minimum datagram size that we are guaranteed any implementation must support.\n\n\nIPv4: 576 bytes. We have no idea whether a given destination can accept a 577-byte datagram or not. Therefore, many IPv4 applications that use UDP (e.g., DNS, RIP, TFTP, BOOTP, SNMP) prevent applications from generating IP datagrams that exceed this size.\n\n\nIPv6: 1,500 bytes\n\n\n\n\n\n\nTCP has a \nmaximum segment size\n (MSS) that announces to the peer TCP the maximum amount of TCP data that the peer can send per segment. We saw the MSS option on the SYN segments in \nFigure 2.5\n. The goal of the MSS is to tell the peer the actual value of the reassembly buffer size and to try to avoid fragmentation. The MSS is often set to the interface MTU minus the fixed sizes of the IP and TCP headers. On an Ethernet using IPv4, this would be 1,460, and on an Ethernet using IPv6, this would be 1,440. (The TCP header is 20 bytes for both, but the IPv4 header is 20 bytes and the IPv6 header is 40 bytes.)\n\n\nIPv4: The MSS value in the TCP MSS option is a 16-bit field, limiting the value to 65,535. The maximum amount of TCP data in an IPv4 datagram is 65,495 (65,535 minus the 20-byte IPv4 header and minus the 20-byte TCP header).\n\n\nIPv6: the maximum amount of TCP data in an IPv6 datagram without the jumbo payload option is 65,515 (65,535 minus the 20-byte TCP header). The MSS value of 65,535 is considered a special case that designates \"infinity.\" This value is used only if the jumbo payload option is being used, which requires an MTU that exceeds 65,535.\n\n\n\n\n\n\n\n\nTCP Output\n\n\nEvery TCP socket has a send buffer and we can change the size of this buffer with the \nSO_SNDBUF\n socket option. When an application calls \nwrite\n, the kernel copies all the data from the application buffer into the socket send buffer. If there is insufficient room in the socket buffer for all the application's data, the process is put to sleep. This assumes the normal default of a blocking socket. The kernel will not return from the write until the final byte in the application buffer has been copied into the socket send buffer. Therefore, \nthe successful return from a write to a TCP socket only tells us that we can reuse our application buffer. It does not tell us that either the peer TCP has received the data or that the peer application has received the data.\n\n\nTCP takes the data in the socket send buffer and sends it to the peer TCP.\n The peer TCP must acknowledge the data, and as the ACKs arrive from the peer, only then can our TCP discard the acknowledged data from the socket send buffer. TCP must keep a copy of our data until it is acknowledged by the peer.\n\n\nTCP sends the data to IP in MSS-sized or smaller chunks, prepending its TCP header to each segment, where the MSS is the value announced by the peer, or 536 if the peer did not send an MSS option. IP prepends its header, searches the routing table for the destination IP address, and passes the datagram to the appropriate datalink. IP might perform fragmentation before passing the datagram to the datalink, but one goal of the MSS option is to try to avoid fragmentation and newer implementations also use path MTU discovery. Each datalink has an output queue, and if this queue is full, the packet is discarded and an error is returned up the protocol stack [p58]\n\n\nUDP Output\n\n\nUDP socket doesn't have a socket send buffer, since it does not need to keep a copy of the application's data. It has a send buffer size (which we can change with the \nSO_SNDBUF\n socket option), but this is simply an upper limit on the maximum-sized UDP datagram that can be written to the socket. If an application writes a datagram larger than the socket send buffer size, \nEMSGSIZE\n is returned.\n\n\nUDP simply prepends its 8-byte header and passes the datagram to IP. IP determines the outgoing interface by performing the routing function, and then either adds the datagram to the datalink output queue (if it fits within the MTU) or fragments the datagram and adds each fragment to the datalink output queue (see \nUDP and IP Fragmentation in TCPv1\n). If a UDP application sends large datagrams, there is a much higher probability of (IP) fragmentation than with TCP.\n\n\nStandard Internet Services\n\n\nProtocol Usage by Common Internet Applications", 
            "title": "Chapter 2. The Transport Layer: TCP, UDP, and SCTP"
        }, 
        {
            "location": "/unp/ch3/", 
            "text": "Chapter 3. Sockets Introduction\n\n\nIntroduction\n\n\nThis chapter begins the description of the sockets API.\n\n\nSocket Address Structures\n\n\nThe name of socket address structures begin with \nsockaddr_\n and end with a unique suffix for each protocol suite.\n\n\nIPv4 Socket Address Structure\n\n\nAn IPv4 socket address structure, commonly called an \"Internet socket address structure\", is named \nsockaddr_in\n and is defined by including the \nnetinet/in.h\n header.\n\n\nstruct\n \nin_addr\n \n{\n\n  \nin_addr_t\n   \ns_addr\n;\n           \n/* 32-bit IPv4 address */\n\n                                \n/* network byte ordered */\n\n\n};\n\n\n\nstruct\n \nsockaddr_in\n \n{\n\n  \nuint8_t\n         \nsin_len\n;\n      \n/* length of structure (16) */\n\n  \nsa_family_t\n     \nsin_family\n;\n   \n/* AF_INET */\n\n  \nin_port_t\n       \nsin_port\n;\n     \n/* 16-bit TCP or UDP port number */\n\n                                \n/* network byte ordered */\n\n  \nstruct\n \nin_addr\n  \nsin_addr\n;\n     \n/* 32-bit IPv4 address */\n\n                                \n/* network byte ordered */\n\n  \nchar\n            \nsin_zero\n[\n8\n];\n  \n/* unused */\n\n\n};\n\n\n\n\n\n\n\n\nsin_len\n: the length field. We need never set it and need never examine it.\n\n\nThe four socket functions that pass a socket address structure from the process to the kernel, \nbind\n, \nconnect\n, \nsendto\n, and \nsendmsg\n, all go through the \nsockargs\n function in a Berkeley-derived implementation. This function copies the socket address structure from the process and explicitly sets its \nsin_len\n member to the size of the structure that was passed as an argument to these four functions. The five socket functions that pass a socket address structure from the kernel to the process, \naccept\n, \nrecvfrom\n, \nrecvmsg\n, \ngetpeername\n, and \ngetsockname\n, all set the \nsin_len\n member before returning to the process.\n\n\n\n\n\n\nPOSIX requires only three members in the structure: \nsin_family\n, \nsin_addr\n, and \nsin_port\n. Almost all implementations add the \nsin_zero\n member so that all socket address structures are at least 16 bytes in size.\n\n\nThe \nin_addr_t\n datatype must be an unsigned integer type of at least 32 bits, \nin_port_t\n must be an unsigned integer type of at least 16 bits, and \nsa_family_t\n can be any unsigned integer type. The latter is normally an 8-bit unsigned integer if the implementation supports the length field, or an unsigned 16-bit integer if the length field is not supported.\n\n\nBoth the IPv4 address and the TCP or UDP port number are always stored in the structure in \nnetwork byte order\n.\n\n\nThe \nsin_zero\n member is unused. By convention, we always set the entire structure to 0 before filling it in.\n\n\nSocket address structures are used only on a given host: The structure itself is not communicated between different hosts\n\n\n\n\nGeneric Socket Address Structure\n\n\nA socket address structures is always passed by reference when passed as an argument to any socket functions. But any socket function that takes one of these pointers as an argument must deal with socket address structures from any of the supported protocol families.\n\n\nA generic socket address structure in the \nsys/socket.h\n header:\n\n\nstruct\n \nsockaddr\n \n{\n\n  \nuint8_t\n      \nsa_len\n;\n\n  \nsa_family_t\n  \nsa_family\n;\n    \n/* address family: AF_xxx value */\n\n  \nchar\n         \nsa_data\n[\n14\n];\n  \n/* protocol-specific address */\n\n\n};\n\n\n\n\n\n\nThe socket functions are then defined as taking a pointer to the generic socket address structure, as shown here in the ANSI C function prototype for the \nbind\n function:\n\n\nint\n \nbind\n(\nint\n,\n \nstruct\n \nsockaddr\n \n*\n,\n \nsocklen_t\n);\n\n\n\n\n\n\nThis requires that any calls to these functions must cast the \npointer to the \nprotocol-specific socket address structure\n to be a \npointer to a \ngeneric socket address structure\n.\n\n\nFor example:\n\n\nstruct\n \nsockaddr_in\n  \nserv\n;\n      \n/* IPv4 socket address structure */\n\n\n\n/* fill in serv{} */\n\n\n\nbind\n(\nsockfd\n,\n \n(\nstruct\n \nsockaddr\n \n*\n)\n \nserv\n,\n \nsizeof\n(\nserv\n));\n\n\n\n\n\n\nIn Chapter 1 in our unp.h header\n, we define \nSA\n to be the string \nstruct sockaddr\n, just to shorten the code that we must write to cast these pointers.\n\n\n\n\nFrom an application programmer \u2019s point of view, \nthe only use of these generic socket address structures is to cast pointers to protocol-specific structures.\n\n\nFrom the kernel\u2019s perspective, another reason for using pointers to generic socket address structures as arguments is that the kernel must take the caller\u2019s pointer, cast it to a \nstruct sockaddr *\n, and then look at the value of \nsa_family\n to determine the type of the structure.\n\n\n\n\nIPv6 Socket Address Structure\n\n\nThe IPv6 socket address is defined by including the \nnetinet/in.h\n header:\n\n\nstruct\n \nin6_addr\n \n{\n\n  \nuint8_t\n  \ns6_addr\n[\n16\n];\n          \n/* 128-bit IPv6 address */\n\n                                 \n/* network byte ordered */\n\n\n};\n\n\n\n#define SIN6_LEN      \n/* required for compile-time tests */\n\n\n\nstruct\n \nsockaddr_in6\n \n{\n\n  \nuint8_t\n         \nsin6_len\n;\n      \n/* length of this struct (28) */\n\n  \nsa_family_t\n     \nsin6_family\n;\n   \n/* AF_INET6 */\n\n  \nin_port_t\n       \nsin6_port\n;\n     \n/* transport layer port# */\n\n                                 \n/* network byte ordered */\n\n  \nuint32_t\n        \nsin6_flowinfo\n;\n \n/* flow information, undefined */\n\n  \nstruct\n \nin6_addr\n \nsin6_addr\n;\n     \n/* IPv6 address */\n\n                                 \n/* network byte ordered */\n\n  \nuint32_t\n        \nsin6_scope_id\n;\n \n/* set of interfaces for a scope */\n\n\n};\n\n\n\n\n\n\n\n\nThe \nSIN6_LEN\n constant must be defined if the system supports the length member for socket address structures.\n\n\nThe IPv6 family is \nAF_INET6\n, whereas the IPv4 family is \nAF_INET\n\n\nThe members in this structure are ordered so that if the \nsockaddr_in6\n structure is 64-bit aligned, so is the 128-bit \nsin6_addr\n member.\n\n\nThe \nsin6_flowinfo\n member is divided into two fields:\n\n\nThe low-order 20 bits are the flow label\n\n\nThe high-order 12 bits are reserved\n\n\n\n\n\n\nThe \nsin6_scope_id\n identifies the scope zone in which a scoped address is meaningful, most commonly an interface index for a link-local address\n\n\n\n\nNew Generic Socket Address Structure\n\n\nA new generic socket address structure was defined as part of the IPv6 sockets API, to overcome some of the shortcomings of the existing \nstruct sockaddr\n. Unlike the \nstruct sockaddr\n, the new \nstruct sockaddr_storage\n is large enough to hold any socket address type supported by the system. The \nsockaddr_storage\n structure is defined by including the \nnetinet/in.h\n header:\n\n\nstruct\n \nsockaddr_storage\n \n{\n\n  \nuint8_t\n      \nss_len\n;\n       \n/* length of this struct (implementation dependent) */\n\n  \nsa_family_t\n  \nss_family\n;\n    \n/* address family: AF_xxx value */\n\n  \n/* implementation-dependent elements to provide:\n\n\n   * a) alignment sufficient to fulfill the alignment requirements of\n\n\n   *    all socket address types that the system supports.\n\n\n   * b) enough storage to hold any type of socket address that the\n\n\n   *    system supports.\n\n\n   */\n\n\n};\n\n\n\n\n\n\nThe \nsockaddr_storage\n type provides a generic socket address structure that is different from \nstruct sockaddr\n in two ways:\n\n\n\n\nIf any socket address structures that the system supports have alignment requirements, the \nsockaddr_storage\n provides the strictest alignment requirement.\n\n\nThe \nsockaddr_storage\n is large enough to contain any socket address structure that the system supports.\n\n\n\n\nThe fields of the \nsockaddr_storage\n structure are opaque to the user, except for \nss_family\n and \nss_len\n (if present). The \nsockaddr_storage\n must be cast or copied to the appropriate socket address structure for the address given in \nss_family\n to access any other fields.\n\n\nComparison of Socket Address Structures\n\n\nIn this figure, we assume that:\n\n\n\n\nSocket address structures all contain a one-byte length field\n\n\nThe family field also occupies one byte\n\n\nAny field that must be at least some number of bits is exactly that number of bits\n\n\n\n\n\n\nTo handle variable-length structures, whenever we pass a pointer to a socket address structure as an argument to one of the socket functions, we pass its length as another argument.\n\n\nValue-Result Arguments\n\n\nWhen a socket address structure is passed to any socket function, it is always passed by reference (a pointer to the structure is passed). The length of the structure is also passed as an argument.\n\n\nThe way in which the length is passed depends on which direction the structure is being passed:\n\n\n\n\nFrom the \nprocess to the kernel\n\n\nFrom the \nkernel to the process\n\n\n\n\nFrom process to kernel\n\n\nbind\n, \nconnect\n, and \nsendto\n functions pass a socket address structure from the process to the kernel.\n\n\nArumgents to these functions:\n\n\n\n\nThe pointer to the socket address structure\n\n\nThe integer size of the structure\n\n\n\n\nstruct\n \nsockaddr_in\n \nserv\n;\n\n\n\n/* fill in serv{} */\n\n\nconnect\n \n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nserv\n,\n \nsizeof\n(\nserv\n));\n\n\n\n\n\n\n\n\nThe datatype for the size of a socket address structure is actually \nsocklen_t\n and not \nint\n, but the POSIX specification recommends that \nsocklen_t\n be defined as \nuint32_t\n.\n\n\nFrom kernel to process\n\n\naccept\n, \nrecvfrom\n, \ngetsockname\n, and \ngetpeername\n functions pass a socket address structure from the kernel to the process.\n\n\nArguments to these functions:\n\n\n\n\nThe pointer to the socket address structure\n\n\nThe pointer to an integer containing the size of the structure.\n\n\n\n\nstruct\n \nsockaddr_un\n  \ncli\n;\n   \n/* Unix domain */\n\n\nsocklen_t\n  \nlen\n;\n\n\n\nlen\n \n=\n \nsizeof\n(\ncli\n);\n         \n/* len is a value */\n\n\ngetpeername\n(\nunixfd\n,\n \n(\nSA\n \n*\n)\n \ncli\n,\n \nlen\n);\n\n\n/* len may have changed */\n\n\n\n\n\n\n\n\nValue-result argument\n (Figure 3.8): the size changes from an integer to be a pointer to an integer because the size is both \na value when the function is called and a result when the function returns.\n\n\n\n\nAs a \nvalue\n: it tells the kernel the size of the structure so that the kernel does not write past the end of the structure when filling it in\n\n\nAs a \nresult\n: it tells the process how much information the kernel actually stored in the structure\n\n\n\n\nFor two other functions that pass socket address structures, \nrecvmsg\n and \nsendmsg\n, the length field is not a function argument but a structure member.\n\n\nIf the socket address structure is fixed-length, the value returned by the kernel will always be that fixed size: 16 for an IPv4 \nsockaddr_in\n and 28 for an IPv6 \nsockaddr_in6\n. But with a variable-length socket address structure (e.g., a Unix domain \nsockaddr_un\n), the value returned can be less than the maximum size of the structure.\n\n\nThough the most common example of a value-result argument is the length of a returned socket address structure, we will encounter other value-result arguments in this text:\n\n\n\n\nThe middle three arguments for the \nselect\n function (Section 6.3)\n\n\nThe length argument for the \ngetsockopt\n function (Section 7.2)\n\n\nThe \nmsg_namelen\n and \nmsg_controllen\n members of the \nmsghdr\n structure, when used with \nrecvmsg\n (Section 14.5)\n\n\nThe \nifc_len\n member of the \nifconf\n structure (Figure 17.2)\n\n\nThe first of the two length arguments for the \nsysctl\n function (Section 18.4)\n\n\n\n\nByte Ordering Functions\n\n\nFor a 16-bit integer that is made up of 2 bytes, there are two ways to store the two bytes in memory:\n\n\n\n\nLittle-endian\n order: low-order byte is at the starting address.\n\n\nBig-endian\n order: high-order byte is at the starting address.\n\n\n\n\n\n\nThe figure shows the most significant bit (MSB) as the leftmost bit of the 16-bit value and the least significant bit (LSB) as the rightmost bit.\n\n\nThe terms \"little-endian\" and \"big-endian\" indicate which end of the multibyte value, the little end or the big end, is stored at the starting address of the value.\n\n\nHost byte order\n refer to the byte ordering used by a given system. The program below prints the host byte order:\n\n\nbyteorder.c\n\n\n\n\n\nWe store the two-byte value \n0x0102\n in the short integer and then look at the two consecutive bytes, \nc[0]\n (the address \nA\n) and \nc[1]\n (the address \nA+1\n) to determine the byte order.\n\n\nThe string \nCPU_VENDOR_OS\n is determined by the GNU \nautoconf\n program.\n\n\nfreebsd4 % byteorder\ni386-unknown-freebsd4.8: little-endian\n\nmacosx % byteorder\npowerpc-apple-darwin6.6: big-endian\n\nfreebsd5 % byteorder\nsparc64-unknown-freebsd5.1: big-endian\n\naix % byteorder\npowerpc-ibm-aix5.1.0.0: big-endian\n\nhpux % byteorder\nhppa1.1-hp-hpux11.11: big-endian\n\nlinux % byteorder\ni586-pc-linux-gnu: little-endian\n\nsolaris % byteorder\nsparc-sun-solaris2.9: big-endian\n\n\n\n\n\nNetworking protocols must specify a \nnetwork byte order\n. The sending protocol stack and the receiving protocol stack must agree on the order in which the bytes of these multibyte fields will be transmitted. \nThe Internet protocols use big-endian byte ordering for these multibyte integers.\n\n\nBut, both history and the POSIX specification say that certain fields in the socket address structures must be maintained in network byte order. We use the following four functions to convert between these two byte orders:\n\n\nunp_htons.h\n\n\n#include \nnetinet/in.h\n\n\n\nuint16_t\n \nhtons\n(\nuint16_t\n \nhost16bitvalue\n);\n\n\nuint32_t\n \nhtonl\n(\nuint32_t\n \nhost32bitvalue\n);\n\n\n\n/* Both return: value in network byte order */\n\n\n\nuint16_t\n \nntohs\n(\nuint16_t\n \nnet16bitvalue\n);\n\n\nuint32_t\n \nntohl\n(\nuint32_t\n \nnet32bitvalue\n);\n\n\n\n/* Both return: value in host byte order */\n\n\n\n\n\n\n\n\nh\n stands for \nhost\n\n\nn\n stands for \nnetwork\n\n\ns\n stands for \nshort\n (16-bit value, e.g. TCP or UDP port number)\n\n\nl\n stands for \nlong\n (32-bit value, e.g. IPv4 address)\n\n\n\n\nWhen using these functions, we do not care about the actual values (big-endian or little-endian) for the host byte order and the network byte order. What we must do is call the appropriate function to convert a given value between the host and network byte order. On those systems that have the same byte ordering as the Internet protocols (big-endian), these four functions are usually defined as null macros.\n\n\nWe use the term \"byte\" to mean an 8-bit quantity since almost all current computer systems use 8-bit bytes. Most Internet standards use the term \noctet\n instead of byte to mean an 8-bit quantity.\n\n\nBit ordering is an important convention in Internet standards, such as the the first 32 bits of the IPv4 header from RFC 791:\n\n\n 0                   1                   2                   3\n 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n|Version|  IHL |Type of Service|           Total Length         |\n+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n\n\n\n\nThis represents four bytes in the order in which they appear on the wire; the leftmost bit is the most significant. However, the numbering starts with zero assigned to the most significant bit.\n\n\nByte Manipulation Functions\n\n\nTwo types functions differ in whether they deal with null-terminated C strings:\n\n\n\n\nThe functions that operate on multibyte fields, without interpreting the data, and without assuming that the data is a null-terminated C string. These types of functions deal with socket address structures to manipulate fields such as IP addresses, which can contain bytes of 0, but are not C character strings.\n\n\nThe functions whose names begin with \nb\n (for byte) (from 4.2BSD)\n\n\nThe functions whose names begin with \nmem\n (for memory) (from ANSI C)\n\n\n\n\n\n\nThe functions that deal with null-terminated C character strings (beginning with \nstr\n (for string), defined by including the \nstring.h\n header)\n\n\n\n\nunp_bzero.h\n\n\n#include \nstrings.h\n\n\n\nvoid\n \nbzero\n(\nvoid\n \n*\ndest\n,\n \nsize_t\n \nnbytes\n);\n\n\nvoid\n \nbcopy\n(\nconst\n \nvoid\n \n*\nsrc\n,\n \nvoid\n \n*\ndest\n,\n \nsize_t\n \nnbytes\n);\n\n\nint\n \nbcmp\n(\nconst\n \nvoid\n \n*\nptr1\n,\n \nconst\n \nvoid\n \n*\nptr2\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: 0 if equal, nonzero if unequal */\n\n\n\n\n\n\nThe memory pointed to by the \nconst\n pointer is read but not modified by the function.\n\n\n\n\nbzero\n sets the specified number of bytes to 0 in the destination. We often use this function to initialize a socket address structure to 0.\n\n\nbcopy\n moves the specified number of bytes from the source to the destination.\n\n\nbcmp\n compares two arbitrary byte strings. The return value is zero if the two byte strings are identical; otherwise, it is nonzero\n\n\n\n\nunp_memset.h\n\n\n#include \nstring.h\n\n\n\nvoid\n \n*\nmemset\n(\nvoid\n \n*\ndest\n,\n \nint\n \nc\n,\n \nsize_t\n \nlen\n);\n\n\nvoid\n \n*\nmemcpy\n(\nvoid\n \n*\ndest\n,\n \nconst\n \nvoid\n \n*\nsrc\n,\n \nsize_t\n \nnbytes\n);\n\n\nint\n \nmemcmp\n(\nconst\n \nvoid\n \n*\nptr1\n,\n \nconst\n \nvoid\n \n*\nptr2\n,\n \nsize_t\n \nnbytes\n);\n\n\n\n/* Returns: 0 if equal, \n0 or \n0 if unequal (see text) */\n\n\n\n\n\n\n\n\nmemset\n sets the specified number of bytes to the value \nc\n in the destination\n\n\nmemcpy\n is similar to \nbcopy\n, but the order of the two pointer arguments is swapped\n\n\nmemcmp\n compares two arbitrary byte strings\n\n\n\n\nNote:\n\n\n\n\n\n\nOne way to remember the order of the two pointers for \nmemcpy\n is to remember that they are written in the same left-to-right order as an assignment statement in C:\n\n\ndest = src;\n\n\n\n\n\n\n\n\n\nOne way to remember the order of the final two arguments to \nmemset\n is to realize that all of the ANSI C \nmemXXX\n functions require a length argument, and it is always the final argument. The comparison is done assuming the two unequal bytes are \nunsigned chars\n.\n\n\n\n\n\n\ninet_aton\n, \ninet_addr\n, and \ninet_ntoa\n Functions\n\n\nThese functions convert Internet addresses between ASCII strings (what humans prefer to use) and network byte ordered binary values (values that are stored in socket address structures).\n\n\nunp_inet_aton.h\n\n\n#include \narpa/inet.h\n\n\n\nint\n \ninet_aton\n(\nconst\n \nchar\n \n*\nstrptr\n,\n \nstruct\n \nin_addr\n \n*\naddrptr\n);\n\n\n/* Returns: 1 if string was valid, 0 on error */\n\n\n\nin_addr_t\n \ninet_addr\n(\nconst\n \nchar\n \n*\nstrptr\n);\n\n\n/* Returns: 32-bit binary network byte ordered IPv4 address; INADDR_NONE if error */\n\n\n\nchar\n \n*\ninet_ntoa\n(\nstruct\n \nin_addr\n \ninaddr\n);\n\n\n/* Returns: pointer to dotted-decimal string */\n\n\n\n\n\n\n\n\ninet_aton\n: converts the C character string pointed to by \nstrptr\n into its 32-bit binary network byte ordered value, which is stored through the pointer \naddrptr\n\n\ninet_addr\n: does the same conversion, returning the 32-bit binary network byte ordered value as the return value. It is deprecated and any new code should use \ninet_aton\n instead\n\n\ninet_ntoa\n: converts a 32-bit binary network byte ordered IPv4 address into its corresponding dotted-decimal string.\n\n\nThe string pointed to by the return value of the function resides in static memory.\n This means the function is not reentrant, which we will discuss in Section 11.18.\n\n\nThis function takes a structure as its argument, not a pointer to a structure. (Functions that take actual structures as arguments are rare. It is more common to pass a pointer to the structure.)\n\n\n\n\n\n\n\n\ninet_pton\n and \ninet_ntop\n Functions\n\n\nThese two functions are new with IPv6 and work with both IPv4 and IPv6 addresses. We use these two functions throughout the text. The letters \"p\" and \"n\" stand for \npresentation\n and \nnumeric\n. The presentation format for an address is often an ASCII string and the numeric format is the binary value that goes into a socket address structure.\n\n\nunp_inet_pton.h\n\n\n#include \narpa/inet.h\n\n\n\nint\n \ninet_pton\n(\nint\n \nfamily\n,\n \nconst\n \nchar\n \n*\nstrptr\n,\n \nvoid\n \n*\naddrptr\n);\n\n\n/* Returns: 1 if OK, 0 if input not a valid presentation format, -1 on error */\n\n\n\nconst\n \nchar\n \n*\ninet_ntop\n(\nint\n \nfamily\n,\n \nconst\n \nvoid\n \n*\naddrptr\n,\n \nchar\n \n*\nstrptr\n,\n \nsize_t\n \nlen\n);\n\n\n/* Returns: pointer to result if OK, NULL on error */\n\n\n\n\n\n\nArguments:\n\n\n\n\nfamily\n: is either \nAF_INET\n or \nAF_INET6\n. If \nfamily\n is not supported, both functions return an error with \nerrno\n set to \nEAFNOSUPPORT\n.\n\n\n\n\nFunctions:\n\n\n\n\ninet_pton\n: converts the string pointed to by \nstrptr\n, storing the binary result through the pointer \naddrptr\n. If successful, the return value is 1. If the input string is not a valid presentation format for the specified \nfamily\n, 0 is returned.\n\n\ninet_ntop\n does the reverse conversion, from numeric (\naddrptr\n) to presentation (\nstrptr\n).\n\n\nlen\n argument is the size of the destination. To help specify this size, the following two definitions are defined by including the \nnetinet/in.h\n header.\n\n\nIf \nlen\n is too small to hold the resulting presentation format, including the terminating null, a null pointer is returned and \nerrno\n is set to \nENOSPC\n.\n\n\nThe \nstrptr\n argument to \ninet_ntop\n cannot be a null pointer. The caller must allocate memory for the destination and specify its size. On success, this pointer is the return value of the function.\n\n\n\n\n\n\n\n\nSize definitions in \nnetinet/in.h\n header for the \nlen\n argument:\n\n\n#define INET_ADDRSTRLEN       16       \n/* for IPv4 dotted-decimal */\n\n\n#define INET6_ADDRSTRLEN      46       \n/* for IPv6 hex string */\n\n\n\n\n\n\nThe following figure summarizes the five functions on address conversion functions:\n\n\n\n\nEven if your system does not yet include support for IPv6, you can start using these newer functions by replacing calls of the form.\n\n\nReplacing \ninet_addr\n to \ninet_pton\n\n\nReplace:\n\n\nfoo\n.\nsin_addr\n.\ns_addr\n \n=\n \ninet_addr\n(\ncp\n);\n\n\n\n\n\n\nwith\n\n\ninet_pton\n(\nAF_INET\n,\n \ncp\n,\n \nfoo\n.\nsin_addr\n);\n\n\n\n\n\n\nReplacing \ninet_ntoa\n to \ninet_ntop\n\n\nReplace:\n\n\nptr = inet_ntoa(foo.sin_addr);\n\n\n\n\n\nwith\n\n\nchar\n \nstr\n[\nINET_ADDRSTRLEN\n];\n\n\nptr\n \n=\n \ninet_ntop\n(\nAF_INET\n,\n \nfoo\n.\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nSimple definitions of \ninet_pton\n and \ninet_ntop\n that support IPv4\n\n\nlibfree/inet_pton_ipv4.c\n\n\nint\n\n\ninet_pton\n(\nint\n \nfamily\n,\n \nconst\n \nchar\n \n*\nstrptr\n,\n \nvoid\n \n*\naddrptr\n)\n\n\n{\n\n    \nif\n \n(\nfamily\n \n==\n \nAF_INET\n)\n \n{\n\n        \nstruct\n \nin_addr\n  \nin_val\n;\n\n\n        \nif\n \n(\ninet_aton\n(\nstrptr\n,\n \nin_val\n))\n \n{\n\n            \nmemcpy\n(\naddrptr\n,\n \nin_val\n,\n \nsizeof\n(\nstruct\n \nin_addr\n));\n\n            \nreturn\n \n(\n1\n);\n\n        \n}\n\n        \nreturn\n(\n0\n);\n\n    \n}\n\n    \nerrno\n \n=\n \nEAFNOSUPPORT\n;\n\n    \nreturn\n \n(\n-\n1\n);\n\n\n}\n\n\n\n\n\n\ninet_ntop_ipv4.c\n\n\nconst\n \nchar\n \n*\n\n\ninet_ntop\n(\nint\n \nfamily\n,\n \nconst\n \nvoid\n \n*\naddrptr\n,\n \nchar\n \n*\nstrptr\n,\n \nsize_t\n \nlen\n)\n\n\n{\n\n    \nconst\n \nu_char\n \n*\np\n \n=\n \n(\nconst\n \nu_char\n \n*\n)\n \naddrptr\n;\n\n\n    \nif\n \n(\nfamily\n \n==\n \nAF_INET\n)\n \n{\n\n        \nchar\n    \ntemp\n[\nINET_ADDRSTRLEN\n];\n\n\n        \nsnprintf\n(\ntemp\n,\n \nsizeof\n(\ntemp\n),\n \n%d.%d.%d.%d\n,\n\n                 \np\n[\n0\n],\n \np\n[\n1\n],\n \np\n[\n2\n],\n \np\n[\n3\n]);\n\n        \nif\n \n(\nstrlen\n(\ntemp\n)\n \n=\n \nlen\n)\n \n{\n\n            \nerrno\n \n=\n \nENOSPC\n;\n\n            \nreturn\n \n(\nNULL\n);\n\n        \n}\n\n        \nstrcpy\n(\nstrptr\n,\n \ntemp\n);\n\n        \nreturn\n \n(\nstrptr\n);\n\n    \n}\n\n    \nerrno\n \n=\n \nEAFNOSUPPORT\n;\n\n    \nreturn\n \n(\nNULL\n);\n\n\n}\n\n\n\n\n\n\nsock_ntop\n and Related Functions\n\n\nA basic problem with \ninet_ntop\n is that it requires the caller to pass a pointer to a binary address. This address is normally contained in a socket address structure, requiring the caller to know the format of the structure and the address family.\n\n\nFor IPv4:\n\n\nstruct\n \nsockaddr_in\n   \naddr\n;\n\n\ninet_ntop\n(\nAF_INET\n,\n \naddr\n.\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nFor IPv6:\n\n\nstruct\n \nsockaddr_in6\n   \naddr6\n;\n\n\ninet_ntop\n(\nAF_INET6\n,\n \naddr6\n.\nsin6_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n));\n\n\n\n\n\n\nThis (above) makes our code protocol-dependent.\n\n\nTo solve this, we will write our own function named \nsock_ntop\n that takes a pointer to a socket address structure, looks inside the structure, and calls the appropriate function to return the presentation format of the address.\n\n\nunp_sock_ntop.h\n\n\n#include \nunp.h\n\n\n\nchar\n \n*\nsock_ntop\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: non-null pointer if OK, NULL on error */\n\n\n\n\n\n\nsockaddr\n points to a socket address structure whose length is \naddrlen\n. The function uses its own static buffer to hold the result and a pointer to this buffer is the return value. Notice that \nusing static storage for the result prevents the function from being \nre-entrant\n or \nthread-safe\n.\n\n\nPresentation format of \nsock_ntop\n\n\n\n\nIPv4: dotted-decimal form, followed by a terminator (colon), followed by the decimal port number, followed by a null character\n\n\nThe buffer size must be at least \nINET_ADDRSTRLEN\n plus 6 bytes for IPv4 (16 + 6 = 22)\n\n\n\n\n\n\nIPv6: hex string form of an IPv6 address surrounded by brackets, followed by a terminator (colon), followed by the decimal port number, followed by a\nnull character. Hence, the buffer size must be at least INET_ADDRSTRLEN plus 6 bytes\n\n\nThe buffer size must be at least \nINET6_ADDRSTRLEN\n plus 8 bytes for IPv6 (46 + 8 = 54)\n\n\n\n\n\n\n\n\nsock_ntop\n definition\n\n\n\n\nlib/sock_ntop.c\n\n\n\n\nThe source code for only the \nAF_INET\n case:\n\n\nchar\n \n*\n\n\nsock_ntop\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsa\n,\n \nsocklen_t\n \nsalen\n)\n\n\n{\n\n    \nchar\n        \nportstr\n[\n8\n];\n\n    \nstatic\n \nchar\n \nstr\n[\n128\n];\n       \n/* Unix domain is largest */\n\n\n    \nswitch\n \n(\nsa\n-\nsa_family\n)\n \n{\n\n    \ncase\n \nAF_INET\n:\n \n{\n\n        \nstruct\n \nsockaddr_in\n  \n*\nsin\n \n=\n \n(\nstruct\n \nsockaddr_in\n \n*\n)\n \nsa\n;\n\n\n        \nif\n \n(\ninet_ntop\n(\nAF_INET\n,\n \nsin\n-\nsin_addr\n,\n \nstr\n,\n \nsizeof\n(\nstr\n))\n \n==\n \nNULL\n)\n\n            \nreturn\n(\nNULL\n);\n\n        \nif\n \n(\nntohs\n(\nsin\n-\nsin_port\n)\n \n!=\n \n0\n)\n \n{\n\n            \nsnprintf\n(\nportstr\n,\n \nsizeof\n(\nportstr\n),\n \n:%d\n,\n \nntohs\n(\nsin\n-\nsin_port\n));\n\n            \nstrcat\n(\nstr\n,\n \nportstr\n);\n\n        \n}\n\n        \nreturn\n(\nstr\n);\n\n    \n}\n\n  \n/* ... */\n\n\n\n\n\n\nRelated functions\n\n\nThere are a few other functions that we define to operate on socket address structures,\nand these will simplify the portability of our code between IPv4 and IPv6.\n\n\napue_sock_bind_wild.h\n\n\n#include \nunp.h\n\n\n\nint\n \nsock_bind_wild\n(\nint\n \nsockfd\n,\n \nint\n \nfamily\n);\n\n\n/* Returns: 0 if OK, -1 on error */\n\n\n\nint\n \nsock_cmp_addr\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr1\n,\n\n                  \nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr2\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: 0 if addresses are of the same family and ports are equal,\n\n\n   else nonzero\n\n\n*/\n\n\n\nint\n \nsock_cmp_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr1\n,\n\n                  \nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr2\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: 0 if addresses are of the same family and ports are equal,\n\n\n   else nonzero\n\n\n*/\n\n\n\nint\n \nsock_get_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: non-negative port number for IPv4 or IPv6 address, else -1 */\n\n\n\nchar\n \n*\nsock_ntop_host\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n/* Returns: non-null pointer if OK, NULL on error */\n\n\n\nvoid\n \nsock_set_addr\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n,\n\n                   \nvoid\n \n*\nptr\n);\n\n\nvoid\n \nsock_set_port\n(\nconst\n \nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n,\n\n                   \nint\n \nport\n);\n\n\nvoid\n \nsock_set_wild\n(\nstruct\n \nsockaddr\n \n*\nsockaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n\n\n\n\n\nsock_bind_wild\n: binds the wildcard address and an ephemeral port to a socket.\n\n\nsock_cmp_addr\n: compares the address portion of two socket address structures.\n\n\nsock_cmp_port\n: compares the port number of two socket address structures.\n\n\nsock_get_port\n: returns just the port number.\n\n\nsock_ntop_host\n: converts just the host portion of a socket address structure to presentation format (not the port number)\n\n\nsock_set_addr\n: sets just the address portion of a socket address structure to the value pointed to by \nptr\n.\n\n\nsock_set_port\n: sets just the port number of a socket address structure.\n\n\nsock_set_wild\n: sets the address portion of a socket address structure to the wildcard\n\n\n\n\nreadn\n, \nwriten\n, and \nreadline\n Functions\n\n\nStream sockets (e.g., TCP sockets) exhibit a behavior with the \nread\n and \nwrite\n functions that differs from normal file I/O. A \nread\n or \nwrite\n on a stream socket might input or output fewer bytes than requested, but this is not an error condition. \nThe reason is that buffer limits might be reached for the socket in the kernel. All that is required to input or output the remaining bytes is for the caller to invoke the \nread\n or \nwrite\n function again.\n This scenario is always a possibility on a stream socket with \nread\n, but is normally seen with \nwrite\n only if the socket is nonblocking.\n\n\nunp_readn.h\n\n\n#include \nunp.h\n\n\n\nssize_t\n \nreadn\n(\nint\n \nfiledes\n,\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nnbytes\n);\n\n\nssize_t\n \nwriten\n(\nint\n \nfiledes\n,\n \nconst\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nnbytes\n);\n\n\nssize_t\n \nreadline\n(\nint\n \nfiledes\n,\n \nvoid\n \n*\nbuff\n,\n \nsize_t\n \nmaxlen\n);\n\n\n\n/* All return: number of bytes read or written, \u20131 on error */\n\n\n\n\n\n\n\n\nlib/readn.c\n\n\nlib/writen.c\n\n\ntest/readline1.c\n\n\nlib/readline.c\n\n\n\n\n#include    \nunp.h\n\n\n\nssize_t\n                     \n/* Read \nn\n bytes from a descriptor. */\n\n\nreadn\n(\nint\n \nfd\n,\n \nvoid\n \n*\nvptr\n,\n \nsize_t\n \nn\n)\n\n\n{\n\n    \nsize_t\n  \nnleft\n;\n\n    \nssize_t\n \nnread\n;\n\n    \nchar\n    \n*\nptr\n;\n\n\n    \nptr\n \n=\n \nvptr\n;\n\n    \nnleft\n \n=\n \nn\n;\n\n    \nwhile\n \n(\nnleft\n \n \n0\n)\n \n{\n\n        \nif\n \n(\n \n(\nnread\n \n=\n \nread\n(\nfd\n,\n \nptr\n,\n \nnleft\n))\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                \nnread\n \n=\n \n0\n;\n      \n/* and call read() again */\n\n            \nelse\n\n                \nreturn\n(\n-\n1\n);\n\n        \n}\n \nelse\n \nif\n \n(\nnread\n \n==\n \n0\n)\n\n            \nbreak\n;\n              \n/* EOF */\n\n\n        \nnleft\n \n-=\n \nnread\n;\n\n        \nptr\n   \n+=\n \nnread\n;\n\n    \n}\n\n    \nreturn\n(\nn\n \n-\n \nnleft\n);\n      \n/* return \n= 0 */\n\n\n}\n\n\n\n\n\n\nOur three functions look for the error \nEINTR\n (the system call was interrupted by a caught signal) and continue reading or writing if the error occurs. We handle the error here, instead of forcing the caller to call \nreadn\n or \nwriten\n again, since the purpose of these three functions is to prevent the caller from having to handle a short count.\n\n\nIn Section 14.3, we will mention that the \nMSG_WAITALL\n flag can be used with the \nrecv\n function to replace the need for a separate \nreadn\n function.\n\n\nIn \ntest/readline1.c\n, our \nreadline\n function calls the system\u2019s \nread\n function once for every byte of data. This is very inefficient, and why we\u2019ve commented the code to state it is \"PAINFULLY SLOW\".\n\n\nOur advice is to think in terms of buffers and not lines. Write your code to read buffers of data, and if a line is expected, check the buffer to see if it contains that line.\n\n\nlib/readline.c\n shows a faster version of the readline function, which uses its own buffering rather than stdio buffering. Most importantly, the state of readline\u2019s internal buffer is exposed, so callers have visibility into exactly what has been received.\n\n\nIn \nlib/readline.c\n, the internal function \nmy_read\n reads up to \nMAXLINE\n characters at a time and then returns them, one at a time. The only change to the \nreadline\n function itself is to call \nmy_read\n instead of \nread\n. A new function, \nreadlinebuf\n, exposes the internal buffer state so that callers can check and see if more data was received beyond a single line.\n\n\nUnfortunately, by using \nstatic\n variables in \nreadline.c\n to maintain the state information across successive calls, the functions are not \nre-entrant\n or \nthread-safe\n.", 
            "title": "Chapter 3. Sockets Introduction"
        }, 
        {
            "location": "/unp/ch4/", 
            "text": "Chapter 4. Elementary TCP Sockets\n\n\n\n\nIn C, we cannot represent a constant structure on the right-hand side of an assignment.\n\nUNP\n\n\n\n\nIntroduction\n\n\nThis chapter describes the elementary socket functions required to write a complete TCP client and server, along with concurrent servers, a common Unix technique for providing concurrency when numerous clients are connected to the same server at the same time. Each client connection causes the server to fork a new process just for that client. In this chapter, we consider only the one-process-per-client model using \nfork\n.\n\n\nThe figure below shows a timeline of the typical scenario that takes place between a TCP client and server. First, the server is started, then sometime later, a client is started that connects to the server. We assume that the client sends a request to the server, the server processes the request, and the server sends a reply back to the client. This continues until the client closes its end of the connection, which sends an end-of-file notification to the server. The server then closes its end of the connection and either terminates or waits for a new client connection.\n\n\n\n\nsocket\n Function\n\n\nTo perform network I/O, the first thing a process must do is call the \nsocket\n function, specifying the type of communication protocol desired (TCP using IPv4, UDP using IPv6, Unix domain stream protocol, etc.).\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nsocket\n \n(\nint\n \nfamily\n,\n \nint\n \ntype\n,\n \nint\n \nprotocol\n);\n\n\n\n/* Returns: non-negative descriptor if OK, -1 on error */\n\n\n\n\n\n\nArguments:\n\n\n\n\n\n\nfamily\n specifies the protocol family and is one of the constants in the table below. This argument is often referred to as \ndomain\n instead of \nfamily\n.\n\n\n\n\n\n\n\n\nfamily\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAF_INET\n\n\nIPv4 protocols\n\n\n\n\n\n\nAF_INET6\n\n\nIPv6 protocols\n\n\n\n\n\n\nAF_LOCAL\n\n\nUnix domain protocols (\nChapter 15\n)\n\n\n\n\n\n\nAF_ROUTE\n\n\nRouting sockets (\nChapter 18\n)\n\n\n\n\n\n\nAF_KEY\n\n\nKey socket (\nChapter 19\n)\n\n\n\n\n\n\n\n\n\n\n\n\nThe socket \ntype\n is one of the constants shown in table below:\n\n\n\n\n\n\n\n\ntype\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSOCK_STREAM\n\n\nstream socket\n\n\n\n\n\n\nSOCK_DGRAM\n\n\ndatagram socket\n\n\n\n\n\n\nSOCK_SEQPACKET\n\n\nsequenced packet socket\n\n\n\n\n\n\nSOCK_RAW\n\n\nraw socket\n\n\n\n\n\n\n\n\n\n\n\n\nThe \nprotocol\n argument to the \nsocket\n function should be set to the specific protocol type found in the table below, or 0 to select the system's default for the given combination of \nfamily\n and \ntype\n.\n\n\n\n\n\n\n\n\nprotocol\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nIPPROTO_TCP\n\n\nTCP transport protocol\n\n\n\n\n\n\nIPPROTO_UDP\n\n\nUDP transport protocol\n\n\n\n\n\n\nIPPROTO_SCTP\n\n\nSCTP transport protocol\n\n\n\n\n\n\n\n\n\n\n\n\nNot all combinations of socket \nfamily\n and \ntype\n are valid. The table below shows the valid combinations, along with the actual protocols that are valid for each pair. The boxes marked \"Yes\" are valid but do not have handy acronyms. The blank boxes are not supported.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAF_INET\n\n\nAF_INET6\n\n\nAF_LOCAL\n\n\nAF_ROUTE\n\n\nAF_KEY\n\n\n\n\n\n\nSOCK_STREAM\n\n\nTCP/SCTP\n\n\nTCP/SCTP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_DGRAM\n\n\nUDP\n\n\nUDP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_SEQPACKET\n\n\nSCTP\n\n\nSCTP\n\n\nYes\n\n\n\n\n\n\n\n\n\n\nSOCK_RAW\n\n\nIPv4\n\n\nIPv6\n\n\n\n\nYes\n\n\nYes\n\n\n\n\n\n\n\n\nNotes:\n\n\n\n\nYou may also encounter the corresponding \nPF_\nxxx\n constant as the first argument to socket. This is discussed in the next section in this Chapter.\n\n\nYou may encounter \nAF_UNIX\n (the historical Unix name) instead of \nAF_LOCAL\n (the POSIX name). This is discussed in \nChapter 15\n.\n\n\nLinux supports a new socket type, \nSOCK_PACKET\n, that provides access to the datalink, similar to BPF and DLPI (\nSection 2.2\n). This is discussed in \nChapter 29\n\n\nThe key socket, \nAF_KEY\n, is newer than the others. It provides support for cryptographic security. Similar to the way that a routing socket (\nAF_ROUTE\n) is an interface to the kernel's routing table, the key socket is an interface into the kernel's key table. This is discussed in \nChapter 19\n.\n\n\n\n\nOn success, the socket function returns a small non-negative integer value, similar to a file descriptor. We call this a \nsocket descriptor\n, or a \nsockfd\n. To obtain this socket descriptor, all we have specified is a protocol family (IPv4, IPv6, or Unix) and the socket type (stream, datagram, or raw). We have not yet specified either the local protocol address or the foreign protocol address.\n\n\nAF_\nxxx\n Versus \nPF_\nxxx\n\n\nThe \"\nAF_\n\" prefix stands for \"address family\" and the \"\nPF_\n\" prefix stands for \"protocol family.\" Historically, the intent was that a single protocol family might support multiple address families and that the \nPF_\n value was used to create the socket and the \nAF_\n value was used in socket address structures. But in actuality, a protocol family supporting multiple address families has never been supported and the \nsys/socket.h\n header defines the \nPF_\n value for a given protocol to be equal to the \nAF_\n value for that protocol. While there is no guarantee that this equality between the two will always be true, should anyone change this for existing protocols, lots of existing code would break.\n\n\nTo conform to existing coding practice, we use only the \nAF_\n constants in this text, although you may encounter the \nPF_\n value, mainly in calls to \nsocket\n.\n\n\n[p98-99]\n\n\nconnect\n Function\n\n\nThe \nconnect\n function is used by a TCP client to establish a connection with a TCP server.\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nconnect\n(\nint\n \nsockfd\n,\n \nconst\n \nstruct\n \nsockaddr\n \n*\nservaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: 0 if OK, -1 on error */\n\n\n\n\n\n\n\n\nsockfd\n is a socket descriptor returned by the \nsocket\n function.\n\n\nThe \nservaddr\n and \naddrlen\n arguments are a pointer to a socket address structure (which contains the IP address and port number of the server) and its size. (\nSection 3.3\n)\n\n\n\n\nThe client does not have to call \nbind\n before calling \nconnect\n: the kernel will choose both an ephemeral port and the source IP address if necessary.\n\n\nIn the case of a TCP socket, the connect function initiates TCP's three-way handshake (\nSection 2.6\n). The function returns only when the connection is established or an error occurs. There are several different error returns possible:\n\n\n\n\nIf the client TCP receives no response to its SYN segment, \nETIMEDOUT\n is returned.\n\n\nFor example, in 4.4BSD, the client sends one SYN when \nconnect\n is called, sends another SYN 6 seconds later, and sends another SYN 24 seconds later. If no response is received after a total of 75 seconds, the error is returned.\n\n\nSome systems provide administrative control over this timeout.\n\n\n\n\n\n\nIf the server's response to the client's SYN is a reset (RST), this indicates that no process is waiting for connections on the server host at the port specified (the server process is probably not running). This is a \nhard error\n and the error \nECONNREFUSED\n is returned to the client as soon as the RST is received. An RST is a type of TCP segment that is sent by TCP when something is wrong. Three conditions that generate an RST are:\n\n\nWhen a SYN arrives for a port that has no listening server.\n\n\nWhen TCP wants to abort an existing connection.\n\n\nWhen TCP receives a segment for a connection that does not exist.\n\n\n\n\n\n\nIf the client's SYN elicits an ICMP \"destination unreachable\" from some intermediate router, this is considered a \nsoft error\n. The client kernel saves the message but keeps sending SYNs with the same time between each SYN as in the first scenario. If no response is received after some fixed amount of time (75 seconds for 4.4BSD), the saved ICMP error is returned to the process as either \nEHOSTUNREACH\n or \nENETUNREACH\n. It is also possible that the remote system is not reachable by any route in the local system's forwarding table, or that the connect call returns without waiting at all. Note that Network unreachables are considered obsolete, and applications should just treat \nENETUNREACH\n and \nEHOSTUNREACH\n as the same error.\n\n\n\n\nExample: nonexistent host on the local subnet *\n\n\nWe run the client \ndaytimetcpcli\n (\nFigure 1.5\n) and specify an IP address that is on the local subnet (192.168.1/24) but the host ID (100) is nonexistent. When the client host sends out ARP requests (asking for that host to respond with its hardware address), it will never receive an ARP reply.\n\n\nsolaris % daytimetcpcli 192.168.1.100\n\n\nconnect error: Connection timed out\n\n\n\n\n\n\nWe only get the error after the connect times out. Notice that our \nerr_sys\n function prints the human-readable string associated with the \nETIMEDOUT\n error.\n\n\nExample: no server process running *\n\n\nWe specify a host (a local router) that is not running a daytime server:\n\n\nsolaris % daytimetcpcli 192.168.1.5\n\n\nconnect error: Connection refused\n\n\n\n\n\n\nThe server responds immediately with an RST.\n\n\nExample: destination not reachable on the Internet *\n\n\nOur final example specifies an IP address that is not reachable on the Internet. If we watch the packets with \ntcpdump\n, we see that a router six hops away returns an ICMP host unreachable error.\n\n\nsolaris % daytimetcpcli 192.3.4.5\n\n\nconnect error: No route to host\n\n\n\n\n\n\nAs with the \nETIMEDOUT\n error, \nconnect\n returns the \nEHOSTUNREACH\n error only after waiting its specified amount of time.\n\n\nIn terms of the TCP state transition diagram (\nFigure 2.4\n):\n\n\n\n\nconnect\n moves from the CLOSED state (the state in which a socket begins when it is created by the \nsocket\n function) to the SYN_SENT state, and then, on success, to the ESTABLISHED state.\n\n\nIf \nconnect\n fails, the socket is no longer usable and must be closed. We cannot call \nconnect\n again on the socket.\n\n\n\n\nIn \nFigure 11.10\n, we will see that when we call \nconnect\n in a loop, trying each IP address for a given host until one works, each time \nconnect\n fails, we must close the socket descriptor and call \nsocket\n again.\n\n\nbind\n Function\n\n\nThe \nbind\n function assigns a local protocol address to a socket. The protocol address is the combination of either a 32-bit IPv4 address or a 128-bit IPv6 address, along with a 16-bit TCP or UDP port number.\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nbind\n \n(\nint\n \nsockfd\n,\n \nconst\n \nstruct\n \nsockaddr\n \n*\nmyaddr\n,\n \nsocklen_t\n \naddrlen\n);\n\n\n\n/* Returns: 0 if OK,-1 on error */\n\n\n\n\n\n\n\n\nThe second argument \nmyaddr\n is a pointer to a protocol-specific addres\n\n\nThe third argument \naddrlen\n is the size of this address structure.\n\n\n\n\nWith TCP, calling \nbind\n lets us specify a port number, an IP address, both, or neither.\n\n\n\n\n\n\nServers bind their well-known port when they start.\n (\nFigure 1.9\n) If a TCP client or server does not do this, the kernel chooses an ephemeral port for the socket when either \nconnect\n or \nlisten\n is called.\n\n\n\n\nIt is normal for a TCP client to let the kernel choose an ephemeral port, unless the application requires a reserved port (\nFigure 2.10\n)\n\n\nHowever, it is rare for a TCP server to let the kernel choose an ephemeral port, since servers are known by their well-known port.\n\n\n\n\nExceptions to this rule are Remote Procedure Call (RPC) servers. They normally let the kernel choose an ephemeral port for their listening socket since this port is then registered with the RPC \nport mapper\n. Clients have to contact the port mapper to obtain the ephemeral port before they can connect to the server. This also applies to RPC servers using UDP.\n\n\n\n\n\n\nA process can bind a specific IP address to its socket.\n \nThe IP address must belong to an interface on the host.\n\n\n\n\nFor a TCP client, this assigns the source IP address that will be used for IP datagrams sent on the socket. Normally, a TCP client does not \nbind\n an IP address to its socket. The kernel chooses the source IP address when the socket is connected, based on the outgoing interface that is used, which in turn is based on the route required to reach the server\n\n\nFor a TCP server, this restricts the socket to receive incoming client connections destined only to that IP address. \nIf a TCP server does not \nbind\n an IP address to its socket, the kernel uses the destination IP address of the client's SYN as the server's source IP address.\n\n\n\n\n\n\n\n\nAs mentioned, calling \nbind\n lets us specify the IP address, the port, both, or neither. The following table summarizes the values to which we set \nsin_addr\n and \nsin_port\n, or \nsin6_addr\n and \nsin6_port\n, depending on the desired result.\n\n\n\n\n\n\n\n\nIP address\n\n\nPort\n\n\nResult\n\n\n\n\n\n\n\n\n\n\nWildcard\n\n\n0\n\n\nKernel chooses IP address and port\n\n\n\n\n\n\nWildcard\n\n\nnonzero\n\n\nKernel chooses IP address, process specifies port\n\n\n\n\n\n\nLocal IP address\n\n\n0\n\n\nProcess specifies IP address, kernel chooses port\n\n\n\n\n\n\nLocal IP address\n\n\nnonzero\n\n\nProcess specifies IP address and port\n\n\n\n\n\n\n\n\n\n\nIf we specify a port number of 0, the kernel chooses an ephemeral port when \nbind\n is called.\n\n\nIf we specify a wildcard IP address, the kernel does not choose the local IP address until either the socket is connected (TCP) or a datagram is sent on the socket (UDP).\n\n\n\n\nWildcard Address and \nINADDR_ANY\n *\n\n\nWith IPv4, the \nwildcard\n address is specified by the constant \nINADDR_ANY\n, whose value is normally 0. This tells the kernel to choose the IP address. \nFigure 1.9\n has the assignment:\n\n\n    \nstruct\n \nsockaddr_in\n   \nservaddr\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n \n(\nINADDR_ANY\n);\n     \n/* wildcard */\n\n\n\n\n\n\nWhile this works with IPv4, where an IP address is a 32-bit value that can be represented as a simple numeric constant (0 in this case), we cannot use this technique with IPv6, since the 128-bit IPv6 address is stored in a structure. \nIn C we cannot represent a constant structure on the right-hand side of an assignment.\n To solve this problem, we write:\n\n\nstruct\n \nsockaddr_in6\n    \nserv\n;\n\n\nserv\n.\nsin6_addr\n \n=\n \nin6addr_any\n;\n     \n/* wildcard */\n\n\n\n\n\n\nThe system allocates and initializes the \nin6addr_any\n variable to the constant \nIN6ADDR_ANY_INIT\n. The \nnetinet/in.h\n header contains the extern declaration for \nin6addr_any\n.\n\n\nThe value of \nINADDR_ANY\n (0) is the same in either network or host byte order, so the use of \nhtonl\n is not really required. But, since all the \nINADDR_\nconstants defined by the \nnetinet/in.h\n header are defined in host byte order, we should use \nhtonl\n with any of these constants.\n\n\nIf we tell the kernel to choose an ephemeral port number for our socket (by specifying a 0 for port number), \nbind\n does not return the chosen value. It cannot return this value since the second argument to \nbind\n has the \nconst\n qualifier. \nTo obtain the value of the ephemeral port assigned by the kernel, we must call \ngetsockname\n to return the protocol address.\n\n\nBinding a non-wildcard IP address *\n\n\nA common example of a process binding a non-wildcard IP address to a socket is a host that provides Web servers to multiple organizations:\n\n\n\n\nFirst, each organization has its own domain name, such as www.organization.com.\n\n\nNext, each organization's domain name maps into a different IP address, but typically on the same subnet.\n\n\n\n\nFor example, if the subnet is 198.69.10, the first organization's IP address could be 198.69.10.128, the next 198.69.10.129, and so on. All these IP addresses are then \naliased\n onto a single network interface (using the \nalias\n option of the \nifconfig\n command on 4.4BSD, for example) so that the IP layer will accept incoming datagrams destined for any of the aliased addresses. Finally, one copy of the HTTP server is started for each organization and each copy \nbind\ns only the IP address for that organization.\n\n\nAn alternative technique is to run a single server that binds the wildcard address. When a connection arrives, the server calls \ngetsockname\n to obtain the destination IP address from the client, which in our discussion above could be 198.69.10.128, 198.69.10.129, and so on. The server then handles the client request based on the IP address to which the connection was issued.\n\n\nOne advantage in binding a non-wildcard IP address is that the demultiplexing of a given destination IP address to a given server process is then done by the kernel.\n\n\nWe must be careful to distinguish between the interface on which a packet arrives versus the destination IP address of that packet. In \nSection 8.8\n, we will talk about the \nweak end system model\n and the \nstrong end system model\n. Most implementations employ the former, meaning it is okay for a packet to arrive with a destination IP address that identifies an interface other than the interface on which the packet arrives. (This assumes a multihomed host.) Binding a non-wildcard IP address restricts the datagrams that will be delivered to the socket based only on the destination IP address. It says nothing about the arriving interface, unless the host employs the strong end system model.\n\n\nA common error from bind is \nEADDRINUSE\n (\"Address already in use\"), which is detailed in \nSection 7.5\n when discussing the \nSO_REUSEADDR\n and \nSO_REUSEPORT\n socket options.\n\n\nlisten\n Function\n\n\nThe \nlisten\n function is called only by a TCP server and it performs two actions:\n\n\n\n\nThe \nlisten\n function converts an unconnected socket into a passive socket, indicating that the kernel should accept incoming connection requests directed to this socket. In terms of the TCP state transition diagram (\nFigure 2.4\n), the call to \nlisten\n moves the socket from the CLOSED state to the LISTEN state.\n\n\nWhen a socket is created by the \nsocket\n function (and before calling \nlisten\n), it is assumed to be an active socket, that is, a client socket that will issue a \nconnect\n.\n\n\n\n\n\n\nThe second argument \nbacklog\n to this function specifies the maximum number of connections the kernel should queue for this socket.\n\n\n\n\nThis function is normally called after both the \nsocket\n and \nbind\n functions and must be called before calling the \naccept\n function.\n\n\nTo understand the \nbacklog\n argument, we must realize that for a given listening socket, the kernel maintains two queues:\n\n\n\n\nAn \nincomplete connection queue\n, which contains an entry for each SYN that has arrived from a client for which the server is awaiting completion of the TCP three-way handshake. These sockets are in the \nSYN_RCVD\n state (\nFigure 2.4\n).\n\n\nA \ncompleted connection queue\n, which contains an entry for each client with whom the TCP three-way handshake has completed. These sockets are in the ESTABLISHED state (\nFigure 2.4\n).\n\n\n\n\nThese two queues are depicted in the figure below:", 
            "title": "Chapter 4. Elementary TCP Sockets"
        }, 
        {
            "location": "/unp/ch5/", 
            "text": "Chapter 5. TCP Client/Server Example\n\n\nIntroduction\n\n\nWe will now use the elementary functions from the previous chapter to write a complete TCP client/server example. Our simple example is an echo server that performs the following steps:\n\n\n\n\nThe client reads a line of text from its standard input and writes the line to the server.\n\n\nThe server reads the line from its network input and echoes the line back to the client.\n\n\nThe client reads the echoed line and prints it on its standard output.\n\n\n\n\nThe figure below depcits this simple client/server:\n\n\n\n\nDespite two arrows between the client and server in the above figure, it is really a \nfull-duplex\n TCP connection. \nfgets\n and \nfputs\n functions are from the standard I/O library. \nwriten\n and \nreadline\n functions were shown in \nSection 3.9\n.\n\n\nThe echo client/server is a valid, simple example of a network application. To expand this example into your own application, all you need to do is change what the server does with the input it receives from its clients.\n\n\nBesides running the client/server in normal mode (type in a line and watch it echo), we examine lots of boundary conditions:\n\n\n\n\nWhat happens when the client and server are started?\n\n\nWhat happens when the client terminates normally?\n\n\nWhat happens to the client if the server process terminates before the client is done?\n\n\nWhat happens to the client if the server host crashes?\n\n\n\n\nIn all these examples, we have \"hard-coded\" protocol-specific constants such as addresses and ports. There are two reasons for this:\n\n\n\n\nWe must understand exactly what needs to be stored in the protocol-specific address structures\n\n\nWe have not yet covered the library functions that can make this more portable\n\n\n\n\nTCP Echo Server: \nmain\n Function\n\n\nOur TCP client and server follow the flow of functions that we diagrammed in \nFigure 4.1\n. The below code is the concurrent server program:\n\n\ntcpcliserv/tcpserv01.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nlistenfd\n,\n \nconnfd\n;\n\n    \npid_t\n               \nchildpid\n;\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n        \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n);\n\n\n        \nif\n \n(\n \n(\nchildpid\n \n=\n \nFork\n())\n \n==\n \n0\n)\n \n{\n    \n/* child process */\n\n            \nClose\n(\nlistenfd\n);\n    \n/* close listening socket */\n\n            \nstr_echo\n(\nconnfd\n);\n   \n/* process the request */\n\n            \nexit\n(\n0\n);\n\n        \n}\n\n        \nClose\n(\nconnfd\n);\n          \n/* parent closes connected socket */\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nCreate socket, bind server's well-known port\n\n\nA TCP socket is created.\n\n\nAn Internet socket address structure is filled in with the wildcard address (\nINADDR_ANY\n) and the server's well-known port (\nSERV_PORT\n, which is defined as 9877 in our \nunp.h\n header). Binding the wildcard address tells the system that we will accept a connection destined for any local interface, in case the system is multihomed. Our choice of the TCP port number is based on \nFigure 2.10\n in \nSection 2.9\n. It should be greater than 1023 (we do not need a reserved port), greater than 5000 (to avoid conflict with the ephemeral ports allocated by many Berkeley-derived implementations), less than 49152 (to avoid conflict with the \"correct\" range of ephemeral ports), and it should not conflict with any registered port.  [p122]\n\n\nThe socket is converted into a listening socket by \nlisten\n.\n\n\n\n\n\n\nWait for client connection to complete\n\n\nThe server blocks in the call to \naccept\n, waiting for a client connection to complete.\n\n\n\n\n\n\nConcurrent server\n\n\nFor each client, \nfork\n spawns a child, and the child handles the new client. The child closes the listening socket and the parent closes the connected socket. (\nSection 4.8\n)\n\n\n\n\n\n\n\n\nTCP Echo Server: \nstr_echo\n Function\n\n\nThe function \nstr_echo\n performs the server processing for each client: It reads data from the client and echoes it back to the client.\n\n\nlib/str_echo.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nssize_t\n     \nn\n;\n\n    \nchar\n        \nbuf\n[\nMAXLINE\n];\n\n\n\nagain\n:\n\n    \nwhile\n \n(\n \n(\nn\n \n=\n \nread\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n \n0\n)\n\n        \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n\n    \nif\n \n(\nn\n \n \n0\n \n \nerrno\n \n==\n \nEINTR\n)\n\n        \ngoto\n \nagain\n;\n\n    \nelse\n \nif\n \n(\nn\n \n \n0\n)\n\n        \nerr_sys\n(\nstr_echo: read error\n);\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nRead a buffer and echo the buffer\n\n\nread\n reads data from the socket and the line is echoed back to the client by \nwriten\n. If the client closes the connection (the normal scenario), \nthe receipt of the client's FIN causes the child's read to return 0.\n This causes the \nstr_echo\n function to return, which terminates the child.\n\n\n\n\n\n\n\n\nTCP Echo Client: \nmain\n Function\n\n\ntcpcliserv/tcpcli01.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nsockfd\n;\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n    \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n    \nConnect\n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n);\n     \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nCreate socket, fill in Internet socket address structure\n\n\nA TCP socket is created and an Internet socket address structure is filled in with the server's IP address and port number. The server's IP address is taken from the command-line argument and the server's well-known port (\nSERV_PORT\n) is from our \nunp.h\n header.\n\n\n\n\n\n\nConnect to server\n\n\nconnect\n establishes the connection with the server. The function \nstr_cli\n handles the rest of the client processing.\n\n\n\n\n\n\n\n\nTCP Echo Client: \nstr_cli\n Function\n\n\nThe \nstr_cli\n function handles the client processing loop: It reads a line of text from standard input, writes it to the server, reads back the server's echo of the line, and outputs the echoed line to standard output.\n\n\nlib/str_cli.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nchar\n    \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n!=\n \nNULL\n)\n \n{\n\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \nstrlen\n(\nsendline\n));\n\n\n        \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n            \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n\n        \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe above code does the following:\n\n\n\n\nRead a line, write to server\n\n\nfgets\n reads a line of text and \nwriten\n sends the line to the server.\n\n\n\n\n\n\nRead echoed line from server, write to standard output\n\n\nreadline\n reads the line echoed back from the server and \nfputs\n writes it to standard output.\n\n\n\n\n\n\nReturn to main\n\n\nThe loop terminates when \nfgets\n returns a null pointer, which occurs when it encounters either an end-of-file (EOF) or an error. Our \nFgets\n wrapper function checks for an error and aborts if one occurs, so \nFgets\n returns a null pointer only when an end-of-file is encountered.\n\n\n\n\n\n\n\n\nNormal Startup\n\n\nAlthough the TCP example is small, it is essential that we understand:\n\n\n\n\nHow the client and server start and end,\n\n\nWhat happens when something goes wrong:\n\n\nthe client host crashes,\n\n\nthe client process crashes,\n\n\nnetwork connectivity is lost\n\n\n\n\n\n\n\n\nOnly by understanding these boundary conditions, and their interaction with the TCP/IP protocols, can we write robust clients and servers that can handle these conditions.\n\n\nStart the server in the background\n\n\nFirst, we start the server in the background:\n\n\nlinux % tcpserv01 \n\n[1] 17870\n\n\n\n\n\nWhen the server starts, it calls \nsocket\n, \nbind\n, \nlisten\n, and \naccept\n, blocking in the call to accept.\n\n\nRun \nnetstat\n\n\nBefore starting the client, we run the \nnetstat\n program to verify the state of the server's listening socket.\n\n\nlinux % netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address       Foreign Address      State\ntcp        0      0 *:9877              *:*                  LISTEN\n\n\n\n\n\nThis command shows the status of all sockets on the system. We must specify the \n-a\n flag to see listening sockets.\n\n\nIn the output, a socket is in the LISTEN state with a wildcard for the local IP address and a local port of 9877. \nnetstat\n prints an asterisk for an IP address of 0 (\nINADDR_ANY\n, the wildcard) or for a port of 0.\n\n\nStart the client on the same host\n\n\nWe then start the client on the same host, specifying the server's IP address of 127.0.0.1 (the loopback address). We could have also specified the server's normal (nonloopback) IP address.\n\n\nlinux % tcpcli01 127.0.0.1\n\n\n\n\n\nThe client calls \nsocket\n, and \nconnect\n which causes TCP's three-way handshake. When the three-way handshake completes, \nconnect\n returns in the client and \naccept\n returns in the server. The connection is established. The following steps then take place:\n\n\n\n\nThe client calls \nstr_cli\n, which will block in the call to \nfgets\n.\n\n\nWhen \naccept\n returns in the server, it calls \nfork\n and the child calls \nstr_echo\n. This function calls \nreadline\n, which calls \nread\n, which blocks while waiting for a line to be sent from the client.\n\n\nThe server parent, on the other hand, calls \naccept\n again, and blocks while waiting for the next client connection.\n\n\n\n\nNotes from the previous three steps:\n\n\n\n\nAll three processes are asleep (blocked): client, server parent, and server child.\n\n\nWe purposely list the client step first, and then the server steps when the three-way handshake completes. This is because \naccept\n returns one-half of the RTT after \nconnect\n returns (see \nFigure 2.5\n):\n\n\nOn the client side, \nconnect\n returns when the second segment of the handshake is received\n\n\nOn the server side, \naccept\n does not return until the third segment of the handshake is received\n\n\n\n\n\n\n\n\nRun \nnetstat\n after connection completes\n\n\nSince we are running the client and server on the same host, \nnetstat\n now shows two additional lines of output, corresponding to the TCP connection:\n\n\nlinux % netstat -a\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address          State\ntcp        0      0 local host:9877         localhost:42758          ESTABLISHED\ntcp        0      0 local host:42758        localhost:9877           ESTABLISHED\ntcp        0      0 *:9877                  *:*                      LISTEN\n\n\n\n\n\n\n\nThe first ESTABLISHED line corresponds to the server child's socket, since the local port is 9877.\n\n\nThe second ESTABLISHED lines is the client's socket, since the local port is 42758\n\n\n\n\nIf we were running the client and server on different hosts, the client host would display only the client's socket, and the server host would display only the two server sockets.\n\n\nRun \nps\n to check process status and relationship\n\n\nlinux % ps -t pts/6 -o pid,ppid,tty,stat,args,wchan\n  PID  PPID TT       STAT COMMAND          WCHAN\n22038 22036 pts/6    S    -bash            wait4\n17870 22038 pts/6    S    ./tcpserv01      wait_for_connect\n19315 17870 pts/6    S    ./tcpserv01      tcp_data_wait\n19314 22038 pts/6    S    ./tcpcli01 127.0 read_chan\n\n\n\n\n\nVery specific arguments to \nps\n are used:\n\n\n\n\nThe TT column (\npts/6\n): client and server are run from the same window, pseudo-terminal number 6.\n\n\nThe PID and PPID columns show the parent and child relationships.\n\n\nThe first \ntcpserv01\n line is the parent and the second tcpserv01 line is the child since the PPID of the child is the parent's PID.\n\n\nThe PPID of the parent is the shell (bash).\n\n\n\n\n\n\nThe STAT column for all three of our network processes is \"S\", meaning the process is sleeping (waiting for something).\n\n\nThe WCHAN column specifies the condition when a process is asleep.\n\n\nLinux prints \nwait_for_connect\n when a process is blocked in either \naccept\n or \nconnect\n, \ntcp_data_wait\n when a process is blocked on socket input or output, or \nread_chan\n when a process is blocked on terminal I/O.\n\n\nIn \nps(1)\n, WCHAN column indicates the name of the kernel function in which the process is sleeping, a \"-\" if the process is running, or a \"*\" if the process is multi-threaded and ps is not displaying threads.\n\n\n\n\n\n\n\n\nNormal Termination\n\n\nAt this point, the connection is established and whatever we type to the client is echoed back.\n\n\nlinux % tcpcli01 127.0.0.1   # we showed this line earlier\n\n\nhello, world                 # we now type this\n\n\nhello, world                 # and the line is echoed\n\n\ngood bye\n\n\ngood bye\n\n\n^D                           # Control-D is our terminal EOF character\n\n\n\n\n\n\nIf we immediately execute netstat, we have:\n\n\nlinux % netstat -a | grep 9877\n\n\ntcp        0      0 *:9877               *:*               LISTEN\n\n\ntcp        0      0 localhost:42758      localhost:9877    TIME_WAIT\n\n\n\n\n\n\nThis time we pipe the output of netstat into \ngrep\n, printing only the lines with our server's well-known port:\n\n\n\n\nThe client's side of the connection (since the local port is 42758) enters the TIME_WAIT state\n\n\nThe listening server is still waiting for another client connection.\n\n\n\n\nThe following steps are involved in the normal termination of client and server:\n\n\n\n\nWhen we type our EOF character, \nfgets\n returns a null pointer and the function \nstr_cli\n (\nSection 5.5\n) returns.\n\n\nstr_cli\n returns to the client \nmain\n function (\nSection 5.5\n), which terminates by calling \nexit\n.\n\n\nPart of process termination is the closing of all open descriptors, so the client socket is closed by the kernel. This sends a FIN to the server, to which the server TCP responds with an ACK. This is the first half of the TCP connection termination sequence. At this point, the server socket is in the CLOSE_WAIT state and the client socket is in the FIN_WAIT_2 state (\nFigure 2.4\n and \nFigure 2.5\n)\n\n\nWhen the server TCP receives the FIN, the server child is blocked in a call to \nread\n (\nSection 3.8\n), and \nread\n then returns 0. This causes the \nstr_echo\n function to return to the server child main. [Errata] [p128]\n\n\nThe server child terminates by calling exit. (\nSection 5.2\n)\n\n\nAll open descriptors in the server child are closed.\n\n\nThe closing of the connected socket by the child causes the final two segments of the TCP connection termination to take place: a FIN from the server to the client, and an ACK from the client.\n\n\n\n\n\n\nFinally, the \nSIGCHLD\n signal is sent to the parent when the server child terminates.\n\n\nThis occurs in this example, but we do not catch the signal in our code, and the default action of the signal is to be ignored. Thus, the child enters the zombie state. We can verify this with the \nps\n command.\n\n\n\n\n\n\n\n\nlinux % ps -t pts/6 -o pid,ppid,tty,stat,args,wchan\n\n\n  PID  PPID TT       STAT COMMAND          WCHAN\n\n\n22038 22036 pts/6    S    -bash            read_chan\n\n\n17870 22038 pts/6    S    ./tcpserv01      wait_for_connect\n\n\n19315 17870 pts/6    Z    [tcpserv01 \ndefu do_exit\n\n\n\n\n\n\nThe STAT of the child is now \nZ\n (for zombie).\n\n\nWe need to clean up our zombie processes and doing this requires dealing with Unix signals. The next section will give an overview of signal handling.\n\n\nPOSIX Signal Handling\n\n\nA \nsignal\n is a notification to a process that an event has occurred. Signals are sometimes called \nsoftware interrupts\n. Signals usually occur asynchronously, which means that a process doesn't know ahead of time exactly when a signal will occur.\n\n\nSignals can be sent:\n\n\n\n\nBy one process to another process (or to itself)\n\n\nBy the kernel to a process.\n\n\nFor example, whenever a process terminates, the kernel send a \nSIGCHLD\n signal to the parent of the terminating process.\n\n\n\n\n\n\n\n\nEvery signal has a \ndisposition\n, which is also called the \naction\n associated with the signal. We set the disposition of a signal by calling the \nsigaction\n function and we have three choices for the disposition:\n\n\n\n\n\n\nCatching a signal\n. We can provide a function called a \nsignal handler\n that is called whenever a specific signal occurs. The two signals \nSIGKILL\n and \nSIGSTOP\n cannot be caught. Our function is called with a single integer argument that is the signal number and the function returns nothing. Its function prototype is therefore:\n\n\nvoid handler (int signo);\n\n\n\n\n\nFor most signals, we can call \nsigaction\n and specify the signal handler to catch it. A few signals, \nSIGIO\n, \nSIGPOLL\n, and \nSIGURG\n, all require additional actions on the part of the process to catch the signal.\n\n\n\n\n\n\nIgnoring a signal\n. We can ignore a signal by setting its disposition to \nSIG_IGN\n. The two signals SIGKILL and SIGSTOP cannot be ignored.\n\n\n\n\nSetting the default disposition for a signal\n. This can be done by setting its disposition to \nSIG_DFL\n. The default is normally to terminate a process on receipt of a signal, with certain signals also generating a core image of the process in its current working directory. There are a few signals whose default disposition is to be ignored: \nSIGCHLD\n and \nSIGURG\n (sent on the arrival of out-of-band data) are two that we will encounter in this text.\n\n\n\n\nsignal\n Function\n\n\nThe POSIX way to establish the disposition of a signal is to call the \nsigaction\n function, which is complicated in that one argument to the function is a structure (\nstruct sigaction\n) that we must allocate and fill in.\n\n\nAn easier way to set the disposition of a signal is to call the \nsignal\n function. The first argument is the signal name and the second argument is either a pointer to a function or one of the constants \nSIG_IGN\n or \nSIG_DFL\n.\n\n\nHowever, \nsignal\n is an historical function that predates POSIX. Different implementations provide different signal semantics when it is called, providing backward compatibility, whereas POSIX explicitly spells out the semantics when \nsigaction\n is called.\n\n\nThe solution is to define our own function named \nsignal\n that just calls the POSIX \nsigaction\n function. This provides a simple interface with the desired POSIX semantics. We include this function in our own library, along with our \nerr\n_XXX functions and our wrapper functions. [p130]\n\n\nlib/signal.c\n\n\n#include    \nunp.h\n\n\n\nSigfunc\n \n*\n\n\nsignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n\n\n{\n\n    \nstruct\n \nsigaction\n    \nact\n,\n \noact\n;\n\n\n    \nact\n.\nsa_handler\n \n=\n \nfunc\n;\n\n    \nsigemptyset\n(\nact\n.\nsa_mask\n);\n\n    \nact\n.\nsa_flags\n \n=\n \n0\n;\n\n    \nif\n \n(\nsigno\n \n==\n \nSIGALRM\n)\n \n{\n\n\n#ifdef  SA_INTERRUPT\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_INTERRUPT\n;\n   \n/* SunOS 4.x */\n\n\n#endif\n\n    \n}\n \nelse\n \n{\n\n\n#ifdef  SA_RESTART\n\n        \nact\n.\nsa_flags\n \n|=\n \nSA_RESTART\n;\n     \n/* SVR4, 44BSD */\n\n\n#endif\n\n    \n}\n\n    \nif\n \n(\nsigaction\n(\nsigno\n,\n \nact\n,\n \noact\n)\n \n \n0\n)\n\n        \nreturn\n(\nSIG_ERR\n);\n\n    \nreturn\n(\noact\n.\nsa_handler\n);\n\n\n}\n\n\n/* end signal */\n\n\n\nSigfunc\n \n*\n\n\nSignal\n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n)\n    \n/* for our signal() function */\n\n\n{\n\n    \nSigfunc\n \n*\nsigfunc\n;\n\n\n    \nif\n \n(\n \n(\nsigfunc\n \n=\n \nsignal\n(\nsigno\n,\n \nfunc\n))\n \n==\n \nSIG_ERR\n)\n\n        \nerr_sys\n(\nsignal error\n);\n\n    \nreturn\n(\nsigfunc\n);\n\n\n}\n\n\n\n\n\n\nSimplify function prototype using \ntypedef\n\n\nThe normal function prototype for \nsignal\n is complicated by the level of nested parentheses.\n\n\nvoid\n \n(\n*\nsignal\n \n(\nint\n \nsigno\n,\n \nvoid\n \n(\n*\nfunc\n)\n \n(\nint\n)))\n \n(\nint\n);\n\n\n\n\n\n\nTo simplify this, we define the \nSigfunc\n type in our \nunp.h\n header as\n\n\ntypedef\n    \nvoid\n    \nSigfunc\n(\nint\n);\n\n\n\n\n\n\nstating that signal handlers are functions with an integer argument and the function returns nothing (\nvoid\n). The function prototype then becomes\n\n\nSigfunc\n \n*\nsignal\n \n(\nint\n \nsigno\n,\n \nSigfunc\n \n*\nfunc\n);\n\n\n\n\n\n\nA pointer to a signal handling function is the second argument to the function, as well as the return value from the function.\n\n\nSet handler\n\n\nThe \nsa_handler\n member of the \nsigaction\n structure is set to the \nfunc\n argument.\n\n\nSet signal mask for handler\n\n\nPOSIX allows us to specify a set of signals that will be blocked when our signal handler is called. Any signal that is blocked cannot be delivered to a process. We set the \nsa_mask\n member to the empty set, which means that no additional signals will be blocked while our signal handler is running. \nPOSIX guarantees that the signal being caught is always blocked while its handler is executing.\n\n\nSet \nSA_RESTART\n flag\n\n\nSA_RESTART\n is an optional flag. When the flag is set, a system call interrupted by this signal will be automatically restarted by the kernel.\n\n\nIf the signal being caught is not \nSIGALRM\n, we specify the \nSA_RESTART\n flag, if defined. This is because the purpose of generating the \nSIGALRM\n signal is normally to place a timeout on an I/O operation, in which case, we want the blocked system call to be interrupted by the signal. [p131]\n\n\nCall \nsigaction\n\n\nWe call \nsigaction\n and then \nreturn the old action for the signal as the return value of the signal function.\n\n\nThroughout this text, we will use the \nsignal\n function from the above definition.\n\n\nHandling \nSIGCHLD\n Signals\n\n\nThe zombie state is to maintain information about the child for the parent to fetch later, which includes:\n\n\n\n\nprocess ID of the child,\n\n\ntermination status,\n\n\ninformation on the resource utilization of the child.\n\n\n\n\nIf a parent process of zombie children terminates, the parent process ID of all the zombie children is set to 1 (the \ninit\n process), which will inherit the children and clean them up (\ninit\n will \nwait\n for them, which removes the zombie). [p132]\n\n\nHandling Zombies\n\n\nZombies take up space in the kernel and eventually we can run out of processes. Whenever we \nfork\n children, we must \nwait\n for them to prevent them from becoming zombies. We can establish a signal handler to catch \nSIGCHLD\n and call \nwait\n within the handler. We establish the signal handler by adding the following function call after the call to \nlisten\n (in \nserver's \nmain\n function\n; it must be done before \nfork\ning the first child and needs to be done only once.):\n\n\nSignal\n \n(\nSIGCHLD\n,\n \nsig_chld\n);\n\n\n\n\n\n\nThe signal handler, the function \nsig_chld\n, is defined below:\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstat\n;\n\n\n    \npid\n \n=\n \nwait\n(\nstat\n);\n\n    \nprintf\n(\nchild %d terminated\n\\n\n,\n \npid\n);\n\n    \nreturn\n;\n\n\n}\n\n\n\n\n\n\nNote that calling standard I/O functions such as \nprintf\n in a signal handler is not recommended. We call \nprintf\n here as a diagnostic tool to see when the child terminates.\n\n\nCompiling and running the program on Solaris\n *\n\n\nThis program (\ntcpcliserv/tcpserv02.c\n) is compiled on Solaris 9 and uses the \nsignal\n function from the system library (not \nour version\n).\n\n\nsolaris % tcpserv02 \n                 # start server in background\n\n\n[2] 16939\n\n\nsolaris % tcpcli01 127.0.0.1          # then start client in foreground\n\n\nhi there                              # we type this\n\n\nhi there                              # and this is echoed\n\n\n^D                                    # we type our EOF character\n\n\nchild 16942 terminated                # output by printf in signal handler\n\n\naccept error: Interrupted system call # main function aborts\n\n\n\n\n\n\nThe sequence of steps is as follows:\n\n\n\n\nWe terminate the client by typing our EOF character. The client TCP sends a FIN to the server and the server responds with an ACK.\n\n\nThe receipt of the FIN delivers an EOF to the child's pending \nreadline\n. The child terminates.\n\n\nThe parent is blocked in its call to accept when the \nSIGCHLD\n signal is delivered. The \nsig_chld\n function executes (our signal handler), \nwait\n fetches the child's PID and termination status, and \nprintf\n is called from the signal handler. The signal handler returns.\n\n\nSince the signal was caught by the parent while the parent was blocked in a slow system call (\naccept\n), the kernel causes the \naccept\n to return an error of \nEINTR\n (interrupted system call). The parent does not handle this error (see \nserver's \nmain\n function\n), so it aborts.\n\n\n\n\nFrom this example, we know that when writing network programs that catch signals, we must be cognizant of interrupted system calls, and we must handle them. In this example, the \nsignal\n function provided in the standard C library does not cause an interrupted system call to be automatically restarted by the kernel. Some other systems automatically restart the interrupted system call. If we run the same example under 4.4BSD, using its library version of the \nsignal\n function, the kernel restarts the interrupted system call and accept does not return an error. To handle this potential problem between different operating systems is one reason we define our own version of the \nsignal\n function. [p134]\n\n\nAs part of the coding conventions used in this text, we always code an explicit return in our signal handlers, even though this is unnecessary for a function returning \nvoid\n. This reads as a reminder that the return may interrupt a system call.\n\n\nHandling Interrupted System Calls\n\n\nThe term \"slow system call\" is used to describe any system call that can block forever, such as \naccept\n. That is, the system call need never return. Most networking functions fall into this category. Examples are:\n\n\n\n\naccept\n: there is no guarantee that a server's call to \naccept\n will ever return, if there are no clients that will connect to the server.\n\n\nread\n: the server's call to \nread\n in \nserver's \nstr_echo\n function\n will never return if the client never sends a line for the server to echo.\n\n\n\n\nOther examples of slow system calls are reads and writes of pipes and terminal devices. A notable exception is disk I/O, which usually returns to the caller (assuming no catastrophic hardware failure).\n\n\nWhen a process is blocked in a slow system call and the process catches a signal and the signal handler returns, the system call can return an error of \nEINT\n. Some kernels automatically restart some interrupted system calls. For portability, when we write a program that catches signals (most concurrent servers catch \nSIGCHLD\n), we must be prepared for slow system calls to return \nEINTR\n. [p134]\n\n\nTo handle an interrupted \naccept\n, we change the call to \naccept\n in \nserver's \nmain\n function\n, the beginning of the for loop, to the following:\n\n\n     \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n         \nclilen\n \n=\n \nsizeof\n \n(\ncliaddr\n);\n\n         \nif\n \n(\n \n(\nconnfd\n \n=\n \naccept\n \n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n))\n \n \n0\n)\n \n{\n\n             \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                 \ncontinue\n;\n         \n/* back to for () */\n\n             \nelse\n\n                 \nerr_sys\n \n(\naccept error\n);\n\n        \n}\n\n\n\n\n\n\nNote that this \naccept\n is not our wrapper function \nAccept\n, since we must handle the failure of the function ourselves.\n\n\nThe modified version of the server source code is \ntcpcliserv/tcpserv03.c\n.\n\n\nRestarting the interrupted system call is fine for:\n\n\n\n\naccept\n\n\nread\n\n\nwrite\n\n\nselect\n\n\nopen\n\n\n\n\nHowever, there is one function that we cannot restart: \nconnect\n. If this function returns \nEINTR\n, we cannot call it again, as doing so will return an immediate error. When \nconnect\n is interrupted by a caught signal and is not automatically restarted, we must call \nselect\n to wait for the connection to complete.\n\n\nwait\n and \nwaitpid\n Functions\n\n\nWe can call \nwait\n function to handle the terminated child.\n\n\n#include \nsys/wait.h\n\n\n\npid_t\n \nwait\n \n(\nint\n \n*\nstatloc\n);\n\n\npid_t\n \nwaitpid\n \n(\npid_t\n \npid\n,\n \nint\n \n*\nstatloc\n,\n \nint\n \noptions\n);\n\n\n\n/* Both return: process ID if OK, 0 or\u20131 on error */\n\n\n\n\n\n\nwait\n and \nwaitpid\n both return two values: the return value of the function is the process ID of the terminated child, and the termination status of the child (an integer) is returned through the statloc pointer.\n\n\nThere are three macros that we can call that examine the termination status (see \nAPUE\n):\n\n\n\n\nWIFEXITED\n: tells if the child terminated normally\n\n\nWIFSIGNALED\n: tells if the child was killed by a signal\n\n\nWIFSTOPPED\n: tells if the child was just stopped by job control\n\n\n\n\nAdditional macros let us then fetch the exit status of the child, or the value of the signal that killed the child, or the value of the job-control signal that stopped the child. We will use the \nWIFEXITED\n and \nWEXITSTATUS\n macros  for this purpose.\n\n\nIf there are no terminated children for the process calling \nwait\n, but the process has one or more children that are still executing, then \nwait\n blocks until the first of the existing children terminates.\n\n\nwaitpid\n has more control over which process to wait for and whether or not to block:\n\n\n\n\nThe \npid\n argument specifies the process ID that we want to wait for. A value of -1 says to wait for the first of our children to terminate.\n\n\nThe \noptions\n argument specifies additional options. The most common option is \nWNOHANG\n, which tells the kernel not to block if there are no terminated children.\n\n\n\n\nDifference between \nwait\n and \nwaitpid\n\n\nThe following example illustrates the difference between the \nwait\n and \nwaitpid\n functions when used to clean up terminated children.\n\n\nWe modify our TCP client as below, which establishes five connections with the server and then uses only the first one (\nsockfd[0]\n) in the call to \nstr_cli\n. The purpose of establishing multiple connections is to spawn multiple children from the concurrent server.\n\n\ntcpcliserv/tcpcli04.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \ni\n,\n \nsockfd\n[\n5\n];\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \n5\n;\n \ni\n++\n)\n \n{\n\n        \nsockfd\n[\ni\n]\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n        \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n        \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n        \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n        \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n        \nConnect\n(\nsockfd\n[\ni\n],\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \n}\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n[\n0\n]);\n      \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nWhen the client terminates, all open descriptors are closed automatically by the kernel (we do not call \nclose\n, only \nexit\n), and all five connections are terminated at about the same time. This causes five FINs to be sent, one on each connection, which in turn causes all five server children to terminate at about the same time. This causes five \nSIGCHLD\n signals to be delivered to the parent at about the same time. This causes the problem under discussion.\n\n\nWe first run the server (\ntcpcliserv/tcpserv03.c\n) in the background and then our new client:\n\n\nlinux % tcpserv03 \n\n\n[1] 20419\n\n\nlinux % tcpcli04 127.0.0.1\n\n\nhello                       # we type this\n\n\nhello                       # and it is echoed\n\n\n^D                          # we then type our EOF character\n\n\nchild 20426 terminated      # output by server\n\n\n\n\n\n\nOnly one \nprintf\n is output, when we expect all five children to have terminated. If we execute \nps\n, we see that the other four children still exist as zombies.\n\n\nPID TTY          TIME CMD\n20419 pts/6     00:00:00 tcpserv03\n20421 pts/6     00:00:00 tcpserv03 \ndefunct\n\n20422 pts/6     00:00:00 tcpserv03 \ndefunct\n\n20423 pts/6     00:00:00 tcpserv03 \ndefunct\n\n\n\n\n\n\nEstablishing a signal handler and calling wait from that handler are insufficient for preventing zombies. \nThe problem is that all five signals are generated before the signal handler is executed, and the signal handler is executed only one time because Unix signals are normally not queued.\nThis problem is nondeterministic. Dependent on the timing of the FINs arriving at the server host, the signal handler is executed two, three or even four times.\n\n\nThe correct solution is to call \nwaitpid\n instead of \nwait\n. The code below shows the version of our \nsig_chld\n function that handles \nSIGCHLD\n correctly. This version works because we call \nwaitpid\n within a loop, fetching the status of any of our children that have terminated, with the \nWNOHANG\n option, which tells \nwaitpid\n not to block if there are running children that have not yet terminated. We cannot call \nwait\n in a loop, because there is no way to prevent wait from blocking if there are running children that have not yet terminated.\n\n\ntcpcliserv/sigchldwaitpid.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nsig_chld\n(\nint\n \nsigno\n)\n\n\n{\n\n    \npid_t\n   \npid\n;\n\n    \nint\n     \nstat\n;\n\n\n    \nwhile\n \n(\n \n(\npid\n \n=\n \nwaitpid\n(\n-\n1\n,\n \nstat\n,\n \nWNOHANG\n))\n \n \n0\n)\n\n        \nprintf\n(\nchild %d terminated\n\\n\n,\n \npid\n);\n\n    \nreturn\n;\n\n\n}\n\n\n\n\n\n\nThe code below shows the final version of our server. It correctly handles a return of \nEINTR\n from \naccept\n and it establishes a signal handler (code above) that calls \nwaitpid\n for all terminated children.\n\n\ntcpcliserv/tcpserv04.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nlistenfd\n,\n \nconnfd\n;\n\n    \npid_t\n               \nchildpid\n;\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n    \nvoid\n                \nsig_chld\n(\nint\n);\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nSignal\n(\nSIGCHLD\n,\n \nsig_chld\n);\n  \n/* must call waitpid() */\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n        \nif\n \n(\n \n(\nconnfd\n \n=\n \naccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n))\n \n \n0\n)\n \n{\n\n            \nif\n \n(\nerrno\n \n==\n \nEINTR\n)\n\n                \ncontinue\n;\n       \n/* back to for() */\n\n            \nelse\n\n                \nerr_sys\n(\naccept error\n);\n\n        \n}\n\n\n        \nif\n \n(\n \n(\nchildpid\n \n=\n \nFork\n())\n \n==\n \n0\n)\n \n{\n    \n/* child process */\n\n            \nClose\n(\nlistenfd\n);\n    \n/* close listening socket */\n\n            \nstr_echo\n(\nconnfd\n);\n   \n/* process the request */\n\n            \nexit\n(\n0\n);\n\n        \n}\n\n        \nClose\n(\nconnfd\n);\n          \n/* parent closes connected socket */\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe purpose of this section has been to demonstrate three scenarios that we can encounter with network programming:\n\n\n\n\nWe must catch the \nSIGCHLD\n signal when forking child processes.\n\n\nWe must handle interrupted system calls when we catch signals.\n\n\nA \nSIGCHLD\n handler must be coded correctly using \nwaitpid\n to prevent any zombies from being left around.\n\n\n\n\nConnection Abort before \naccept\n Returns\n\n\nThere is another condition similar to the interrupted system call that can cause \naccept\n to return a nonfatal error, in which case we should just call \naccept\n again. The sequence of packets shown below has been seen on busy servers (typically busy Web servers), where the server receives an RST for an \nESTABLISHED\n connection before accept is called.\n\n\n\n\nThe three-way handshake completes, the connection is established, and then the client TCP sends an RST (reset). On the server side, the connection is queued by its TCP, waiting for the server process to call accept when the RST arrives. Sometime later, the server process calls accept.\n\n\nAn easy way to simulate this scenario is to start the server, have it call \nsocket\n, \nbind\n, and \nlisten\n, and then go to sleep for a short period of time before calling \naccept\n. While the server process is asleep, start the client and have it call \nsocket\n and \nconnect\n. As soon as \nconnect\n returns, set the \nSO_LINGER\n socket option to generate the RST and terminate.\n\n\nTermination of Server Process\n\n\nWe will now start our client/server and then kill the server child process, which simulates the crashing of the server process. We must be careful to distinguish between the crashing of the server \nprocess\n and the crashing of the server \nhost\n.\n\n\nThe following steps take place:\n\n\n\n\nWe start the server and client and type one line to the client to verify that all is okay. That line is echoed normally by the server child.\n\n\nWe find the process ID of the server child and \nkill\n it. As part of process termination, all open descriptors in the child are closed. This causes a FIN to be sent to the client, and the client TCP responds with an ACK. This is the first half of the TCP connection termination.\n\n\nThe \nSIGCHLD\n signal is sent to the server parent and handled correctly.\n\n\nNothing happens at the client. The client TCP receives the FIN from the server TCP and responds with an ACK, but the problem is that the client process is blocked in the call to \nfgets\n waiting for a line from the terminal.\n\n\n\n\nRunning \nnetstat\n at this point shows the state of the sockets.\n\n\nlinux % netstat -a | grep 9877\ntcp        0      0 *:9877               *:*                 LISTEN\ntcp        0      0 localhost:9877       localhost:43604     FIN_WAIT2\ntcp        1      0 localhost:43604      localhost:9877      CLOSE_WAIT\n\n\n\n\n\n\n\n\n\nWe can still type a line of input to the client. Here is what happens at the client starting from Step 1:\n\n\nlinux % tcpcli01 127.0.0.1  # start client\nhello               # the first line that we type\nhello               # is echoed correctly  we kill the server child on the server host\nanother line        # we then type a second line to the client\nstr_cli : server terminated prematurely\n\n\n\n\n\nWhen we type \"another line,\" \nstr_cli\n calls \nwriten\n and the client TCP sends the data to the server. This is allowed by TCP because the receipt of the FIN by the client TCP only indicates that the server process has closed its end of the connection and will not be sending any more data. The receipt of the FIN does not tell the client TCP that the server process has terminated (which in this case, it has).\n\n\nWhen the server TCP receives the data from the client, it responds with an RST since the process that had that socket open has terminated. We can verify that the RST was sent by watching the packets with \ntcpdump\n.\n\n\n\n\n\n\nThe client process will not see the RST because it calls \nreadline\n immediately after the call to writen and readline returns 0 (EOF) immediately because of the FIN that was received in Step 2. Our client is not expecting to receive an EOF at this point (\nstr_cli\n) so it quits with the error message \"server terminated prematurely.\"\n\n\n\n\nWhen the client terminates (by calling \nerr_quit\n in \nstr_cli\n), all its open descriptors are closed.\n\n\nIf the \nreadline\n happens before the RST is received (as shown in this example), the result is an unexpected EOF in the client.\n\n\nIf the RST arrives first, the result is an \nECONNRESET\n (\"Connection reset by peer\") error return from \nreadline\n.\n\n\n\n\n\n\n\n\nThe problem in this example is that the client is blocked in the call to \nfgets\n when the FIN arrives on the socket. The client is really working with two descriptors,the socket and the user input. Instead of blocking on input from only one of the two sources, it should block on input from either source. Indeed, this is one purpose of the \nselect\n and \npoll\n functions described in \nChapter 6\n.\n\n\nSIGPIPE\n Signal\n\n\nThe rules are:\n\n\n\n\nWhen a process writes to a socket that has received an RST, the \nSIGPIPE\n signal is sent to the process. The default action of this signal is to terminate the process, so the process must catch the signal to avoid being involuntarily terminated.\n\n\nIf the process either catches the signal and returns from the signal handler, or ignores the signal, the write operation returns \nEPIPE\n.\n\n\n\n\nWe can simulate this from the client by performing two writes to the server (which has sent FIN to the client) before reading anything back, with the first write eliciting the RST (causing the server to send an RST to the client). We must use two writes to obtain the signal, because the first write elicits the RST and the second write elicits the signal. It is okay to write to a socket that has received a FIN, but it is an error to write to a socket that has received an RST.\n\n\nWe modify our client as below:\n\n\ntcpcliserv/str_cli11.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nchar\n    \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nwhile\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n!=\n \nNULL\n)\n \n{\n\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \n1\n);\n\n        \nsleep\n(\n1\n);\n\n        \nWriten\n(\nsockfd\n,\n \nsendline\n+\n1\n,\n \nstrlen\n(\nsendline\n)\n-\n1\n);\n\n\n        \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n            \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n\n        \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThe \nwriten\n is called two times. The intent is for the first \nwriten\n to elicit the RST and then for the second \nwriten\n to generate \nSIGPIPE\n.\n\n\nRun the program on the Linux host:\n\n\nlinux % tcpclill 127.0.0.1\n\n\nhi there       # we type this line\n\n\nhi there       # this is echoed by the server\n\n\n               # here we kill the server child\n\n\nbye            # then we type this line\n\n\nBroken pipe    # this is printed by the shell\n\n\n\n\n\n\nWe start the client, type in one line, see that line echoed correctly, and then terminate the server child on the server host. We then type another line (\"bye\") and the shell tells us the process died with a \nSIGPIPE\n signal.\n\n\nThe recommended way to handle \nSIGPIPE\n depends on what the application wants to do when this occurs:\n\n\n\n\nIf there is nothing special to do, then setting the signal disposition to \nSIG_IGN\n is easy, assuming that subsequent output operations will catch the error of \nEPIPE\n and terminate.\n\n\nIf special actions are needed when the signal occurs (writing to a log file perhaps), then the signal should be caught and any desired actions can be performed in the signal handler.\n\n\nIf multiple sockets are in use, the delivery of the signal will not tell us which socket encountered the error. If we need to know which \nwrite\n caused the error, then we must either ignore the signal or return from the signal handler and handle \nEPIPE\n from the \nwrite\n.\n\n\n\n\nCrashing of Server Host\n\n\nTo simulate what happens when the server host crashes, we must run the client and server on different hosts. We then start the server, start the client, type in a line to the client to verify that the connection is up, disconnect the server host from the network, and type in another line at the client. This also covers the scenario of the server host being unreachable when the client sends data (i.e., some intermediate router goes down \nafter the connection has been established\n).\n\n\nThe following steps take place:\n\n\n\n\nWhen the server host crashes (which means it is not shut down by an operator), nothing is sent out on the existing network connections.\n\n\nWe type a line of input to the client, it is written by \nwriten\n (\nstr_cli\n), and is sent by the client TCP as a data segment. The client then blocks in the call to \nreadline\n, waiting for the echoed reply.\n\n\nWith \ntcpdump\n, we will see the client TCP continually retransmitting the data segment, trying to receive an ACK from the server. Berkeley-derived implementations retransmit the data segment 12 times, waiting for around 9 minutes before giving up. When the client TCP finally gives up (assuming the server host has not been rebooted during this time, or the server host is still unreachable), an error is returned to the client process's \nreadline\n. The error can be one of the following:\n\n\nIf the server host crashed and there were no responses at all to the client's data segments, the error is \nETIMEDOUT\n.\n\n\nIf some intermediate router determined that the server host was unreachable and responded with an ICMP \"destination unreachable\" message, the error is either \nEHOSTUNREACH\n or \nENETUNREACH\n.\n\n\n\n\n\n\n\n\nTo detect that the peer is down or unreachable quicker than 9 minutes, we can place a timeout on the call to \nreadline\n, which is discussed in \nChapter 14\n.\n\n\nThis example detects that the server host has crashed only when we send data to that host. If we want to detect the crashing of the server host even if we are not actively sending it data, another technique is required: SO_KEEPALIVE socket option (\nChapter 7\n).\n\n\nCrashing and Rebooting of Server Host\n\n\nIn the following example, we will establish a connection between the client and server and then assume the server host crashes and reboots. The easiest way to simulate this is to establish the connection, disconnect the server from the network, shut down the server host and then reboot it, and then reconnect the server host to the network. We do not want the client to see the server host shut down.\n\n\nAs stated in the previous section, if the client is not actively sending data to the server when the server host crashes, the client is not aware that the server host has crashed. The following steps take place:\n\n\n\n\nWe start the server and then the client. We type a line to verify that the connection is established.\n\n\nThe server host crashes and reboots.\n\n\nWe type a line of input to the client, which is sent as a TCP data segment to the server host.\n\n\nWhen the server host reboots after crashing, its TCP loses all information about connections that existed before the crash. Therefore, the server TCP responds to the received data segment from the client with an RST.\n\n\nOur client is blocked in the call to \nreadline\n when the RST is received, causing \nreadline\n to return the error \nECONNRESET\n.\n\n\n\n\nIf it is important for our client to detect the crashing of the server host, even if the client is not actively sending data, then some other technique, such as the \nSO_KEEPALIVE\n socket option or some client/server heartbeat function, is required.\n\n\nShutdown of Server Host\n\n\nThis section discusses what happens if the server host is shut down by an operator while our server process is running on that host.\n\n\nWhen a Unix system is shut down, the following steps happen:\n\n\n\n\nThe \ninit\n process normally sends the \nSIGTERM\n signal to all processes (we can catch this signal).\n\n\nThe \ninit\n waits some fixed amount of time (often between 5 and 20 seconds).\n\n\nThe \ninit\n sends the \nSIGKILL\n signal (which we cannot catch) to any processes still running.\n\n\n\n\nThis gives all running processes a short amount of time to clean up and terminate. When the process terminates, all open descriptors are closed (the sequence of steps are same to \nTermination of Server Process\n). We must use the \nselect\n or \npoll\n function in our client to have the client detect the termination of the server process as soon as it occurs.\n\n\nSummary of TCP Example\n\n\nBefore any TCP client and server can communicate with each other, each end must specify the socket pair for the connection: the local IP address, local port, foreign IP address, and foreign port. These four values are shown as bullets in the two figures below.\n\n\nClient's perspective\n\n\n\n\n\n\nconnect\n. The foreign IP address and foreign port must be specified by the client in the call to \nconnect\n. The two local values are normally chosen by the kernel as part of the \nconnect\n function.\n\n\nbind\n. The client has the option of specifying either or both of the local values, by \ncalling\n bind before \nconnect\n, but this is not common.\n\n\ngetsockname\n. The client can obtain the two local values chosen by the kernel by calling \ngetsockname\n after the connection is established.\n\n\n\n\nServer's perspective\n\n\n\n\n\n\nbind\n. The local port (the server's well-known port) is specified by \nbind\n. Normally, the server also specifies the wildcard IP address in this call.\n\n\ngetsockname\n. If the server binds the wildcard IP address on a multihomed host, it can determine the local IP address by calling \ngetsockname\n after the connection is established.\n\n\naccept.\n The two foreign values are returned to the server by \naccept\n.\n\n\ngetpeername\n. If another program is \nexec\ned by the server that calls \naccept\n, that program can call \ngetpeername\n to determine the client's IP address and port, if necessary.\n\n\n\n\nData Format\n\n\nNormally we must worry about the format of the data exchanged between the client and server.\n\n\nExample: Passing Text Strings between Client and Server\n\n\nWe modify our server so that it still reads a line of text from the client, but the server now expects that line to contain two integers separated by white space, and the server returns the sum of those two integers. All that changes is our \nstr_echo\n function:\n\n\ntcpcliserv/str_echo08.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nlong\n        \narg1\n,\n \narg2\n;\n\n    \nssize_t\n     \nn\n;\n\n    \nchar\n        \nline\n[\nMAXLINE\n];\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\n \n(\nn\n \n=\n \nReadline\n(\nsockfd\n,\n \nline\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n\n            \nreturn\n;\n     \n/* connection closed by other end */\n\n\n        \nif\n \n(\nsscanf\n(\nline\n,\n \n%ld%ld\n,\n \narg1\n,\n \narg2\n)\n \n==\n \n2\n)\n\n            \nsnprintf\n(\nline\n,\n \nsizeof\n(\nline\n),\n \n%ld\n\\n\n,\n \narg1\n \n+\n \narg2\n);\n\n        \nelse\n\n            \nsnprintf\n(\nline\n,\n \nsizeof\n(\nline\n),\n \ninput error\n\\n\n);\n\n\n        \nn\n \n=\n \nstrlen\n(\nline\n);\n\n        \nWriten\n(\nsockfd\n,\n \nline\n,\n \nn\n);\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe call \nsscanf\n to convert the two arguments from text strings to long integers, and then snprintf is called to convert the result into a text string.\n\n\nThis modified client and server work fine, regardless of the byte ordering of the client and server hosts.\n\n\nExample: Passing Binary Structures between Client and Server\n\n\nWe now modify our client and server to pass binary values across the socket, instead of text strings. We will see that this does not work when the client and server are run on hosts with different byte orders, or on hosts that do not agree on the size of a long integer\n\n\nWe define one structure for the two arguments, another structure for the result, and place both definitions in our \nsum.h\n header. Below show the modified \nstr_cli\n function and \nstr_echo\n function.\n\n\ntcpcliserv/tcpcli09.c\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \nsockfd\n;\n\n    \nstruct\n \nsockaddr_in\n  \nservaddr\n;\n\n\n    \nif\n \n(\nargc\n \n!=\n \n2\n)\n\n        \nerr_quit\n(\nusage: tcpcli \nIPaddress\n);\n\n\n    \nsockfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_port\n \n=\n \nhtons\n(\nSERV_PORT\n);\n\n    \nInet_pton\n(\nAF_INET\n,\n \nargv\n[\n1\n],\n \nservaddr\n.\nsin_addr\n);\n\n\n    \nConnect\n(\nsockfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nstr_cli\n(\nstdin\n,\n \nsockfd\n);\n     \n/* do it all */\n\n\n    \nexit\n(\n0\n);\n\n\n}\n\n\n\n\n\n\nsscanf\n converts the two arguments from text strings to binary, and we call \nwriten\n to send the structure to the server. We call \nreadn\n to read the reply, and print the result using \nprintf\n.\n\n\ntcpcliserv/str_echo09.c\n\n\n#include    \nunp.h\n\n\n#include    \nsum.h\n\n\n\nvoid\n\n\nstr_echo\n(\nint\n \nsockfd\n)\n\n\n{\n\n    \nssize_t\n         \nn\n;\n\n    \nstruct\n \nargs\n     \nargs\n;\n\n    \nstruct\n \nresult\n   \nresult\n;\n\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\n \n(\nn\n \n=\n \nReadn\n(\nsockfd\n,\n \nargs\n,\n \nsizeof\n(\nargs\n)))\n \n==\n \n0\n)\n\n            \nreturn\n;\n     \n/* connection closed by other end */\n\n\n        \nresult\n.\nsum\n \n=\n \nargs\n.\narg1\n \n+\n \nargs\n.\narg2\n;\n\n        \nWriten\n(\nsockfd\n,\n \nresult\n,\n \nsizeof\n(\nresult\n));\n\n    \n}\n\n\n}\n\n\n\n\n\n\nWe read the arguments by calling \nreadn\n, calculate and store the sum, and call \nwriten\n to send back the result structure.\n\n\nIf we run the client and server on two machines of the same architecture, say two SPARC machines, everything works fine. But when the client and server are on two machines of different architectures (say the server is on the big-endian SPARC system freebsd and the client is on the little endian Intel system linux), it does not work.\n\n\nlinux % tcpcli09 206.168.112.96\n\n\n1 2        # we type this\n\n\n3          # and it works\n\n\n-22 -77    # then we type this\n\n\n-16777314  # and it does not work\n\n\n\n\n\n\nThe problem is that the two binary integers are sent across the socket in little-endian format by the client, but interpreted as big-endian integers by the server. It appears to work for positive integers but fails for negative integers. There are really three potential problems:\n\n\n\n\nDifferent implementations store binary numbers in different formats. The most common formats are big-endian and little-endian, as we described in Section 3.4.\n\n\nDifferent implementations can store the same C datatype differently. For example, most 32-bit Unix systems use 32 bits for a long but 64-bit systems typically use 64 bits for the same datatype. There is no guarantee that a \nshort\n, \nint\n, or \nlong\n is of any certain size.\n\n\nDifferent implementations pack structures differently, depending on the number of bits used for the various datatypes and the alignment restrictions of the machine. Therefore, it is never wise to send binary structures across a socket.\n\n\n\n\nThere are two common solutions to this data format problem:\n\n\n\n\nPass all numeric data as text strings.\n\n\nExplicitly define the binary formats of the supported datatypes (number of bits, big- or little-endian) and pass all data between the client and server in this format. RPC packages normally use this technique. RFC 1832 describes the External Data Representation (XDR) standard that is used with the Sun RPC package.\n\n\n\n\nSummary\n\n\n\n\nThe first problem was zombie children and we caught the \nSIGCHLD\n signal to handle this. Our signal handler then called \nwaitpid\n and  we must call this function instead of the older \nwait\n function, since Unix signals are not queued.\n\n\nThe next problem we encountered was the client not being notified when the server process terminated. We saw that our client's TCP was notified, but we did not receive that notification since we were blocked, waiting for user input. We will use the \nselect\n or \npoll\n function in \nChapter 6\n to handle this scenario, by waiting for any one of multiple descriptors to be ready, instead of blocking on a single descriptor.\n\n\nIf the server host crashes, we do not detect this until the client sends data to the server. Some applications must be made aware of this fact sooner; we will look at the \nSO_KEEPALIVE\n socket option in \nChapter 7\n.", 
            "title": "Chapter 5. TCP Client/Server Example"
        }, 
        {
            "location": "/unp/ch6/", 
            "text": "Chapter 6. I/O Multiplexing: The \nselect\n and \npoll\n Functions\n\n\nIntroduction\n\n\nWhen the TCP client is handling two inputs at the same time: standard input and a TCP socket, we encountered a problem when the client was blocked in a call to \nfgets\n (on standard input) and the server process was killed. The server TCP correctly sent a FIN to the client TCP, but since the client process was blocked reading from standard input, it never saw the EOF until it read from the socket (possibly much later).\n\n\nWe want to be notified if one or more I/O conditions are ready (i.e., input is ready to be read, or the descriptor is capable of taking more output). This capability is called \nI/O multiplexing\n and is provided by the \nselect\n and \npoll\n functions, as well as a newer POSIX variation of the former, called \npselect\n.\n\n\nI/O multiplexing is typically used in networking applications in the following scenarios:\n\n\n\n\nWhen a client is handling multiple descriptors (normally interactive input and a network socket)\n\n\nWhen a client to handle multiple sockets at the same time (this is possible, but rare)\n\n\nIf a TCP server handles both a listening socket and its connected sockets\n\n\nIf a server handles both TCP and UDP\n\n\nIf a server handles multiple services and perhaps multiple protocols\n\n\n\n\nI/O multiplexing is not limited to network programming. Many nontrivial applications find a need for these techniques.\n\n\nI/O Models\n\n\nWe first examine the basic differences in the five I/O models that are available to us under Unix:\n\n\n\n\nblocking I/O\n\n\nnonblocking I/O\n\n\nI/O multiplexing (\nselect\n and \npoll\n)\n\n\nsignal driven I/O (\nSIGIO\n)\n\n\nasynchronous I/O (the POSIX \naio_\n functions)\n\n\n\n\nThere are normally two distinct phases for an input operation:\n\n\n\n\nWaiting for the data to be ready. This involves waiting for data to arrive on the network. When the packet arrives, it is copied into a buffer within the kernel.\n\n\nCopying the data from the kernel to the process. This means copying the (ready) data from the kernel's buffer into our application buffer\n\n\n\n\nBlocking I/O Model\n\n\nThe most prevalent model for I/O is the blocking I/O model (which we have used for all our examples in the previous sections). By default, all sockets are blocking. The scenario is shown in the figure below:\n\n\n\n\nWe use UDP for this example instead of TCP because with UDP, the concept of data being \"ready\" to read is simple: either an entire datagram has been received or it has not. With TCP it gets more complicated, as additional variables such as the socket's low-water mark come into play.\n\n\nWe also refer to \nrecvfrom\n as a system call to differentiate between our application and the kernel, regardless of how \nrecvfrom\n is implemented (system call on BSD and function that invokes \ngetmsg\n system call on System V). There is normally a switch from running in the application to running in the kernel, followed at some time later by a return to the application.\n\n\nIn the figure above, the process calls \nrecvfrom\n and the system call does not return until the datagram arrives and is copied into our application buffer, or an error occurs. The most common error is the system call being interrupted by a signal, as we described in \nSection 5.9\n. We say that the process is blocked the entire time from when it calls \nrecvfrom\n until it returns. When \nrecvfrom\n returns successfully, our application processes the datagram.\n\n\nNonblocking I/O Model\n\n\nWhen a socket is set to be nonblocking, we are telling the kernel \"when an I/O operation that I request cannot be completed without putting the process to sleep, do not put the process to sleep, but return an error instead\". The figure is below:\n\n\n\n\n\n\nFor the first three \nrecvfrom\n, there is no data to return and the kernel immediately returns an error of \nEWOULDBLOCK\n.\n\n\nFor the fourth time we call recvfrom, a datagram is ready, it is copied into our application buffer, and \nrecvfrom\n returns successfully. We then process the data.\n\n\n\n\nWhen an application sits in a loop calling \nrecvfrom\n on a nonblocking descriptor like this, it is called \npolling\n. The application is continually polling the kernel to see if some operation is ready. This is often a waste of CPU time, but this model is occasionally encountered, normally on systems dedicated to one function.\n\n\nI/O Multiplexing Model\n\n\nWith \nI/O multiplexing\n, we call \nselect\n or \npoll\n and block in one of these two system calls, instead of blocking in the actual I/O system call. The figure is a summary of the I/O multiplexing model:\n\n\n\n\nWe block in a call to \nselect\n, waiting for the datagram socket to be readable. When \nselect\n returns that the socket is readable, we then call \nrecvfrom\n to copy the datagram into our application buffer.\n\n\nComparing to the blocking I/O model\n *\n\n\nComparing \nFigure 6.3\n to \nFigure 6.1\n:\n\n\n\n\nDisadvantage: using \nselect\n requires two system calls (\nselect\n and \nrecvfrom\n) instead of one\n\n\nAdvantage: we can wait for more than one descriptor to be ready (see \nthe \nselect\n function\n later in this chapter)\n\n\n\n\nMultithreading with blocking I/O\n *\n\n\nAnother closely related I/O model is to use multithreading with blocking I/O. That model very closely resembles the model described above, except that instead of using \nselect\n to block on multiple file descriptors, the program uses multiple threads (one per file descriptor), and each thread is then free to call blocking system calls like \nrecvfrom\n.\n\n\nSignal-Driven I/O Model\n\n\nThe \nsignal-driven I/O model\n uses signals, telling the kernel to notify us with the \nSIGIO\n signal when the descriptor is ready. The figure is below:\n\n\n\n\n\n\nWe first enable the socket for signal-driven I/O (\nSection 25.2\n) and install a signal handler using the \nsigaction\n system call. The return from this system call is immediate and our process continues; it is not blocked.\n\n\nWhen the datagram is ready to be read, the \nSIGIO\n signal is generated for our process. We can either:\n\n\nread the datagram from the signal handler by calling \nrecvfrom\n and then notify the main loop that the data is ready to be processed (\nSection 25.3\n)\n\n\nnotify the main loop and let it read the datagram.\n\n\n\n\n\n\n\n\nThe advantage to this model is that we are not blocked while waiting for the datagram to arrive. The main loop can continue executing and just wait to be notified by the signal handler that either the data is ready to process or the datagram is ready to be read.\n\n\nAsynchronous I/O Model\n\n\nAsynchronous I/O\n is defined by the POSIX specification, and various differences in the \nreal-time\n functions that appeared in the various standards which came together to form the current POSIX specification have been reconciled.\n\n\nThese functions work by telling the kernel to start the operation and to notify us when the entire operation (including the copy of the data from the kernel to our buffer) is complete. \nThe main difference between this model and the signal-driven I/O model is that with signal-driven I/O, the kernel tells us when an I/O operation can be initiated, but with asynchronous I/O, the kernel tells us when an I/O operation is complete.\n See the figure below for example:\n\n\n\n\n\n\n\n\nWe call \naio_read\n (the POSIX asynchronous I/O functions begin with \naio_\n or \nlio_\n) and pass the kernel the following:\n\n\n\n\ndescriptor, buffer pointer, buffer size (the same three arguments for \nread\n),\n\n\nfile offset (similar to \nlseek\n),\n\n\nand how to notify us when the entire operation is complete.\n\n\n\n\nThis system call returns immediately and our process is not blocked while waiting for the I/O to complete.\n\n\n\n\n\n\nWe assume in this example that we ask the kernel to generate some signal when the operation is complete. This signal is not generated until the data has been copied into our application buffer, which is different from the signal-driven I/O model.\n\n\n\n\n\n\nComparison of the I/O Models\n\n\nThe figure below is a comparison of the five different I/O models.\n\n\n\n\nThe main difference between the first four models is the first phase, as the second phase in the first four models is the same: the process is blocked in a call to \nrecvfrom\n while the data is copied from the kernel to the caller's buffer. Asynchronous I/O, however, handles both phases and is different from the first four.\n\n\nSynchronous I/O versus Asynchronous I/O\n\n\nPOSIX defines these two terms as follows:\n\n\n\n\nA synchronous I/O operation causes the requesting process to be blocked until that I/O operation completes.\n\n\nAn asynchronous I/O operation does not cause the requesting process to be blocked.\n\n\n\n\nUsing these definitions, the first four I/O models (blocking, nonblocking, I/O multiplexing, and signal-driven I/O) are all synchronous because the actual I/O operation (\nrecvfrom\n) blocks the process. Only the asynchronous I/O model matches the asynchronous I/O definition.\n\n\nselect\n Function\n\n\nThe \nselect\n function allows the process to instruct the kernel to either:\n\n\n\n\nWait for any one of multiple events to occur and to wake up the process only when one or more of these events occurs, or\n\n\nWhen a specified amount of time has passed.\n\n\n\n\nThis means that we tell the kernel what descriptors we are interested in (for reading, writing, or an exception condition) and how long to wait. The descriptors in which we are interested are not restricted to sockets; any descriptor can be tested using \nselect\n.\n\n\n#include \nsys/select.h\n\n\n#include \nsys/time.h\n\n\n\nint\n \nselect\n(\nint\n \nmaxfdp1\n,\n \nfd_set\n \n*\nreadset\n,\n \nfd_set\n \n*\nwriteset\n,\n \nfd_set\n \n*\nexceptset\n,\n\n           \nconst\n \nstruct\n \ntimeval\n \n*\ntimeout\n);\n\n\n\n/* Returns: positive count of ready descriptors, 0 on timeout, \u20131 on error */\n\n\n\n\n\n\nThe \ntimeout\n argument\n *\n\n\nThe \ntimeout\n argument tells the kernel how long to wait for one of the specified descriptors to become ready. A \ntimeval\n structure specifies the number of seconds and microseconds.\n\n\nstruct\n \ntimeval\n  \n{\n\n  \nlong\n   \ntv_sec\n;\n          \n/* seconds */\n\n  \nlong\n   \ntv_usec\n;\n         \n/* microseconds */\n\n\n};\n\n\n\n\n\n\nThere are three possibilities for the \ntimeout\n:\n\n\n\n\nWait forever\n (\ntimeout\n is specified as a null pointer). Return only when one of the specified descriptors is ready for I/O.\n\n\nWait up to a fixed amount of time\n (\ntimeout\n points to a \ntimeval\n structure). Return when one of the specified descriptors is ready for I/O, but do not wait beyond the number of seconds and microseconds specified in the \ntimeval\n structure.\n\n\nDo not wait at all\n (\ntimeout\n points to a \ntimeval\n structure and the timer value is 0, i.e. the number of seconds and microseconds specified by the structure are 0). Return immediately after checking the descriptors. This is called \npolling\n.\n\n\n\n\nNote:\n\n\n\n\nThe wait in the first two scenarios is normally interrupted if the process catches a signal and returns from the signal handler. For portability, we must be prepared for \nselect\n to return an error of \nEINTR\n if we are catching signals. Berkeley-derived kernels never automatically restart \nselect\n.\n\n\nAlthough the \ntimeval\n structure has a microsecond field \ntv_usec\n, the actual resolution supported by the kernel is often more coarse. Many Unix kernels round the timeout value up to a multiple of 10 ms. There is also a scheduling latency involved, meaning it takes some time after the timer expires before the kernel schedules this process to run.\n\n\nOn some systems, the \ntimeval\n structure can represent values that are not supported by \nselect\n; it will fail with \nEINVAL\n if the \ntv_sec\n field in the timeout is over 100 million seconds.\n\n\nThe \nconst\n qualifier on the \ntimeout\n argument means it is not modified by \nselect\n on return.\n\n\n\n\nThe descriptor sets arguments\n *\n\n\nThe three middle arguments, \nreadset\n, \nwriteset\n, and \nexceptset\n, specify the descriptors that we want the kernel to test for reading, writing, and exception conditions. There are only two exception conditions currently supported:\n\n\n\n\nThe arrival of \nout-of-band data\n for a socket.\n\n\nThe presence of control status information to be read from the master side of a pseudo-terminal that has been put into packet mode. (Not covered in UNP)\n\n\n\n\nselect\n uses \ndescriptor sets\n, typically an array of integers, with each bit in each integer corresponding to a descriptor. For example, using 32-bit integers, the first element of the array corresponds to descriptors 0 through 31, the second element of the array corresponds to descriptors 32 through 63, and so on. All the implementation details are irrelevant to the application and are hidden in the \nfd_set\n datatype and the following four macros:\n\n\nvoid\n \nFD_ZERO\n(\nfd_set\n \n*\nfdset\n);\n         \n/* clear all bits in fdset */\n\n\nvoid\n \nFD_SET\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n  \n/* turn on the bit for fd in fdset */\n\n\nvoid\n \nFD_CLR\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n  \n/* turn off the bit for fd in fdset */\n\n\nint\n \nFD_ISSET\n(\nint\n \nfd\n,\n \nfd_set\n \n*\nfdset\n);\n \n/* is the bit for fd on in fdset ? */\n\n\n\n\n\n\nWe allocate a descriptor set of the \nfd_set\n datatype, we set and test the bits in the set using these macros, and we can also assign it to another descriptor set across an equals sign (=) in C.\n\n\nAn array of integers using one bit per descriptor, is just one possible way to implement select. Nevertheless, it is common to refer to the individual descriptors within a descriptor set as bits, as in \"turn on the bit for the listening descriptor in the read set.\"\n\n\nThe following example defines a variable of type \nfd_set\n and then turn on the bits for descriptors 1, 4, and 5:\n\n\nfd_set\n \nrset\n;\n\n\n\nFD_ZERO\n(\nrset\n);\n          \n/* initialize the set: all bits off */\n\n\nFD_SET\n(\n1\n,\n \nrset\n);\n        \n/* turn on bit for fd 1 */\n\n\nFD_SET\n(\n4\n,\n \nrset\n);\n        \n/* turn on bit for fd 4 */\n\n\nFD_SET\n(\n5\n,\n \nrset\n);\n        \n/* turn on bit for fd 5 */\n\n\n\n\n\n\nIt is important to initialize the set, since unpredictable results can occur if the set is allocated as an automatic variable and not initialized.\n\n\nAny of the middle three arguments to \nselect\n, \nreadset\n, \nwriteset\n, or \nexceptset\n, can be specified as a null pointer if we are not interested in that condition. Indeed, if all three pointers are null, then we have a higher precision timer than the normal Unix \nsleep\n function. The \npoll\n function provides similar functionality.\n\n\nThe \nmaxfdp1\n argument\n *\n\n\nThe \nmaxfdp1\n argument specifies the number of descriptors to be tested. Its value is the maximum descriptor to be tested plus one. The descriptors 0, 1, 2, up through and including \nmaxfdp1\n\u20131 are tested.\n\n\nThe constant \nFD_SETSIZE\n, defined by including \nsys/select.h\n, is the number of descriptors in the \nfd_set\n datatype. Its value is often 1024, but few programs use that many descriptors.\n\n\nThe reason the \nmaxfdp1\n argument exists, along with the burden of calculating its value, is for efficiency. Although each \nfd_set\n has room for many descriptors, typically 1,024, this is much more than the number used by a typical process. The kernel gains efficiency by not copying unneeded portions of the descriptor set between the process and the kernel, and by not testing bits that are always 0.\n\n\nreadset\n, \nwriteset\n, and \nexceptset\n as value-result arguments\n *\n\n\nselect\n modifies the descriptor sets pointed to by the \nreadset\n, \nwriteset\n, and \nexceptset\n pointers. These three arguments are value-result arguments. When we call the function, we specify the values of the descriptors that we are interested in, and on return, the result indicates which descriptors are ready. We use the \nFD_ISSET\n macro on return to test a specific descriptor in an \nfd_set\n structure. Any descriptor that is not ready on return will have its corresponding bit cleared in the descriptor set. To handle this, we turn on all the bits in which we are interested in all the descriptor sets each time we call select.\n\n\nReturn value of \nselect\n *\n\n\nThe return value from this function indicates the total number of bits that are ready across all the descriptor sets. If the timer value expires before any of the descriptors are ready, a value of 0 is returned. A return value of \u20131 indicates an error (which can happen, for example, if the function is interrupted by a caught signal).\n\n\nConditions for a Ready Descriptor\n\n\nPrevious sections discusses waiting for a descriptor to become ready for I/O (reading or writing) or to have an exception condition pending on it (out-of-band data). The following discussion are specific about the conditions that cause select to return \"ready\" for sockets\n\n\n\n\nA socket is ready for reading\n if any of the following four conditions is true:\n\n\nThe number of bytes of data in the socket receive buffer is greater than or equal to the current size of the low-water mark for the socket receive buffer. A read operation on the socket will not block and will return a value greater than 0 (i.e., the data that is ready to be read). We can set this low-water mark using the \nSO_RCVLOWAT\n socket option. It defaults to 1 for TCP and UDP sockets.\n\n\nThe read half of the connection is closed (i.e., a TCP connection that has received a FIN). A read operation on the socket will not block and will return 0 (i.e., EOF).\n\n\nThe socket is a listening socket and the number of completed connections is nonzero.\n\n\nA socket error is pending. A read operation on the socket will not block and will return an error (\u20131) with \nerrno\n set to the specific error condition. These pending errors can also be fetched and cleared by calling \ngetsockopt\n and specifying the \nSO_ERROR\n socket option.\n\n\n\n\n\n\nA socket is ready for writing\n if any of the following four conditions is true:\n\n\nThe number of bytes of available space in the socket send buffer is greater than or equal to the current size of the low-water mark for the socket send buffer and either: (i) the socket is connected, or (ii) the socket does not require a connection (e.g., UDP). This means that if we set the socket to nonblocking (\nChapter 16\n), a write operation will not block and will return a positive value (e.g., the number of bytes accepted by the transport layer). We can set this low-water mark using the \nSO_SNDLOWAT\n socket option. This low-water mark normally defaults to 2048 for TCP and UDP sockets.\n\n\nThe write half of the connection is closed. A write operation on the socket will generate \nSIGPIPE\n (\nSection 5.12\n).\n\n\nA socket using a non-blocking connect has completed the connection, or the connect has failed.\n\n\nA socket error is pending. A write operation on the socket will not block and will return an error (\u20131) with \nerrno\n set to the specific error condition. These pending errors can also be fetched and cleared by calling getsockopt with the \nSO_ERROR\n socket option.\n\n\n\n\n\n\nA socket has an exception condition pending if there is out-of-band data for the socket or the socket is still at the out-of-band mark\n (\nChapter 24\n).\n\n\n\n\nWhen an error occurs on a socket, it is marked as both readable and writable by select.\n\n\nThe purpose of the receive and send low-water marks is to give the application control over how much data must be available for reading or how much space must be available for writing before select returns a readable or writable status. For example, if we know that our application has nothing productive to do unless at least 64 bytes of data are present, we can set the receive low-water mark to 64 to prevent select from waking us up if less than 64 bytes are ready for reading.\n\n\nAs long as the send low-water mark for a UDP socket is less than the send buffer size (which should always be the default relationship), the UDP socket is always writable, since a connection is not required.\n\n\nThe following table is the summary of conditions that cause a socket to be ready for select.\n\n\n\n\n\n\n\n\nCondition\n\n\nReadable?\n\n\nWritable?\n\n\nException\n\n\n\n\n\n\n\n\n\n\nData to read\n\n\nx\n\n\n\n\n\n\n\n\n\n\nRead half of the connection closed\n\n\nx\n\n\n\n\n\n\n\n\n\n\nNew connection ready for listening socket\n\n\nx\n\n\n\n\n\n\n\n\n\n\nSpace available for writing\n\n\n\n\nx\n\n\n\n\n\n\n\n\nWrite half of the connection closed\n\n\n\n\nx\n\n\n\n\n\n\n\n\nPending error\n\n\nx\n\n\nx\n\n\n\n\n\n\n\n\nTCP out-of-band data\n\n\n\n\n\n\nx\n\n\n\n\n\n\n\n\nMaximum Number of Descriptors for \nselect\n\n\nMost applications do not use lots of descriptors. It is rare to find an application that uses hundreds of descriptors, but such applications do exist, and they often use \nselect\n to multiplex the descriptors.\n\n\nWhen \nselect\n was originally designed, the OS normally had an upper limit on the maximum number of descriptors per process (the 4.2BSD limit was 31), and select just used this same limit. But, current versions of Unix allow for a virtually unlimited number of descriptors per process (often limited only by the amount of memory and any administrative limits), which affects \nselect\n.\n\n\nMany implementations have declarations similar to the following, which are taken from the 4.4BSD \nsys/types.h\n header:\n\n\n/*\n\n\n * Select uses bitmasks of file descriptors in longs. These macros\n\n\n * manipulate such bit fields (the filesystem macros use chars).\n\n\n * FD_SETSIZE may be defined by the user, but the default here should\n\n\n * be enough for most uses.\n\n\n */\n\n\n#ifndef FD_SETSIZE\n\n\n#define FD_SETSIZE      256\n\n\n#endif\n\n\n\n\n\n\nThis makes us think that we can just \n#define FD_SETSIZE\n to some larger value before including this header to increase the size of the descriptor sets used by \nselect\n. Unfortunately, this normally does not work. The three descriptor sets are declared within the kernel and also uses the kernel's definition of \nFD_SETSIZE\n as the upper limit. The only way to increase the size of the descriptor sets is to increase the value of \nFD_SETSIZE\n and then recompile the kernel. Changing the value without recompiling the kernel is inadequate.\n\n\nSome vendors are changing their implementation of select to allow the process to define \nFD_SETSIZE\n to a larger value than the default. BSD/OS has changed the kernel implementation to allow larger descriptor sets, and it also provides four new \nFD_\nxxx\n macros to dynamically allocate and manipulate these larger sets. From a portability standpoint, however, beware of using large descriptor sets.\n\n\nstr_cli\n Function (Revisited)\n\n\nThe problem with earlier version of the \nstr_cli\n (\nSection 5.5\n) was that we could be blocked in the call to \nfgets\n when something happened on the socket. We can now rewrite our \nstr_cli\n function using \nselect\n so that:\n\n\n\n\nThe client process is notified as soon as the server process terminates.\n\n\nThe client process blocks in a call to \nselect\n waiting for either standard input or the socket to be readable.\n\n\n\n\nThe figure below shows the various conditions that are handled by our call to \nselect\n:\n\n\n\n\nThree conditions are handled with the socket:\n\n\n\n\nIf the peer TCP sends data, the socket becomes readable and read \nreturns\n greater than 0 (the number of bytes of data).\n\n\nIf the peer TCP sends a FIN (the peer process terminates), the socket becomes readable and read returns 0 (EOF).\n\n\nIf the peer TCP sends an RST (the peer host has crashed and rebooted), the socket becomes readable, read returns \u20131, and \nerrno\n contains the specific error code.\n\n\n\n\nBelow is the source code for this new version.\n\n\nselect/strcliselect01.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nint\n         \nmaxfdp1\n;\n\n    \nfd_set\n      \nrset\n;\n\n    \nchar\n        \nsendline\n[\nMAXLINE\n],\n \nrecvline\n[\nMAXLINE\n];\n\n\n    \nFD_ZERO\n(\nrset\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nFD_SET\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n        \nFD_SET\n(\nsockfd\n,\n \nrset\n);\n\n        \nmaxfdp1\n \n=\n \nmax\n(\nfileno\n(\nfp\n),\n \nsockfd\n)\n \n+\n \n1\n;\n\n        \nSelect\n(\nmaxfdp1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n  \n/* socket is readable */\n\n            \nif\n \n(\nReadline\n(\nsockfd\n,\n \nrecvline\n,\n \nMAXLINE\n)\n \n==\n \n0\n)\n\n                \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n            \nFputs\n(\nrecvline\n,\n \nstdout\n);\n\n        \n}\n\n\n        \nif\n \n(\nFD_ISSET\n(\nfileno\n(\nfp\n),\n \nrset\n))\n \n{\n  \n/* input is readable */\n\n            \nif\n \n(\nFgets\n(\nsendline\n,\n \nMAXLINE\n,\n \nfp\n)\n \n==\n \nNULL\n)\n\n                \nreturn\n;\n     \n/* all done */\n\n            \nWriten\n(\nsockfd\n,\n \nsendline\n,\n \nstrlen\n(\nsendline\n));\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\nThis code does the following:\n\n\n\n\nCall \nselect\n.\n\n\nWe only need one descriptor set (\nrset\n) to check for readability. This set is initialized by \nFD_ZERO\n and then two bits are turned on using \nFD_SET\n: the bit corresponding to the standard I/O file pointer, \nfp\n, and the bit corresponding to the socket, \nsockfd\n. The function \nfileno\n converts a standard I/O file pointer into its corresponding descriptor, since \nselect\n (and \npoll\n) work only with descriptors.\n\n\nselect\n is called after calculating the maximum of the two descriptors. In the call, the write-set pointer and the exception-set pointer are both null pointers. The final argument (the time limit) is also a null pointer since we want the call to block until something is ready.\n\n\n\n\n\n\nHandle readable socket\n. On return from select, if the socket is readable, the echoed line is read with \nreadline\n and output by \nfputs\n.\n\n\nHandle readable input\n. If the standard input is readable, a line is read by \nfgets\n and written to the socket using \nwriten\n.\n\n\n\n\nInstead of the function flow being driven by the call to \nfgets\n, it is now driven by the call to \nselect\n.\n\n\nBatch Input and Buffering\n\n\nUnfortunately, our \nstr_cli\n function is still not correct. Our original version in \nSection 5.5\n operates in a stop-and-wait mode, which is fine for interactive use: It sends a line to the server and then waits for the reply. This amount of time is one RTT plus the server's processing time (which is close to 0 for a simple echo server). We can therefore estimate how long it will take for a given number of lines to be echoed if we know the RTT between the client and server. We can use \nping\n to measure RTTs.\n\n\nStop-and-wait mode *\n\n\nIf we consider the network between the client and server as a full-duplex pipe, with requests going from the client to the server and replies in the reverse direction, then the following figure shows our stop-and-wait mode:\n\n\n\n\nNote that this figure:\n\n\n\n\nAssumes that there is no server processing time and that the size of the request is the same as the reply\n\n\nShows show only the data packets, ignoring the TCP acknowledgments that are also going across the network\n\n\n\n\nA request is sent by the client at time 0 and we assume an RTT of 8 units of time. The reply sent at time 4 is received at time 7.\n\n\nThis stop-and-wait mode is fine for interactive input. The problem is: if we run our client in a batch mode, when we redirect the input and output, however, the resulting output file is always smaller than the input file (and they should be identical for an echo server).\n\n\nBatch mode *\n\n\nTo see what's happening, realize that in a batch mode, we can keep sending requests as fast as the network can accept them. The server processes them and sends back the replies at the same rate. This leads to the full pipe at time 7, as shown below:\n\n\n\n\nWe assume:\n\n\n\n\nAfter sending the first request, we immediately send another, and then another\n\n\nWe can keep sending requests as fast as the network can accept them, along with processing replies as fast as the network supplies them.\n\n\n\n\nAssume that the input file contains only nine lines. The last line is sent at time 8, as shown in the above figure. But we cannot close the connection after writing this request because there are still other requests and replies in the pipe. The cause of the problem is our handling of an EOF on input: The function returns to the \nmain\n function, which then terminates. But \nin a batch mode, an EOF on input does not imply that we have finished reading from the socket; there might still be requests on the way to the server, or replies on the way back from the server.\n\n\nThe solution is to close one-half of the TCP connection by sending a FIN to the server, telling it we have finished sending data, but leave the socket descriptor open for reading. This is done with the \nshutdown\n function, described in the next section.\n\n\nBuffering concerns *\n\n\nBuffering for performance as in \nstr_cli\n (\nSection 6.7\n) adds complexity to a network application.\n\n\nWhen several lines of input are available from the standard input. \nselect\n will cause the code (\nselect/strcliselect01.c#L24\n) to read the input using \nfgets\n, which will read the available lines into a buffer used by stdio. But, \nfgets\n only returns a single line and leaves any remaining data sitting in the stdio buffer. The following code (\nselect/strcliselect01.c#L26\n) writes that single line to the server and then \nselect\n is called again to wait for more work, even if there are additional lines to consume in the stdio buffer. The reason is that \nselect\n knows nothing of the buffers used by stdio;it will only show readability from the viewpoint of the \nread\n system call, not calls like \nfgets\n. Thus, mixing stdio and \nselect\n is considered very error-prone and should only be done with great care.\n\n\nThe same problem exists with \nreadline\n in this example (\nstr_cli\n function). Instead of data being hidden from \nselect\n in a stdio buffer, it is hidden in \nreadline\n's buffer. In \nSection 3.9\n we provided a function (\nlib/readline.c#L52\n) that gives visibility into \nreadline\n's buffer, so one possible solution is to modify our code to use that function before calling \nselect\n to see if data has already been read but not consumed. But again, the complexity grows out of hand quickly when we have to handle the case where the readline buffer contains a partial line (meaning we still need to read more) as well as when it contains one or more complete lines (which we can consume).\n\n\nWe will address these buffering concerns in the improved version of \nstr_cli\n shown in \nSection 6.7\n.\n\n\nshutdown\n Function\n\n\nThe normal way to terminate a network connection is to call the \nclose\n function. But, there are two limitations with \nclose\n that can be avoided with \nshutdown\n:\n\n\n\n\nclose\n decrements the descriptor's reference count and closes the socket only if the count reaches 0 (\nSection 4.8\n). With \nshutdown\n, we can initiate TCP's normal connection termination sequence (the four segments beginning with a FIN in \nFigure 2.5\n), regardless of the reference count.\n\n\nclose\n terminates both directions of data transfer, reading and writing. Since a TCP connection is full-duplex, there are times when we want to tell the other end that we have finished sending, even though that end might have more data to send us. This is the scenario we encountered in the previous section with batch input to our \nstr_cli\n function. The figure below shows the typical function calls in this scenario.\n\n\n\n\n\n\n#include \nsys/socket.h\n\n\n\nint\n \nshutdown\n(\nint\n \nsockfd\n,\n \nint\n \nhowto\n);\n\n\n\n/* Returns: 0 if OK, \u20131 on error */\n\n\n\n\n\n\nThe action of the function depends on the value of the \nhowto\n argument:\n\n\n\n\nSHUT_RD\n: \nThe read half of the connection is closed.\n No more data can be received on the socket and any data currently in the socket receive buffer is discarded. The process can no longer issue any of the read functions on the socket. Any data received after this call for a TCP socket is acknowledged and then silently discarded.\n\n\nSHUT_WR\n: \nThe write half of the connection is closed.\n In the case of TCP, this is called a \nhalf-close\n. Any data currently in the socket send buffer will be sent, followed by TCP's normal connection termination sequence. As we mentioned earlier, this closing of the write half is done regardless of whether or not the socket descriptor's reference count is currently greater than 0. The process can no longer issue any of the write functions on the socket.\n\n\nSHUT_RDWR\n: \nThe read half and the write half of the connection are both closed.\n This is equivalent to calling \nshutdown\n twice: first with \nSHUT_RD\n and then with \nSHUT_WR\n.\n\n\n\n\nThe three \nSHUT_\nxxx\n names are defined by the POSIX specification. Typical values for the howto argument that you will encounter will be 0 (close the read half), 1 (close the write half), and 2 (close the read half and the write half).\n\n\nstr_cli\n Function (Revisited Again)\n\n\nThe following code is our revised and correct version of the \nstr_cli\n function that uses \nselect\n and \nshutdown\n. In the function, \nselect\n notifies us as soon as the server closes its end of the connection and \nshutdown\n lets us handle batch input correctly.\n\n\nselect/strcliselect02.c\n\n\n#include    \nunp.h\n\n\n\nvoid\n\n\nstr_cli\n(\nFILE\n \n*\nfp\n,\n \nint\n \nsockfd\n)\n\n\n{\n\n    \nint\n         \nmaxfdp1\n,\n \nstdineof\n;\n\n    \nfd_set\n      \nrset\n;\n\n    \nchar\n        \nbuf\n[\nMAXLINE\n];\n\n    \nint\n     \nn\n;\n\n\n    \nstdineof\n \n=\n \n0\n;\n\n    \nFD_ZERO\n(\nrset\n);\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nif\n \n(\nstdineof\n \n==\n \n0\n)\n\n            \nFD_SET\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n        \nFD_SET\n(\nsockfd\n,\n \nrset\n);\n\n        \nmaxfdp1\n \n=\n \nmax\n(\nfileno\n(\nfp\n),\n \nsockfd\n)\n \n+\n \n1\n;\n\n        \nSelect\n(\nmaxfdp1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n  \n/* socket is readable */\n\n            \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                \nif\n \n(\nstdineof\n \n==\n \n1\n)\n\n                    \nreturn\n;\n     \n/* normal termination */\n\n                \nelse\n\n                    \nerr_quit\n(\nstr_cli: server terminated prematurely\n);\n\n            \n}\n\n\n            \nWrite\n(\nfileno\n(\nstdout\n),\n \nbuf\n,\n \nn\n);\n\n        \n}\n\n\n        \nif\n \n(\nFD_ISSET\n(\nfileno\n(\nfp\n),\n \nrset\n))\n \n{\n  \n/* input is readable */\n\n            \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nfileno\n(\nfp\n),\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                \nstdineof\n \n=\n \n1\n;\n\n                \nShutdown\n(\nsockfd\n,\n \nSHUT_WR\n);\n  \n/* send FIN */\n\n                \nFD_CLR\n(\nfileno\n(\nfp\n),\n \nrset\n);\n\n                \ncontinue\n;\n\n            \n}\n\n\n            \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n        \n}\n\n    \n}\n\n\n}\n\n\n\n\n\n\n\n\nstdineof\n is a new flag that is initialized to 0. As long as this flag is 0, each time around the main loop, we \nselect\n on standard input for readability.\n\n\nNormal and premature termination.\n When we read the EOF on the socket, and:\n\n\nIf we have already encountered an EOF on standard input, this is normal termination and the function returns.\n\n\nIf we have not yet encountered an EOF on standard input, the server process has prematurely terminated. We now call \nread\n and \nwrite\n to operate on buffers instead of lines and allow select to work for us as expected.\n\n\n\n\n\n\nshutdown\n. When we encounter the EOF on standard input, our new flag, \nstdineof\n, is set and we call \nshutdown\n with a second argument of \nSHUT_WR\n to send the FIN. Here we also use buffers instead of lines, using \nread\n and \nwriten\n.\n\n\n\n\nTCP Echo Server (Revisited)\n\n\nWe now rewrite the TCP echo server (\nSection 5.2\n and \n5.3\n as a single process that uses \nselect\n to handle any number of clients, instead of \nfork\ning one child per client.\n\n\nBefore first client has established a connection *\n\n\nBefore the first client has established a connection, the server has a single listening descriptor.\n\n\n\n\nThe server maintains only a read descriptor set (\nrset\n), shown in the following figure. Assuming the server is started in the foreground, descriptors 0, 1, and 2 are set to standard input, output, and error, so the first available descriptor for the listening socket is 3.\n\n\nWe also show an array of integers named \nclient\n that contains the connected socket descriptor for each client. All elements in this array are initialized to \u20131.\n\n\n\n\n\n\nThe only nonzero entry in the descriptor set is the entry for the listening sockets and the first argument to \nselect\n will be 4.\n\n\nAfter first client establishes connection *\n\n\nWhen the first client establishes a connection with our server, the listening descriptor becomes readable and our server calls \naccept\n. The new connected descriptor returned by accept will be 4. The following figure shows this connection:\n\n\n\n\nThe server must remember the new connected socket in its \nclient\n array, and the connected socket must be added to the descriptor set. The updated data structures are shown in the figure below:\n\n\n\n\nAfter second client connection is established *\n\n\nSometime later a second client establishes a connection and we have the scenario shown below:\n\n\n\n\nThe new connected socket (which we assume is 5) must be remembered, giving the data structures shown below:\n\n\n\n\nAfter first client terminates its connection *\n\n\nNext, we assume the first client terminates its connection. The client TCP sends a FIN, which makes descriptor 4 in the server readable. When our server reads this connected socket, \nread\n returns 0. We then close this socket and update our data structures accordingly. The value of \nclient[0]\n is set to \u20131 and descriptor 4 in the descriptor set is set to 0. This is shown in the figure below. Notice that the value of \nmaxfd\n does not change.\n\n\n\n\nSummary of TCP echo server (revisited)\n\n\n\n\nAs clients arrive, we record their connected socket descriptor in the first available entry in the client array (the first entry with a value of \u20131) and also add the connected socket to the read descriptor set.\n\n\nThe variable \nmaxi\n is the highest index in the client array that is currently in use and the variable \nmaxfd\n (plus one) is the current value of the first argument to select.\n\n\nThe only limit on the number of clients that this server can handle is the minimum of the two values \nFD_SETSIZE\n and the maximum number of descriptors allowed for this process by the kernel (\nSection 6.3\n).\n\n\n\n\ntcpcliserv/tcpservselect01.c\n\n\n/* include fig01 */\n\n\n#include    \nunp.h\n\n\n\nint\n\n\nmain\n(\nint\n \nargc\n,\n \nchar\n \n**\nargv\n)\n\n\n{\n\n    \nint\n                 \ni\n,\n \nmaxi\n,\n \nmaxfd\n,\n \nlistenfd\n,\n \nconnfd\n,\n \nsockfd\n;\n\n    \nint\n                 \nnready\n,\n \nclient\n[\nFD_SETSIZE\n];\n\n    \nssize_t\n             \nn\n;\n\n    \nfd_set\n              \nrset\n,\n \nallset\n;\n\n    \nchar\n                \nbuf\n[\nMAXLINE\n];\n\n    \nsocklen_t\n           \nclilen\n;\n\n    \nstruct\n \nsockaddr_in\n  \ncliaddr\n,\n \nservaddr\n;\n\n\n    \nlistenfd\n \n=\n \nSocket\n(\nAF_INET\n,\n \nSOCK_STREAM\n,\n \n0\n);\n\n\n    \nbzero\n(\nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n    \nservaddr\n.\nsin_family\n      \n=\n \nAF_INET\n;\n\n    \nservaddr\n.\nsin_addr\n.\ns_addr\n \n=\n \nhtonl\n(\nINADDR_ANY\n);\n\n    \nservaddr\n.\nsin_port\n        \n=\n \nhtons\n(\nSERV_PORT\n);\n\n\n    \nBind\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \nservaddr\n,\n \nsizeof\n(\nservaddr\n));\n\n\n    \nListen\n(\nlistenfd\n,\n \nLISTENQ\n);\n\n\n    \nmaxfd\n \n=\n \nlistenfd\n;\n           \n/* initialize */\n\n    \nmaxi\n \n=\n \n-\n1\n;\n                  \n/* index into client[] array */\n\n    \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nFD_SETSIZE\n;\n \ni\n++\n)\n\n        \nclient\n[\ni\n]\n \n=\n \n-\n1\n;\n         \n/* -1 indicates available entry */\n\n    \nFD_ZERO\n(\nallset\n);\n\n    \nFD_SET\n(\nlistenfd\n,\n \nallset\n);\n\n\n/* end fig01 */\n\n\n\n/* include fig02 */\n\n    \nfor\n \n(\n \n;\n \n;\n \n)\n \n{\n\n        \nrset\n \n=\n \nallset\n;\n      \n/* structure assignment */\n\n        \nnready\n \n=\n \nSelect\n(\nmaxfd\n+\n1\n,\n \nrset\n,\n \nNULL\n,\n \nNULL\n,\n \nNULL\n);\n\n\n        \nif\n \n(\nFD_ISSET\n(\nlistenfd\n,\n \nrset\n))\n \n{\n    \n/* new client connection */\n\n            \nclilen\n \n=\n \nsizeof\n(\ncliaddr\n);\n\n            \nconnfd\n \n=\n \nAccept\n(\nlistenfd\n,\n \n(\nSA\n \n*\n)\n \ncliaddr\n,\n \nclilen\n);\n\n\n#ifdef  NOTDEF\n\n            \nprintf\n(\nnew client: %s, port %d\n\\n\n,\n\n                    \nInet_ntop\n(\nAF_INET\n,\n \ncliaddr\n.\nsin_addr\n,\n \n4\n,\n \nNULL\n),\n\n                    \nntohs\n(\ncliaddr\n.\nsin_port\n));\n\n\n#endif\n\n\n            \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n \nFD_SETSIZE\n;\n \ni\n++\n)\n\n                \nif\n \n(\nclient\n[\ni\n]\n \n \n0\n)\n \n{\n\n                    \nclient\n[\ni\n]\n \n=\n \nconnfd\n;\n \n/* save descriptor */\n\n                    \nbreak\n;\n\n                \n}\n\n            \nif\n \n(\ni\n \n==\n \nFD_SETSIZE\n)\n\n                \nerr_quit\n(\ntoo many clients\n);\n\n\n            \nFD_SET\n(\nconnfd\n,\n \nallset\n);\n    \n/* add new descriptor to set */\n\n            \nif\n \n(\nconnfd\n \n \nmaxfd\n)\n\n                \nmaxfd\n \n=\n \nconnfd\n;\n         \n/* for select */\n\n            \nif\n \n(\ni\n \n \nmaxi\n)\n\n                \nmaxi\n \n=\n \ni\n;\n               \n/* max index in client[] array */\n\n\n            \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                \ncontinue\n;\n               \n/* no more readable descriptors */\n\n        \n}\n\n\n        \nfor\n \n(\ni\n \n=\n \n0\n;\n \ni\n \n=\n \nmaxi\n;\n \ni\n++\n)\n \n{\n   \n/* check all clients for data */\n\n            \nif\n \n(\n \n(\nsockfd\n \n=\n \nclient\n[\ni\n])\n \n \n0\n)\n\n                \ncontinue\n;\n\n            \nif\n \n(\nFD_ISSET\n(\nsockfd\n,\n \nrset\n))\n \n{\n\n                \nif\n \n(\n \n(\nn\n \n=\n \nRead\n(\nsockfd\n,\n \nbuf\n,\n \nMAXLINE\n))\n \n==\n \n0\n)\n \n{\n\n                        \n/* connection closed by client */\n\n                    \nClose\n(\nsockfd\n);\n\n                    \nFD_CLR\n(\nsockfd\n,\n \nallset\n);\n\n                    \nclient\n[\ni\n]\n \n=\n \n-\n1\n;\n\n                \n}\n \nelse\n\n                    \nWriten\n(\nsockfd\n,\n \nbuf\n,\n \nn\n);\n\n\n                \nif\n \n(\n--\nnready\n \n=\n \n0\n)\n\n                    \nbreak\n;\n              \n/* no more readable descriptors */\n\n            \n}\n\n        \n}\n\n    \n}\n\n\n}\n\n\n/* end fig02 */\n\n\n\n\n\n\nThe code does the following:\n\n\n\n\nCreate listening socket and initialize for \nselect\n.\n We create the listening socket using \nsocket\n, \nbind\n, and \nlisten\n and initialize our data structures assuming that the only descriptor that we will \nselect\n on initially is the listening socket.\n\n\nBlock in \nselect\n. \nselect\n waits for something to happen, which is one of the following:\n\n\nThe establishment of a new client connection.\n\n\nThe arrival of data on the existing connection.\n\n\nA FIN on the existing connection.\n\n\nA RST on the existing connection.\n\n\n\n\n\n\naccept\n new connections\n. * If the listening socket is readable, a new connection has been established.\n\n\nWe call \naccept\n and update our data structures accordingly. We use the first unused entry in the \nclient\n array to record the connected socket.\n\n\nThe number of ready descriptors is decremented, and if it is 0 (\ntcpcliserv/tcpservselect01.c#L62\n), we can avoid the next \nfor\n loop. This lets us use the return value from \nselect\n to avoid checking descriptors that are not ready.\n\n\n\n\n\n\nCheck existing connections\n.\n\n\nIn the second nested \nfor\n loop, a test is made for each existing client connection as to whether or not its descriptor is in the descriptor set returned by \nselect\n, and a line is read from the client and echoed back to the client. Otherwsie, if the client closes the connection, read returns 0 and we update our data structures accordingly.\n\n\nWe never decrement the value of \nmaxi\n, but we could check for this possibility each time a client closes its connection.\n\n\n\n\n\n\n\n\nThis server is more complicated than the earlier version (\nSection 5.2\n and \n5.3\n, but it avoids all the overhead of creating a new process for each client and it is a nice example of \nselect\n. Nevertheless, in \nSection 16.6\n, we will describe a problem with this server that is easily fixed by making the listening socket nonblocking and then checking for, and ignoring, a few errors from \naccept\n.\n\n\nDenial-of-Service Attacks\n\n\nThere is a problem with the server in the above example. If a malicious client connects to the server, sends one byte of data (other than a newline), and then goes to sleep. The server will call \nread\n, which will read the single byte of data from the client and then block in the next call to \nread\n, waiting for more data from this client. The server is then blocked (\"hung\"( by this one client and will not service any other clients, until the malicious client either sends a newline or terminates.\n\n\nThe basic concept here is that when a server is handling multiple clients, the server can never block in a function call related to a single client. Doing so can hang the server and deny service to all other clients. This is called a \ndenial-of-service\n attack, which prevents the server from servicing other legitimate clients.\n\n\nPossible solutions are:\n\n\n\n\nUse nonblocking I/O (\nChapter 16\n)\n\n\nHave each client serviced by a separate thread of control (either spawn a process or a thread to service each client)\n\n\nPlace a timeout on the I/O operations", 
            "title": "Chapter 6. I/O Multiplexing: The select and poll Functions"
        }, 
        {
            "location": "/tcpv1/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nSome terms [p1]:\n\n\n\n\nGateways\n: later called routers\n\n\nCatenet\n (\"concatenated\" network): obsolete term, later called internetwork\n\n\n\n\nThis chapter provides an overview of the Internet architecture and TCP/IP protocol suite.\n\n\nArchitectural Principles\n\n\nThe TCP/IP protocol suite is an open system which forms the basis for the Internet. We refer to World Wide Web (WWW) as an application that uses the Internet for communication (which is perhaps the most important Internet application) [p2-3]\n\n\nPackets, Connections, and Datagrams\n\n\nIn 1960s one of the most important concepts was \npacket switching\n, where \"chunks\" (packets) of digital information comprising some number of bytes are carried through the network somewhat independently. Chunks coming from different sources or senders can be mixed together and pulled apart later, which is called \nmultiplexing\n. The chunks can be moved around from one switch to another on their way to a destination, and the path might be subject to change. This has two potential advantages:\n\n\n\n\nThe network can be more resilient (against being physically attacked).\n\n\nThere can be better utilization of the network links and switches because of statistical multiplexing.\n\n\n\n\n[p4]\n\n\nConnection-oriented networks\n\n\nVirtual circuits\n (VCs) that behave like circuits but do not depend on physical circuit switches can be implemented atop connection-oriented packets. This is the basis for a protocol known as \nX.25\n that was popular until about the early 1990s when it was largely replaced with \nFrame Relay\n and ultimately \ndigital subscriber line\n (DSL) technology.\n\n\nThe VC abstraction and connection-oriented packet networks such as X.25 required \nstate\n to be stored in each switch for each connection. The reason is that each packet carries only a small bit of overhead information that provides an index into a state table. [p5] Such networks are consequently called \nconnection-oriented\n.\n\n\nConnectionless networks\n\n\nIn the late 1960s, another option was developed known as the datagram. A datagram is a special type of packet in which all the identifying information of the source and final destination resides inside the packet itself. Thus, a \nconnectionless network\n could be built.\n\n\nMessage boundaries\n\n\nMessage boundaries\n (or \nrecord markers\n) are related concepts. As shown in the figure below, when an application sends more than one chunk into the network, the fact that more than one chunk was written may or may not be preserved by the communication protocol. Most datagram protocols preserve message boundaries. This is natural because the datagram itself has a beginning and an end.  However, in a circuit or VC network, it is possible that an application may write several chunks of data, all of which are read together as one or more different-size chunks by a receiving application. These types of protocols do not preserve message boundaries. In cases where an underlying protocol fails to preserve message boundaries but they are needed by an application, the application must provide its own.\n\n\n\n\nIn this figure, applications write messages that are carried in protocols. A message boundary is the position or byte offset between one write and another.\n\n\n\n\nProtocols that preserve message boundaries\n (e.g., UDP) indicate the position of the sender\u2019s message boundaries at the receiver.\n\n\nProtocols that do not preserve message boundaries\n (e.g., streaming protocols like TCP) ignore this information and do not make it available to a receiver. As a result, applications may need to implement their own methods to indicate a sender\u2019s message boundaries if this capability is required.\n\n\n\n\nDesign and Implementation\n\n\nThe Architecture and Protocols of the TCP/IP Suite\n\n\nThe ARPANET Reference Model\n\n\nMultiplexing, Demultiplexing, and Encapsulation in TCP/IP\n\n\nPort Numbers\n\n\nPort numbers are 16-bit nonnegative integers (0\u201365535).\n\n\nNames, Addresses, and the DNS\n\n\nInternets, Intranets, and Extranets\n\n\nDesigning Applications\n\n\nClient/Server\n\n\nPeer-to-Peer\n\n\nApplication Programming Interfaces (APIs)\n\n\nStandardization Process\n\n\nThe group with which we will most often be concerned is the \nInternet Engineering Task Force\n (IETF). [p22]\n\n\nRequest for Comments (RFC)\n\n\nEvery official standard in the Internet community is published as a \nRequest for Comments\n (RFC).\n\n\nImplementations and Software Distributions\n\n\nThe historical de facto standard TCP/IP implementations were from the Computer Systems Research Group (CSRG) at the University of California, Berkeley. They were distributed with the 4.x BSD (Berkeley Software Distribution) system and with the BSD Networking Releases until the mid-1990s. This source code has been the starting point for many other implementations. [p24]\n\n\nIn this text, we tend to draw examples from the TCP/IP implementations in Linux, Windows, and sometimes FreeBSD and Mac OS (both of which are derived from historical BSD releases).\n\n\n\n\nAttacks Involving the Internet Architecture\n\n\nSpoofing *\n\n\nThe Internet architecture delivers IP datagrams based on destination IP addresses. As a result, malicious users are able to insert whatever IP address they choose into the source IP address field of each IP datagram they send, an activity called \nspoofing\n. The resulting datagrams are delivered to their destinations, but it is difficult to perform \nattribution\n. That is, it may be difficult or impossible to determine the origin of a datagram received from the Internet. [p25-26]\n\n\nDenial-of-service (DoS) *\n\n\n\n\nDenial-of-service (DoS)\n\n\nDistributed DoS (DDS)\n\n\n\n\nUnauthorized access\n\n\n\n\nBlack hats\n are programmers who intentionally develop malware and exploit systems for (illegal) profit or other malicious purposes are generally called .\n\n\nWhite Hats\n do the same sorts of technical things but notify vulnerable parties instead of exploit them.\n\n\n\n\nEncryption concerns\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np5-6 on message boundaries:\n\n\n\n\nProtocols that preserve message boundaries (e.g., UDP) indicate the position of the sender\u2019s message boundaries at the receiver. Protocols that do not preserve message boundaries (e.g., streaming protocols like TCP) ignore this information and do not make it available to a receiver.\n\n\n\n\nSome explanations:\n\n\n\n\nTCP stream vs UDP message\n\n\nWhat is a message boundary?", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/tcpv1/ch2/", 
            "text": "Chapter 2. The Internet Address Architecture\n\n\nIntroduction\n\n\nThis chapter deals with the structure of network-layer addresses used in the Internet, the IP addresses. [p31-32]\n\n\n\n\nEvery device connected to the Internet has at least one IP address.\n\n\nWhen devices are attached to the global Internet, they are assigned addresses that must be coordinated so as to not duplicate other addresses in use on the network.\n\n\n\n\nExpressing IP Addresses\n\n\nIn IPv4, the dotted-quad notation for IPv4 addresses consists of four decimal numbers separated by periods. For example, 165.195.130.107. Each such number is a nonnegative integer in the range [0, 255] and represents one-quarter of the entire IP address. It is simply a way of writing the whole IPv4 address ( a 32-bit nonnegative integer used throughout the Internet system) using convenient decimal numbers. [p32]\n\n\nIn IPv6, addresses are 128 bits in length, four times larger than IPv4 addresses. The conventional notation for IPv6 addresses is a series of four hexadecimal (\"hex\" or base-16) numbers called \nblocks\n or \nfields\n separated by colons. For example, an IPv6 address containing eight blocks would be written as 5f05:2000:80ad:5800:0058:0800:2023:1d71. In addition, a number of agreed-upon simplifications have been standardized for expressing IPv6 addresses:\n\n\n\n\nLeading zeros of a block need not be written. In the preceding example, the address could have been written as 5f05:2000:80ad:5800:58:800:2023:1d71.\n\n\nBlocks of all zeros can be omitted and replaced by the notation ::.\n\n\nFor example, the IPv6 address 0:0:0:0:0:0:0:1 can be written more compactly as ::1.\n\n\nSimilarly, the address 2001:0db8:0:0:0:0:0:2 can be written more compactly as 2001:db8::2.\n\n\nTo avoid ambiguities, the :: notation may be used only once in an IPv6 address\n\n\n\n\n\n\nIPv4-mapped IPv6 address\n. The block immediately preceding the IPv4 portion of the address has the value ffff and the remaining part of the address is formatted using dotted-quad. For example, the IPv6 address ::ffff:10.0.0.1 represents the IPv4 address 10.0.0.1. This is called an \nIPv4-mapped IPv6 address\n.\n\n\nIPv4-compatible IPv6 address\n. The low-order 32 bits of the IPv6 address can be written using dotted-quad notation. The IPv6 address ::0102:f001 is therefore equivalent to the address ::1.2.240.1.\n\n\n\n\nThe colon delimiter in an IPv6 address may be confused with another separator such as the colon used between an IP address and a port number. In such circumstances, bracket characters, [ and ], are used to surround the IPv6 address. The following URL is an example:\n\n\nhttp://[2001:0db8:85a3:08d3:1319:8a2e:0370:7344]:443/\n\n\n\n\n\nThe flexibility provided by [RFC4291] resulted in unnecessary confusion due to the ability to represent the same IPv6 address in multiple ways. To remedy this situation, [RFC5952] imposes some rules to narrow the range of options while remaining compatible with [RFC4291]. They are as follows:\n\n\n\n\nLeading zeros must be suppressed (e.g., 2001:0db8::0022 becomes 2001:db8::22).\n\n\nThe :: construct must be used to its maximum possible effect (most zeros suppressed) but not for only 16-bit blocks. If multiple blocks contain equallength runs of zeros, the first is replaced with ::.\n\n\nThe hexadecimal digits a through f should be represented in lowercase.\n\n\n\n\nBasic IP Address Structure\n\n\nIPv4 has 2\n32\n possible addresses and IPv6 has 2\n128\n.\n\n\n\n\nMost of the IPv4 address space is \nunicast\n address space, which is IPv4 addresses chunks subdivided down to a single address and used to identify a single network interface of a computer attached to the Internet or to some private intranet.\n\n\nMost of the IPv6 address space is not currently being used.\n\n\n\n\nClassful Addressing", 
            "title": "Chapter 2. The Internet Address Architecture"
        }, 
        {
            "location": "/tcpv1/ch5/", 
            "text": "Chapter 5. The Internet Protocol (IP)\n\n\n\n\nIP is the workhorse protocol of the TCP/IP protocol suite.\n\nTCPv1\n\n\n\n\nIntroduction\n\n\nIP provides a best-effort, connectionless datagram delivery service. When something goes wrong, such as a router temporarily running out of buffers, IP simly throws away some data. Any required reliability must be provided by the upper layers (e.g. TCP). IPv4 and IPv6 both use this basic best-effort delivery model.\n\n\nThe term \nconnectionless\n means that IP does not maintain any connection state information about related datagrams within the network elements (within the routers):\n\n\n\n\nEach IP datagram is handled independently from all other others.\n\n\nDatagrams can be delivered out of order.\n\n\n\n\nThis chapter is on IPv4 and IPv6 header fields, and describes how IP forwarding works.\n\n\nIPv4 and IPv6 Headers\n\n\nIPv4 Header\n *\n\n\n\n\nIPv6 Header\n *\n\n\n\n\nSize and network byte order\n *\n\n\n\n\nThe normal size of the IPv4 header is 20 bytes, unless options are present (which is rare).\n\n\nThe IPv6 header is twice as large as the IPv4 Header but never has any options.\n It may have \nextension headers\n.\n\n\n\n\nIn our pictures of headers and datagrams, for a 32-bit value, \nthe most significant bit is numbered 0 at the left, and the least significant bit of a 32-bit value is numbered 31 on the right.\n The 4 bytes in a 32-bit value are transmitted in the following order: bits 0\u20137 first, then bits 8\u201315, then 16\u201323, and bits 24\u201331 last. This is called \nbig endian\n byte ordering, which is the byte ordering required for all binary integers in the TCP/IP headers as they traverse a network. It is also called \nnetwork byte order\n. Computer CPUs that store binary integers in little endian format must convert the header values into network byte order for transmission and back again for reception.\n\n\nIP Header Fields\n\n\n\n\nThe \nVersion\n field is the first field (only 4 bits or one nibble wide). It contains the version number of the IP datagram: 4 for IPv4 and 6 for IPv6.\n\n\nThis is the only field that IPv4 and IPv6 of which share the location. The two protocols are not directly interoperable, which means a host or router must handle either IPv4 or IPv6 (or both, called \ndual stack\n) separately.\n\n\n\n\n\n\nThe \nInternet Header Length (IHL)\n field is the number of 32-bit words in the IPv4 header, including any options.\n\n\nBecause this is also a 4-bit field, the IPv4 header is limited to a maximum of fifteen 32-bit words or 60 bytes.\n\n\nThe normal value of this field (when no options are present) is 5. There is no such field in IPv6 because the header length is fixed at 40 bytes.\n\n\n\n\n\n\nThe 8 bits following the header length (IPv4) are two fields used for special processing of the datagram when it is forwarded, in both IPv4 and IPv6:\n\n\nThe first 6 bits are the \nDifferentiated Services (DS)\n field.\n\n\nThe last 2 bits are the \nExplicit Congestion Notification (ECN)\n field or indicator bits.\n\n\n\n\n\n\n\n\nThe \nTotal Length\n field is the total length of the IPv4 datagram in bytes.\n\n\n\n\nUsing this field and the IHL field can indicate where the data portion of the datagram starts, and its length.\n\n\nBecause this is a 16-bit field, the maximum size of an IPv4 datagram (including header) is 65,535 bytes.\n\n\nThis field is required in the header because some lower-layer protocols that carry IPv4 datagrams do not (accurately) convey the size of encapsulated datagrams on their own. For example, Ethernet pads small frames to be a minimum length (64 bytes) and an IPv4 datagram (minimum 20 bytes) can be smaller than the minimum Ethernet payload size (46 bytes). Without the Total Length field, the IPv4 implementation would not know how much of a 46-byte Ethernet frame was really an IP datagram, as opposed to padding.\n\n\n\n\nAlthough it is possible to send a 65,535-byte IP datagram, most link layers (such as Ethernet) are not able to carry one this large without fragmenting it into smaller pieces.\n\n\n\n\nIn IPv4, a host is not required to be able to receive an IPv4 datagram larger than 576 bytes.\n\n\nIn IPv6 a host must be able to process a datagram at least as large as the MTU of the link to which it is attached, and the minimum link MTU is 1280 bytes.\n\n\n\n\nMany applications that use the UDP protocol (\nChapter 10\n) for data transport (e.g., DNS, DHCP, etc.) use a limited data size of 512 bytes to avoid the 576-byte IPv4 limit. TCP chooses its own datagram size based on additional information (\nChapter 15\n).\n\n\n\n\n\n\nWhen an IPv4 datagram is fragmented into multiple smaller fragments, each of which itself is an independent IP datagram, the Total Length field reflects the length of the particular fragment.\n\n\n\n\n\n\n\n\n\n\nThe \nPayload Length\n field is the length of the IPv6 datagram not including the length of the header; extension headers, however, are included in the Payload Length field. In IPv6, fragmentation is not supported by the header.\n\n\n\n\nThe 16-bit size of this field limits its maximum value to 65,535 (64KB), which applies to the payload length, not the entire datagram.\n\n\nIn addition, IPv6 supports a \njumbogram\n option that provides for the possibility (at least theoretically) of single packets with payloads as large as 4GB (4,294,967,295 bytes).\n\n\n\n\n\n\nThe \nIdentification\n field (IPv4) indentifies each datagram sent by an IPv4 host. To prevent confusion among fragments of a datagrams, the sending host normally increments an internal counter by 1 each time a datagram is sent (from one of its IP addresses) and copies the value of the counter into the IPv4 Identification field.\n\n\nThis field is most important for implementing fragmentation, along with the Flags and Fragment Offset fields.\n\n\nIn IPv6, this field shows up in the Fragmentation extension header,\n\n\n\n\n\n\nThe \nTime-to-Live\n field, or \nTTL\n, sets an upper limit on the number of routers through which a datagram can pass.\n\n\nThis field initialized by the sender to some value (64 is recommended, although 128 or 255 is not uncommon) and decremented by 1 by every router that forwards the datagram. \nWhen this field reaches 0, the datagram is thrown away, and the sender is notified with an ICMP message\n (\nChapter 8\n). This prevents packets from getting caught in the network forever should an unwanted routing loop occur.\n\n\nIn IPv6, the field has been renamed to its de facto use: \nHop Limit\n.\n\n\n\n\n\n\nThe \nProtocol\n field in the IPv4 header contains a number indicating the type of data found in the payload portion of the datagram. The most common values are 17 (for UDP) and 6 (for TCP).\n\n\nThis field provides a demultiplexing feature so that the IP protocol can be used to carry payloads of more than one protocol type. Although this field originally specified the transport-layer protocol the datagram is encapsulating, it now can identify the encapsulated protocol, which may or not be a transport protocol. Other encapsulations are possible, such as IPv4-in-IPv4 (value 4). The official list of the possible values of the Protocol field\nis given in the \nassigned numbers page\n.\n\n\n\n\n\n\nThe \nNext Header\n field in the IPv6 header generalizes the Protocol field from IPv4. It is used to indicate the type of header following the IPv6 header. This field may contain any values defined for the IPv4 Protocol field, or any of the values associated with the IPv6 extension headers.\n\n\nThe \nHeader Checksum\n field is calculated \nover the IPv4 header only\n, which means that \nthe payload of the IPv4 datagram (e.g., TCP or UDP data) is not checked for correctness by the IP protocol.\n To ensure the payload has been correctly delivered, other protocols must cover any important data that follows the header with their own data-integrity-checking mechanisms.\n\n\nAlmost all protocols encapsulated in IP (ICMP, IGMP, UDP, and TCP) have a checksum in their own headers to cover their header and data and also to cover certain parts of the IP header they deem important (a form of \"layering violation\").\n\n\nThe IPv6 header does not have any checksum field.\n\n\nThe algorithm used in computing a checksum (also used by most of the other Internet-related protocols) is sometimes known as the \nInternet checksum\n.\n\n\nWhen an IPv4 datagram passes through a router, its header checksum must change as a result of decrementing the TTL field.\n\n\n\n\n\n\nThe \nSource IP Address\n is the IP address of the datagram's sender and the \nDestination IP Address\n of where the datagram is destined. These are 32-bit values for IPv4 and 128-bit values for IPv6, and they usually identify a single interface on a computer, although multicast and broadcast addresses (\nChapter 2\n) violate this rule.\n\n\n\n\nThe Internet Checksum\n\n\nThe \nInternet checksum\n is a 16-bit mathematical sum used to determine, with reasonably high probability, whether a received message or portion of a message matches the one sent. the Internet checksum algorithm is not the same as the common \ncyclic redundancy check\n (CRC), which offers stronger protection.\n\n\nTo compute the IPv4 header checksum for an outgoing datagram, the value of the datagram\u2019s Checksum field is first set to 0. Then, the 16-bit one\u2019s complement sum of the header is calculated (the entire header is considered a sequence of 16-bit words). The 16-bit one\u2019s complement of this sum is then stored in the Checksum field to make the datagram ready for transmission.\n\n\nWhen an IPv4 datagram is received, a checksum is computed across the whole header, including the value of the Checksum field itself. Assuming there are no errors, the computed checksum value is always 0 (a one\u2019s complement of the value FFFF). \nThe value of the Checksum field in the packet can never be FFFF.\n If it were, the sum (prior to the final one\u2019s complement operation at the sender) would have to have been 0. No sum can ever be 0 using one\u2019s complement addition unless all the bytes are 0. (\nend-round carry\n)\n\n\nWhen the header is found to be bad (the computed checksum is nonzero), the IPv4 implementation discards the received datagram. No error message is generated. It is up to the higher layers to somehow detect the missing datagram and retransmit if necessary.\n\n\nMathematics of the Internet Checksum\n\n\nFor the mathematically inclined, the set of 16-bit hexadecimal values V = {0001, . . . , FFFF} and the one\u2019s complement sum operation + together form an \nAbelian group\n. The following properties are obeyed:\n\n\n\n\nFor any X,Y in V, (X + Y) is in V [closure]\n\n\nFor any X,Y,Z in V, X + (Y + Z) = (X + Y) + Z [associativity]\n\n\nFor any X in V, e + X = X + e = X where e = FFFF [identity]\n\n\nFor any X in V, there is an X\u2032 in V such that X + X\u2032 = e [inverse]\n\n\nFor any X,Y in V, (X + Y) = (Y + X) [commutativity]\n\n\n\n\nNote that in the set V and the group \nV,+\n, number 0000 deleted the from consideration. If we put the number 0000 in the set V, then \nV,+\n is not a group any longer. [p187-188]\n\n\nDS Field and ECN\n\n\nThe third and fourth fields of the IPv4 header (second and third fields of the IPv6 header) are the \nDifferentiated Services\n (called DS Field) and \nECN\n fields, formerly called the \nToS Byte\n or IPv6 \nTraffic Class\n.\n\n\nDifferentiated Services (called \nDiffServ\n) is a framework and set of standards aimed at supporting differentiated classes of service (beyond just best-effort) on the Internet. IP datagrams that are marked in certain ways may be forwarded differently (e.g., with higher priority) and can lead to increased or decreased queuing delay in the network and other special effects (possibly with associated special fees imposed by an ISP). [p188]\n\n\nThe Differentiated Services Code Point (DSCP) is a number (in the DS Field) that refers to a particular predefined arrangement of bits with agreed-upon meaning. Datagrams have a DSCP assigned to them when they are given to the network infrastructure that remains unmodified during delivery ,but policies (such as how many high-priority packets are allowed to be sent in a period of time) may cause a change in DSCP during delivery. [p188]\n\n\nThe pair of ECN bits marks a datagram with a \ncongestion indicator\n when passing through a router that has a significant amount of internally queued traffic. Both bits are set by persistently congested ECN-aware routers when forwarding packets. When a marked packet is received at the destination, some protocol (such as TCP) will notice that the packet is marked and indicate this fact back to the sender, which would then slow down, thereby easing congestion before a router is forced to drop traffic because of overload. This mechanism is one of several aimed at avoiding or dealing with network congestion.\n\n\n(Original uses for the ToS and Traffic Class skipped) [p188-189]\n\n\nThe 6-bit DS Field holds the DSCP, providing support for 64 distinct code points. The particular value of the DSCP, expressed as \nper-hop behavior\n (PHB), tells a router the forwarding treatment or special handling the datagram should receive. The default value for the DSCP is generally 0, which corresponds to routine, best-effort Internet traffic.\n\n\n\n\nAs indicated in the table below, the DSCP values are divided into three pools: standardized, experimental/local use (EXP/LU), and experimental/local use.\n\n\n\n\n\n\n\n\nPool\n\n\nCode Point Prefix\n\n\nPolicy\n\n\n\n\n\n\n\n\n\n\n1\n\n\nxxxxx0\n\n\nStandards\n\n\n\n\n\n\n2\n\n\nxxxx11\n\n\nEXP/LU\n\n\n\n\n\n\n3\n\n\nxxxx01\n\n\nEXP/LU(*)\n\n\n\n\n\n\n\n\nA router is to first segregate traffic into different classes. Traffic within a common class may have different drop probabilities, allowing the router to decide what traffic to drop first if it is forced to discard traffic.\n\n\n\n\nThe 3-bit class selector provides for eight defined code points (called the \nclass selector code points\n) that correspond to PHBs with a specified minimum set of features providing similar functionality to the earlier IP precedence capability. These are called \nclass selector compliant PHBs\n. Code points of the form xxx000 always map to such PHBs.\n\n\nThe \nAssured Forwarding\n (AF) group provides forwarding of IP packets in a fixed number of independent AF classes. Traffic from one class is forwarded separately from other classes. Within a traffic class, a datagram is assigned a \ndrop precedence\n. Datagrams of higher drop precedence in a class areare discarded with higher priority over those with lower drop precedence in the same class. Combining the traffic class and drop precedence, the name \nAFij\n corresponds to assured forwarding class \ni\n with drop precedence \nj\n.\n\n\nThe \nExpedited Forwarding\n (EF) service provides the appearance of an uncongested network (EF traffic should receive relatively low delay, jitter, and loss). This requires the rate of EF traffic going out of a router to be at least as large as the rate coming in. Consequently, EF traffic will only ever have to wait in a router queue behind other EF traffic.\n\n\n\n\nThe following table indicates the class selector DSCP values:\n\n\n\n\n\n\n\n\n\n\nName\n\n\nValue\n\n\nReference\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nCS0\n\n\n000000\n\n\n[RFC2474]\n\n\nClass selector (best-effort/routine)\n\n\n\n\n\n\nCS1\n\n\n001000\n\n\n[RFC2474]\n\n\nClass selector (priority)\n\n\n\n\n\n\nCS2\n\n\n010000\n\n\n[RFC2474]\n\n\nClass selector (immediate)\n\n\n\n\n\n\nCS3\n\n\n011000\n\n\n[RFC2474]\n\n\nClass selector (flash)\n\n\n\n\n\n\nCS4\n\n\n100000\n\n\n[RFC2474]\n\n\nClass selector (flash override)\n\n\n\n\n\n\nCS5\n\n\n101000\n\n\n[RFC2474]\n\n\nClass selector (CRITIC/ECP)\n\n\n\n\n\n\nCS6\n\n\n110000\n\n\n[RFC2474]\n\n\nClass selector (internetwork control)\n\n\n\n\n\n\nCS7\n\n\n111000\n\n\n[RFC2474]\n\n\nClass selector (control)\n\n\n\n\n\n\nAF11\n\n\n001010\n\n\n[RFC2597]\n\n\nAssured Forwarding (class 1,dp 1)\n\n\n\n\n\n\nAF12\n\n\n001100\n\n\n[RFC2597]\n\n\nAssured Forwarding (1,2)\n\n\n\n\n\n\nAF13\n\n\n001110\n\n\n[RFC2597]\n\n\nAssured Forwarding (1,3)\n\n\n\n\n\n\nAF21\n\n\n010010\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,1)\n\n\n\n\n\n\nAF22\n\n\n010100\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,2)\n\n\n\n\n\n\nAF23\n\n\n010110\n\n\n[RFC2597]\n\n\nAssured Forwarding (2,3)\n\n\n\n\n\n\nAF31\n\n\n011010\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,1)\n\n\n\n\n\n\nAF32\n\n\n011100\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,2)\n\n\n\n\n\n\nAF33\n\n\n011110\n\n\n[RFC2597]\n\n\nAssured Forwarding (3,3)\n\n\n\n\n\n\nAF41\n\n\n100010\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,1)\n\n\n\n\n\n\nAF42\n\n\n100100\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,2)\n\n\n\n\n\n\nAF43\n\n\n100110\n\n\n[RFC2597]\n\n\nAssured Forwarding (4,3)\n\n\n\n\n\n\nEF PHB\n\n\n101110\n\n\n[RFC3246]\n\n\nExpedited Forwarding\n\n\n\n\n\n\nVOICE-ADMIT\n\n\n101100\n\n\n[RFC5865]\n\n\nCapacity-Admitted Traffic\n\n\n\n\n\n\n\n\n\n\nIP Options\n\n\nIP options may be selected on a per-datagram basis. Many of the options are no longer practical or desirable because of the limited size of the IPv4 header or concerns regarding security. With IPv6, most of the options have been removed or altered and are in the basic IPv6 header but are placed after the IPv6 header in one or more extension headers.\n\n\nAn IP router that receives a datagram containing options should perform special processing. In some cases IPv6 routers process extension headers, but many headers are designed to be processed only by end hosts. In some routers, datagrams with options or extensions are not forwarded as fast as ordinary datagrams.\n\n\nThe table shows most of the IPv4 options that have been standardized over the years.\n\n\n\n\nThe options area always ends on a 32-bit boundary. Pad bytes with a value of 0 are added if necessary. This ensures that the IPv4 header is always a multiple of 32 bits (as required by the IHL field). [p192]\n\n\nOptions are identified by an 8-bit option \nType\n field. This field is subdivided into three subfields: \nCopy\n (1 bit), \nClass\n (2 bits), and \nNumber\n (5 bits). Options 0 and 1 are a single byte long, and most others are variable in length. Variable options consist of 1 byte of type identifier, 1 byte of length, and the option itself.\n\n\nMost of the standardized options are rarely or never used in the Internet today. In addition, the options are primarily for diagnostic purposes and make the construction of firewalls more cumbersome and risky. Thus, IPv4 options are typically disallowed or stripped at the perimeter of enterprise networks by firewalls. (\nChapter 7\n)\n\n\nWithin enterprise networks, where the average path length is smaller and protection from malicious users may be less of a concern, options can still be useful. In addition, since the \nRouter Alert\n option is designed primarily as a performance optimization and does not change fundamental router behavior, it is permitted more often than the other options. Some router implementations have a highly optimized internal pathway for forwarding IP traffic containing no options. The Router Alert option informs routers that a packet requires processing beyond the conventional forwarding algorithms. The experimental \nQuick-Start\n option at the end of the table is applicable to both IPv4 and IPv6.\n\n\nIPv6 Extension Headers\n\n\nIn IPv6, special functions such as those provided by options in IPv4 can be enabled by adding extension headers that follow the IPv6 header. IPv6 header is fixed at 40 bytes, and extension headers are added only when needed. [p194]\n\n\nIn choosing the IPv6 header to be of a fixed size, and requiring that extension headers be processed only by end hosts (with one exception), design and construction of high-performance routers are easier because the demands on packet processing at routers can be simpler than with IPv4.\n\n\nExtension headers, along with headers of higher-layer protocols such as TCP or UDP, are chained together with the IPv6 header to form a cascade of headers (see the figure below). The \nNext Header\n field in each header indicates the type of the subsequent header, which could be an IPv6 extension header or some other type.  The value of 59 indicates the end of the header chain. The most possible values for the Next Header field are provided in the following table.\n\n\n\n\nThis figure shows IPv6 headers form a chain using the Next Header field. Headers in the chain may be IPv6 extension headers or transport headers. The IPv6 header appears at the beginning of the datagram and is always 40 bytes long.\n\n\n\n\nThis table show values for the IPv6 Next Header field may indicate extensions or headers for other protocols. The same values are used with the IPv4 Protocol field, where appropriate. The IPv6 extension header mechanism distinguishes some functions (e.g., routing and fragmentation) from options.\n\n\n\n\nThe order of the extension headers is given as a recommendation, except for the location of the \nHop-by-Hop Options\n (HOPOPT)), which is mandatory, so an IPv6 implementation must be prepared to process extension headers in the order in which they are received.\n\n\nOnly the \nDestination Options\n header can be used twice: the first time for options pertaining to the destination IPv6 address contained in the IPv6 header and the second time (position 8) for options pertaining to the final destination of the datagram.\n\n\nIn some cases (e.g., when the \nRouting header\n is used), the \nDestination IP Address\n field in the IPv6 header changes as the datagram is forwarded to its ultimate destination.\n\n\n\n\nIPv6 Options\n\n\nIPv6 options, if present, are grouped into either of the following:\n\n\n\n\nHop-by-Hop Options\n: relevant to every router along a datagram\u2019s path\n\n\nDestination Options\n: relevant only to the recipient\n\n\n\n\nHopby-Hop Options (called HOPOPTs) are the only ones that need to be processed by every router a packet encounters.  The format for encoding options within the Hop-by-Hop and Destination Options extension headers is common.\n\n\nThe Hop-by-Hop and Destination Options headers are capable of holding more than one option. Each of these options is encoded as \ntype-length-value\n (TLV) sets, as shown below:\n\n\n\n\nIn the TLV sets, the first byte gives the option type, including subfields indicating how an IPv6 node should behave if the option is not recognized, and whether the option data might change as the datagram is forwarded. The \nOpt Data Len\n field gives the size of the option data in bytes.\n\n\nThe 2 high-order bits in an IPv6 TLV option type indicate whether an IPv6 node should forward or drop the datagram if the option is not recognized, and whether a message indicating the datagram\u2019s fate should be sent back to the sender, as shown in the table below:\n\n\n\n\nOptions in IPv6 are carried in either Hop-by-Hop (H) or Destination (D) Options extension headers. The option Type field contains the value from the \"Type\" column with the Action and Change subfields denoted in binary. The \"Length\" column contains the value of the Opt Data Len byte. See the table below:\n\n\n\n\n[p196-197]\n\n\nPad1 and PadN\n\n\nIPv6 options are aligned to 8-byte offsets, so options that are naturally smaller are padded with 0 bytes to round out their lengths to the nearest 8 bytes. [p197]\n\n\nIPv6 Jumbo Payload\n\n\nIn some TCP/IP networks, such as those used to interconnect supercomputers, the normal 64KB limit on the IP datagram size can lead to unwanted overhead when moving large amounts of data. The IPv6 \nJumbo Payload\n option specifies an IPv6 datagram with payload size larger than 65,535 bytes, called a \njumbogram\n. This option need not be implemented by nodes attached to links with MTU sizes below 64KB. The Jumbo Payload option provides a 32-bit field for holding the payload size for datagrams with payloads of sizes between 65,535 and 4,294,967,295 bytes (4 GB).\n\n\nWhen a jumbogram is formed for transmission, its normal Payload Length field is set to 0. The TCP protocol makes use of the Payload Length field in order to compute its checksum using the Internet checksum algorithm described previously. When the Jumbo Payload option is used, TCP must be careful to use the length value from the option instead of the regular Length field in the base header. [p198]\n\n\nTunnel Encapsulation Limit\n\n\nTunneling\n refers to the encapsulation of one protocol in another that does not conform to traditional layering. For example, IP datagrams may be encapsulated inside the payload portion of another IP datagram.\n\n\n\n\nTunneling can be used to form virtual \noverlay networks\n, in which one network (e.g., the Internet) acts as a well-connected link layer for another layer of IP.\n\n\nTunnels can be nested in the sense that datagrams that are in a tunnel may themselves be placed in a tunnel, in a recursive fashion.\n\n\n\n\nUsing Tunnel Encapsulation Limit option, a sender can specify a limit to have control over how many tunnel levels are ultimately used for encapsulation. Using this option.\n\n\nRouter Alert\n\n\nThe Router Alert option indicates that the datagram contains information that needs to be processed by a router. It is used for the same purpose as the IPv4 Router Alert option.\n\n\nQuick-Start\n\n\nThe Quick-Start (QS) option is used in conjunction with the experimental QuickStart procedure for TCP/IP specified in [RFC4782]. It is applicable to both IPv4 and IPv6 but at present is suggested only for private networks and not the global Internet. [p199]\n\n\nCALIPSO\n\n\nThis option is used for supporting the \nCommon Architecture Label IPv6 Security Option\n (CALIPSO) [RFC5570] in certain private networks.\n\n\nHome Address\n\n\nThis option holds the \"home\" address of the IPv6 node sending the datagram when IPv6 mobility options are in use. Mobile IP (\nSection 5.5\n) specifies a set of procedures for handling IP nodes that may change their point of network attachment without losing their higher-layer network connections. [p199]\n\n\nRouting Header\n\n\nThe IPv6 Routing header provides a mechanism for the sender of an IPv6 datagram to control the path the datagram takes through the network. Two different versions of the routing extension header have been specified: type 0 (RH0) and type 2 (RH2):\n\n\n\n\nRH0 has been deprecated because of security concerns [RFC5095]\n\n\nRH2 is defined in conjunction with Mobile IP.\n\n\n\n\nTo best understand the Routing header, we begin by discussing RH0 and then investigate why it has been deprecated and how it differs from RH2. RH0 specifies one or more IPv6 nodes to be \"visited\" as the datagram is forwarded.\n\n\n\n\nThe IPv6 Routing header shown below generalizes the loose Source and Record Route options from IPv4. RH0 allows the sender to specify a vector of IPv6 addresses for nodes to be visited. [p200-201]\n\n\n\n\nThe header contains an 8-bit \nRouting Type\n identifier and an 8-bit \nSegments Left\n field.\n\n\nThe Routing Type identifier for IPv6 addresses is 0 for RH0 and 2 for RH2.\n\n\nThe Segments Left field indicates how many route segments remain to be processed. (The number of explicitly listed intermediate nodes still to be visited before reaching the final destination.) [p201]\n\n\n\n\n\n\n\n\nA Routing header is not processed until it reaches the node whose address is contained in the \nDestination IP Address\n field of the IPv6 header. At this time, the Segments Left field is used to determine the next hop address from the address vector, and this address is swapped with the Destination IP Address field in the IPv6 header. Thus, as the datagram is forwarded, the Segments Left field grows smaller, and the list of addresses in the header reflects the node addresses that forwarded the datagram.\n\n\nThe forwarding procedure is shown in the below figure:\n\n\n\n\n\n\nThe sender (S) constructs the datagram with destination address R1 and a Routing header (type 0) containing the addresses R2, R3, and D. The final destination of the datagram is the last address in the list (D). The Segments Left field (labeled \"Left\") starts at 3.\n\n\nThe datagram is forwarded toward R1 automatically by S and R0 . Because R0's address is not present in the datagram, no modifications of the Routing header or addresses are performed by R0 .\n\n\nUpon reaching R1, the destination address from the base header is swapped with the first address listed in the Routing header and the Segments Left field is decremented.\n\n\nAs the datagram is forwarded, the process of swapping the destination address with the next address from the address list in the Routing header repeats until the last destination listed in the Routing header is reached.\n\n\n\n\nRH0 has been deprecated by [RFC5095] because of a security concern that allows RH0 to be used to increase the effectiveness of DoS attacks. \nThe problem is that RH0 allows the same address to be specified in multiple locations within the Routing header. This can lead to traffic being forwarded many times between two or more hosts or routers along a particular path.\n The potentially high traffic loads that can be created along particular paths in the network can cause disruption to other traffic flows competing for bandwidth across the same path. Consequently, RH0 has been deprecated and only RH2 remains as the sole Routing header supported by IPv6. RH2 is equivalent to RH0 except it has room for only a single address and uses a different value in the \nRouting Type\n field.\n\n\nFragment Header\n\n\nThe Fragment header is used by an IPv6 source when sending a datagram larger than the path MTU of the datagram\u2019s intended destination. (Path MTU and how it is determined are detailed in \nChapter 13\n). 1280 bytes is a network-wide link-layer minimum MTU for IPv6 [RFC2460].\n\n\n\n\nIn IPv4, any host or router can fragment a datagram if it is too large for the MTU on the next hop, and fields within the second 32-bit word of the IPv4 header indicate the fragmentation information.\n\n\nIn IPv6, only the sender of the datagram is permitted to perform fragmentation, and in such cases a Fragment header is added.\n\n\n\n\nThe Fragment header includes the same information as is found in the IPv4 header, but the Identification field is 32 bits instead of the 16 that are used for IPv4. The larger field provides the ability for more fragmented packets to be outstanding in the network simultaneously. The Fragment header uses the format shown in the figure below:\n\n\n\n\n\n\nThe \nReserved\n field and 2-bit Res field are both zero and ignored by receivers.\n\n\nThe \nFragment Offset\n field indicates where the data that follows the Fragment header is located, as a positive offset in 8-byte units, relative to the \"fragmentable part\" of the original IPv6 datagram.\n\n\n\n\nThe datagram serving as input to the fragmentation process is called the \"original packet\" and consists of two parts: the \"unfragmentable part\" and the \"fragmentable part\":\n\n\n\n\nThe \nunfragmentable part\n includes the IPv6 header and any included extension headers required to be processed by intermediate nodes to the destination, which includes:\n\n\nAll headers up to and including the Routing header, or,\n\n\nthe Hop-by-Hop Options extension header if only it is present.\n\n\n\n\n\n\nThe \nfragmentable part\n constitutes the remainder of the datagram, which includes:\n\n\nDestination Options header\n\n\nUpper-layer headers\n\n\nPayload data)\n\n\n\n\n\n\n\n\nWhen the original packet is fragmented, multiple fragment packets are produced, each of which contains a copy of the unfragmentable part of the original packet followed by the Fragment header. In each fragmented IPv6 packet:\n\n\n\n\nThe IPv6 header has the \nPayload Length\n field altered to reflect the size of the fragment packet it describes.\n\n\nFollowing the unfragmentable part, each new fragment packet contains a Fragment header with the following fields:\n\n\nAn appropriately assigned \nFragment Offset\n field (the first fragment contains offset 0)\n\n\nA copy of the original packet\u2019s \nIdentification\n field.\n\n\nThe last fragment has its \nM\n (\nMore Fragments\n) bit field set to 0.\n\n\n\n\n\n\n\n\nThe following example illustrates the way an IPv6 source might fragment a datagram:\n\n\n\n\nIn the figure above, a payload of 3960 bytes is fragmented such that no fragment\u2019s total packet size exceeds 1500 bytes (a typical MTU for Ethernet), yet the \nfragment data sizes still are arranged to be multiples of 8 bytes.\n [p204-205]\n\n\n\n\nA 3960-byte payload is split into three fragment packets of size 1448 bytes or less.\n\n\nThe Fragment header in each fragment contains a common Identification field\n\n\nAll but the last fragment have the More Fragments field (M) set to 1. The offset is given in 8-byte units\u2014the last fragment, for example, contains data beginning at offset (362 * 8) = 2896 bytes from the beginning of the original packet\u2019s data. The scheme is similar to fragmentation in IPv4.\n\n\nThe IPv6 header\u2019s Payload Length field is modified to reflect the size of the data and newly formed Fragment header.\n\n\n\n\nThe receiver must ensure that all fragments of an original datagram have been received before performing reassembly. As with fragmentation in IPv4 (\nChapter 10\n), fragments may arrive out of order at the receiver but are reassembled in order to form a datagram that is given to other protocols for processing.\n\n\n[p205-208]\n\n\n(Wireshark example skipped)\n\n\nIP Forwarding\n\n\nIP forwarding is simple, especially for a host:\n\n\n\n\nIf the destination is directly connected to the host (e.g., a point-to-point link) or on a shared network (e.g., Ethernet), the IP datagram is sent directly to the destination; a router is not required or used.\n\n\nOtherwise, the host sends the datagram to a single router (called the \ndefault\n router) and lets the router deliver the datagram to its destination.\n\n\n\n\nA host differs from a router in how IP datagrams are handled: a host never forwards datagrams it does not originate, whereas routers do.\n\n\nThe IP protocol can receive a datagram from either of the following:\n\n\n\n\nAnother protocol on the same machine (TCP, UDP, etc.),\n\n\nA network interface.\n\n\n\n\nThe IP layer has some information in memory, called a \nrouting table\n or \nforwarding table\n, which it searches each time it receives a datagram to send.\n\n\nWhen a datagram is received from a network interface, IP first checks if the destination IP address is one of its own IP addresses (one of the IP addresses associated with one of its network interfaces) or some other address for which it should receive traffic such as an IP broadcast or multicast address:\n\n\n\n\nIf so, the datagram is delivered to the protocol module specified by the \nProtocol\n field in the IPv4 header or \nNext Header\n field in the IPv6 header.\n\n\nIf the datagram is not destined for one of the IP addresses being used locally by the IP module, then:\n\n\nIf the IP layer was configured to act as a router, the datagram is forwarded (that is, handled as an outgoing datagram as described in \nSection 5.4.2\n); or,\n\n\nThe datagram is silently discarded. Under some circumstances (e.g., no route is known in case 1), an ICMP message may be sent back to the source indicating an error condition.\n\n\n\n\n\n\n\n\nForwarding Table\n\n\nThe data in a forwarding table is up to the implementation, though several key pieces of information are generally required to implement the forwarding table for IP. Each entry in the routing or forwarding table contains (at least conceptually) the following information fields:\n\n\n\n\nDestination\n: This contains a 32-bit field (or 128-bit field for IPv6) used for matching the result of a masking operation. The destination can be:\n\n\nZero, for a \"default route\" covering all destinations, or,\n\n\nFull length of an IP address, for a \"host route\" that describes only a single destination.\n\n\n\n\n\n\nMask\n: This contains a 32-bit field (or 128-bit field for IPv6) applied as a bitwise AND mask to the destination IP address of a datagram being looked up in the forwarding table. The masked result is compared with the set of destinations in the forwarding table entries.\n\n\nNext-hop\n: This contains the 32-bit IPv4 address or 128-bit IPv6 address of the next IP entity (router or host) to which the datagram should be sent. The next-hop entity is typically on a network shared with the system performing the forwarding lookup, meaning the two share the same network prefix.\n\n\nInterface\n: This contains an identifier used by the IP layer to reference the network interface that should be used to send the datagram to its next hop. For example, it could refer to a host\u2019s 802.11 wireless interface, a wired Ethernet interface, or a PPP interface associated with a serial port. If the forwarding system is also the sender of the IP datagram, this field is used in selecting which source IP address to use on the outgoing datagram (see \nSection 5.6.2.1\n).\n\n\n\n\nIP forwarding is performed on a \nhop-by-hop\n basis. The routers and hosts do not contain the complete forwarding path to any destination, except those destinations that are directly connected to the host or router. IP forwarding provides the IP address of only the next-hop entity to which the datagram is sent. The following assumption are made:\n\n\n\n\nThe next hop is really \"closer\" to the destination than the forwarding system is, and that the next-hop router is directly connected to (shares a common network prefix with) the forwarding system.\n\n\nNo \"loops\" are constructed between the next hops so that a datagram does not circulate around the network until its TTL or hop limit expires.\n\n\n\n\nThe job of ensuring correctness of the routing table is given to one or more routing protocols. Many different routing protocols are available to do this job, including \nRIP\n, \nOSPF\n, \nBGP\n, and \nIS-IS\n.\n\n\nIP Forwarding Actions\n\n\nWhen the IP layer in a host or router needs to send an IP datagram to a next-hop router or host, it first examines the destination IP address (\nD\n) in the datagram  Using the value \nD\n, the following \nlongest prefix match\n algorithm is executed on the forwarding table:\n\n\n\n\n\n\nSearch the table for all entries (masking and comparing) for which the following property holds:\n\n\n(\nD\n \n \nm\nj\n) = \nd\nj\n\n\nWhere:\n\n\n\n\nm\nj\n is the value of the mask field associated with the forwarding entry \ne\nj\n having index j\n\n\nd\nj\n is the value of the destination field associated with \ne\nj\n.\n\n\n\n\nThis means that the destination IP address \nD\n is bitwise ANDed with the mask in each forwarding table entry (\nm\nj\n), and the result is compared against the destination in the same forwarding table entry (\nd\nj\n). If the property holds, the entry (\ne\nj\n here) is a \"match\" for the destination IP address. When a match happens, the algorithm notes the entry index (\nj\n here) and how many bits in the mask \nm\nj\n were 1. The more bits are 1, the \"better\" the match.\n\n\n\n\n\n\nThe best matching entry \ne\nk\n (the one with the largest number of 1 bits in its mask \nm\nj\n) is selected, and its next-hop field \nnm\nk\n is used as the next-hop IP address in forwarding the datagram.\n\n\n\n\n\n\nIf no matches in the forwarding table are found, the datagram is undeliverable:\n\n\n\n\nIf on a host (the undeliverable datagram was generated locally), a \"host unreachable\" error is normally returned to the application that generated the datagram.\n\n\nIf on a router, an ICMP message is normally sent back to the host that sent the datagram.\n\n\n\n\nIn some circumstances, more than one entry may match an equal number of 1 bits: for example, when more than one default route is available (e.g., when attached to more than one ISP, called \nmultihoming\n). A common behavior is for the system to simply choose the first match. More sophisticated systems may attempt to load-balance or split traffic across the multiple routes. Studies suggest that multihoming can be beneficial not only for large enterprises, but also for residential users. [p210]\n\n\nExamples of IP Forwarding\n\n\nThere are two cases of IP forwarding:\n\n\n\n\nDirect delivery\n: all systems are using the same network prefix.\n\n\nIndirect delivery\n (\nFigure 5-16\n).\n\n\n\n\nDirect Delivery\n\n\nHost S (with IPv4 address S and MAC address \nS\n) has an IP datagram to send to Host D (IPv4 address D, MAC address \nD\n). Both hosts are on the same Ethernet (\nfront cover\n) and are interconnected using a switch. [p210]\n\n\nThe top part of the following figure shows the delivery of the datagram and the forwarding table on S to contain the information as shown in the following table:\n\n\n\n\n\n\n\n\n\n\nDestination\n\n\nMask\n\n\nGateway (Next Hop)\n\n\nInterface\n\n\n\n\n\n\n\n\n\n\n0.0.0.0\n\n\n0.0.0.0\n\n\n10.0.0.1\n\n\n10.0.0.100\n\n\n\n\n\n\n10.0.0.0\n\n\n255.255.255.128\n\n\n10.0.0.100\n\n\n10.0.0.100\n\n\n\n\n\n\n\n\n\nThe (unicast) IPv4 forwarding table at host S contains only two entries. Host S is configured with IPv4 address and subnet mask 10.0.0.100/25. Datagrams destined for addresses in the range 10.0.0.1 through 10.0.0.126 use the second forwarding table entry and are sent using direct delivery. All other datagrams use the first entry and are given to router R with IPv4 address 10.0.0.1.\n\n\n\nDirect delivery does not require the presence of a router: IP datagrams are encapsulated in a link-layer frame that directly identifies the source and destination. In the above forwarding table, the destination IPv4 address D (10.0.0.9) matches both the first and second forwarding table entries. Because it matches the second entry better (25 bits instead of none), the \"gateway\" or next-hop address is 10.0.0.100, the address S. Thus, \nthe gateway portion of the entry contains the address of the sending host\u2019s own network interface (no router is referenced), indicating that direct delivery is to be used to send the datagram.\n\n\nThe datagram is encapsulated in a lower-layer frame destined for the target host D. If the lower-layer address of the target host is unknown, the ARP protocol (for IPv4; \nChapter 4\n) or Neighbor Solicitation (for IPv6; \nChapter 8\n) operation may be invoked at this point to determine the correct lower-layer address, \nD\n. Once known, the destination address in the datagram is D\u2019s IPv4 address (10.0.0.9), and \nD\n is placed in the \nDestination IP Address\n field in the lower-layer header. The switch delivers the frame to D based solely on the link-layer address \nD\n; it pays no attention to the IP addresses.\n\n\nIndirect Delivery\n\n\nHost S has an IP datagram to send to the Host D (\nftp.uu.net\n), whose IPv4 address is 192.48.96.9. The bottom part of the \nFigure 5-16\n shows the conceptual path of the datagram through four routers. Host S searches its forwarding table but does not find a matching prefix on the local network. It uses its default route entry (which matches every destination, but with no 1 bits at all).\n\n\nThe IP addresses correspond to the source and destination hosts, but the lower-layer addresses do not. The lower-layer addresses determine which machines receive the frame containing the datagram on a per-hop basis.\n\n\nIn this example:\n\n\n\n\nThe lower-layer address needs the Ethernet address of the next-hop router R1\u2019s a-side interface (the lower-layer address corresponding to IPv4 address 10.0.0.1). This is accomplished by ARP (or a Neighbor Solicitation request for IPv6) on the network interconnecting S and R1.\n\n\nOnce R1 responds with its a-side lower-layer address, S sends the datagram to R1. Delivery from S to R1 takes place based on processing only the lower-layer headers (the lower-layer destination address).\n\n\nUpon receipt of the datagram, R1 checks its forwarding table.\n\n\n\n\nThe following table is the forwarding table of R1:\n\n\n\n\n\n\n\n\nDestination\n\n\nMask\n\n\nGateway (Next Hop)\n\n\nInterface\n\n\nNote\n\n\n\n\n\n\n\n\n\n\n0.0.0.0\n\n\n0.0.0.0\n\n\n70.231.159.254\n\n\n70.231.132.85\n\n\nNAT\n\n\n\n\n\n\n10.0.0.0\n\n\n255.255.255.128\n\n\n10.0.0.100\n\n\n10.0.0.1\n\n\nNAT\n\n\n\n\n\n\n\n\n\nThe forwarding table at R1 indicates that address translation should be performed for traffic. The router has a private address on one side (10.0.0.1) and a public address on the other (70.231.132.85). Address translation is used to make datagrams originating on the 10.0.0.0/25 network appear to the Internet as though they had been sent from 70.231.132.85.\n\n\n\n\n\nWhen R1 receives the datagram, it realizes that the datagram\u2019s destination IP address is not one of its own, so it forwards the datagram. Its forwarding table is searched and the default entry is used. The default entry in this case has a next hop within the ISP servicing the network, 70.231.159.254 (this is R2\u2019s a-side interface).\n\n\nBecause this router is in the global Internet and the source address of Host S is the private address 10.0.0.100, R1 performs \nNetwork Address Translation\n (NAT) on the datagram to make it routable on the Internet. The NAT operation results in the datagram having the new source address 70.231.132.85, which corresponds to R1\u2019s b-side interface.\n\n\nWhen router R2 (inside the ISP) receives the datagram, it goes through the same steps that the local router R1 did (except for the NAT operation). If the datagram is not destined for one of its own IP addresses, the datagram is forwarded.\n\n\n\n\nIPv6 uses a slightly different mechanism (Neighbor Solicitation messages) from IPv4 (which uses ARP) to ascertain the lower-layer address of its next hop (\nChapter 8\n). In addition, IPv6 has both link-local addresses and global addresses (\nChapter 2\n). While global addresses behave like regular IP addresses, link-local addresses can be used only on the same link. In addition, because all the link-local addresses share the same IPv6 prefix (fe80::/10), a multihomed host may require user to determine which interface to use when sending a datagram destined for a link-local destination.\n\n\n[p213-214]\n\n\nTo see the path taken to an IP destination, we can use the \ntraceroute\n program:\n\n\nLinux% traceroute -n ftp.uu.net\ntraceroute to ftp.uu.net (192.48.96.9), 30 hops max, 38 byte packets\n 1 70.231.159.254 9.285 ms 8.404 ms 8.887 ms\n 2 206.171.134.131 8.412 ms 8.764 ms 8.661 ms\n 3 216.102.176.226 8.502 ms 8.995 ms 8.644 ms\n 4 151.164.190.185 8.705 ms 8.673 ms 9.014 ms\n 5 151.164.92.181 9.149 ms 9.057 ms 9.537 ms\n 6 151.164.240.134 9.680 ms 10.389 ms 11.003 ms\n 7 151.164.41.10 11.605 ms 37.699 ms 11.374 ms\n 8 12.122.79.97 13.449 ms 12.804 ms 13.126 ms\n 9 12.122.85.134 15.114 ms 15.020 ms 13.654 ms\n MPLS Label=32307 CoS=5 TTL=1 S=0\n10 12.123.12.18 16.011 ms 13.555 ms 13.167 ms\n11 192.205.33.198 15.594 ms 15.497 ms 16.093 ms\n12 152.63.57.102 15.103 ms 14.769 ms 15.128 ms\n13 152.63.34.133 77.501 ms 77.593 ms 76.974 ms\n14 152.63.38.1 77.906 ms 78.101 ms 78.398 ms\n15 207.18.173.162 81.146 ms 81.281 ms 80.918 ms\n16 198.5.240.36 77.988 ms 78.007 ms 77.947 ms\n17 198.5.241.101 81.912 ms 82.231 ms 83.115 ms\n\n\n\n\n\nThis program lists each of the IP hops traversed while sending a series of datagrams to the destination \nftp.uu.net\n (192.48.96.9). The \ntraceroute\n program uses a combination of UDP datagrams (with increasing TTL over time) and ICMP messages (used to detect each hop when the UDP datagrams expire) to accomplish its task. Three UDP packets are sent at each TTL value, providing three roundtrip-time measurements to each hop. The following line indicates that \nMultiprotocol Label Switching\n (MPLS) [RFC3031] is being used.\n\n\nMPLS Label=32307 CoS=5 TTL=1 S=0\n\n\n\n\n\nMPLS is a form of link-layer network capable of carrying multiple network-layer protocols. Many network operators use it for traffic engineering purposes (controlling where network traffic flows through their networks). [p215]\n\n\nDiscussion (IP Forwarding)\n\n\nKey points regarding the operation of IP unicast forwarding:\n\n\n\n\nMost of the hosts and routers in this example used a default route consisting of a single forwarding table entry of this form: mask 0, destination 0, next hop \nsome IP address\n. Indeed, most hosts and most routers at the edge of the Internet can use a default route for everything other than destinations on local networks because there is only one interface available that provides connectivity to the rest of the Internet.\n\n\nThe source and destination IP addresses in the datagram never change once in the regular Internet. This is always the case unless either source routing is used, or when other functions (such as NAT, as in the example) are encountered along the data path. Forwarding decisions at the IP layer are based on the destination address.\n\n\nA different lower-layer header is used on each link that uses addressing, and the lower-layer destination address (if present) always contains the lower-layer address of the next hop. Therefore, lower-layer headers routinely change as the datagram is moved along each hop toward its destination.  In our example, both Ethernet LANs encapsulated a link-layer header containing the next hop\u2019s Ethernet address, but the DSL link did not. Lower-layer addresses are normally obtained using ARP (see Chap\n\n\n\n\nMobile IP\n\n\n(skipped)\n\n\n[p215-220]\n\n\nHost Processing of IP Datagrams\n\n\nHost Models", 
            "title": "Chapter 5. The Internet Protocol (IP)"
        }, 
        {
            "location": "/tcpv1/ch7/", 
            "text": "Chapter 7. Firewalls and Network Address Translation (NAT)\n\n\n\n\nPerhaps ironically, the development and eventual widespread use of NAT has contributed to significantly slow the adoption of IPv6.\n\nTCPv1\n\n\n\n\nMany security problems (attacks) were caused by bugs or unplanned protocol operations in the software implementations of Internet hosts. Fixing the problem would have required a way to control the Internet traffic to which the end hosts were exposed. Today, this is provided by a \nfirewall\n, a type of router that restricts the types of traffic it forwards. [p299]\n\n\nAs firewalls are being deployed, another problem was becoming important: the number of available IPv4 addresses was diminishing,\nwith a threat of exhaustion. One of the most important mechanisms developed to deal with this, aside from IPv6, is called \nNetwork Address Translation\n (NAT). With NAT, Internet addresses need not be globally unique, but can be reused in different parts of the Internet, called \naddress realms\n. This greatly eased the problem of address exhaustion.\n\n\nFirewalls\n\n\nGiven the enormous management problems associated with trying to keep end system software up-to-date and bug-free, the focus of resisting attacks expanded\n\n\n\n\nFrom: securing end systems,\n\n\nTo: restricting the Internet traffic allowed to flow to end systems by filtering out some traffic using firewalls.\n\n\n\n\nToday, several different types of firewalls have evolved.\n\n\nThe two major types of firewalls commonly used include \nproxy firewalls\n and \npacket-filtering firewalls\n. The main difference between them is the layer in the protocol stack at which they operate, and consequently the way IP addresses and port numbers are used. The packet-filtering firewall is an Internet router that drops datagrams that (fail to) meet specific criteria. The proxy firewall operates as a multihomed server host from the viewpoint of an Internet client. That is, it is the endpoint of TCP and UDP transport associations; it does not typically route IP datagrams at the IP protocol layer.\n\n\nPacket-Filtering Firewalls\n\n\nPacket-filtering firewalls act as Internet routers and filter (drop) some traffic. They can generally be configured to discard or forward packets whose headers meet (or fail to meet) certain criteria, called \nfilters\n.\n\n\nPopular filters involve:\n\n\n\n\nUndesired IP addresses or options,\n\n\nTypes of ICMP messages,\n\n\nVarious UDP or TCP services, based on the port numbers contained in each packet.\n\n\n\n\nStateless and stateful:\n\n\n\n\nStateless\n firewalls treat each datagram individually.\n\n\nStateful\n firewalls are able associate packets with either previous or future packets to make inferences about datagrams or streams.\n\n\n\n\n[p300]\n\n\nA typical packet-filtering firewall is shown below.\n\n\nIn this figure\n\n\n\n\nThe firewall is an Internet router with three network interfaces:\n\n\n\"inside\"\n\n\n\"outside\"\n\n\n\"DMZ\"\n\n\n\n\n\n\nThe DMZ subnet provides access to an extranet or DMZ where servers are deployed for Internet users to access.\n\n\nNetwork administrators install filters or \naccess control lists\n (ACLs, basically policy lists indicating what types of packets to discard or forward) in the firewall.\n\n\nTypically, these filters conservatively block traffic from the outside that may be harmful and liberally allow traffic to travel from inside to outside.\n\n\n\n\n\n\nProxy Firewalls\n\n\nProxy firewalls are not really Internet routers. They are essentially hosts running one or more \napplication-layer gateways\n (ALGs), hosts with more than one network interface that relay traffic of certain types between one connection/association and another at the application layer.\n\n\nThe figure below illustrates a proxy firewall:\n\n\n\n\nClients on the inside of the firewall are usually configured in a special way to associate (or connect) with the proxy instead of the actual end host providing the desired service.\n\n\nThe firewalls act as multihomed hosts with their IP forwarding capability typically disabled.\n\n\nAs with packet-filtering firewalls, a common configuration is to have an \"outside\" interface assigned a globally routable IP address and for its \"inner\" interface to be configured with a private IP address. Thus, proxy firewalls support the use of private address realms.\n\n\n\n\n\n\nThis type of firewall can be quite secure at the cost of brittleness and lack of flexibility:\n\n\n\n\nSince this style of firewall must contain a proxy for each transport-layer service, any new services to be used must have a corresponding proxy installed and operated for connectivity to take place through the proxy.\n\n\nEach client must be configured to find the proxy, for example using the \nWeb Proxy Auto-Discovery Protocol\n (WPAD), although there are some alternatives: capturing proxies that catch all traffic of a certain type regardless of destination address).\n\n\nSignificant intervention is required from network operators to support additional services.\n\n\n\n\nThe two most common forms of proxy firewalls are HTTP proxy firewalls and SOCKS firewalls.\n\n\n\n\nHTTP proxy firewalls\n, also called \nWeb proxies\n, work only for the HTTP and HTTPS (Web) protocols.\n\n\nThese proxies act as Web servers for internal clients and as Web clients when accessing external Web sites.\n\n\nSuch proxies often also operate as \nWeb caches\n. These caches save copies of Web pages so that subsequent accesses can be served directly from the cache instead of from the originating Internet Web server. Doing so can reduce latency to display Web pages and improve the experience of users accessing the Web.\n\n\nSome Web proxies are also used as \ncontent filters\n, which attempt to block access to certain Web sites based on a \u201cblacklist\u201d of prohibited sites. Conversely, \ntunneling proxy servers\n are available on the Internet. These servers (e.g., \npsiphon\n, \nCGIProxy\n) essentially perform the opposite function: to allow users to avoid being blocked by content filters.\n\n\n\n\n\n\nSOCKS firewalls\n uses the \nSOCKS protocol\n, which is more generic than HTTP for proxy access and is applicable to more services than just the Web. Two versions of SOCKS are currently in use: version 4 (SOCKS5) and version 5 (SOCKS5). Version 4 provides the basic support for proxy traversal, and version 5 adds strong authentication, UDP traversal, and IPv6 addressing.\n\n\nTo use a SOCKS proxy, an application must be written to use SOCKS (it must be \"socksified\") and configured to know the location and version of the SOCKS proxy. Then the client uses the SOCKS protocol to request the proxy to perform network connections and, optionally, DNS lookups.\n\n\n\n\n\n\n\n\nNetwork Address Translation (NAT)\n\n\nNAT is a mechanism that allows the same sets of IP addresses to be reused in different parts of the Internet. With NAT as a common use, all incoming and outgoing traffic passes through a single NAT device that partitions the inside (private) address realm from the global Internet address realm, all the internal systems can be provided Internet connectivity as clients using locally assigned, private IP addresses. [p303]\n\n\nNAT was introduced to solve two problems: address depletion and concerns regarding the scalability of routing. NAT was initially suggested as a stopgap, temporary measure to be used until the deployment of some protocol with a larger number of addresses (IPv6) became widespread. Routing scalability was being tackled with the development of Classless Inter-Domain Routing (CIDR, \nChapter 2\n)\n\n\nNAT is popular because:\n\n\n\n\nIt reduces the need for globally routable Internet addresses\n\n\nIt offers some degree of natural firewall capability and requires little configuration.\n\n\n\n\nPerhaps ironically, the development and eventual widespread use of NAT has contributed to significantly slow the adoption of IPv6. Among its other benefits, IPv6 was intended to make NAT unnecessary.\n\n\nNAT has several drawbacks:\n\n\n\n\nOffering Internet-accessible services from the private side requires special configuration because privately addressed systems are not directly reachable from the Internet.\n\n\nEvery packet in both directions of a connection or association must pass through the same NAT, because the NAT must actively rewrite the addressing information in each packet.\n\n\nNATs require connection state on a \nper-association\n (or \nper-connection\n) basis and must operate across multiple protocol layers, unlike conventional routers. Modifying an address at the IP layer also requires modifying checksums at the transport layer (see \nChapters 10\n and \nChatper 13\n regarding the pseudoheader checksum)\n\n\n\n\n\n\nSome applications protocols, especially those that send IP addressing information inside the application-layer payload, such as \nFile Transfer Protocol\n (FTP) and \nSession Initiation Protocol\n (SIP), require a special application-layer gateway function that rewrites the application content in order to work unmodified with NAT or other NAT traversal methods that allow the applications to determine how to work with the specific NAT they are using.\n\n\n\n\nDespite its shortcomings, NATs are very widely used, and most network routers support it; NAT supports the basic protocols (e.g., e-mail, Web browsing) that are needed by millions of client systems accessing the Internet every day.\n\n\nA NAT works by rewriting the identifying information in packets transiting through a router. Most commonly NAT involves rewriting the source IP address of packets as they are forwarded in one direction and the destination IP addresses of packets traveling in the reverse direction. This allows the source IP address in outgoing packets to become one of the NAT router\u2019s Internet-facing interfaces instead of the originating host\u2019s. Thus, \nto a host on the Internet, packets coming from any of the hosts on the privately addressed side of the NAT appear to be coming from a globally routable IP address of the NAT router.\n\n\nMost NATs perform both \ntranslation\n and \npacket filtering\n, and the packet-filtering criteria depend on the dynamics of the NAT state. The choice of packet-filtering policy may have a different granularity. For example, the treatment of unsolicited packets (those not associated with packets originating from behind the NAT) received by the NAT may depend on source and destination IP address and/or source and destination port number. [p305]\n\n\nTraditional NAT: Basic NAT and NAPT\n\n\nTraditional NAT\n includes both:\n\n\n\n\nBasic NAT\n. It performs rewriting of IP addresses only: a private address is rewritten to be a public address, often from a pool or range of public addresses supplied. This type of NAT is not the most popular because it does not help to dramatically reduce the need for (globally routable) IP addresses.\nby an ISP.\n\n\nNetwork Address Port Translation\n (NAPT), also known as \nIP masquerading\n. It uses transport-layer identifiers (i.e., ports for TCP and UDP, query identifiers for ICMP) to differentiate which host on the private side of the NAT is associated with a particular packet. This allows a large number of internal hosts to access the Internet simultaneously using a limited number of public addresses, often only a single one.\n\n\n\n\nSee the following figure for the distinction between basic NAT and NAPT:\n\n\n\n\nThe addresses used in a private addressing realm \"behind\" (or \"inside\") a NAT are not enforced by anyone other than the local network administrator. It is possible and acceptable for a private realm to make use of global address space. However, \nlocal systems in the private realm would most likely be unable to reach the public systems using the same addresses because the close proximity of the local systems would effectively \"mask\" the visibility of the farther-away systems using the same addresses.\n To avoid this, three IPv4 address ranges are reserved for use with private addressing realms: 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0/16, which are often used as default values for address pools in embedded DHCP servers\n\n\nNAT provides some degree of security, similar to a firewall [p306]:\n\n\n\n\nBy default, systems on the private side (using private addresses) of the NAT cannot be reached from the Internet.\n\n\nA common policy allows almost all outgoing and returning traffic (associated with outgoing traffic) to pass through the NAT but blocks almost all incoming new connection requests. This behavior inhibits \"probing\" attacks that attempt to ascertain which IP addresses have active hosts available to exploit.\n\n\nA NAT (especially a NAPT) \"hides\" the number and configuration of internal addresses from the outside. NAT helps by providing \ntopology hiding\n.\n\n\n\n\nThe following subsections discusses how NAT behaves with each major transport protocol and how it may be used in mixed IPv4/IPv6 environments. [p306]\n\n\nNAT and TCP\n\n\nWhen a TCP connection starts, an \"active opener\" or client usually sends a synchronization (SYN) packet to a \"passive opener\" or server. The server responds with its own SYN packet, which also includes an acknowledgment (ACK) of the client\u2019s SYN.  The client then responds with an ACK to the server. This \u201cthree-way handshake\u201d establishes the connection. A similar exchange with finish (FIN) packets is used to gracefully close a connection. The connection can also be forcefully closed right away using a reset (RST) packet. The behavioral requirements for traditional NAT with TCP relate primarily to the TCP three-way handshake.\n\n\nReferring to the figure below, consider a TCP connection initiated by the wireless client at 10.0.0.126 destined for the Web server on the host www.isoc.org (IPv4 address 212.110.167.157). With the format \"(source IP:source port; destination IP:destination port)\", the packet initiating the connection on the private segment might be addressed as (10.0.0.126:9200; 212.110.167.157:80).\n\n\n\n\n[p307]\n\n\n\n\nThe NAT receives the first incoming packet from the client and notices it is a new connection (SYN bit in the TCP header is turned on).\n\n\nIt modifies the source IP address to the routable IP address of the NAT router\u2019s external interface. Thus, when the NAT forwards this packet, the addressing is (63.204.134.177:9200; 212.110.167.157:80).\n\n\nIt creates a \nNAT session\n, which is internal state to remember that a new connection is being handled by the NAT. This state includes an entry, called a \nNAT mapping\n, containing the source port number and IP address of the client.\n\n\n\n\n\n\nThe server replies to the endpoint (63.204.134.177:9200), the external NAT address, using the port number chosen initially by the client. This behavior is called \nport preservation\n. By matching the destination port number on the received datagram against the NAT mapping, the NAT ascertains the internal IP address of the client that made the initial request. The NAT rewrites the response packet from (212.110.167.157:80; 63.204.134.177:9200) to (212.110.167.157:80; 10.0.0.126:9200) and forwards it.\n\n\nThe client then receives a response to its request and is now connected to the server.\n\n\n\n\nSession state is removed if FINs are exchanged. The NAT must also remove \"dead\" mappings (identified by lack of traffic or RST) that are left stale in the NAT's memory, such when a client host is simply turned off.\n\n\nMost NATs include a simplified TCP connection establishment procedures and can distinguish between connection success and failure:\n\n\n\n\nA \nconnection timer\n is activated when an outgoing SYN segment is observed, and if no ACK is seen before the timer expires, the session state is cleared.\n\n\nA \nsession timer\n is created, with a longer timeout (hours), after an ACK does arrives and the connection timer is canceled.\n\n\nThe NAT may send an additional packet to the internal endpoint to doublecheck if the session is indeed dead (called \nprobing\n). If it receives an ACK, the NAT realizes that the connection is still active, resets the session timer, and does not delete the session. If it receives either no response (after a \nclose timer\n has expired) or an RST segment, the connection has gone dead, and the state is cleared.\n\n\n\n\n\n\n\n\nA TCP connection can be configured to send \"keepalive\" packets (\nChapter 17\n), and the default rate is one packet every 2 hours, if enabled. Otherwise, a TCP connection can remain established indefinitely. While a connection is being set up or cleared, however, the maximum idle time is 4 minutes. Consequently, [RFC5382] requires (REQ-5) that a NAT wait at least 2 hours and 4 minutes before concluding that an established connection is dead and at least 4 minutes before concluding that a partially opened or closed connection is dead.\n\n\nThere are tricky problems for TCP NAT. [p308] See \nDoubts and Solutions\n\n\nNAT and UDP\n\n\nBesides issues when performing NAT on TCP, the NAT on UDP has other issues due to:\n\n\n\n\nUDP has no connection establishment and clearing procedures as in TCP.\n\n\nThere are no indicators such as the SYN, FIN, and RST bits to indicate that a session is being created or destroyed.\n\n\nAn association may not be completely clear: UDP does not use a 4-tuple to identify a connection like TCP; it can rely on only the two endpoint address/port number combinations.\n\n\n\n\nTo handle these issues, UDP NATs use a \nmapping timer\n to clear NAT state if a binding has not been used \"recently\". The \"recently\" may mean different values. [RFC4787] requires the timer to be at least 2 minutes and recommends that it be 5 minutes. Timers can be refreshed when packets travel from the inside to the outside of the NAT (NAT outbound refresh behavior). [p309]\n\n\nWith IP fragmentation, an IP fragment other than the first one does not contain the port number information needed by NAPT to operate properly. This also applies to TCP and ICMP. Thus, fragments cannot be handled properly by simple NATs or NAPTs. [p309]\n\n\nNAT and Other Transport Protocols (DCCP, SCTP)\n\n\n\n\nThe \nDatagram Congestion Control Protocol\n (DCCP) [RFC4340] provides a congestion-controlled datagram service.\n\n\nThe \nStream Control Transmission Protocol\n (SCTP) [RFC4960] provides a reliable messaging service that can accommodate hosts with multiple addresses.\n\n\n\n\nNAT and ICMP\n\n\nThe Internet Control Message Protocol (ICMP) provides status information about IP packets and can also be used for making certain measurements and gathering information about the state of the network.\n\n\nICMP has two categories of messages: informational and error: [p310]\n\n\n\n\nError messages contain a (partial or full) copy of the IP packet that induced the error condition. They are sent from the point where an error was detected, often in the middle of the network, to the original sender.\n\n\nWhen an ICMP error message passes through a NAT, the IP addresses in the included \"offending datagram\" need to be rewritten by the NAT in order for them to make sense to the end client (called \nICMP fix-up\n).\n\n\n\n\n\n\nInformational messages include a \nQuery ID\n field that is handled much like port numbers for TCP or UDP.\n\n\nNAT handling these types of messages can recognize outgoing informational requests and set a timer in anticipation of a returning response.\n\n\n\n\n\n\n\n\nNAT and Tunneled Packets\n\n\nWhen tunneled packets (\nChapter 3\n) are to be sent through a NATs, not only must a NAT rewrite the IP header, but it may also have to rewrite the headers or payloads of other packets that are encapsulated in them. One example of this is the \nGeneric Routing Encapsulation\n (GRE) header used with the \nPoint-to-Point Tunneling Protocol\n (PPTP). [p310]\n\n\nNAT and Multicast\n\n\nNATs can be configured to support multicast traffic (\nChapter 9\n), although this is rare. [p310]\n\n\nNAT and IPv6\n\n\nThere is staunch resistance to supporting the use of NAT with IPv6 based on the idea that saving address space is unnecessary with IPv6 and that other desirable NAT features (firewall-like functionality, topology hiding, and privacy) can be better achieved using Local Network Protection (LNP) [RFC4864]. LNP represents a collection of techniques with IPv6 that match or exceed the properties of NATs.\n\n\nAside from its packet-filtering properties, NAT supports the coexistence of multiple address realms and thereby helps to avoid the problem of a site having to change its IP addresses when it switches ISPs. [p310-311]\n\n\nAddress and Port Translation Behavior\n\n\nOne of the primary goals of the BEHAVE working group in IETF was to clarify the common behaviors and set guidelines. [p311]\n\n\nSee the following figure as a generic NAT mapping example:\n\n\n\n\nIn this figure:\n\n\n\n\nThe notation \nX:x\n indicates that a host in the private addressing realm (inside host) uses IP address \nX\n with port number \nx\n (for ICMP, the query ID is used instead of the port number). The IP address \nX\n is a private IPv4 address.\n\n\nTo reach the remote address/port combination \nY:y\n, the NAT establishes a mapping using an external (globally routable) address \nX1\u2032\n and port number \nx1\u2032\n. Assuming that the internal host contacts \nY1:y1\n followed by \nY2:y2\n, the NAT establishes mappings \nX1\u2032:x1\u2032\n and \nX2\u2032:x2\u2032\n, respectively.\n\n\nIn most cases, X1\u2032 equals X2\u2032 because most sites use only a single globally routable IP address.\n\n\nThe mapping is said to be \nreused\n if \nx1\u2032\n equals \nx2\u2032\n. If \nx1\u2032\n and \nx2\u2032\n equal \nx\n, the NAT implements port preservation, as \nmentioned earlier\n.\n\n\n\n\n\n\n\n\nA NAT\u2019s address and port behavior is characterized by what its mappings depend on.  The inside host uses IP address:port \nX:x\n to contact \nY1:y1\n and then \nY2:y2\n. The address and port used by the NAT for these associations are \nX1\u2032:x1\u2032\n and \nX2\u2032:x2\u2032\n, respectively.\n\n\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n for any \nY1:y1\n or \nY2:y2\n, the NAT has \nendpoint-independent\n mappings.\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n if and only if \nY1\n equals \nY2\n, the NAT has \naddress-dependent\n mappings.\n\n\nIf \nX1\u2032:x1\u2032\n equals \nX2\u2032:x2\u2032\n if and only if \nY1:y1\n equals \nY2:y2\n, the NAT has \naddress and port-dependent\n mappings.\n\n\n\n\nA NAT with multiple external addresses (i.e., where \nX1\u2032\n may not equal \nX2\u2032\n) has an address pooling behavior of arbitrary if the outside address is chosen without regard to inside or outside address. Alternatively, it may have a pooling behavior of paired, in which case the same \nX1\n is used for any association with \nY1\n.\n\n\nThe figure above and the table below summarize the various NAT port and address behaviors based on definitions from [RFC4787]. The table also gives filtering behaviors that use similar terminology.\n\n\nFor all common transports, including TCP and UDP, the required NAT address- and port-handling behavior is endpoint-independent.\n The purpose of this requirement is to help applications that attempt to determine the external addresses used for their traffic to work more reliably. This is detailed in \nNAT traversal\n.\n\n\n\n\n\n\n\n\nBehavior Name\n\n\nTranslation Behavior\n\n\nFiltering Behavior\n\n\n\n\n\n\n\n\n\n\nEndpoint-independent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n for all \nY2:y2\n (required)\n\n\nAllows any packets for \nX1:x1\n as long as any \nX1\u2032:x1\u2032\n exists (recommended for greatest transparency)\n\n\n\n\n\n\nAddress-dependent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n iff \nY1 = Y2\n\n\nAllows packets for \nX1:x1\n from \nY1:y1\n as long as \nX1\n has previously contacted \nY1\n (recommended for more stringent filtering)\n\n\n\n\n\n\nAddress-and port-dependent\n\n\nX1\u2032:x1\u2032 = X2\u2032:x2\u2032\n iff \nY1:y1 = Y2:y2\n\n\nAllows packets for \nX1:x1\n from \nY1:y\n\n\n\n\n\n\n\n\nFiltering Behavior\n\n\nServers behind NATs\n\n\nHairpinning and NAT Loopback\n\n\nNAT Editors\n\n\nService Provider NAT (SPNAT) and Service Provider IPv6 Transition\n\n\nNAT Traversal\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\np308 on TCP NAT:\n\n\nOne of the tricky problems for a TCP NAT is handling peer-to-peer applications operating on hosts residing on the private sides of multiple NATs [RFC5128].  Some of these applications use a simultaneous open whereby each end of the connection acts as a client and sends SYN packets more or less simultaneously. TCP is able to handle this case by responding with SYN + ACK packets that complete the connection faster than with the three-way handshake, but many existing NATs do not handle it properly. [RFC5382] addresses this by requiring (REQ-2) that a NAT handle all valid TCP packet exchanges, and simultaneous opens in particular.  Some peer-to-peer applications (e.g., network games) use this behavior. In addition, [RFC5382] specifies that an inbound SYN for a connection about which the NAT knows nothing should be silently discarded. This can occur when a simultaneous open is attempted but the external host\u2019s SYN arrives at the NAT before the internal host\u2019s SYN. Although this may seem unlikely, it can happen as a result of clock skew, for example. If the incoming external SYN is dropped, the internal SYN has time to establish a NAT mapping for the same connection represented by the external SYN. If no internal SYN is forthcoming in 6s, the NAT may signal an error to the external host.\n\n\n\nSome other NAT drawbacks:\n\n\n\n\nThe ugly side of NAT", 
            "title": "Chapter 7. Firewalls and Network Address Translation (NAT)"
        }, 
        {
            "location": "/tcpv1/ch10/", 
            "text": "Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation\n\n\nIntroduction\n\n\nUDP is a simple, datagram-oriented, transport-layer protocol that preserves message boundaries.\n\n\nIP Fragmentation\n\n\nIP employs \nfragmentation\n and \nreassembly\n. Fragmentation in IPv4 can take place at the original sending host and at any intermediate routers along the end-to-end path. Note that datagram fragments can themselves be fragmented. Fragmentation in IPv6 is somewhat different because \nonly the source is permitted to perform fragmentation\n.\n\n\nWhen an IP datagram is fragmented, it is not reassembled until it reaches its final destination, because:\n\n\n\n\nNot performing reassembly within the network alleviates the forwarding software (or hardware) in routers from implementing this feature\n\n\nDifferent fragments of the same datagram may follow different paths to their common destination\n\n\n\n\nExample: UDP/IPv4 Fragmentation\n\n\nAn UDP application may wish to avoid IP fragmentation, because when the size of the resulting datagram exceeds the link\u2019s MTU, the IP datagram is split across multiple IP packets, which can lead to performance issues because \nif any fragment is lost, the entire datagram is lost.\n\n\n\n\nA single UDP datagram with 2992 UDP payload bytes is fragmented into three UDP/ IPv4 packets (no options). The UDP header that contains the source and destination port numbers appears only in the first fragment (a complicating factor for firewalls and NATs). Fragmentation is controlled by the \nIdentification\n, \nFragment Offset\n, and \nMore Fragments\n (MF) fields in the IPv4 header.\n\n\nThe original UDP datagram included 2992 bytes of application (UDP payload) data and 8 bytes of UDP header, resulting in an IPv4 Total Length field value of 3020 bytes (IP header is 20-byte). When this datagram was fragmented into three packets, 40 extra bytes were created (20 bytes for each of the newly created IPv4 fragment headers). Thus, the total number of bytes sent is 3060. [p489]\n\n\nFields:\n\n\n\n\nIdentification\n: its value (set by the original sender) is copied to each fragment and is used to group them together when they arrive\n\n\nFragment Offset\n: the offset of the first byte of the fragment payload byte in the original IPv4 datagram (in 8-byte units)\n\n\nMF\n: indicates whether more fragments in the datagram should be expected and is 0 only in the final fragment\n\n\n\n\nIf one fragment is lost, the entire datagram is lost, since IP itself has no error correction mechanism of its own. Mechanisms such as timeout and retransmission are left as the responsibility of the higher layers. \nFor this reason, fragmentation is often avoided.\n\n\nWe can use our \nsock\n program and increase the size of the datagram until fragmentation occurs. On an Ethernet, the maximum amount of data in a frame is ordinarily 1500 bytes, which leaves at most 1472 bytes for application data to avoid fragmentation, assuming 20 bytes for the IPv4 header and 8 bytes for the UDP header.\n\n\nWe will run our sock program with data sizes of 1471, 1472, 1473, and 1474 bytes. We expect the last two to cause fragmentation:\n\n\n[p490-492]\n\n\nLinux% sock -u -i -n1 -w1471 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1472 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1473 10.0.0.3 discard\nLinux% sock -u -i -n1 -w1474 10.0.0.3 discard\n\n\n\n\n\n1 23:42:43.562452 10.0.0.5.46530 \n 10.0.0.3.9:\n        udp 1471 (DF) (ttl 64, id 61350, len 1499)\n2 23:42:50.267424 10.0.0.5.46531 \n 10.0.0.3.9:\n        udp 1472 (DF) (ttl 64, id 62020, len 1500)\n3 23:42:57.814555 10.0.0.5 \n 10.0.0.3:\n        udp (frag 37671:1@1480) (ttl 64, len 21)\n4 23:42:57.814715 10.0.0.5.46532 \n 10.0.0.3.9:\n        udp 1473 (frag 37671:1480@0+) (ttl 64, len 1500)\n5 23:43:04.368677 10.0.0.5 \n 10.0.0.3:\n        udp (frag 37672:2@1480) (ttl 64, len 22)\n6 23:43:04.368838 10.0.0.5.46535 \n 10.0.0.3.9:\n        udp 1474 (frag 37672:1480@0+) (ttl 64, len 1500)\n\n\n\n\n\nOne observation that may be surprising is that the fragments with larger offsets are delivered \nprior\n to the first fragments. In effect, \nthe sender has intentionally reordered the fragments.\n This behavior can be beneficial. If the last fragment is delivered first, the receiving host is able to ascertain the maximum amount of buffer space it will require in order to reassemble the entire datagram.", 
            "title": "Chapter 10. User Datagram Protocol (UDP) and IP Fragmentation"
        }, 
        {
            "location": "/tcpv1/ch11/", 
            "text": "Chapter 11. Name Resolution and the Domain Name System (DNS)\n\n\nTo identify hosts, IP addresses (especially IPv6 addresses) are cumbersome for humans to use and remember. The Internet supports the use of \nhost names\n to identify hosts, both clients and servers. In order to be used by protocols such as TCP and IP, host names are converted into IP addresses using a process known as name resolution. There are different forms of name resolution in the Internet, but the most prevalent and important one uses a distributed database system known as the \nDomain Name System\n (DNS). DNS runs as an application on the Internet, using IPv4 or IPv6 (or both). For scalability, DNS names are hierarchical, as are the servers that support name resolution.\n\n\nThe DNS Name Space", 
            "title": "Chapter 11. Name Resolution and the Domain Name System (DNS)"
        }, 
        {
            "location": "/tcpv1/ch12/", 
            "text": "Chapter 12. TCP: The Transmission Control Protocol (Preliminaries)\n\n\nIntroduction\n\n\n[p579]\n\n\nThe protocols discussed so far do not include mechanisms for delivering data reliably; they may detect that erroneous data has been received, using a checksum or CRC, but they do not try very hard to repair errors:\n\n\n\n\nWith IP and UDP, no error repair is done at all.\n\n\nWith Ethernet and other protocols based on it, the protocol provides some number of retries and then gives up if it cannot succeed.\n\n\n\n\nInformation theory and coding theory\n\n\n\n\nError-correcting codes\n (adding redundant bits so that the real information can be retrieved even if some bits are damaged) is one way to correct communications problems is one very important method for handling errors.\n\n\nAutomatic Repeat Request\n (ARQ): which means \"try sending again\" until the information is finally received. This approach forms the basis for many communications protocols, including TCP.\n\n\n\n\nARQ and Retransmission\n\n\nFor a multihop communications channel, there are other problems besides packet bit errors:\n\n\n\n\nProblems that arise at an intermediate router\n\n\nPacket reordering\n\n\nPacket duplication\n\n\nPacket erasures (drops)\n\n\n\n\nAn error-correcting protocol designed for use over a multihop communications channel (such as IP) must cope with all of these problems.\n\n\nA straightforward method dealing with packet drops (and bit errors) is to resend the packet until it is received properly. This requires a way to determine:\n\n\n\n\nWhether the receiver has received the packet.\n\n\nWhether the packet it received was the same one the sender sent.\n\n\n\n\n[p580]\n\n\nWindows of Packets and Sliding Windows\n\n\nVariable Windows: Flow Control and Congestion Control\n\n\nSetting the Retransmission Timeout\n\n\nIntroduction to TCP\n\n\nOur description of TCP starts in this chapter and continues in the next five chapters:\n\n\n\n\nChapter 13: how a TCP connection is established and terminated.\n\n\nChapter 14:\n\n\nHow TCP estimates the per-connection RTT.\n\n\nHow the retransmission timeout is set based on the above estimate.\n\n\n\n\n\n\nChapter 15:\n\n\nNormal transfer of data (starting with \"interactive\" applications, such as chat).\n\n\nWindow management and flow control, which apply to both interactive and \"bulk\" data flow applications (such as file transfer).\n\n\nUrgent mechanism\n of TCP, which allows a sender to mark certain data in the data stream as special.\n\n\n\n\n\n\nChapter 16:\n\n\nCongestion control algorithms in TCP that help to reduce packet loss when the network is very busy.\n\n\nModifications that have been proposed to increase throughput on fast networks or improve resiliency on lossy (e.g., wireless) networks.\n\n\n\n\n\n\nChapter 17: how TCP keeps connections active even when no data is flowing.\n\n\n\n\nThe TCP Service Model", 
            "title": "Chapter 12. TCP: The Transmission Control Protocol (Preliminaries)"
        }, 
        {
            "location": "/tcpv1/headers/", 
            "text": "Headers\n\n\nIPv4 Header\n\n\n\n\nIPv6 Header\n\n\n\n\nUDP Header\n\n\n\n\nTCP Header", 
            "title": "Headers"
        }, 
        {
            "location": "/tcpv1/headers/#headers", 
            "text": "IPv4 Header   IPv6 Header   UDP Header   TCP Header", 
            "title": "Headers"
        }, 
        {
            "location": "/utlk/ch1/", 
            "text": "Chapter 1. Introduction\n\n\nThis chapter gives an overview of major features of Linux, as well as Unix kernels. This book is based on \nLinux 2.6.11\n source code.\n\n\nLinux Versus Other Unix-Like Kernels\n\n\nSeveral differences between Linux and Unix implementations:\n\n\n\n\nKernel threading\n\n\nPreemptive kernel: Linux 2.6 can arbitrarily interleave execution flows while they are in privileged mode\n\n\nMultiprocessor support: Linux 2.6 supports symmetric multiprocessing (SMP)\n\n\nSTREAMS\n is not included in Linux\n\n\n\n\nThe Process/Kernel Model\n\n\n\n\nUsers processes\n\n\nKernel threads:\n\n\nrun in Kernel Mode;\n\n\nare non-interactive;\n\n\ncreated during system startup\n\n\n\n\n\n\nKernel routines can be activated in: \n\n\nsystem call;\n\n\nexception signaled by a process; \n\n\ninterrupt by a peripheral device;\n\n\nkernel thread executed\n\n\n\n\n\n\n\n\nProcess Implementation\n\n\nProcess descriptor\n contains registers:\n\n\n\n\nProgram counter (PC) registers\n\n\nStack pointer (SP) registers\n\n\nGeneral purpose registers\n\n\nFloating point registers\n\n\nProcessor control registers\n\n\nMemory management registers\n\n\n\n\nReentrant Kernels\n\n\nA \nkernel control\n path denotes the sequence of instructions executed by the kernel to handle a system call, an exception, or an interrupt.\n\n\nProcess Address Space\n\n\nSynchronization and Critical Regions\n\n\nSignals and Interprocess Communication\n\n\n\n\nUnix signals\n\n\nSystem V IPC: semaphores, message queues, and shared memory\n\n\n\n\nProcess Management\n\n\n\n\nfork()\n, \n_exit()\n, and \nexec()\n-like system calls\n\n\nwait4()\n\n\nProcess groups and login sessions\n\n\n\n\nMemory Management\n\n\n\n\nVirtual memory acts as a logical layer between the application memory requests and the hardware Memory Management Unit (MMU).\n\n\nKernel Memory Allocator: Linux\u2019s KMA uses a Slab allocator on top of a buddy system.\n\n\nProcess virtual address space\n\n\n\n\n\n\nDoubts and Solutions\n\n\nVerbatim\n\n\nChatper 1 on Linux Versus Other Unix-Like Kernels [p3]:\n\n\n\n\nLinux uses kernel threads in a very limited way to execute a few kernel functions periodically; however, they do not represent the basic execution context abstraction. \n\n\n\n\nSummary\n\n\nKernel Architecture\n\n\n\n\nThe Linux kernel, as with most Unix kernels, is \nmonolithic\n: each kernel layer is integrated into the whole kernel program and runs in Kernel Mode on behalf of the current process. [p11]", 
            "title": "Chapter 1. Introduction"
        }, 
        {
            "location": "/utlk/ch2/", 
            "text": "Chapter 2. Memory Addressing\n\n\nThis chapter offers details in \nx86\n microprocessors address memory chips and how Linux uses the available addressing circuits.\n\n\nMemory Addresses\n\n\n\n\nLogical address\n\n\nLinear address\n (also known as \nvirtual address\n)\n\n\nPhysical address\n\n\n\n\nMemory Management Unit (MMU) transforms a logical address into a linear address, and the linear address into a physical address.\n\n\n\n\nMemory arbiter: read or write operations on a RAM chip must be performed serially.\n\n\nSegmentation in Hardware\n\n\nThe following sections focus on address translation when \nprotected mode\n is enabled, in Intel microprocessors starting with the 80286 model.\n\n\nSegment Selectors\n\n\nA logical address consists of:\n\n\n\n\nSegment Selector\n (segment identifier): 16-bit\n\n\nOffset: 32-bit\n\n\n\n\nSegmentation registers\n\n\nSegmentation Registers\n hold Segment Selectors.\n\n\n\n\ncs\n: code segment (program instructions); 2-bit field for CPU's Current Privilege Level (CPL), Linux uses only levels 0 and 3 for Kernel Mode and User Mode\n\n\nss\n: stack segment (current program stack)\n\n\nds\n: data segment (global and static data)\n\n\nes\n, \nfs\n, and \ngs\n: general purpose (arbitrary data)\n\n\n\n\nSegment Descriptors\n\n\nEach segment is represented by an 8-byte \nSegment Descriptor\n that describes the segment characteristics. Segment Descriptors are stored either in the \nGlobal Descriptor Table\n (GDT) or in the \nLocal Descriptor Table\n (LDT). The address and size of GDT and LDT are contained in \ngdtr\n and \nldtr\n control registers respectively.\n\n\n\n\nCode Segment Descriptor: included in GDT or LDT\n\n\nData Segment Descriptor: included in GDT or LDT\n\n\nTask State Segment Descriptor (TSSD): refers to a Task State Segment (TSS), a segment used to save the contents of the processor registers; included in GDT only\n\n\nLocal Descriptor Table Descriptor (LDTD): refers to a segment containing an LDT; included in GDT only\n\n\n\n\nFast Access to Segment Descriptors\n\n\nSegmentation registers store only the Segment Selector. The x86 process provides an additional nonprogrammable register for each of the six programmable segmentation registers to speed up the translation of logical addresses into linear addresses. Each nonprogrammable register contains the 8-byte Segment Descriptor.\n\n\nSegment Selector fields [p40]:\n\n\n\n\nindex\n: identifies the Segment Descriptor entry contained in GDT or LDT\n\n\nTI\n (Table Indicator): specifies whether the Segment Descriptor is included in the GDT (\nTI\n = 0) or in the LDT (\nTI\n = 1).\n\n\nRPL\n (Requestor Privilege Level):  specifies the \nCurrent Privilege Level\n (CPL) of the CPU when the corresponding Segment Selector is loaded into the \ncs\n register\n\n\n\n\nSegmentation Unit\n\n\nThe \nsegmentation unit\n performs the following operations to obtain the linear address:\n\n\n\n\n\n\nExamines the \nTI\n field of the Segment Selector to determine which Descriptor Table (GDT or LDT) stores the Segment Descriptor\n\n\nComputes the address of the Segment Descriptor from the \nindex\n field of the Segment Selector\n\n\nAdds the offset of the logical address to the \nBase\n field of the Segment Descriptor\n\n\n\n\nSegmentation in Linux\n\n\nAll Linux processes running in User Mode use the same pair of segments to address instructions and data. This is similar to processes running in Kernel Mode.\n\n\n\n\nuser code segment\n\n\nuser data segment\n\n\nkernel code segment\n\n\nkernel data segment\n\n\n\n\nSegment Selectors are defined by the macros:\n\n\n\n\n__USER_CS\n\n\n__USER_DS\n\n\n__KERNEL_CS\n\n\n__KERNEL_DS\n\n\n\n\nTo address the kernel code segment, for instance, the kernel just loads the value yielded by the \n__KERNEL_CS\n macro into the \ncs\n segmentation register.\n\n\nThe linear addresses associated with such segments all start at 0 and reach the addressing limit of 2\n32\n \u20131. This means that all processes, either in User Mode or in Kernel Mode, may use the same logical addresses.\n\n\nCPL\n, \nRPL\n and registers\n\n\nThe Current Privilege Level (CPL) of the CPU indicates whether the processor is in User or Kernel Mode and is specified by the \nRPL\n field of the Segment Selector stored in the \ncs\n register. [p42]\n\n\nWhenever the CPL is changed, some segmentation registers (e.g. \nds\n, \nss\n) must be correspondingly updated. [p42-43]\n\n\nImplicit Segment Selector\n\n\nOnly Offset component of its logical address is specified:\n\n\n\n\nss\n: kernel saves a pointer to an instruction or to a data structure\n\n\ncs\n: kernel invokes a function\n\n\nds\n: kernel data structure\n\n\nes\n: user data structure\n\n\n\n\nThe Linux GDT\n\n\nIn multiprocessor systems there is one GDT for every CPU [p43].\n\n\n\n\ncpu_gdt_table\n array: stores GDTs\n\n\ncpu_gdt_descr\n array: addresses and sizes of the GDTs\n\n\n\n\nEach GDT includes 18 segment descriptors and 14 null, unused, or reserved entries. Unused entries are inserted on purpose so that Segment Descriptors usually accessed together are kept in the same 32-byte line of the hardware cache.\n\n\n\n\nFour user and kernel code and data segments\n\n\nTask State Segment (TSS)\n\n\nDefault Local Descriptor Table(LDT), usually shared by all processes\n\n\nThree Thread-Local Storage (TLS) segments: allows multithreaded applications to make use of up to three segments containing data local to each thread. The \nset_thread_area()\n and \nget_thread_area()\n system calls, respectively, create and release a TLS segment for the executing process.\n\n\nThree segments related to Advanced Power Management (APM)\n\n\nFive segments related to Plug and Play (PnP) BIOS services\n\n\nA special TSS segment used by the kernel to handle \"Double fault\" exceptions\n\n\n\n\nThe Linux LDT\n\n\nMost Linux User Mode applications do not make use of a Local Descriptor Table. The kernel defines a default LDT to be shared by most processes. It has five entries but only two are used by the kernel: a \ncall gate\n for \niBCS\n executables, and a call gate for Solaris/x86 executables.\n\n\nIn some cases, processes may require to set up their own LDT, such as applications (such as Wine) that execute segment-oriented Microsoft Windows applications. The \nmodify_ldt()\n system call allows a process to do this.\n\n\nPaging in Hardware\n\n\nThe paging unit translates linear addresses into physical ones. Its key task is to check the requested access type against the access rights of the linear address, and generates a Page Fault exception if memory access is not valid.\n\n\n\n\nPages\n: grouped fixed-length intervals of linear addresses; contiguous linear addresses within a page are mapped into contiguous physical addresses. The term \"page\" to refer both to a set of linear addresses and to the data contained in this group of addresses.\n\n\nPage frames\n (or \nphysical pages\n): RAM partitions from the perspective of the paging unit. Each page frame (storage area) contains a page (block of data), thus the length of a page frame coincides with that of a page.\n\n\nPage table\n: data structures (in main memory) that map linear to physical addresses\n\n\n\n\nRegular Paging\n\n\nThe x86 processors support paging; it is enabled by setting the \nPG\n flag of a control register named \ncr0\n.\n\n\n\n\nDoubts and Solutions\n\n\nSegmentation in Linux [p41]\n\n\n\n\nHowever, Linux uses segmentation in a very limited way. In fact, segmentation and paging are somewhat redundant, because both can be used to separate the physical address spaces of processes: segmentation can assign a different linear address space to each process, while paging can map the same linear address space into different physical address spaces. Linux prefers paging to segmentation for the following reasons:", 
            "title": "Chapter 2. Memory Addressing"
        }, 
        {
            "location": "/icnd1/part1/", 
            "text": "Part I: Networking Fundamentals\n\n\nChapter 1. Introduction to Computer Networking\n\n\nChapter 2. The TCP/IP and OSI Networking Models\n\n\nTCP/IP Networking Model\n\n\nA \nnetworking model\n (\nnetworking architecture\n or \nnetworking blueprint\n), refers to a comprehensive set of documents that define everything that should happen for a computer network to work.\n\n\nThe TCP/IP model both defines and references a large collection of protocols that allow computers to communicate. TCP/IP uses documents called \nRequests for Comments\n (RFC).\n\n\nData Encapsulation Terminology\n\n\n\n\n\n\nCreate and encapsulate the application data with any required application layer headers.\n\n\nEncapsulate the data supplied by the application layer inside a transport layer header.\n\n\nEncapsulate the data supplied by the transport layer inside an Internet layer (IP) header.\n\n\nEncapsulate the data supplied by the Internet layer inside a data link layer header and trailer. This is the only layer that uses both a \nheader\n and a \ntrailer\n.\n\n\nTransmit the bits.\n\n\n\n\nOSI Networking Model\n\n\n\n\nDescribing Protocols by Referencing the OSI Layers\n\n\nNetworking documents often describe TCP/IP protocols and standards by referencing OSI layers, both by layer number and layer name. For instance, a common description of a LAN switch is \u201clayer 2 switch,\u201d with \u201clayer 2\u201d referring to OSI layer 2.\n\n\n\n\n\n\n\n\nLayer Name\n\n\nProtocols and Specifications\n\n\nDevices\n\n\n\n\n\n\n\n\n\n\nApplication, presentation, session (Layers 5\u20137)\n\n\nTelnet, HTTP, FTP, SMTP, POP3, VoIP, SNMP\n\n\nFirewall, intrusion detection systems, hosts\n\n\n\n\n\n\nTransport (Layer 4)\n\n\nTCP, UDP\n\n\nHosts, firewalls\n\n\n\n\n\n\nNetwork (Layer 3)\n\n\nIP\n\n\nRouter\n\n\n\n\n\n\nData link (Layer 2)\n\n\nEthernet (IEEE 802.3), HDLC, Frame Relay, PPP\n\n\nLAN switch, wireless access point, cable modem, DSL modem\n\n\n\n\n\n\nPhysical (Layer 1)\n\n\nRJ-45, EIA/TIA-232, V.35, Ethernet (IEEE 802.3)\n\n\nLAN hub, LAN repeater, cables\n\n\n\n\n\n\n\n\nOSI Layering Concepts and Benefits\n\n\n[p41]\n\n\n\n\nLess complex\n\n\nStandard interfaces\n\n\nEasier to learn\n\n\nEasier to develop\n\n\nMultivendor interoperability\n\n\nModular engineering\n\n\n\n\nOSI Encapsulation Terminology\n\n\n\n\nThe TCP/IP model uses terms such as \nsegment\n, \npacket\n, and \nframe\n to refer to various layers and their respective encapsulated data. OSI uses a more generic term: \nprotocol data unit\n (PDU).\n\n\nChapter 3. Fundamentals of LANs\n\n\nAn Overview of Modern Ethernet LANs\n\n\nTypes of cabling:\n\n\n\n\nUnshielded Twisted-Pair\n (UTP)\n\n\nFiber-optic\n\n\n\n\nMost IEEE standards define a different variation of Ethernet at the physical layer.\nFor the data link layer:\n\n\n\n\n802.3 Media Access Control (MAC) sublayer\n\n\n802.2 Logical Link Control (LLC) sublayer\n\n\n\n\n[p52]\n\n\n\n\n\n\n\n\nCommon Name\n\n\nSpeed\n\n\nAlternative Name\n\n\nName of IEEE Standard\n\n\nCable Type, Maximum Length\n\n\n\n\n\n\n\n\n\n\nEthernet\n\n\n10 Mbps\n\n\n10BASE-T\n\n\nIEEE 802.3\n\n\nCopper, 100 m\n\n\n\n\n\n\nFast Ethernet\n\n\n100 Mbps\n\n\n100BASE-TX\n\n\nIEEE 802.3u\n\n\nCopper, 100 m\n\n\n\n\n\n\nGigabit Ethernet\n\n\n1000 Mbps\n\n\n1000BASE-LX, 1000BASE-SX\n\n\nIEEE 802.3z\n\n\nFiber, 550 m (SX) 5 km (LX)\n\n\n\n\n\n\nGigabit Ethernet\n\n\n1000 Mbps\n\n\n1000BASE-T\n\n\nIEEE 802.3ab\n\n\n100 m\n\n\n\n\n\n\n\n\nThe term Ethernet is often used to mean \"all types of Ethernet\", but in some cases it is used to mean \"10BASE-T Ethernet\"\n\n\nA Brief History of Ethernet\n\n\n\n\nCarrier sense multiple access with collision detection (CSMA/CD) algorithm\n\n\n\n\nRepeaters\n\n\nRepeaters\n extended the length of LANs by cleaning up the electrical signal and repeating it (a Layer 1 function) but without interpreting the meaning of the electrical signal. [p56]\n\n\nBuilding 10BASE-T Networks with Hubs\n\n\nHubs\n are essentially repeaters with multiple physical ports. It simply regenerates the electrical signal that comes in one port and sends the same signal out every other port.\n\n\nEthernet UTP Cabling\n\n\nTransmitting Data Using Twisted Pairs\n\n\nUTP cabling consists of matched pairs of wires that are indeed twisted together, with current on the two wires in opposite directions.\n\n\nUTP Cabling Pinouts for \n10BASE-T and 100BASE-TX\n\n\n10BASE-T and 100BASE-TX Ethernet define that one pair should be used to send data in one direction, with the other pair used to send data in the other direction.\n\n\nThe wires in the UTP cable must be connected to the correct \npin positions\n in the RJ-45 connectors in order for communication to work correctly.\n\n\n[p62-64]\n\n\nThe following applies to 10BASE-T and 100BASE-TX only:\n\n\n\n\nEthernet \nstraight-through cable\n: both ends of the cable use the same EIA/TIA pinout standard on each end of the cable. A straight-through cable is used when the devices on the ends of the cable use opposite pins when they transmit data.\n\n\nEthernet \ncrossover cable\n:  two devices both use the same pins to transmit and the pinouts of the cable are set up to swap the wire pair\n\n\n\n\n\n\n\n\n\n\nDevices That Transmit on 1,2 and Receive on 3,6\n\n\nDevices That Transmit on 3,6 and Receive on 1,2\n\n\n\n\n\n\n\n\n\n\nPC NICs\n\n\nHubs\n\n\n\n\n\n\nRouters\n\n\nSwitches\n\n\n\n\n\n\nWireless Access Point (Ethernet interface)\n\n\n\u2014\n\n\n\n\n\n\nNetworked printers (printers that connect directly to the LAN)\n\n\n\u2014\n\n\n\n\n\n\n\n\n1000BASE-T Cabling\n\n\n1000BASE-T differs from 10BASE-T and 100BASE-TX as far as the cabling and pinouts:\n\n\n\n\nReequires four wire pairs\n\n\nTransmits and receives on each of the four wire pairs simultaneously\n\n\nHas no concept of straight-through and crossover cables\n\n\n\n\nImproving Performance by Using Switches Instead of Hubs\n\n\nCSMA/CD logic helps prevent collisions and also defines how to act when a collision does occur:\n\n\n\n\nA device with a frame to send listens until the Ethernet is not busy.\n\n\nWhen the Ethernet is not busy, the sender(s) begin(s) sending the frame.\n\n\nThe sender(s) listen(s) to make sure that no collision occurred.\n\n\nIf a collision occurs, the devices that had been sending a frame each send a jamming signal to ensure that all stations recognize the collision.\n\n\nAfter the jamming is complete, each sender randomizes a timer and waits that long before trying to resend the collided frame. When each random timer expires, the process starts over with Step 1.\n\n\n\n\nIncreasing Available Bandwidth Using Switches\n\n\nThe term \ncollision domain\n defines the set of devices whose frames could collide. For example, all devices connected to the hub are in the same collision domain. To avoid collisions, and to recover when they occur, devices in the same collision domain use CSMA/CD.\n\n\nSwitches\n significantly reduce, or even eliminate, the number of collisions on a LAN:\n\n\n\n\nSwitches interpret the bits in the received frame so that they can typically send the frame out the one required port, rather than all other ports\n\n\nIf a switch needs to forward multiple frames out the same port, the switch buffers the frames in memory, sending one at a time, thereby avoiding collisions\n\n\n\n\nThe switch\u2019s logic requires that the switch look at the Ethernet header, which is considered a Layer 2 feature. As a result, switches are considered to operate as a Layer 2 device, whereas hubs are Layer 1 devices.\n\n\nBuffering (temporarily holds the frame in memory) also helps prevent collisions.\n\n\nSwitch features provide significant performance improvements:\n\n\n\n\nIf only one device is cabled to each port of a switch, no collisions can occur.\n\n\nDevices connected to one switch port do not share their bandwidth with devices connected to another switch port. Each has its own separate bandwidth, meaning that a switch with 100-Mbps ports has 100 Mbps of bandwidth \nper port\n.\n\n\n\n\nShared Ethernet vs. Switched Ethernet\n\n\n\n\nShared Ethernet\n: bandwidth is shared among the devices on the LAN because they must take turns using the LAN because of the CSMA/CD algorithm. A hub with 24 100-Mbps Ethernet devices connected to it allows for a theoretical maximum of 100 Mbps of bandwidth\n\n\nSwitched Ethernet\n: bandwidth does not have to be shared, allowing for far greater performance. A switch with 24 100-Mbps Ethernet devices connected to it supports 100 Mbps for each port, or 2400 Mbps (2.4 Gbps) theoretical maximum bandwidth.\n\n\n\n\nDoubling Performance by Using Full-Duplex Ethernet\n\n\nIn an Ethernet network using hubs, CSMA/CD imposes \nhalf-duplex\n logic on each device, meaning that only one device can send at a time. LAN switches with only one device cabled to each port of the switch allow the use of \nfull-duplex\n operation; Ethernet card can send and receive concurrently.\n\n\nEthernet Data-Link Protocols\n\n\nEthernet Addressing\n\n\n\n\n\n\n\n\nLAN Addressing Term or Feature\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nMAC\n\n\nMedia Access Control. 802.3 (Ethernet) defines the MAC sublayer of IEEE Ethernet.\n\n\n\n\n\n\nEthernet address, NIC address, LAN address\n\n\nOther names often used instead of MAC address. These terms describe the 6-byte address of the LAN interface card.\n\n\n\n\n\n\nBurned-in address\n\n\nThe 6-byte address assigned by the vendor making the card.\n\n\n\n\n\n\nUnicast address\n\n\nA term for a MAC that represents a single LAN interface.\n\n\n\n\n\n\nBroadcast address\n\n\nAn address that means \u201call devices that reside on this LAN right now.\u201d (FFFF.FFFF.FFFF)\n\n\n\n\n\n\nMulticast address\n\n\nOn Ethernet, a multicast address implies some subset of all devices currently on the Ethernet LAN. (0100.5exx.xxxx, any value can be used in the last half)\n\n\n\n\n\n\n\n\nEthernet Framing\n\n\nFraming\n defines the meaning of the bits transmitted and received over a network.\n\n\n\n\n\n\nData\n field holds Layer 3 packets (L3 PDU)\n\n\nMaximum transmission unit\n (MTU) defines the maximum Layer 3 packet that can be sent over a medium. 1500 bytes is the largest IP MTU allowed over an Ethernet.\n\n\n\n\nIdentifying the Data Inside an Ethernet Frame\n\n\nType/Length\n filed:\n\n\n\n\nLength\n field: with a value less than hex 0600 (decimal 1536); another field is needed to identify the type of L3 PDU inside the frame.\n\n\nType\n field: value of hexadecimal 0800 (decimal 2048) implies an IP packet\n\n\n\n\nError Detection\n\n\nErrors (bit changes) occur due to electrical interference. Trailer containing a \nFrame Check Sequence\n (FCS) field used for error detection.\n\n\nChapter 4. Fundamentals of WANs\n\n\nThe WAN topics in this chapter describe mainly how enterprise networks use WANs to connect remote sites.\n\n\nOSI Layer 1 for Point-to-Point WANs\n\n\n\n\nLeased line\n or \nleased circuit\n: WAN cable, line or point-to-point connection that is paid for use\n\n\nTelephone company (telco), or public telephone and telegraph (PTT)\n\n\nService provider\n: a company that provides any form of WAN connectivity, including Internet services.\n\n\n\n\nRouters provide the capability to connect many different types of OSI Layer 1 and Layer 2 technologies. A router is connected to each end of a WAN connection.\n\n\n\n\n\n\nCentral Office (CO): a building where the telco locates the devices used to create its own network\n\n\nChannel service unit/data service (\nCSU/DSU\n)\n\n\ndemarc\n (\ndemarcation point\n): he point at which the telco\u2019s responsibility is on one side and the customer\u2019s responsibility is on the other\n\n\nCustomer premises equipment\n (CPE): devices that are at the customer site\n\n\n\n\nWAN Cabling Standards\n\n\n[p84]\n\n\nClock Rates, Synchronization, DCE, and DTE\n\n\n[p86]\n\n\n\n\nSynchronization: various devices need to synchronize their clocks so that they run at exactly the same speed to make a link work\n\n\nData communications equipment (DCE): device that provides clocking, typically the CSU/DSU\n\n\nData terminal equipment (DTE): device receiving clocking, typically the router\n\n\n\n\nLink Speeds\n\n\n\n\n\n\n\n\nName(s) of Line\n\n\nBit Rate\n\n\n\n\n\n\n\n\n\n\nDS0\n\n\n64 kbps\n\n\n\n\n\n\nDS1 (T1)\n\n\n1.544 Mbps (24 DS0s, plus 8 kbps overhead)\n\n\n\n\n\n\nDS3 (T3)\n\n\n44.736 Mbps (28 DS1s, plus management overhead)\n\n\n\n\n\n\nE1\n\n\n2.048 Mbps (32 DS0s)\n\n\n\n\n\n\nE3\n\n\n34.368 Mbps (16 E1s, plus management overhead)\n\n\n\n\n\n\nJ1 (Y1)\n\n\n2.048 Mbps (32 DS0s; Japanese standard)\n\n\n\n\n\n\n\n\nOSI Layer 2 for Point-to-Point WANs\n\n\nHDLC\n\n\n\n\nHigh-Level Data Link Control\n (HDLC) defines framing to:\n\n\n\n\nDelivers data across the link\n\n\nCheck for errors\n\n\nIdentify the packet type\n\n\n\n\nPoint-to-Point Protocol\n\n\nPoint-to-Point Protocol (PPP) behaves much like HDLC. The framing looks identical to the Cisco proprietary HDLC framing. PPP has become the most popular and feature-rich of WAN data link layer protocols. [p91]\n\n\nPoint-to-Point WAN Summary\n\n\nWAN Terminology [p91-92]\n\n\n\n\nSynchronous: The imposition of time ordering on a bit stream\n\n\nClock source: The device to which the other devices on the link adjust their speed when using synchronous links\n\n\nCSU/DSU: Used on digital links as an interface to the telephone company in the United States. Routers typically use a short cable from a serial interface to a CSU/DSU, which is attached to the line from the telco\n\n\nTelco\n\n\nFour-wire circuit: A line from the telco with four wires, composed of two twisted-pair wires. Each pair is used to send in one direction, so a four-wire circuit allows full-duplex communication.\n\n\nT1\n\n\nE1\n\n\n\n\nAll the following terms may be used to refer to a point-to-point leased line:\n\n\n\n\nleased line\n\n\nleased circuit\n\n\nlink\n\n\nserial link\n\n\nserial line\n\n\npoint-to-point link\n\n\ncircuit\n\n\n\n\nFrame Relay and Packet-Switching Services\n\n\nPacket-switching service\n: a company can connect a large number of routers using a single serial link from each router into the packet-switching service. Once connected, each router can send packets to all the other routers\u2014much like all the devices connected to an Ethernet hub or switch can send data directly to each other.\n\n\nTwo types of packet-switching service are very popular today:\n\n\n\n\nFrame Relay: much more common\n\n\nAsynchronous Transfer Mode (ATM)\n\n\n\n\nChapter 5. Fundamentals of IPv4 Addressing and Routing\n\n\n\n\nRouting: the process of forwarding packets (Layer 3 PDUs).\n\n\nLogical addressing: enables the routing process to identify a packet\u2019s source and destination.\n\n\nRouting protocol: aids routers by dynamically learning about the groups of addresses in the network, which in turn allows the routing (forwarding) process to work well.\n\n\nOther utilities: The network layer also relies on other utilities: Domain Name System (DNS), Dynamic Host Configuration Protocol (DHCP), Address Resolution Protocol (ARP), and ping.\n\n\n\n\nPath selection\n sometimes is used to mean:\n\n\n\n\nRouting protocol\n\n\nRouting (forwarding) of packets\n\n\n\n\nOverview of Network Layer Functions\n\n\nToday, the only Layer 3 protocol that is used widely is the TCP/IP network layer protocol, specifically, IP.  IP does not require any overhead agreements or messages before sending a packet, making IP a connectionless protocol, with no error recovery.\n\n\nRouting (Forwarding)\n\n\nRouting focuses on the end-to-end logic of forwarding data.\n\n\nThe routing table for any particular network layer protocol contains a list of network layer address groupings. Instead of a single entry in the routing table per individual destination network layer address, there is one routing table entry per group.\n\n\nNetwork Layer Interaction with the Data Link Layer\n\n\nThe routing process forwards the packet, and only the packet, end-to-end through the network, discarding data-link headers and trailers along the way.\n\n\nRouters build new data-link headers and trailers and because the new headers contain data-link addresses, the PCs and routers must decide what data-link addresses to use. The Address Resolution Protocol (ARP) is used to dynamically learn the data-link address of an IP host connected to a LAN.\n\n\nRouting as covered so far has two main concepts:\n\n\n\n\nThe process of routing forwards Layer 3 packets, also called Layer 3 protocol data units (L3 PDU), based on the destination Layer 3 address in the packet.\n\n\nThe routing process uses the data link layer to encapsulate the Layer 3 packets into Layer 2 frames for transmission across each successive data link.", 
            "title": "ICND1 Part I: Networking Fundamentals"
        }, 
        {
            "location": "/icnd1/part1/#chapter-1-introduction-to-computer-networking", 
            "text": "", 
            "title": "Chapter 1. Introduction to Computer Networking"
        }, 
        {
            "location": "/icnd1/part1/#chapter-2-the-tcpip-and-osi-networking-models", 
            "text": "TCP/IP Networking Model  A  networking model  ( networking architecture  or  networking blueprint ), refers to a comprehensive set of documents that define everything that should happen for a computer network to work.  The TCP/IP model both defines and references a large collection of protocols that allow computers to communicate. TCP/IP uses documents called  Requests for Comments  (RFC).  Data Encapsulation Terminology    Create and encapsulate the application data with any required application layer headers.  Encapsulate the data supplied by the application layer inside a transport layer header.  Encapsulate the data supplied by the transport layer inside an Internet layer (IP) header.  Encapsulate the data supplied by the Internet layer inside a data link layer header and trailer. This is the only layer that uses both a  header  and a  trailer .  Transmit the bits.   OSI Networking Model   Describing Protocols by Referencing the OSI Layers  Networking documents often describe TCP/IP protocols and standards by referencing OSI layers, both by layer number and layer name. For instance, a common description of a LAN switch is \u201clayer 2 switch,\u201d with \u201clayer 2\u201d referring to OSI layer 2.     Layer Name  Protocols and Specifications  Devices      Application, presentation, session (Layers 5\u20137)  Telnet, HTTP, FTP, SMTP, POP3, VoIP, SNMP  Firewall, intrusion detection systems, hosts    Transport (Layer 4)  TCP, UDP  Hosts, firewalls    Network (Layer 3)  IP  Router    Data link (Layer 2)  Ethernet (IEEE 802.3), HDLC, Frame Relay, PPP  LAN switch, wireless access point, cable modem, DSL modem    Physical (Layer 1)  RJ-45, EIA/TIA-232, V.35, Ethernet (IEEE 802.3)  LAN hub, LAN repeater, cables     OSI Layering Concepts and Benefits  [p41]   Less complex  Standard interfaces  Easier to learn  Easier to develop  Multivendor interoperability  Modular engineering   OSI Encapsulation Terminology   The TCP/IP model uses terms such as  segment ,  packet , and  frame  to refer to various layers and their respective encapsulated data. OSI uses a more generic term:  protocol data unit  (PDU).", 
            "title": "Chapter 2. The TCP/IP and OSI Networking Models"
        }, 
        {
            "location": "/icnd1/part1/#chapter-3-fundamentals-of-lans", 
            "text": "An Overview of Modern Ethernet LANs  Types of cabling:   Unshielded Twisted-Pair  (UTP)  Fiber-optic   Most IEEE standards define a different variation of Ethernet at the physical layer.\nFor the data link layer:   802.3 Media Access Control (MAC) sublayer  802.2 Logical Link Control (LLC) sublayer   [p52]     Common Name  Speed  Alternative Name  Name of IEEE Standard  Cable Type, Maximum Length      Ethernet  10 Mbps  10BASE-T  IEEE 802.3  Copper, 100 m    Fast Ethernet  100 Mbps  100BASE-TX  IEEE 802.3u  Copper, 100 m    Gigabit Ethernet  1000 Mbps  1000BASE-LX, 1000BASE-SX  IEEE 802.3z  Fiber, 550 m (SX) 5 km (LX)    Gigabit Ethernet  1000 Mbps  1000BASE-T  IEEE 802.3ab  100 m     The term Ethernet is often used to mean \"all types of Ethernet\", but in some cases it is used to mean \"10BASE-T Ethernet\"  A Brief History of Ethernet   Carrier sense multiple access with collision detection (CSMA/CD) algorithm   Repeaters  Repeaters  extended the length of LANs by cleaning up the electrical signal and repeating it (a Layer 1 function) but without interpreting the meaning of the electrical signal. [p56]  Building 10BASE-T Networks with Hubs  Hubs  are essentially repeaters with multiple physical ports. It simply regenerates the electrical signal that comes in one port and sends the same signal out every other port.  Ethernet UTP Cabling  Transmitting Data Using Twisted Pairs  UTP cabling consists of matched pairs of wires that are indeed twisted together, with current on the two wires in opposite directions.  UTP Cabling Pinouts for  10BASE-T and 100BASE-TX  10BASE-T and 100BASE-TX Ethernet define that one pair should be used to send data in one direction, with the other pair used to send data in the other direction.  The wires in the UTP cable must be connected to the correct  pin positions  in the RJ-45 connectors in order for communication to work correctly.  [p62-64]  The following applies to 10BASE-T and 100BASE-TX only:   Ethernet  straight-through cable : both ends of the cable use the same EIA/TIA pinout standard on each end of the cable. A straight-through cable is used when the devices on the ends of the cable use opposite pins when they transmit data.  Ethernet  crossover cable :  two devices both use the same pins to transmit and the pinouts of the cable are set up to swap the wire pair      Devices That Transmit on 1,2 and Receive on 3,6  Devices That Transmit on 3,6 and Receive on 1,2      PC NICs  Hubs    Routers  Switches    Wireless Access Point (Ethernet interface)  \u2014    Networked printers (printers that connect directly to the LAN)  \u2014     1000BASE-T Cabling  1000BASE-T differs from 10BASE-T and 100BASE-TX as far as the cabling and pinouts:   Reequires four wire pairs  Transmits and receives on each of the four wire pairs simultaneously  Has no concept of straight-through and crossover cables   Improving Performance by Using Switches Instead of Hubs  CSMA/CD logic helps prevent collisions and also defines how to act when a collision does occur:   A device with a frame to send listens until the Ethernet is not busy.  When the Ethernet is not busy, the sender(s) begin(s) sending the frame.  The sender(s) listen(s) to make sure that no collision occurred.  If a collision occurs, the devices that had been sending a frame each send a jamming signal to ensure that all stations recognize the collision.  After the jamming is complete, each sender randomizes a timer and waits that long before trying to resend the collided frame. When each random timer expires, the process starts over with Step 1.   Increasing Available Bandwidth Using Switches  The term  collision domain  defines the set of devices whose frames could collide. For example, all devices connected to the hub are in the same collision domain. To avoid collisions, and to recover when they occur, devices in the same collision domain use CSMA/CD.  Switches  significantly reduce, or even eliminate, the number of collisions on a LAN:   Switches interpret the bits in the received frame so that they can typically send the frame out the one required port, rather than all other ports  If a switch needs to forward multiple frames out the same port, the switch buffers the frames in memory, sending one at a time, thereby avoiding collisions   The switch\u2019s logic requires that the switch look at the Ethernet header, which is considered a Layer 2 feature. As a result, switches are considered to operate as a Layer 2 device, whereas hubs are Layer 1 devices.  Buffering (temporarily holds the frame in memory) also helps prevent collisions.  Switch features provide significant performance improvements:   If only one device is cabled to each port of a switch, no collisions can occur.  Devices connected to one switch port do not share their bandwidth with devices connected to another switch port. Each has its own separate bandwidth, meaning that a switch with 100-Mbps ports has 100 Mbps of bandwidth  per port .   Shared Ethernet vs. Switched Ethernet   Shared Ethernet : bandwidth is shared among the devices on the LAN because they must take turns using the LAN because of the CSMA/CD algorithm. A hub with 24 100-Mbps Ethernet devices connected to it allows for a theoretical maximum of 100 Mbps of bandwidth  Switched Ethernet : bandwidth does not have to be shared, allowing for far greater performance. A switch with 24 100-Mbps Ethernet devices connected to it supports 100 Mbps for each port, or 2400 Mbps (2.4 Gbps) theoretical maximum bandwidth.   Doubling Performance by Using Full-Duplex Ethernet  In an Ethernet network using hubs, CSMA/CD imposes  half-duplex  logic on each device, meaning that only one device can send at a time. LAN switches with only one device cabled to each port of the switch allow the use of  full-duplex  operation; Ethernet card can send and receive concurrently.  Ethernet Data-Link Protocols  Ethernet Addressing     LAN Addressing Term or Feature  Description      MAC  Media Access Control. 802.3 (Ethernet) defines the MAC sublayer of IEEE Ethernet.    Ethernet address, NIC address, LAN address  Other names often used instead of MAC address. These terms describe the 6-byte address of the LAN interface card.    Burned-in address  The 6-byte address assigned by the vendor making the card.    Unicast address  A term for a MAC that represents a single LAN interface.    Broadcast address  An address that means \u201call devices that reside on this LAN right now.\u201d (FFFF.FFFF.FFFF)    Multicast address  On Ethernet, a multicast address implies some subset of all devices currently on the Ethernet LAN. (0100.5exx.xxxx, any value can be used in the last half)     Ethernet Framing  Framing  defines the meaning of the bits transmitted and received over a network.    Data  field holds Layer 3 packets (L3 PDU)  Maximum transmission unit  (MTU) defines the maximum Layer 3 packet that can be sent over a medium. 1500 bytes is the largest IP MTU allowed over an Ethernet.   Identifying the Data Inside an Ethernet Frame  Type/Length  filed:   Length  field: with a value less than hex 0600 (decimal 1536); another field is needed to identify the type of L3 PDU inside the frame.  Type  field: value of hexadecimal 0800 (decimal 2048) implies an IP packet   Error Detection  Errors (bit changes) occur due to electrical interference. Trailer containing a  Frame Check Sequence  (FCS) field used for error detection.", 
            "title": "Chapter 3. Fundamentals of LANs"
        }, 
        {
            "location": "/icnd1/part1/#chapter-4-fundamentals-of-wans", 
            "text": "The WAN topics in this chapter describe mainly how enterprise networks use WANs to connect remote sites.  OSI Layer 1 for Point-to-Point WANs   Leased line  or  leased circuit : WAN cable, line or point-to-point connection that is paid for use  Telephone company (telco), or public telephone and telegraph (PTT)  Service provider : a company that provides any form of WAN connectivity, including Internet services.   Routers provide the capability to connect many different types of OSI Layer 1 and Layer 2 technologies. A router is connected to each end of a WAN connection.    Central Office (CO): a building where the telco locates the devices used to create its own network  Channel service unit/data service ( CSU/DSU )  demarc  ( demarcation point ): he point at which the telco\u2019s responsibility is on one side and the customer\u2019s responsibility is on the other  Customer premises equipment  (CPE): devices that are at the customer site   WAN Cabling Standards  [p84]  Clock Rates, Synchronization, DCE, and DTE  [p86]   Synchronization: various devices need to synchronize their clocks so that they run at exactly the same speed to make a link work  Data communications equipment (DCE): device that provides clocking, typically the CSU/DSU  Data terminal equipment (DTE): device receiving clocking, typically the router   Link Speeds     Name(s) of Line  Bit Rate      DS0  64 kbps    DS1 (T1)  1.544 Mbps (24 DS0s, plus 8 kbps overhead)    DS3 (T3)  44.736 Mbps (28 DS1s, plus management overhead)    E1  2.048 Mbps (32 DS0s)    E3  34.368 Mbps (16 E1s, plus management overhead)    J1 (Y1)  2.048 Mbps (32 DS0s; Japanese standard)     OSI Layer 2 for Point-to-Point WANs  HDLC   High-Level Data Link Control  (HDLC) defines framing to:   Delivers data across the link  Check for errors  Identify the packet type   Point-to-Point Protocol  Point-to-Point Protocol (PPP) behaves much like HDLC. The framing looks identical to the Cisco proprietary HDLC framing. PPP has become the most popular and feature-rich of WAN data link layer protocols. [p91]  Point-to-Point WAN Summary  WAN Terminology [p91-92]   Synchronous: The imposition of time ordering on a bit stream  Clock source: The device to which the other devices on the link adjust their speed when using synchronous links  CSU/DSU: Used on digital links as an interface to the telephone company in the United States. Routers typically use a short cable from a serial interface to a CSU/DSU, which is attached to the line from the telco  Telco  Four-wire circuit: A line from the telco with four wires, composed of two twisted-pair wires. Each pair is used to send in one direction, so a four-wire circuit allows full-duplex communication.  T1  E1   All the following terms may be used to refer to a point-to-point leased line:   leased line  leased circuit  link  serial link  serial line  point-to-point link  circuit   Frame Relay and Packet-Switching Services  Packet-switching service : a company can connect a large number of routers using a single serial link from each router into the packet-switching service. Once connected, each router can send packets to all the other routers\u2014much like all the devices connected to an Ethernet hub or switch can send data directly to each other.  Two types of packet-switching service are very popular today:   Frame Relay: much more common  Asynchronous Transfer Mode (ATM)", 
            "title": "Chapter 4. Fundamentals of WANs"
        }, 
        {
            "location": "/icnd1/part1/#chapter-5-fundamentals-of-ipv4-addressing-and-routing", 
            "text": "Routing: the process of forwarding packets (Layer 3 PDUs).  Logical addressing: enables the routing process to identify a packet\u2019s source and destination.  Routing protocol: aids routers by dynamically learning about the groups of addresses in the network, which in turn allows the routing (forwarding) process to work well.  Other utilities: The network layer also relies on other utilities: Domain Name System (DNS), Dynamic Host Configuration Protocol (DHCP), Address Resolution Protocol (ARP), and ping.   Path selection  sometimes is used to mean:   Routing protocol  Routing (forwarding) of packets   Overview of Network Layer Functions  Today, the only Layer 3 protocol that is used widely is the TCP/IP network layer protocol, specifically, IP.  IP does not require any overhead agreements or messages before sending a packet, making IP a connectionless protocol, with no error recovery.  Routing (Forwarding)  Routing focuses on the end-to-end logic of forwarding data.  The routing table for any particular network layer protocol contains a list of network layer address groupings. Instead of a single entry in the routing table per individual destination network layer address, there is one routing table entry per group.  Network Layer Interaction with the Data Link Layer  The routing process forwards the packet, and only the packet, end-to-end through the network, discarding data-link headers and trailers along the way.  Routers build new data-link headers and trailers and because the new headers contain data-link addresses, the PCs and routers must decide what data-link addresses to use. The Address Resolution Protocol (ARP) is used to dynamically learn the data-link address of an IP host connected to a LAN.  Routing as covered so far has two main concepts:   The process of routing forwards Layer 3 packets, also called Layer 3 protocol data units (L3 PDU), based on the destination Layer 3 address in the packet.  The routing process uses the data link layer to encapsulate the Layer 3 packets into Layer 2 frames for transmission across each successive data link.", 
            "title": "Chapter 5. Fundamentals of IPv4 Addressing and Routing"
        }, 
        {
            "location": "/icnd2/part1/", 
            "text": "Part I: LAN Switching\n\n\nChapter 1. Virtual LANs", 
            "title": "ICND2 Part I: LAN Switching"
        }, 
        {
            "location": "/icnd2/part1/#chapter-1-virtual-lans", 
            "text": "", 
            "title": "Chapter 1. Virtual LANs"
        }, 
        {
            "location": "/htae/", 
            "text": "Hacking: The Art of Exploitation, 2nd Edition\n\n\n0x200 Programming", 
            "title": "HTAE"
        }, 
        {
            "location": "/golang/", 
            "text": "Golang\n\n\nStructs\n\n\nVisibility\n\n\nThe naming of the struct type and its fields adheres to the visibility rule. It is possible that an exported struct type has a mix of fields: some exported, others not.\n\n\nFactory methods\n\n\nForce using factory methods on a private type [TWTG p233]:\n\n\nwrong\n \n:=\n \nnew\n(\nmatrix\n.\nmatrix\n)\n    \n// will NOT compile (matrix is private)\n\n\nright\n \n:=\n \nmatrix\n.\nNewMatrix\n(\n...\n)\n   \n// the ONLY way to instantiate a matrix\n\n\n\n\n\n\nStructs with tags\n\n\nOnly the package \nreflect\n can access tag content. \nreflect.TypeOf()\n on a variable gives the right type; if this is a struct type, it can be indexed by \nField\n, and then the \nTag\n property can be used. For example:\n\n\n\n\nstruct_tag.go\n\n\n\n\nAnonymous fields and embedded structs\n\n\nConflicting names [TWTG p239]\n\n\n\n\nAn outer name hides an inner name. This provides a way to override a field or method.\n\n\nIf the same name appears twice at the same level, it is an error if the name is used by the program.\n\n\n\n\nMethods\n\n\n\n\nReceiver type\n\n\nMethod set: collection of all the methods on a given type \nT\n (or \n*T\n)\n\n\nNo method overloading\n\n\nA method and the type on which it acts must be defined in the same package\n\n\nPointer or value as receiver: if for a type \nT\n a method \nMeth()\n exists on \n*T\n and \nt\n is a variable of type \nT\n, then \nt.Meth()\n is automatically translated to \n(\nt).Meth()\n [TWTG p246]\n\n\n\n\nMethods on embedded types and inheritance\n\n\n\n\nOverriding: \nmethod4.go\n [TWTG p250]\n\n\nEmbedding multiple anonymous types: \nmult_inheritance.go\n [TWTG p253-254]\n\n\n\n\nEmbed functionality in a type\n\n\n\n\nAggregation (or composition): include a named field of the type of the wanted functionality, \nembed_func1.go\n\n\nEmbedding: \nembed_func2.go\n\n\n\n\nFormat specifiers\n\n\nString()\n-method on a type [TWTG p259]:\n\n\n\n\n%T\n: complete type specification\n\n\n%#v\n complete output of the instance with its fields\n\n\n\n\nInterfaces\n\n\nInterfaces in Go provide a way to specify the behavior of an object: if something can do this, then it can be used here.\n\n\n\n\nA type doesn\u2019t have to state explicitly that it implements an interface: interfaces are satisfied implicitly. Multiple types can implement the same interface.\n\n\nA type that implements an interface can also have other functions.\n\n\nA type can implement many interfaces.\n\n\nAn interface type can contain a reference to an instance of any of the types that implement the interface (an interface has what is called a dynamic type)\n\n\n\n\nThe interface variable both contains the value of the receiver instance and a pointer to the appropriate method in a method table.\n\n\n\n\ninterfaces_poly.go\n\n\n\n\nInterface embedding interfaces\n\n\nAn interface can contain the name of one or more other interface(s), which is equivalent to explicitly enumerating the methods of the embedded interface in the containing interface. [TWTG p270]\n\n\nDetect and convert the type of an interface variable: type assertions\n\n\nWe can test if \nvarI\n (interface variable) contains at a certain moment a variable of type \nT\n with the type assertion test [TWTG p271]:\n\n\nif\n \nv\n,\n \nok\n \n:=\n \nvarI\n.(\nT\n);\n \nok\n \n{\n\n    \n// checked type assertion\n\n\n}\n\n\n\n\n\n\n\n\ntype_interfaces.go\n\n\n\n\nThe type switch\n\n\n\n\nType switch\n\n\n\n\ntype_switch.go\n\n\n\n\n\nTesting if a value implements an interface\n\n\nv\n is a value and we want to test whether it implements the \nStringer\n interface:\n\n\nif\n \nsv\n,\n \nok\n \n:=\n \nv\n.(\nStringer\n);\n \nok\n \n{\n\n    \nfmt\n.\nPrintf\n(\n\u201c\nv\n \nimplements\n \nString\n():\n \n%\ns\n\\\nn\n\u201d\n,\n \nsv\n.\nString\n());\n \n// note: sv, not v\n\n\n}\n\n\n\n\n\n\nWriting functions so that they accept an interface variable as a parameter makes them more general. Use interfaces to make code more generally applicable.\n\n\nVariables of interface type\n\n\nA variable of interface type stores a pair: the concrete value assigned to the variable, and that value's type descriptor.\n\n\n\n\nThe representation of an interface\n\n\n\n\nUsing method sets with interfaces\n\n\n\n\nPointer methods can be called with pointers.\n\n\nValue methods can be called with values.\n\n\nValue-receiver methods can be called with pointer values because they can be dereferenced first.\n\n\nPointer-receiver methods \ncannot\n be called with values, however, because the value stored inside an interface has no address.\n\n\n\n\nExamples:\n\n\n\n\nmethodset2.go\n\n\nsort.go\n\n\nsortmain.go\n\n\n\n\nEmpty Interface\n\n\nA variable of empty interface type \ninterface{}\n can through assignment receive a variable of any type.\n\n\nInterface Slice\n\n\n\n\nInterface slice\n\n\n\n\nInterface to interface\n\n\nAn interface value can also be assigned to another interface value, as long as the underlying value implements the necessary methods.\n\n\ntwtg_11.9.5.go\n\n\n\n\n\nReflection\n\n\nReflection is the ability of a program to examine its own structure, particularly through the types; it\u2019s a form of \nmetaprogramming\n. \nreflect\n can be used to investigate types and variables at runtime, e.g. its size, its methods, and it can also call these methods \"dynamically\".\n\n\n\n\nreflect.TypeOf\n\n\nreflect.ValueOf\n\n\n\n\ntwtg_11.10.1.go\n\n\n\n\n\n\n\nv.Kind()\n: returns a constant indicating the type\n\n\nv.Interface()\n: recovers the (interface) value\n\n\n\n\nExample:\n\n\n\n\nreflect1.go\n\n\n\n\nSetting a value through reflection\n\n\n\n\nSettability\n: a \nValue\n can be changed only if it is addressable and was not obtained by the use of unexported struct fields, \nreflect2.go\n\n\n\n\nReflection on structs\n\n\n\n\nreflect_struct.go\n\n\n\n\nPrintf\n and reflection\n\n\nPrintf\n uses the reflection package to unpack it and discover the argument list, \nprint.go\n\n\nInterfaces and dynamic typing\n\n\n\n\nIn Go there are no classes: data (structures, or more general types) and methods are treated \northogonally\n, they are much more \nloosely coupled\n.\n\n\nThere is no requirement for explicitly declaring that a type satisfies an interface. This allows interfaces to be defined and used without having to modify existing code.\n\n\nTypes implementing an interface can be passed to any function which takes that interface as an argument. This resembles much more the \nduck typing\n in dynamic languages.\n\n\nExtraction of an interface reduces thereby the number of types and methods needed [TWTG p301]: \nmulti_interfaces_poly.go\n\n\nIf a type must implement a new interface, the type itself doesn\u2019t have to be changed, you must only make the new method(s) on the type. [TWTG p303]\n\n\n\n\n\n\nEmpty interface and function overloading [TWTG p304]\n\n\nInheritance of interfaces:\n\n\nA type includes (embeds) another type (which implements one or more interfaces) as a pointer, then the type can use all of the interfaces-methods. [TWTG p304]\n\n\nA type can also inherit from multiple interfaces providing something like \nmultiple inheritance\n. [TWTG p305]\n\n\n\n\n\n\n\n\nSummary of object-orientedness of Go\n\n\n[TWTG p306]\n\n\n\n\nEncapsulation (data hiding): visibility rule\n\n\nPackage scope\n: lowercase\n\n\nExported\n: uppercase\n\n\n\n\n\n\nInheritance: embedding one or multiple types\n\n\nPolymorphism: a variable of a type can be assigned to a variable of any interface it implements. Types and interfaces are loosely coupled; multiple inheritance is possible through implementing multiple interfaces\n\n\n\n\nHigher order functions\n\n\n[TWTG p306-309]\n\n\n\n\nReferences\n\n\n\n\n[TWTG] \nThe Way To Go: A Thorough Introduction To The Go Programming Language\n\n\n[EG] \nEffective Go\n\n\n[TGB] \nThe Go Blog", 
            "title": "Go"
        }, 
        {
            "location": "/bash/", 
            "text": "Bash\n\n\nIntroduction\n\n\nWhat is Bash?\n\n\nBash is the shell, or command language interpreter, for the GNU operating system. The name is an acronym for the \"\nB\nourne-\nA\ngain \nSH\nell\", a pun on \nStephen Bourne\n, the author of the direct ancestor of the current Unix shell \nsh\n.\n\n\nWhat is a shell?\n\n\nA shell is simply a macro processor that executes commands. The term \"macro processor\" means functionality where text and symbols are expanded to create larger expressions.\n\n\nA Unix shell is both a command interpreter and a programming language:\n\n\n\n\nAs a command interpreter, the shell provides the user interface to the rich set of GNU utilities.\n\n\nThe programming language features allow these utilities to be combined. Files containing commands can be created, and become commands themselves. These new commands have the same status as system commands in directories such as \n/bin\n, allowing users or groups to establish custom environments to automate their common tasks.\n\n\n\n\nShells may be used interactively or non-interactively:\n\n\n\n\nIn interactive mode, they accept input typed from the keyboard.\n\n\nWhen executing non-interactively, shells execute commands read from a file.\n\n\n\n\nA shell allows execution of GNU commands, both synchronously and asynchronously:\n\n\n\n\nThe shell waits for synchronous commands to complete before accepting more input;\n\n\nAsynchronous commands continue to execute in parallel with the shell while it reads and executes additional commands.\n\n\nThe redirection constructs permit fine-grained control of the input and output of those commands. Moreover, the shell allows control over the contents of commands\u2019 environments.\n\n\n\n\nShells also provide a small set of built-in commands (builtins) implementing functionality impossible or inconvenient to obtain via separate utilities. For example:\n\n\n\n\ncd\n, \nbreak\n, \ncontinue\n, and \nexec\n cannot be implemented outside of the shell because they directly manipulate the shell itself.\n\n\nThe \nhistory\n, \ngetopts\n, \nkill\n, or \npwd\n builtins, among others, could be implemented in separate utilities, but they are more convenient to use as builtin commands.\n\n\n\n\nWhile executing commands is essential, most of the power (and complexity) of shells is due to their embedded programming languages. Like any high-level language, the shell provides variables, flow control constructs, quoting, and functions.\n\n\nShells offer features geared specifically for interactive use rather than to augment the programming language. These interactive features include job control, command line editing, command history and aliases.\n\n\nDefinitions\n\n\n\n\n\n\nPOSIX\n: A family of open system standards based on Unix. Bash is primarily concerned with the Shell and Utilities portion of the POSIX 1003.1 standard.\n\n\n\n\n\n\nblank\n: A space or tab character.\n\n\n\n\n\n\nbuiltin\n: A command that is implemented internally by the shell itself, rather than by an executable program somewhere in the file system.\n\n\n\n\n\n\ncontrol operator\n: A token that performs a control function. It is a newline or one of the following: \u2018||\u2019, \u2018\n\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018;;\u2019, \u2018|\u2019, \u2018|\n\u2019, \u2018(\u2019, or \u2018)\u2019.\n\n\n\n\n\n\nexit status\n: The value returned by a command to its caller. The value is restricted to eight bits, so the maximum value is 255.\n\n\n\n\n\n\nfield\n: A unit of text that is the result of one of the shell expansions. After expansion, when executing a command, the resulting fields are used as the command name and arguments.\n\n\n\n\n\n\nfilename\n: A string of characters used to identify a file.\n\n\n\n\n\n\njob\n: A set of processes comprising a pipeline, and any processes descended from it, that are all in the same process group.\n\n\n\n\n\n\njob control\n: A mechanism by which users can selectively stop (suspend) and restart (resume) execution of processes.\n\n\n\n\n\n\nmetacharacter\n: A character that, when unquoted, separates words. A metacharacter is a \nblank\n or one of the following characters: \u2018|\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018(\u2019, \u2018)\u2019, \u2018\n\u2019, or \u2018\n\u2019.\n\n\n\n\n\n\nname\n: A \nword\n consisting solely of letters, numbers, and underscores, and beginning with a letter or underscore. Names are used as shell variable and function names. Also referred to as an \nidentifier\n.\n\n\n\n\n\n\noperator\n: A \ncontrol operator\n or a \nredirection operator\n. See \nRedirections\n, for a list of redirection operators. Operators contain at least one unquoted \nmetacharacter\n.\n\n\n\n\n\n\nprocess group\n: A collection of related processes each having the same \nprocess group ID\n.\n\n\n\n\n\n\nprocess group ID\n: A unique identifier that represents a \nprocess group\n during its lifetime.\n\n\n\n\n\n\nreserved word\n: A word that has a special meaning to the shell. Most reserved words introduce shell flow control constructs, such as \nfor\n and \nwhile\n.\n\n\n\n\n\n\nreturn status\n: A synonym for \nexit status\n.\n\n\n\n\n\n\nsignal\n: A mechanism by which a process may be notified by the kernel of an event occurring in the system.\n\n\n\n\n\n\nspecial builtin\n: A shell builtin command that has been classified as special by the POSIX standard.\n\n\n\n\n\n\ntoken\n: A sequence of characters considered a single unit by the shell. It is either a \nword\n or an \noperator\n.\n\n\n\n\n\n\nword\n: A sequence of characters treated as a unit by the shell. Words may not include unquoted \nmetacharacters\n.\n\n\n\n\n\n\nRelationships of some definitions *\n\n\n\n\ntoken\n\n\nword\n\n\nname\n\n\nreserved word\n\n\n\n\n\n\noperator\n\n\ncontrol operator\n\n\nredirection operator\n\n\n\n\n\n\n\n\n\n\nmetacharacter\n\n\nblank\n\n\n\u2018|\u2019, \u2018\n\u2019, \u2018;\u2019, \u2018(\u2019, \u2018)\u2019, \u2018\n\u2019, or \u2018\n\u2019\n\n\n\n\n\n\nbuiltin\n\n\nspecial bulitin\n\n\n\n\n\n\n\n\nBasic Shell Features\n\n\nAll of the Bourne shell builtin commands are available in Bash, The rules for evaluation and quoting are taken from the POSIX specification for the \"standard\" Unix shell.\n\n\nThis chapter briefly summarizes the shell\u2019s \"building blocks\": commands, control structures, shell functions, shell parameters, shell expansions, redirections, which are a way to direct input and output from and to named files, and how the shell executes commands.\n\n\nShell Syntax\n\n\n\n\nIf the input indicates the beginning of a comment, the shell ignores the comment symbol (\u2018#\u2019), and the rest of that line.\n\n\nOtherwise, \nthe shell reads its input and divides the input into words and operators\n, employing the quoting rules to select which meanings to assign various words and characters.\n\n\n\n\n[\ns3.1\n]\n\n\nShell Operation\n\n\nBasically, the shell does the following:\n\n\n\n\nReads its input in one of the following way:\n\n\nfrom a file (see \nShell Scripts\n),\n\n\nfrom a string supplied as an argument to the \n-c\n invocation option (see \nInvoking Bash\n),\n\n\nfrom the user\u2019s terminal.\n\n\n\n\n\n\nBreaks the input into words and operators, obeying the quoting rules described in \nQuoting\n. These tokens are separated by \nmetacharacters\n. Alias expansion is performed by this step (see \nAliases\n).\n\n\nParses the tokens into simple and compound commands (see \nShell Commands\n).\n\n\nPerforms the various shell expansions (see \nShell Expansions\n), breaking the expanded tokens into lists of filenames (see \nFilename Expansion\n) and commands and arguments.\n\n\nPerforms any necessary redirections (see \nRedirections\n) and removes the redirection operators and their operands from the argument list.\n\n\nExecutes the command (see \nExecuting Commands\n).\n\n\nOptionally waits for the command to complete and collects its exit status (see \nExit Status\n).\n\n\n\n\nQuoting\n\n\nQuoting is used to remove the special meaning of certain characters or words to the shell. It is used to:\n\n\n\n\nDisable special treatment for special characters,\n\n\nPrevent reserved words from being recognized as such,\n\n\nPrevent parameter expansion.\n\n\n\n\nThere are three quoting mechanisms: the \nescape character\n, single quotes, and double quotes.\n\n\nEscape Character\n\n\nA non-quoted backslash \u2018\\\u2019 is the Bash escape character. It preserves the literal value of the next character that follows, with the exception of newline. If a \\newline pair appears, and the backslash itself is not quoted, the \\newline is treated as a line continuation.\n\n\nSingle Quotes\n\n\nEnclosing characters in single quotes (\u2018'\u2019) preserves the literal value of each character within the quotes. A single quote may not occur between single quotes, even when preceded by a backslash.\n\n\nDouble Quotes\n\n\nEnclosing characters in double quotes (\u2018\"\u2019) preserves the literal value of all characters within the quotes, with the exception of \u2018$\u2019, \u2018`\u2019, \u2018\\\u2019, and, when history expansion is enabled, \u2018!\u2019.\n\n\n\n\n\u2018$\u2019 and \u2018`\u2019 retain their special meaning within double quotes (see \nShell Expansions\n).\n\n\nThe backslash retains its special meaning only when followed by one of the following characters: \u2018$\u2019, \u2018`\u2019, \u2018\"\u2019, \u2018\\\u2019, or newline. Within double quotes, backslashes that are followed by one of these characters are removed. Backslashes preceding characters without a special meaning are left unmodified.\n\n\nA double quote may be quoted within double quotes by preceding it with a backslash.\n\n\nHistory expansion (if enabled) will be performed unless an \u2018!\u2019 appearing in double quotes is escaped using a backslash.\n\n\nThe backslash preceding the \u2018!\u2019 is not removed.\n\n\n\n\nExamples on history expansion and \u2018!\u2019 (history expansion enabled):\n\n\n$ foo\n\n\n-bash: foo: command not found\n\n\n$ echo \n!!\n\n\necho \nfoo\n\n\nfoo\n\n\n$ echo \n\\!!\n\n\n\\!!\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\nThe GNU Bash Reference Manual\n\n\nBash Hackers Wiki", 
            "title": "Bash"
        }, 
        {
            "location": "/c/", 
            "text": "C\n\n\n\n\nIf you think like a computer, writing C actually makes sense.\n\n Linus Torvalds \n\n\n\n\nFirst-class ADT\n\n\nBad:\n\n\n/* Include guards and include files omitted. */\n\n\n\n#define MAX_NO_OF_ORDERS 42\n\n\n\n/* Internal representation of a customer. */\n\n\n\ntypedef\n \nstruct\n\n\n\n{\n\n    \nconst\n \nchar\n*\n \nname\n;\n\n    \nAddress\n \naddress\n;\n\n    \nsize_t\n \nnoOfOrders\n;\n\n    \nOrder\n \norders\n[\nMAX_NO_OF_ORDERS\n];\n\n\n}\n \nCustomer\n;\n\n\n\nvoid\n \ninitCustomer\n(\nCustomer\n*\n \ntheCustomer\n,\n\n                  \nconst\n \nchar\n*\n \nname\n,\n\n                  \nconst\n \nAddress\n*\n \naddress\n);\n\n\n\nvoid\n \nplaceOrder\n(\nCustomer\n \n*\ncustomer\n,\n \nconst\n \nOrder\n*\n \norder\n);\n\n\n\n/* A lot of other related functions... */\n\n\n\n\n\n\nGood:\n\n\n\n\n1_FirstClassADT\n\n\n\n\nInformation hiding\n\n\nThe First-class ADT pattern will eliminate dependency problems. Thuis pattern provides a method that separates interface from implementation.\n\n\nIncomplete Types\n\n\nThe C standard (C99) allows us to declare objects of incomplete types in a context where their sizes aren\u2019t needed.\n\n\nIn the following code:\n\n\n/* Pointer to an incomplete type */\n\n\ntypedef\n \nstruct\n \nCustomer\n*\n \nCustomerPtr\n;\n\n\n\n\n\n\nInstances of this pointer will serve as a handle for the clients of a first-class ADT. This mechanism enforces the constraint on clients to use the provided interface functions (\nCustomer.h\n) because there is no way a client can access a field in the \nCustomer\n structure (the C language \ndoes not allow an incomplete type to be de-referenced\n). The type is considered complete as soon as the compiler detects a subsequent specifier (\nCustomer.c\n), with the same tag, and a declaration list containing the members.\n\n\nCopy Semantics\n\n\nClients only use a handle, which is declared as a pointer, to the ADT. Copies of a handle are simply pointer assignment.\n\n\nDependencies managed\n\n\nInternals of the data structure are encapsulated in the implementation and clients cannot access them.\n\n\nConsequences\n\n\nPros:\n\n\n\n\nImproved encapsulation\n\n\nLoose coupling\n\n\nControlled construction and destruction\n\n\n\n\nCons:\n\n\n\n\nExtra level of indirection\n\n\nIncreased dynamic memory usage\n\n\n\n\n\n\nReferences\n\n\n\n\n[PIC]: \nPatterns in C", 
            "title": "C"
        }, 
        {
            "location": "/asm/", 
            "text": "x86 Assembly\n\n\n\n\nIf you don't assemble the (assembly) code, it's complete gibberish to the computer.\n\nWikibooks\n\n\n\n\nIntroduction\n\n\nIntroduction\n\n\nWhy Learn Assembly?\n\n\n\n\nWith assembly, the programmer can precisely track the flow of data and execution in a program in a mostly human-readable form.\n\n\nDebuggers will frequently only show program code in assembly language.\n\n\n\n\n\n\nAssembly language is also the preferred tool for implementing some low-level tasks, such as bootloaders and low-level kernel components. Code written in assembly has less overhead than code written in high-level languages\n\n\nAs hardware manufacturers such as Intel and AMD add new features and new instructions to their processors, often times the only way to access those features is to use assembly routines, at least until the major compiler vendors add support for those features.\n\n\n\n\n\n\n\n\nBasic FAQ\n\n\nBasic FAQ\n\n\nHow Computer Reads Assembly\n\n\nThe computer cannot read the assembly language that you write. Your assembler will convert the assembly language into a form of binary information called \"machine code\" that your computer uses to perform its operations.\n\n\nPlatform differences\n\n\nThe basic x86 machine code is dependent only on the processor. The x86 versions of Windows and Linux are obviously built on the x86 machine code. There are a few differences between Linux and Windows programming in x86 Assembly:\n\n\n\n\nOn a Linux computer, the most popular assemblers are the GAS assembler, which uses the AT\nT syntax for writing code, and the Netwide Assembler, also known as NASM, which uses a syntax similar to MASM.\n\n\nOn a Windows computer, the most popular assembler is MASM, which uses the Intel syntax.\n\n\nThe available software interrupts, and their functions, are different on Windows and Linux.\n\n\nThe available code libraries are different on Windows and Linux.\n\n\n\n\nx86 Family\n\n\nx86 Family\n\n\nThe term \"x86\" can refer both to an instruction set architecture and to microprocessors which implement it. The name x86 is derived from the fact that many of Intel's early processors had names ending in \"86\".\n\n\nThe x86 instruction set architecture originated at Intel and has evolved over time by the addition of new instructions as well as the expansion to 64-bits. As of 2009, x86 primarily refers to \nIA-32\n (Intel Architecture, 32-bit) and/or \nx86-64\n, the extension to 64-bit computing.\n\n\nVersions of the x86 instruction set architecture have been implemented by Intel, AMD and several other vendors, with each vendor having its own family of x86 processors.\n\n\nx86 Architecture\n\n\nx86 Architecture\n\n\nThe x86 Architecture\n\n\nThe x86 architecture has:\n\n\n\n\n8 General-Purpose Registers (GPR)\n\n\n6 Segment Registers\n\n\n1 Flags Register\n\n\n1 Instruction Pointer\n\n\n\n\n64-bit x86 has additional registers.\n\n\nGeneral-Purpose Registers (GPR) (32-bit naming conventions)\n\n\nThe 8 GPRs are:\n\n\n\n\nAccumulator register (AX). Used in arithmetic operations.\n\n\nCounter register (CX). Used in shift/rotate instructions and loops.\n\n\nData register (DX). Used in arithmetic operations and I/O operations.\n\n\nBase register (BX). Used as a pointer to data (located in segment register DS, when in segmented mode).\n\n\nStack Pointer register (SP). Pointer to the top of the stack.\n\n\nStack Base Pointer register (BP). Used to point to the base of the stack.\n\n\nSource Index register (SI). Used as a pointer to a source in stream operations.\n\n\nDestination Index register (DI). Used as a pointer to a destination in stream operations.\n\n\n\n\nThe order in which they are listed here is for a reason: it is the same order that is used in a push-to-stack operation, which will be covered later.\n\n\nAll registers can be accessed in 16-bit, 32-bit and 64-bit modes:\n\n\n\n\n16-bit: the register is identified by its two-letter abbreviation from the list above. For example, 'AX'.\n\n\n32-bit: the two-letter abbreviation is prefixed with an 'E' (extended). For example, 'EAX'.\n\n\n64-bit: the two-letter abbreviation is prefixed with an 'R'. For example, 'RAX'.\n\n\n\n\nIt is also possible to address the first four registers (AX, CX, DX and BX) in their size of 16-bit as two 8-bit halves:\n\n\n\n\nThe least significant byte (LSB), or low half, is identified by replacing the 'X' with an 'L'.\n\n The most significant byte (MSB), or high half, uses an 'H' instead.\n\n\n\n\nFor example, CL is the LSB of the counter register, whereas CH is its MSB.\n\n\nThe following table summarizes five ways to access the accumulator, counter, data and base registers: 64-bit, 32-bit, 16-bit, 8-bit LSB, and 8-bit MSB:\n\n\n\n\nSegment Registers\n\n\nThe 6 Segment Registers are:\n\n\n\n\nStack Segment (SS). Pointer to the stack.\n\n\nCode Segment (CS). Pointer to the code.\n\n\nData Segment (DS). Pointer to the data.\n\n\nExtra Segment (ES). Pointer to extra data ('E' stands for 'Extra').\n\n\nF Segment (FS). Pointer to more extra data ('F' comes after 'E').\n\n\nG Segment (GS). Pointer to still more extra data ('G' comes after 'F').\n\n\n\n\nMost applications on most modern operating systems (FreeBSD, Linux or Microsoft Windows) use a memory model that points nearly all segment registers to the same place and uses paging instead, effectively disabling their use. Typically the use of FS or GS is an exception to this rule, instead being used to point at thread-specific data.\n\n\nEFLAGS Register\n\n\nThe EFLAGS is a 32-bit register used as a collection of bits representing Boolean values to store the results of operations and the state of the processor.\n\n\n\n\nThe bits named 0 and 1 are reserved bits and shouldn't be modified.\n\n\nThe different use of these flags are:\n\n\n\n\n0 CF : Carry Flag. Set if the last arithmetic operation carried (addition) or borrowed (subtraction) a bit beyond the size of the register. This is then checked when the operation is followed with an add-with-carry or subtract-with-borrow to deal with values too large for just one register to contain.\n\n\n2 PF : Parity Flag. Set if the number of set bits in the least significant byte is a multiple of 2.\n\n\n4 AF : Adjust Flag. Carry of Binary Code Decimal (BCD) numbers arithmetic operations.\n\n\n6 ZF : Zero Flag. Set if the result of an operation is Zero (0).\n\n\n7 SF : Sign Flag. Set if the result of an operation is negative.\n\n\n8 TF : Trap Flag. Set if step by step debugging.\n\n\n9 IF : Interruption Flag. Set if interrupts are enabled.\n\n\n10 DF : Direction Flag. Stream direction. If set, string operations will decrement their pointer rather than incrementing it, reading memory backwards.\n\n\n11 OF : Overflow Flag. Set if signed arithmetic operations result in a value too large for the register to contain.\n\n\n12-13 IOPL : I/O Privilege Level field (2 bits). I/O Privilege Level of the current process.\n\n\n14 NT : Nested Task flag. Controls chaining of interrupts. Set if the current process is linked to the next process.\n\n\n16 RF : Resume Flag. Response to debug exceptions.\n\n\n17 VM : Virtual-8086 Mode. Set if in 8086 compatibility mode.\n\n\n18 AC : Alignment Check. Set if alignment checking of memory references is done.\n\n\n19 VIF : Virtual Interrupt Flag. Virtual image of IF.\n\n\n20 VIP : Virtual Interrupt Pending flag. Set if an interrupt is pending.\n\n\n21 ID : Identification Flag. Support for CPUID instruction if can be set.\n\n\n\n\nInstruction Pointer\n\n\nThe EIP register contains the address of the next instruction to be executed if no branching is done.\n\n\nEIP can only be read through the stack after a \ncall\n instruction.\n\n\nMemory\n\n\nThe x86 architecture is \nlittle-endian\n, meaning that multi-byte values are written least significant byte first. (This refers only to the ordering of the bytes, not to the bits.)\n\n\n\n\nThe 32 bit value B3B2B1B0\n16\n on an x86 would be represented in memory as:\n\n\n+----+----+----+----+\n| B0 | B1 | B2 | B3 |\n+----+----+----+----+\n\n\n\n\n\nThe 32 bits double word 0x1BA583D4 (the 0x denotes hexadecimal) would be written in memory as:\n\n\n+----+----+----+----+\n| D4 | 83 | A5 | 1B |\n+----+----+----+----+\n\n\n\n\n\nThis will be seen as \n0xD4 0x83 0xA5 0x1B\n when doing a memory dump.\n\n\nTwo's Complement Representation\n\n\nTwo's complement is the standard way of representing negative integers in binary. The sign is changed by inverting all of the bits and adding one.\n\n\nFor example,\n\n\n+----------+------+\n| Start:   | 0001 |\n+----------+------+\n| Invert:  | 1110 |\n+----------+------+\n| Add One: | 1111 |\n+----------+------+\n\n\n\n\n\n\n\n0001 represents decimal 1\n\n\n1111 represents decimal -1\n\n\n\n\nAddressing modes\n\n\nThe addressing mode indicates how the operand is presented.\n\n\nRegister Addressing\n\n\nOperand address R is in the address field.\n\n\nmov\n \nax\n,\n \nbx\n  \n; moves contents of register bx into ax\n\n\n\n\n\n\nImmediate\n\n\nAactual value is in the field.\n\n\nmov\n \nax\n,\n \n1\n   \n; moves value of 1 into register ax\n\n\n\n\n\n\nOr:\n\n\nmov\n \nax\n,\n \n010Ch\n \n; moves value of 0x010C into register ax\n\n\n\n\n\n\nDirect memory addressing\n\n\nOperand address is in the address field.\n\n\n.data\n\n\nmy_var\n \ndw\n \n0abcdh\n \n; my_var = 0xabcd\n\n\n.code\n\n\nmov\n \nax\n,\n \n[\nmy_var\n]\n \n; copy my_var content in ax (ax=0xabcd)\n\n\n\n\n\n\nDirect offset addressing\n\n\nUses arithmetics to modify address.\n\n\nbyte_tbl\n \ndb\n \n12\n,\n15\n,\n16\n,\n22\n,\n.....\n \n; Table of bytes\n\n\nmov\n \nal\n,[\nbyte\n_tbl\n+\n2\n]\n\n\nmov\n \nal\n,\nbyte\n_tbl\n[\n2\n]\n \n; same as the former\n\n\n\n\n\n\nRegister Indirect\n\n\nField points to a register that contains the operand address.\n\n\nmov\n \nax\n,[\ndi\n]\n\n\n\n\n\n\nThe registers used for indirect addressing are BX, BP, SI, DI\n\n\nBase-index\n\n\nmov\n \nax\n,[\nbx\n \n+\n \ndi\n]\n\n\n\n\n\n\nFor example, if we are talking about an array, BX contains the address of the beginning of the array, and DI contains the index into the array.\n\n\nBase-index with displacement\n\n\nmov\n \nax\n,[\nbx\n \n+\n \ndi\n \n+\n \n10\n]\n\n\n\n\n\n\nGeneral-Purpose Registers (GPR) (64-bit naming conventions)\n\n\n16 32 and 64 Bits\n\n\n64-bit x86 adds 8 more general-purpose registers, named R8, R9, R10 and so on up to R15. It also introduces a new naming convention that must be used for these new registers and can also be used for the old ones (except that AH, CH, DH and BH have no equivalents). In the new convention:\n\n\n\n\nR0 is RAX.\n\n\nR1 is RCX.\n\n\nR2 is RDX.\n\n\nR3 is RBX.\n\n\nR4 is RSP.\n\n\nR5 is RBP.\n\n\nR6 is RSI.\n\n\nR7 is RDI.\n\n\nR8, R9, R10, R11, R12, R13, R14, R15 are the new registers and have no other names.\n\n\nR0D~R15D are the lowermost 32 bits of each register. For example, R0D is EAX.\n\n\nR0W~R15W are the lowermost 16 bits of each register. For example, R0W is AX.\n\n\nR0L~R15L are the lowermost 8 bits of each register. For example, R0L is AL.\n\n\n\n\nFor 128-bit registers, see \nSSE\n.\n\n\nStack\n\n\nThe stack is a Last In First Out (LIFO) data structure; data is pushed onto it and popped off of it in the reverse order.\n\n\nmov\n \nax\n,\n \n006Ah\n\n\nmov\n \nbx\n,\n \nF79Ah\n\n\nmov\n \ncx\n,\n \n1124h\n\n\n; Push the value in AX, BX, and CX onto the top of the stack\n\n\npush\n \nax\n\n\npush\n \nbx\n\n\npush\n \ncx\n\n\n\n\n\n\nNow the stack has $006A, $F79A, and $1124.\n\n\ncall\n \ndo_stuff\n\n\n\n\n\n\nDo some stuff. The function is not forced to save the registers it uses, hence us saving them.\n\n\npop\n \ncx\n \n;Pop the last element pushed onto the stack into CX, $1124; the stack now has $006A and $F79A.\n\n\npop\n \nbx\n \n;Pop the last element pushed onto the stack into BX, $F79A; the stack now has just $006A.\n\n\npop\n \nax\n \n;Pop the last element pushed onto the stack into AX, $006A; the stack is empty.\n\n\n\n\n\n\nThe stack has two common uses:\n\n\n\n\nPassing arguments to functions or procedures and also keeping track of control flow when the \ncall\n instruction is used.\n\n\nTemporarily saving registers.\n\n\n\n\nCPU Operation Modes\n\n\nCPU Operation Modes\n\n\nReal Mode\n\n\nReal Mode is a holdover from the original Intel 8086. The Intel 8086 accessed memory using 20-bit addresses. But, as the processor itself was 16-bit, Intel invented an addressing scheme that provided a way of mapping a 20-bit addressing space into 16-bit words. Today's x86 processors start in the so-called Real Mode, which is an operating mode that mimics the behavior of the 8086, with some very tiny differences, for backwards compatibility.\n\n\nProtected Mode\n\n\nFlat Memory Model\n\n\nIf programming in a modern operating system (such as Linux, Windows), you are basically programming in flat 32-bit mode. Any register can be used in addressing, and it is generally more efficient to use a full 32-bit register instead of a 16-bit register part. Additionally, segment registers are generally unused in flat mode, and it is generally a bad idea to touch them.\n\n\nMulti-Segmented Memory Model\n\n\nUsing a 32-bit register to address memory, the program can access (almost) all of the memory in a modern computer. For earlier processors (with only 16-bit registers) the segmented memory model was used. The 'CS', 'DS', and 'ES' registers are used to point to the different chunks of memory. For a small program (small model) the CS=DS=ES. For larger memory models, these 'segments' can point to different locations.\n\n\nComments\n\n\nWhen writing code, it is very helpful to use some comments explaining what is going on. A comment is a section of regular text that the assembler ignores when turning the assembly code into the machine code. In assembly comments are usually denoted with a semicolon \";\", although GAS uses \"#\" for single line comments and \"/\n ... \n/\" for multi-line comments.\n\n\nFor example:\n\n\nLabel1:\n\n   \nmov\n \nax\n,\n \nbx\n    \n;move contents of bx into ax\n\n   \nadd\n \nax\n,\n \nbx\n    \n;add the contents of bx into ax\n\n   \n...\n\n\n\n\n\n\n16 32 and 64 Bits\n\n\n16 32 and 64 Bits\n\n\nIntrinsic Data Types\n\n\nStrictly speaking, assembly has no predefined data types like higher-level programming languages. Any general purpose register can hold any sequence of two or four bytes, whether these bytes represent numbers, letters, or other data. In the same way, there are no concrete types assigned to blocks of memory; you can assign to them whatever value you like.\n\n\nThat said, one can group data in assembly into two categories: integer and floating point. While you could load a floating point value into a register and treat it like an integer, the results would be unexpected, so it is best to keep them separate.\n\n\nInteger\n\n\nAn integer represents a whole number, either positive or negative.\n\n\n\n\nUnder the 8086 architecture, it originally came in 8-bit and 16-bit sizes, which served the most basic operations.\n\n\nLater, starting with the 80386, the data bus was expanded to support 32-bit operations and thus allow operations on integers of that size.\n\n\nThe newest systems under the x86 architecture support 64-bit instructions; however, this requires a 64-bit operating system for optimal effect.\n\n\n\n\nSome assembly instructions behave slightly differently in regards to the sign bit; as such, there is a minor distinction between signed and unsigned integers.\n\n\nFloating Point Numbers\n\n\nFloating point numbers are used to approximate the \nreal numbers\n that usually contain digits before and after the decimal point (like \u03c0, 3.14159...). Unlike integers where the decimal point is understood to be after all digits, in floating point numbers the decimal point floats anywhere in the sequence of digits. The precision of floating point numbers is limited and thus a number like \u03c0 can only be represented approximately.\n\n\nOriginally, floating point was not part of the main processor, requiring the use of emulating software. However, there were floating point coprocessors that allowed operations on this data-type, and starting with the 486DX, were integrated directly with the CPU.\n\n\nAs such, floating point operations are not necessarily compatible with all processors. If you need to perform this type of arithmetic, you may want to use a software library as a backup code path.\n\n\nx86 Instructions\n\n\nConventions\n\n\n\n\nGAS Syntax\n\n\nMASM Syntax\n\n\n\n\nInstructions that take no operands:\n\n\n\n\nInstr\n\n\n\n\n\nInstructions that take 1 operand:\n\n\n\n\nInstr\n arg\n\n\n\n\nInstructions that take 2 operands. Notice how the format of the instruction is different for different assemblers.\n\n\n\n\nInstr\n src, dest    # \nGAS Syntax\n\n\nInstr\n dest, src    ; \nIntel syntax\n\n\n\n\n\nInstructions that take 3 operands. Notice how the format of the instruction is different for different assemblers.\n\n\n\n\nInstr\n aux, src, dest   # \nGAS Syntax\n\n\nInstr\n dest, src, aux   ; \nIntel syntax\n\n\n\n\n\nSuffixes\n\n\nOperation Suffixes\n\n\nSome instructions require the use of suffixes to specify the size of the data which will be the subject of the operation, such as:\n\n\n\n\nb (byte) = 8 bits\n\n\nw (word) = 16 bits\n\n\nl (long) = 32 bits\n\n\nq (quad) = 64 bits\n\n\n\n\nAn example of the usage with the \nmov\n instruction on a 32-bit architecture, GAS syntax:\n\n\nmovl\n \n$0x000F\n,\n \n%eax\n          \n# Store the value F into the eax register\n\n\n\n\n\n\nData Transfer Instructions\n\n\nMove: \nmov\n\n\nmov\n \nsrc\n,\n \ndest\n  \n# GAS Synatx\n\n\n\n\n\n\nmov\n \ndest\n,\n \nsrc\n  \n; Intel Syntax\n\n\n\n\n\n\nThe \nmov\n instruction copies the \nsrc\n operand into the \ndest\n operand.\n\n\nOperands\n\n\n\n\nsrc\n:\n\n\nImmediate\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\ndest\n:\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\n\n\nModified flags\n: No FLAGS are modified by this instruction.\n\n\nData swap: \nxchg\n and \ncmpxchg\n\n\nxchg\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nxchg\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nThe \nxchg\n instruction swaps the \nsrc\n operand with the dest operand. It's like doing three move operations: from dest to a temporary (another register), then from \nsrc\n to dest, then from the temporary to \nsrc\n, except that no register needs to be reserved for temporary storage.\n\n\nIf one of the operands is a memory address, then the operation has an implicit \nLOCK\n prefix, that is, the exchange operation is atomic. This can have a large performance penalty.\n\n\nIt's also worth noting that the common \nNOP\n (no op) instruction, \n0x90\n, is the opcode for \nxchgl %eax, %eax\n.\n\n\nOperands\n.\n\n\n\n\nsrc\n\n\nRegister\n\n\nMemory\n\n\n\n\n\n\ndest\n\n\nRegister\n\n\nMemory (only one operand can be in memory: the other must be a register)\n\n\n\n\n\n\n\n\nModified flags\n: No FLAGS are modified by this instruction.\n\n\ncmpxchg\n \narg2\n,\n \narg1\n\n\n\n\n\n\ncmpxchg\n \narg1\n,\n \narg2\n\n\n\n\n\n\nCompare and exchange.\n\n\nMove with zero extend\n\n\nmovz\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nmovzx\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nSign Extend\n\n\nmovs\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nmovsx\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nMove String\n\n\nmovsb\n\n\n\n\n\n\nmovsb\n: Move byte\n\n\nmovsw\n\n\n\n\n\n\nmovsw\n: Move word\n\n\nLoad Effective Address\n\n\nlea\n \nsrc\n,\n \ndest\n\n\n\n\n\n\nlea\n \ndest\n,\n \nsrc\n\n\n\n\n\n\nControl Flow Instructions\n\n\nAlmost all programming languages have the ability to change the order in which statements are evaluated, and assembly is no exception. The instruction pointer (EIP) register contains the address of the next instruction to be executed. To change the flow of control, the programmer must be able to modify the value of EIP. This is where control flow functions come in.\n\n\nComparison: \ntest\n and \ncmp\n\n\ntest\n \narg1\n,\n \narg2\n\n\n\n\n\n\ntest\n \narg2\n,\n \narg1\n\n\n\n\n\n\nPerforms a bit-wise logical AND on \narg1\n and \narg2\n the result of which we will refer to as Temp and sets the ZF (zero), SF (sign) and PF (parity) flags based on \nTemp\n. \nTemp\n is then discarded.\n\n\ncmp\n \narg2\n,\n \narg1\n\n\n\n\n\n\ncmp\n \narg1\n,\n \narg2\n\n\n\n\n\n\nJump Instructions\n\n\nUnconditional Jumps\n\n\njmp\n \nloc\n\n\n\n\n\n\nJump on Equality\n\n\nje\n \nloc\n\n\n\n\n\n\nJump on Inequality\n\n\njne\n \nloc\n\n\n\n\n\n\nJump if Greater\n\n\nJump if Less\n\n\nJump on Zero\n\n\nJump on Sign\n\n\nFunction Calls\n\n\ncall\n \nproc\n\n\n\n\n\n\nPushes the address of the next opcode onto the top of the stack, and jumps to the specified location. This is used mostly for subroutines.\n\n\nret\n \n[\nval\n]\n\n\n\n\n\n\nLoads the next value on the stack into EIP, and then pops the specified number of bytes off the stack. If \nval\n is not supplied, the instruction will not pop any values off the stack after returning.\n\n\nLoop Instructions\n\n\nloop\n \narg\n\n\n\n\n\n\nThe loop instruction decrements ECX and jumps to the address specified by arg unless decrementing ECX caused its value to become zero. For example:\n\n\nmov\n \necx\n,\n \n5\n\n\nstart_loop:\n\n\n; the code here would be executed 5 times\n\n\nloop\n \nstart_loop\n\n\n\n\n\n\nEnter and Leave\n\n\nenter\n \narg\n\n\n\n\n\n\nenter\n creates a stack frame with the specified amount of space allocated on the stack.\n\n\nleave\n\n\n\n\n\n\nleave\n destroys the current stack frame, and restores the previous frame. Using Intel syntax this is equivalent to:\n\n\nmov\n \nesp\n,\n \nebp\n\n\npop\n \nebp\n\n\n\n\n\n\nOther Control Instructions\n\n\nhlt\n\n\n\n\n\n\nHalts the processor. Execution will be resumed after processing next hardware interrupt, unless IF is cleared.\n\n\nnop\n\n\n\n\n\n\nNo operation. This instruction doesn't do anything, but wastes an instruction cycle in the processor. This instruction is often represented as an XCHG operation with the operands EAX and EAX.\n\n\nlock\n\n\n\n\n\n\nAsserts #LOCK prefix on next instruction.\n\n\nwait\n\n\n\n\n\n\nWaits for the FPU to finish its last calculation.\n\n\nArithmetic Instructions\n\n\nLogic Instructions\n\n\nShift and Rotate Instructions\n\n\nOther Instructions\n\n\nStack Instructions\n\n\npush\n \narg\n\n\n\n\n\n\nThis instruction decrements the stack pointer and stores the data specified as the argument into the location pointed to by the stack pointer.\n\n\npop\n \narg\n\n\n\n\n\n\nThis instruction loads the data stored in the location pointed to by the stack pointer into the argument specified and then increments the stack pointer.\n\n\nFlags instructions\n\n\nx86 Interrupts\n\n\nInterrupts are special routines that are defined on a per-system basis. This means that the interrupts on one system might be different from the interrupts on another system. Therefore, it is usually a bad idea to rely heavily on interrupts when you are writing code that needs to be portable.\n\n\nInterrupt Instruction\n\n\nint\n \narg\n\n\n\n\n\n\nThis instruction issues the specified interrupt. For instance:\n\n\nint\n \n0x0A\n\n\n\n\n\n\nCalls interrupt 10 (0x0A (hex) = 10 (decimal)).\n\n\nTypes of Interrupts\n\n\nThere are 3 types of interrupts: Hardware Interrupts, Software Interrupts and Exceptions.\n\n\nHardware Interrupts\n\n\nHardware interrupts are triggered by hardware devices. Hardware interrupts are typically asynchronous: their occurrence is unrelated to the instructions being executed at the time they are raised.\n\n\nSoftware Interrupts\n\n\nSoftware interrupts are usually used to transfer control to a function in the operating system kernel. Software interrupts are triggered by the instruction \nint\n. For example, the instruction \nint 14h\n triggers interrupt \n0x14\n. The processor then stops the current program, and jumps to the code to handle interrupt 14. When interrupt handling is complete, the processor returns flow to the original program.\n\n\nExceptions\n\n\nExceptions are caused by exceptional conditions in the code which is executing, for example an attempt to divide by zero or access a protected memory area. The processor will detect this problem, and transfer control to a handler to service the exception. This handler may re-execute the offending code after changing some value (for example, the zero dividend), or if this cannot be done, the program causing the exception may be terminated.\n\n\nx86 Assemblers\n\n\nGAS Syntax\n\n\nMASM Syntax\n\n\nInterfacing with Linux: System Calls\n\n\nInterfacing with Linux\n\n\nSyscalls\n\n\nSyscalls are the interface between user programs and the Linux kernel. They are used to let the kernel perform various system tasks, such as file access, process management and networking. In the C programming language, you would normally call a wrapper function which executes all required steps or even use high-level features such as the standard IO library.\n\n\nOn Linux, there are several ways to make a syscall. This page will focus on making syscalls by calling a software interrupt using \nint $0x80\n (x86 and x86_64) or \nsyscall\n (x86_64). This is an easy and intuitive method of making syscalls in assembly-only programs.\n\n\nMaking a syscalls\n\n\nTo make a syscall using an interrupt, you have to pass all required information to the kernel by copying them into general purpose registers. Each syscall has a fixed number (note the numbers differ between \nint $0x80\n and \nsyscall\n in the following text). You specify the syscall by writing the number into the \neax\n/\nrax\n register and pass the parameters by writing them in the appropriate registers before making the actual calls. Parameters are passed in the order they appear in the function signature of the corresponding C wrapper function.\n\n\nAfter everything is set up correctly, you call the interrupt using \nint $0x80\n or \nsyscall\n and the kernel performs the task.\n\n\nThe return or error value of a syscall is written to \neax\n or \nrax\n.\n\n\nThe kernel uses its own stack to perform the actions. The user stack is not touched in any way.\n\n\nint 0x80\n\n\nOn both Linux x86 and Linux x86_64 systems you can make a syscall by calling interrupt 0x80 using the \nint $0x80\n command. Parameters are passed by setting the general purpose registers as following:\n\n\n\n\n\n\n\n\nSyscall #\n\n\nParam 1\n\n\nParam 2\n\n\nParam 3\n\n\nParam 4\n\n\nParam 5\n\n\nParam 6\n\n\n\n\n\n\n\n\n\n\neax\n\n\nebx\n\n\necx\n\n\nedx\n\n\nesi\n\n\nedi\n\n\nebp\n\n\n\n\n\n\n\n\nThe return value is in the \neax\n register.\n\n\nThe syscall numbers are described in the Linux source file \narch/x86/include/asm/unistd_32.h\n.\n\n\nAll registers are preserved during the syscall.\n\n\nsyscall\n\n\nThe x86_64 architecture introduced a dedicated instruction to make a syscall. It does not access the interrupt descriptor table and is faster. Parameters are passed by setting the general purpose registers as following:\n\n\nThe syscall numbers are described in the Linux source file \narch/x86/include/asm/unistd_64.h\n.\n\n\n\n\n\n\n\n\nSyscall #\n\n\nParam 1\n\n\nParam 2\n\n\nParam 3\n\n\nParam 4\n\n\nParam 5\n\n\nParam 6\n\n\n\n\n\n\n\n\n\n\nrax\n\n\nrdi\n\n\nrsi\n\n\nrdx\n\n\nrcx\n\n\nr8\n\n\nr9\n\n\n\n\n\n\n\n\nThe return value is in the \nrax\n register.\n\n\nAll registers, except \nrcx\n and \nr11\n, are preserved during the syscall.\n\n\nHello World example\n\n\nThis example will write the text \"Hello World\" to stdout using the \nwrite\n syscall and quit the program using the \n_exit\n syscall.\n\n\nSyscall signatures:\n\n\nssize_t\n \nwrite\n(\nint\n \nfd\n,\n \nconst\n \nvoid\n \n*\nbuf\n,\n \nsize_t\n \ncount\n);\n\n\nvoid\n \n_exit\n(\nint\n \nstatus\n);\n\n\n\n\n\n\nThe following is the C program of this example:\n\n\n#include \nunistd.h\n\n\n\nint\n \nmain\n(\nint\n \nargc\n,\n \nchar\n \n*\nargv\n[])\n\n\n{\n\n    \nwrite\n(\n1\n,\n \nHello World\n\\n\n,\n \n12\n);\n \n/* write \nHello World\n to stdout */\n\n    \n_exit\n(\n0\n);\n                      \n/* exit with error code 0 (no error) */\n\n\n}\n\n\n\n\n\n\nBoth of the assembly examples start alike: a string stored in the data segment and \n_start\n as a global symbol.\n\n\n.data\n\n\nmsg:\n \n.ascii\n \nHello World\\n\n\n\n\n.text\n\n\n.global\n \n_start\n\n\n\n\n\n\nint 0x80\n\n\nAs defined in \narch/x86/include/asm/unistd_32.h\n, the syscall numbers for \nwrite\n and \n_exit\n are:\n\n\n#define __NR_exit 1\n\n\n#define __NR_write 4\n\n\n\n\n\n\nThe parameters are passed exactly as one would in a C program, using the correct registers. After everything is set up, the syscall is made using \nint $0x80\n.\n\n\n_start:\n\n    \nmovl\n \n$4\n,\n \n%eax\n   \n# use the write syscall\n\n    \nmovl\n \n$1\n,\n \n%ebx\n   \n# write to stdout\n\n    \nmovl\n \n$msg\n,\n \n%ecx\n \n# use string \nHello World\n\n    \nmovl\n \n$12\n,\n \n%edx\n  \n# write 12 characters\n\n    \nint\n \n$0x80\n       \n# make syscall\n\n\n    \nmovl\n \n$1\n,\n \n%eax\n   \n# use the _exit syscall\n\n    \nmovl\n \n$0\n,\n \n%ebx\n   \n# error code 0\n\n    \nint\n \n$0x80\n       \n# make syscall\n\n\n\n\n\n\nsyscall\n\n\nIn \narch/x86/include/asm/unistd_64.h\n, the syscall numbers are defined as following:\n\n\n#define __NR_write 1\n\n\n#define __NR_exit 60\n\n\n\n\n\n\nParameters are passed just like in the \nint $0x80\n example, except that the order of the registers is different. The syscall is made using \nsyscall\n.\n\n\n_start:\n\n    \nmovq\n \n$1\n,\n \n%rax\n   \n# use the write syscall\n\n    \nmovq\n \n$1\n,\n \n%rdi\n   \n# write to stdout\n\n    \nmovq\n \n$msg\n,\n \n%rsi\n \n# use string \nHello World\n\n    \nmovq\n \n$12\n,\n \n%rdx\n  \n# write 12 characters\n\n    \nsyscall\n         \n# make syscall\n\n\n    \nmovq\n \n$60\n,\n \n%rax\n  \n# use the _exit syscall\n\n    \nmovq\n \n$0\n,\n \n%rdi\n   \n# error code 0\n\n    \nsyscall\n         \n# make syscall\n\n\n\n\n\n\n\n\nReferences\n\n\n\n\nx86 Assembly\n: \nX86 Assembly/Print Version\n\n\nx86 assembly language", 
            "title": "x86 assembly"
        }, 
        {
            "location": "/iptables/", 
            "text": "iptables\n\n\n\n\nReferences\n\n\n\n\n[ITT]: \nIptables Tutorial 1.2.2", 
            "title": "iptables"
        }, 
        {
            "location": "/nginx/", 
            "text": "Nginx\n\n\n\n\nReferences\n\n\n\n\n[ND]: \nnginx documentation\n\n\n[NTAG]: \nNGINX and NGINX Plus Tutorial and Admin Guide", 
            "title": "Nginx"
        }, 
        {
            "location": "/vim/", 
            "text": "Vim\n\n\n\n\nReferences\n\n\n\n\n[LVVE]: Learning the vi and Vim Editors, 7th Edition\n\n\n[LVHW]: \nLearn Vimscript the Hard Way", 
            "title": "Vim"
        }
    ]
}